# 26 - AIåŸºç¡€è®¾æ–½æˆæœ¬ä¼˜åŒ–æ¦‚è§ˆ

> **é€‚ç”¨ç‰ˆæœ¬**: Kubernetes v1.25 - v1.32 | **AIæ ˆç‰ˆæœ¬**: vLLM 0.4+ | **æœ€åæ›´æ–°**: 2026-02 | **è´¨é‡ç­‰çº§**: ä¸“å®¶çº§

## ä¸€ã€AIåŸºç¡€è®¾æ–½æˆæœ¬å…¨æ™¯åˆ†æ

### 1.1 æˆæœ¬æ„æˆæ·±åº¦å‰–æ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI Infrastructure Cost Breakdown                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  ğŸ§  GPUè®¡ç®—æˆæœ¬ (50-70%)                                               â”‚
â”‚  â”œâ”€ GPUå®ä¾‹ç§Ÿèµ: $2.5-8/å°æ—¶/A100                                       â”‚
â”‚  â”œâ”€ GPUæ˜¾å­˜å ç”¨: æ¨¡å‹å¤§å°ç›´æ¥å½±å“æˆæœ¬                                   â”‚
â”‚  â”œâ”€ GPUç©ºé—²æŸè€—: æœªå……åˆ†åˆ©ç”¨çš„è®¡ç®—èµ„æº                                   â”‚
â”‚  â””â”€ GPUæ•…éšœæˆæœ¬: ç¡¬ä»¶æŸåå’Œç»´ä¿®                                         â”‚
â”‚                                                                         â”‚
â”‚  ğŸ’¾ å­˜å‚¨æˆæœ¬ (15-25%)                                                  â”‚
â”‚  â”œâ”€ æ¨¡å‹å­˜å‚¨: å¤§æ¨¡å‹å‚æ•°æ–‡ä»¶ (æ•°åGB-TB)                               â”‚
â”‚  â”œâ”€ æ•°æ®é›†å­˜å‚¨: è®­ç»ƒæ•°æ®ã€ç¼“å­˜æ•°æ®                                     â”‚
â”‚  â”œâ”€ Checkpointå­˜å‚¨: è®­ç»ƒä¸­é—´çŠ¶æ€ä¿å­˜                                   â”‚
â”‚  â””â”€ æ—¥å¿—å­˜å‚¨: ç›‘æ§ã€å®¡è®¡æ—¥å¿—                                           â”‚
â”‚                                                                         â”‚
â”‚  ğŸŒ ç½‘ç»œæˆæœ¬ (5-15%)                                                   â”‚
â”‚  â”œâ”€ æ•°æ®ä¼ è¾“: è·¨åŒºåŸŸã€è·¨äº‘ä¼ è¾“                                         â”‚
â”‚  â”œâ”€ APIè°ƒç”¨: æ¨¡å‹æœåŠ¡APIè¯·æ±‚                                           â”‚
â”‚  â”œâ”€ CDNåˆ†å‘: æ¨¡å‹æ–‡ä»¶åˆ†å‘                                              â”‚
â”‚  â””â”€ å¸¦å®½å³°å€¼: æ¨ç†æœåŠ¡é«˜å³°æœŸ                                           â”‚
â”‚                                                                         â”‚
â”‚  âš™ï¸ è¿ç»´æˆæœ¬ (10-20%)                                                  â”‚
â”‚  â”œâ”€ äººåŠ›æˆæœ¬: AIå·¥ç¨‹å¸ˆã€è¿ç»´å·¥ç¨‹å¸ˆ                                     â”‚
â”‚  â”œâ”€ å·¥å…·æˆæœ¬: ç›‘æ§ã€åˆ†æå·¥å…·è®¸å¯                                       â”‚
â”‚  â”œâ”€ åŸ¹è®­æˆæœ¬: å›¢é˜ŸæŠ€èƒ½æå‡                                             â”‚
â”‚  â””â”€ æœºä¼šæˆæœ¬: èµ„æºåˆ†é…å†³ç­–                                             â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 AIå·¥ä½œè´Ÿè½½æˆæœ¬ç‰¹å¾çŸ©é˜µ

| å·¥ä½œè´Ÿè½½ç±»å‹ | GPUéœ€æ±‚ | å­˜å‚¨éœ€æ±‚ | ç½‘ç»œéœ€æ±‚ | æˆæœ¬ç‰¹ç‚¹ | ä¼˜åŒ–é‡ç‚¹ |
|-------------|---------|---------|---------|---------|---------|
| **æ¨¡å‹è®­ç»ƒ** | é«˜(å¤šå¡) | é«˜(æ•°æ®é›†) | ä¸­(æ•°æ®åŠ è½½) | æ—¶é—´æˆæœ¬é«˜ | æ‰¹å¤„ç†ä¼˜åŒ–ã€Spotå®ä¾‹ |
| **æ¨¡å‹æ¨ç†** | ä¸­(å•å¡) | ä½(æ¨¡å‹æ–‡ä»¶) | é«˜(APIè°ƒç”¨) | å®æ—¶æ€§è¦æ±‚ | ç¼“å­˜ã€æ‰¹å¤„ç†ã€é‡åŒ– |
| **æ•°æ®å¤„ç†** | ä½(CPU) | æé«˜(åŸå§‹æ•°æ®) | ä¸­(ETL) | å­˜å‚¨æˆæœ¬é«˜ | å­˜å‚¨åˆ†å±‚ã€å‹ç¼© |
| **å®éªŒç®¡ç†** | ä½ | ä¸­(æ—¥å¿—) | ä½ | è¿ç»´æˆæœ¬é«˜ | è‡ªåŠ¨åŒ–ã€æ ‡å‡†åŒ– |

## äºŒã€ä¼ä¸šçº§æˆæœ¬ä¼˜åŒ–æ¡†æ¶

### 2.1 æˆæœ¬ä¼˜åŒ–äº”ç»´æ¨¡å‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Enterprise Cost Optimization Framework               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  ğŸ¯ æˆ˜ç•¥å±‚ (Strategic)                                                 â”‚
â”‚  â”œâ”€ æˆæœ¬æ²»ç†æ”¿ç­–åˆ¶å®š                                                   â”‚
â”‚  â”œâ”€ é¢„ç®—åˆ†é…å’Œå®¡æ‰¹æµç¨‹                                                 â”‚
â”‚  â”œâ”€ ROIè¯„ä¼°å’ŒæŠ•èµ„å›æŠ¥åˆ†æ                                              â”‚
â”‚  â””â”€ é•¿æœŸæˆæœ¬è§„åˆ’                                                       â”‚
â”‚                                                                         â”‚
â”‚  ğŸ—ï¸ æ¶æ„å±‚ (Architectural)                                             â”‚
â”‚  â”œâ”€ èµ„æºæ± åŒ–å’Œå…±äº«                                                     â”‚
â”‚  â”œâ”€ æ··åˆäº‘å’Œå¤šäº‘ç­–ç•¥                                                   â”‚
â”‚  â”œâ”€ æœåŠ¡åŒ–å’ŒAPIåŒ–                                                      â”‚
â”‚  â””â”€ æ ‡å‡†åŒ–å’Œæ¨¡å—åŒ–                                                     â”‚
â”‚                                                                         â”‚
â”‚  âš™ï¸ è¿è¥å±‚ (Operational)                                               â”‚
â”‚  â”œâ”€ è‡ªåŠ¨åŒ–è°ƒåº¦å’Œæ‰©ç¼©å®¹                                                 â”‚
â”‚  â”œâ”€ èµ„æºç›‘æ§å’Œå‘Šè­¦                                                     â”‚
â”‚  â”œâ”€ æˆæœ¬åˆ†æ‘Šå’Œè®¡é‡                                                     â”‚
â”‚  â””â”€ æ€§èƒ½ä¼˜åŒ–å’Œè°ƒä¼˜                                                     â”‚
â”‚                                                                         â”‚
â”‚  ğŸ“Š åˆ†æå±‚ (Analytical)                                                â”‚
â”‚  â”œâ”€ æˆæœ¬æ•°æ®æ”¶é›†å’Œå¤„ç†                                                 â”‚
â”‚  â”œâ”€ æˆæœ¬æ´å¯Ÿå’Œå¯è§†åŒ–                                                   â”‚
â”‚  â”œâ”€ å¼‚å¸¸æ£€æµ‹å’Œæ ¹å› åˆ†æ                                                 â”‚
â”‚  â””â”€ é¢„æµ‹åˆ†æå’Œå®¹é‡è§„åˆ’                                                 â”‚
â”‚                                                                         â”‚
â”‚  ğŸ›¡ï¸ æ²»ç†å±‚ (Governance)                                               â”‚
â”‚  â”œâ”€ æˆæœ¬åˆè§„å’Œå®¡è®¡                                                     â”‚
â”‚  â”œâ”€ ç­–ç•¥æ‰§è¡Œå’Œæ§åˆ¶                                                     â”‚
â”‚  â”œâ”€ é£é™©ç®¡ç†å’Œæ§åˆ¶                                                     â”‚
â”‚  â””â”€ æŒç»­æ”¹è¿›å’Œä¼˜åŒ–                                                     â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æˆæœ¬ä¼˜åŒ–æŠ€æœ¯æ ˆå…¨æ™¯å›¾

| æŠ€æœ¯é¢†åŸŸ | æ ¸å¿ƒå·¥å…· | ä¸»è¦åŠŸèƒ½ | é›†æˆæ–¹å¼ | æˆæœ¬æ•ˆç›Š |
|---------|---------|---------|---------|---------|
| **èµ„æºè°ƒåº¦** | Kubernetes CA/HPA | è‡ªåŠ¨æ‰©ç¼©å®¹ | åŸç”Ÿé›†æˆ | 20-40% |
| **GPUä¼˜åŒ–** | vLLM/TGI | æ¨ç†ä¼˜åŒ– | æ¨¡å‹æœåŠ¡ | 30-60% |
| **æˆæœ¬ç›‘æ§** | Kubecost/OpenCost | æˆæœ¬åˆ†æ | Prometheus | å¯è§æ€§ |
| **å­˜å‚¨ä¼˜åŒ–** | JuiceFS/Alluxio | åˆ†å¸ƒå¼ç¼“å­˜ | CSIæ’ä»¶ | 20-50% |
| **ç½‘ç»œä¼˜åŒ–** | Cilium/eBPF | ç½‘ç»œåŠ é€Ÿ | CNIæ’ä»¶ | 10-30% |
| **è‡ªåŠ¨åŒ–** | Argo Workflows | æµæ°´çº¿ä¼˜åŒ– | CRD | æ•ˆç‡æå‡ |

## ä¸‰ã€GPUæˆæœ¬æ·±åº¦ä¼˜åŒ–

### 3.1 GPUå®ä¾‹é€‰å‹ç­–ç•¥

```yaml
# GPUå®ä¾‹æˆæœ¬å¯¹æ¯”çŸ©é˜µ
apiVersion: v1
kind: ConfigMap
metadata:
  name: gpu-instance-cost-matrix
  namespace: cost-optimization
data:
  instance-comparison.yaml: |
    # æŒ‰æ€§ä»·æ¯”æ’åº (æˆæœ¬/æ€§èƒ½æ¯”)
    instances:
      - name: "g5.2xlarge"  # A10G
        hourly_cost: 1.204
        gpu_memory: 24GB
        performance_score: 85  # ç›¸å¯¹åˆ†æ•°
        cost_performance_ratio: 0.014  # è¶Šä½è¶Šå¥½
        use_cases: ["æ¨ç†æœåŠ¡", "å°è§„æ¨¡è®­ç»ƒ"]
      
      - name: "p4d.24xlarge"  # A100 40GB
        hourly_cost: 32.7726
        gpu_memory: 40GB
        performance_score: 100
        cost_performance_ratio: 0.328
        use_cases: ["å¤§è§„æ¨¡è®­ç»ƒ", "å¤æ‚æ¨ç†"]
      
      - name: "g6.2xlarge"  # L4
        hourly_cost: 0.800
        gpu_memory: 24GB
        performance_score: 70
        cost_performance_ratio: 0.011
        use_cases: ["æˆæœ¬æ•æ„Ÿæ¨ç†", "å¼€å‘æµ‹è¯•"]
      
      - name: "trn1.32xlarge"  # Trainium
        hourly_cost: 6.200
        gpu_memory: 512GB
        performance_score: 120
        cost_performance_ratio: 0.052
        use_cases: ["è¶…å¤§è§„æ¨¡è®­ç»ƒ", "é¢„è®­ç»ƒ"]
    
    # æˆæœ¬ä¼˜åŒ–å»ºè®®
    recommendations:
      - workload: "LLMæ¨ç†"
        instance: "g5.2xlarge"
        batch_size: 32
        expected_cost: "$0.05/request"
        savings_vs_on_demand: "60% (Spot)"
      
      - workload: "å¤§è§„æ¨¡è®­ç»ƒ"
        instance: "p4d.24xlarge"
        multi_node: true
        spot_ratio: "70%"
        expected_cost: "$500/epoch"
        savings_vs_dedicated: "40%"
```

### 3.2 GPUèµ„æºåˆ©ç”¨ç‡ä¼˜åŒ–

```python
# gpu-utilization-optimizer.py
import asyncio
import kubernetes_asyncio
from kubernetes_asyncio import client, config
import prometheus_api_client as prom
from typing import Dict, List, Tuple
import logging

class GPUResourceOptimizer:
    def __init__(self):
        self.v1 = None
        self.prom_client = None
        self.logger = logging.getLogger(__name__)
        
    async def initialize(self):
        """åˆå§‹åŒ–K8så®¢æˆ·ç«¯å’ŒPrometheuså®¢æˆ·ç«¯"""
        await config.load_kube_config()
        self.v1 = client.CoreV1Api()
        self.prom_client = prom.PrometheusConnect(
            url='http://prometheus-server:9090',
            disable_ssl=True
        )
        
    async def get_gpu_utilization_metrics(self) -> Dict[str, float]:
        """è·å–GPUåˆ©ç”¨ç‡æŒ‡æ ‡"""
        try:
            # æŸ¥è¯¢GPUåˆ©ç”¨ç‡
            query = 'avg(nvidia_gpu_utilization) by (instance, gpu)'
            result = self.prom_client.custom_query(query)
            
            utilization_map = {}
            for item in result:
                instance = item['metric']['instance']
                gpu_id = item['metric']['gpu']
                utilization = float(item['value'][1])
                utilization_map[f"{instance}-{gpu_id}"] = utilization
                
            return utilization_map
        except Exception as e:
            self.logger.error(f"Failed to get GPU metrics: {e}")
            return {}
    
    async def optimize_pod_placement(self, namespace: str = "ai-models") -> List[str]:
        """ä¼˜åŒ–Podæ”¾ç½®ç­–ç•¥"""
        # è·å–æ‰€æœ‰GPU Pod
        pods = await self.v1.list_namespaced_pod(
            namespace=namespace,
            label_selector="nvidia.com/gpu in (1)"
        )
        
        recommendations = []
        for pod in pods.items:
            # è·å–Podçš„GPUä½¿ç”¨æƒ…å†µ
            pod_name = pod.metadata.name
            container_status = pod.status.container_statuses[0] if pod.status.container_statuses else None
            
            if container_status and container_status.state.running:
                # åˆ†æå®¹å™¨èµ„æºä½¿ç”¨
                requests = container_status.resources.requests or {}
                limits = container_status.resources.limits or {}
                
                # åŸºäºä½¿ç”¨æ¨¡å¼ä¼˜åŒ–å»ºè®®
                if 'nvidia.com/gpu' in requests:
                    gpu_count = int(requests['nvidia.com/gpu'])
                    if gpu_count > 1:
                        recommendations.append(
                            f"Pod {pod_name}: è€ƒè™‘æ‹†åˆ†ä¸ºå•GPU Podä»¥æé«˜èµ„æºåˆ©ç”¨ç‡"
                        )
                    
        return recommendations
    
    async def implement_batching_strategy(self, service_name: str) -> Dict:
        """å®ç°è¯·æ±‚æ‰¹å¤„ç†ä¼˜åŒ–"""
        # åŠ¨æ€è°ƒæ•´æ‰¹å¤„ç†å¤§å°
        current_qps = await self.get_current_qps(service_name)
        
        if current_qps < 10:
            batch_size = 1
            timeout_ms = 100
        elif current_qps < 100:
            batch_size = 4
            timeout_ms = 200
        else:
            batch_size = 16
            timeout_ms = 500
            
        return {
            "batch_size": batch_size,
            "timeout_ms": timeout_ms,
            "estimated_cost_savings": f"{30 * (1 - batch_size/16)}%"
        }
    
    async def get_current_qps(self, service_name: str) -> float:
        """è·å–æœåŠ¡å½“å‰QPS"""
        try:
            query = f'sum(rate(http_requests_total{{service="{service_name}"}}[5m]))'
            result = self.prom_client.custom_query(query)
            return float(result[0]['value'][1]) if result else 0.0
        except Exception:
            return 0.0

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    optimizer = GPUResourceOptimizer()
    await optimizer.initialize()
    
    # æ‰§è¡Œä¼˜åŒ–
    gpu_metrics = await optimizer.get_gpu_utilization_metrics()
    placement_recs = await optimizer.optimize_pod_placement()
    batching_config = await optimizer.implement_batching_strategy("llm-inference")
    
    print(f"GPU Utilization: {gpu_metrics}")
    print(f"Placement Recommendations: {placement_recs}")
    print(f"Batching Configuration: {batching_config}")

if __name__ == "__main__":
    asyncio.run(main())
```

### 3.3 GPUæˆæœ¬ç›‘æ§ä»ªè¡¨æ¿

```yaml
# gpu-cost-dashboard.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: gpu-cost-monitoring-dashboard
  namespace: monitoring
data:
  dashboard.json: |
    {
      "dashboard": {
        "title": "AI GPU Cost Optimization Dashboard",
        "panels": [
          {
            "title": "å®æ—¶GPUæˆæœ¬åˆ†æ",
            "type": "graph",
            "targets": [
              {
                "expr": "sum(node_gpu_hourly_cost) by (instance_type)",
                "legendFormat": "{{instance_type}}"
              },
              {
                "expr": "sum(node_gpu_utilization) / count(node_gpu_count) * 100",
                "legendFormat": "å¹³å‡åˆ©ç”¨ç‡ %"
              }
            ],
            "description": "æ˜¾ç¤ºä¸åŒGPUå®ä¾‹çš„æˆæœ¬å’Œåˆ©ç”¨ç‡"
          },
          {
            "title": "æˆæœ¬èŠ‚çœæœºä¼š",
            "type": "stat",
            "targets": [
              {
                "expr": "sum(node_gpu_hourly_cost * (1 - node_gpu_utilization/100))",
                "legendFormat": "æ½œåœ¨èŠ‚çœ $/å°æ—¶"
              }
            ],
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 100},
                {"color": "red", "value": 500}
              ]
            }
          },
          {
            "title": "GPUå®ä¾‹ç±»å‹æˆæœ¬å¯¹æ¯”",
            "type": "table",
            "targets": [
              {
                "expr": "avg by(instance_type) (node_gpu_hourly_cost)",
                "legendFormat": "æ¯å°æ—¶æˆæœ¬"
              },
              {
                "expr": "avg by(instance_type) (node_gpu_utilization)",
                "legendFormat": "å¹³å‡åˆ©ç”¨ç‡ %"
              },
              {
                "expr": "avg by(instance_type) (node_gpu_count)",
                "legendFormat": "å®ä¾‹æ•°é‡"
              }
            ]
          },
          {
            "title": "æ¨¡å‹æœåŠ¡æˆæœ¬æ˜ç»†",
            "type": "graph",
            "targets": [
              {
                "expr": "sum(increase(model_requests_total[1h])) by (model_name)",
                "legendFormat": "è¯·æ±‚æ•° {{model_name}}"
              },
              {
                "expr": "sum(model_request_cost_usd[1h]) by (model_name)",
                "legendFormat": "æˆæœ¬ $ {{model_name}}"
              }
            ]
          }
        ]
      }
    }
```

## å››ã€æ™ºèƒ½æˆæœ¬é¢„æµ‹ä¸è§„åˆ’

## èµ„æºå³ç½®å¤§å°(Right-sizing)

| é—®é¢˜ | æ£€æµ‹æ–¹æ³• | ä¼˜åŒ–å»ºè®® | å·¥å…· |
|-----|---------|---------|------|
| **è¿‡åº¦é…ç½®** | å®é™…ä½¿ç”¨<50%è¯·æ±‚ | é™ä½requests | VPA/Kubecost |
| **é…ç½®ä¸è¶³** | é¢‘ç¹OOM/CPUèŠ‚æµ | å¢åŠ limits | ç›‘æ§å‘Šè­¦ |
| **æœªè®¾é™åˆ¶** | QoSä¸ºBestEffort | è®¾ç½®requests/limits | LimitRange |
| **é—²ç½®èµ„æº** | ä½¿ç”¨ç‡é•¿æœŸ<10% | ç¼©å®¹æˆ–åˆ é™¤ | Kubecost |

```yaml
# VPAæ¨èé…ç½®
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: myapp-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  updatePolicy:
    updateMode: "Off"  # ä»…æ¨èï¼Œä¸è‡ªåŠ¨æ›´æ–°
  resourcePolicy:
    containerPolicies:
    - containerName: "*"
      controlledResources: ["cpu", "memory"]
```

## èŠ‚ç‚¹æ± ä¼˜åŒ–

| ç­–ç•¥ | æè¿° | èŠ‚çœæ¯”ä¾‹ | é£é™© | é€‚ç”¨åœºæ™¯ |
|-----|------|---------|------|---------|
| **Spot/æŠ¢å å®ä¾‹** | ä½¿ç”¨ç«ä»·å®ä¾‹ | 50-90% | å¯èƒ½è¢«å›æ”¶ | æ— çŠ¶æ€/å¯ä¸­æ–­ä»»åŠ¡ |
| **é¢„ç•™å®ä¾‹** | æå‰è´­ä¹°æŠ˜æ‰£ | 30-60% | é¢„ä»˜æ¬¾ | ç¨³å®šåŸºçº¿è´Ÿè½½ |
| **èŠ‚çœè®¡åˆ’** | æ‰¿è¯ºä½¿ç”¨é‡æŠ˜æ‰£ | 20-50% | æ‰¿è¯º | å¯é¢„æµ‹è´Ÿè½½ |
| **æ··åˆèŠ‚ç‚¹æ± ** | æŒ‰éœ€+Spotç»„åˆ | 30-50% | ä¸­ç­‰ | ç”Ÿäº§ç¯å¢ƒ |
| **è‡ªåŠ¨æ‰©ç¼©å®¹** | æŒ‰éœ€æ‰©ç¼© | 20-40% | æ‰©å®¹å»¶è¿Ÿ | å¼¹æ€§è´Ÿè½½ |

```yaml
# ACK SpotèŠ‚ç‚¹æ± é…ç½®
apiVersion: v1
kind: NodePool
metadata:
  name: spot-pool
spec:
  nodeConfig:
    instanceTypes:
    - ecs.c6.xlarge
    - ecs.c6.2xlarge
    spotStrategy: SpotWithPriceLimit
    spotPriceLimit: 0.5  # æœ€é«˜å‡ºä»·
  scaling:
    minSize: 0
    maxSize: 100
    desiredSize: 5
  taints:
  - key: spot
    value: "true"
    effect: NoSchedule
```

## Cluster Autoscalerä¼˜åŒ–

| å‚æ•° | ä¼˜åŒ–å€¼ | æ•ˆæœ |
|-----|-------|------|
| **scale-down-utilization-threshold** | 0.5 | åˆ©ç”¨ç‡<50%è§¦å‘ç¼©å®¹ |
| **scale-down-unneeded-time** | 10m | ç©ºé—²10åˆ†é’Ÿåç¼©å®¹ |
| **scale-down-delay-after-add** | 10m | æ‰©å®¹å10åˆ†é’Ÿå†…ä¸ç¼©å®¹ |
| **expander** | least-waste | é€‰æ‹©æµªè´¹æœ€å°‘çš„èŠ‚ç‚¹ç»„ |
| **skip-nodes-with-local-storage** | false | å…è®¸ç¼©å®¹å¸¦æœ¬åœ°å­˜å‚¨èŠ‚ç‚¹ |

## å­˜å‚¨æˆæœ¬ä¼˜åŒ–

| ç­–ç•¥ | æè¿° | èŠ‚çœæ¯”ä¾‹ | å®ç°æ–¹å¼ |
|-----|------|---------|---------|
| **å­˜å‚¨åˆ†å±‚** | å†·çƒ­æ•°æ®åˆ†ç¦» | 30-50% | å¤šStorageClass |
| **å¿«ç…§ç”Ÿå‘½å‘¨æœŸ** | è‡ªåŠ¨åˆ é™¤æ—§å¿«ç…§ | 20-40% | å¿«ç…§ç­–ç•¥ |
| **PVCå›æ”¶** | æ¸…ç†æœªä½¿ç”¨PVC | å˜åŒ– | å®šæœŸå®¡è®¡ |
| **å‹ç¼©/å»é‡** | å­˜å‚¨ä¼˜åŒ– | 20-40% | å­˜å‚¨ç³»ç»Ÿé…ç½® |

```yaml
# å­˜å‚¨åˆ†å±‚StorageClass
# é«˜æ€§èƒ½å±‚
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: high-performance
provisioner: diskplugin.csi.alibabacloud.com
parameters:
  type: cloud_essd
  performanceLevel: PL2
---
# æ ‡å‡†å±‚
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: standard
provisioner: diskplugin.csi.alibabacloud.com
parameters:
  type: cloud_essd
  performanceLevel: PL0
---
# å½’æ¡£å±‚
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: archive
provisioner: diskplugin.csi.alibabacloud.com
parameters:
  type: cloud_efficiency
```

## ç½‘ç»œæˆæœ¬ä¼˜åŒ–

| ç­–ç•¥ | æè¿° | å®ç°æ–¹å¼ |
|-----|------|---------|
| **åŒåŒºéƒ¨ç½²** | å‡å°‘è·¨AZæµé‡ | æ‹“æ‰‘çº¦æŸ |
| **æœ¬åœ°DNSç¼“å­˜** | å‡å°‘DNSæŸ¥è¯¢ | NodeLocal DNSCache |
| **æœåŠ¡ç½‘æ ¼ä¼˜åŒ–** | å‡å°‘Sidecarå¼€é”€ | eBPFæ¨¡å¼ |
| **å‹ç¼©ä¼ è¾“** | å‡å°‘æ•°æ®é‡ | gzip/brotli |
| **CDN** | ç¼“å­˜é™æ€å†…å®¹ | äº‘CDN |

```yaml
# åŒåŒºæ‹“æ‰‘çº¦æŸ
apiVersion: apps/v1
kind: Deployment
spec:
  template:
    spec:
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: ScheduleAnyway
        labelSelector:
          matchLabels:
            app: myapp
```

## æˆæœ¬ç›‘æ§å·¥å…·

| å·¥å…· | åŠŸèƒ½ | éƒ¨ç½²æ–¹å¼ | æˆæœ¬ |
|-----|------|---------|------|
| **Kubecost** | å…¨é¢æˆæœ¬åˆ†æ | Helm | å¼€æº/å•†ä¸š |
| **OpenCost** | CNCFæˆæœ¬ç›‘æ§ | Helm | å¼€æº |
| **äº‘å‚å•†æˆæœ¬å·¥å…·** | äº‘è´¦å•åˆ†æ | åŸç”Ÿ | å…è´¹ |
| **Prometheus+Grafana** | è‡ªå®šä¹‰æŒ‡æ ‡ | Helm | å¼€æº |

```bash
# Kubecostå®‰è£…
helm repo add kubecost https://kubecost.github.io/cost-analyzer/
helm install kubecost kubecost/cost-analyzer \
  --namespace kubecost \
  --create-namespace \
  --set prometheus.server.persistentVolume.enabled=false
```

## æˆæœ¬åˆ†é…æ ‡ç­¾

```yaml
# æˆæœ¬åˆ†é…æ ‡ç­¾è§„èŒƒ
metadata:
  labels:
    # ä¸šåŠ¡æ ‡ç­¾
    app.kubernetes.io/name: myapp
    app.kubernetes.io/component: frontend
    # æˆæœ¬æ ‡ç­¾
    cost-center: "engineering"
    team: "platform"
    environment: "production"
    project: "project-a"
```

## æˆæœ¬ä¼˜åŒ–æ¸…å•

| ä¼˜åŒ–é¡¹ | æ½œåœ¨èŠ‚çœ | å®æ–½éš¾åº¦ | ä¼˜å…ˆçº§ |
|-------|---------|---------|-------|
| **å¯ç”¨è‡ªåŠ¨æ‰©ç¼©å®¹** | 20-40% | ä½ | P0 |
| **ä½¿ç”¨Spotå®ä¾‹** | 50-90% | ä¸­ | P0 |
| **èµ„æºå³ç½®å¤§å°** | 20-30% | ä½ | P0 |
| **æ¸…ç†é—²ç½®èµ„æº** | å˜åŒ– | ä½ | P1 |
| **å­˜å‚¨åˆ†å±‚** | 30-50% | ä¸­ | P1 |
| **é¢„ç•™å®ä¾‹/èŠ‚çœè®¡åˆ’** | 30-60% | ä½ | P1 |
| **ç½‘ç»œä¼˜åŒ–** | 10-20% | ä¸­ | P2 |

## ACKæˆæœ¬ä¼˜åŒ–

| åŠŸèƒ½ | é…ç½®æ–¹å¼ | æ•ˆæœ |
|-----|---------|------|
| **SpotèŠ‚ç‚¹æ± ** | èŠ‚ç‚¹æ± é…ç½® | è®¡ç®—æˆæœ¬é™ä½ |
| **å¼¹æ€§ä¼¸ç¼©** | ESSé›†æˆ | æŒ‰éœ€ä»˜è´¹ |
| **é¢„ç•™å®ä¾‹åˆ¸** | è´­ä¹° | é•¿æœŸæŠ˜æ‰£ |
| **èŠ‚çœè®¡åˆ’** | è´­ä¹° | æ‰¿è¯ºæŠ˜æ‰£ |
| **èµ„æºç”»åƒ** | ARMS | æ¨èé…ç½® |

---

**æˆæœ¬åŸåˆ™**: ç›‘æ§å…ˆè¡Œï¼Œå³ç½®å¤§å°ï¼Œå¼¹æ€§ä¼˜å…ˆï¼ŒæŒç»­ä¼˜åŒ–

---

**è¡¨æ ¼åº•éƒ¨æ ‡è®°**: Kusheet Project, ä½œè€… Allen Galler (allengaller@gmail.com)