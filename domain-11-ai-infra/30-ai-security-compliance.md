# AIå¹³å°å®‰å…¨åŠ å›ºä¸åˆè§„

> **é€‚ç”¨ç‰ˆæœ¬**: Kubernetes v1.25 - v1.32 | **æœ€åæ›´æ–°**: 2026-02 | **å‚è€ƒ**: [NIST AI RMF](https://csrc.nist.gov/publications/detail/white-paper/2023/03/01/artificial-intelligence-risk-management-framework-ai-rmf-10/final) | [OWASP LLM Top 10](https://owasp.org/www-project-top-10-for-large-language-model-applications/)

## ä¸€ã€AIå¹³å°å®‰å…¨æ¶æ„

### 1.1 åˆ†å±‚å®‰å…¨é˜²æŠ¤ä½“ç³»

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          AI Platform Security Architecture                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                            è®¿é—®æ§åˆ¶å±‚ (Access Control)                         â”‚  â”‚
â”‚  â”‚                                                                               â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â”‚  â”‚   IAM       â”‚  â”‚   RBAC      â”‚  â”‚   ABAC      â”‚  â”‚   mTLS      â”‚          â”‚  â”‚
â”‚  â”‚  â”‚  (Identity) â”‚  â”‚ (Kubernetes)â”‚  â”‚ (Attribute) â”‚  â”‚ (Transport) â”‚          â”‚  â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ ç”¨æˆ·è®¤è¯   â”‚  â”‚ â€¢ æƒé™æ§åˆ¶   â”‚  â”‚ â€¢ å±æ€§ç­–ç•¥   â”‚  â”‚ â€¢ æœåŠ¡é—´åŠ å¯† â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ å¤šå› å­     â”‚  â”‚ â€¢ è§’è‰²åˆ†ç¦»   â”‚  â”‚ â€¢ åŠ¨æ€æˆæƒ   â”‚  â”‚ â€¢ è¯ä¹¦è½®æ¢   â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ SSOé›†æˆ    â”‚  â”‚ â€¢ æœ€å°æƒé™   â”‚  â”‚ â€¢ ä¸Šä¸‹æ–‡æ„ŸçŸ¥ â”‚  â”‚ â€¢ åŒå‘è®¤è¯   â”‚          â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â”‚                                                                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                       â”‚                                             â”‚
â”‚                                       â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                          æ•°æ®ä¿æŠ¤å±‚ (Data Protection)                         â”‚  â”‚
â”‚  â”‚                                                                               â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â”‚  â”‚   Encryptionâ”‚  â”‚   Masking   â”‚  â”‚   Auditing  â”‚  â”‚   Retention â”‚          â”‚  â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ é™æ€åŠ å¯†   â”‚  â”‚ â€¢ æ•°æ®è„±æ•   â”‚  â”‚ â€¢ æ“ä½œå®¡è®¡   â”‚  â”‚ â€¢ ç”Ÿå‘½å‘¨æœŸ   â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ ä¼ è¾“åŠ å¯†   â”‚  â”‚ â€¢ PIIä¿æŠ¤    â”‚  â”‚ â€¢ å˜æ›´è¿½è¸ª   â”‚  â”‚ â€¢ è‡ªåŠ¨æ¸…ç†   â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ å¯†é’¥ç®¡ç†   â”‚  â”‚ â€¢ TokenåŒ–    â”‚  â”‚ â€¢ åˆè§„æŠ¥å‘Š   â”‚  â”‚ â€¢ å½’æ¡£ç­–ç•¥   â”‚          â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â”‚                                                                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                       â”‚                                             â”‚
â”‚                                       â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                          æ¨¡å‹å®‰å…¨éƒ¨ (Model Security)                          â”‚  â”‚
â”‚  â”‚                                                                               â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â”‚  â”‚   Integrity â”‚  â”‚   Privacy   â”‚  â”‚   Fairness  â”‚  â”‚   Robustnessâ”‚          â”‚  â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ æ¨¡å‹ç­¾å   â”‚  â”‚ â€¢ å·®åˆ†éšç§   â”‚  â”‚ â€¢ åè§æ£€æµ‹   â”‚  â”‚ â€¢ å¯¹æŠ—æ”»å‡»   â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ ç‰ˆæœ¬æ§åˆ¶   â”‚  â”‚ â€¢ è”é‚¦å­¦ä¹    â”‚  â”‚ â€¢ å…¬å¹³æ€§æµ‹è¯• â”‚  â”‚ â€¢ è¾“å…¥éªŒè¯   â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ è¡€ç¼˜è¿½è¸ª   â”‚  â”‚ â€¢ åŒæ€åŠ å¯†   â”‚  â”‚ â€¢ åŒ…å®¹æ€§å®¡æŸ¥ â”‚  â”‚ â€¢ å¼‚å¸¸æ£€æµ‹   â”‚          â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â”‚                                                                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                       â”‚                                             â”‚
â”‚                                       â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                          å¨èƒé˜²æŠ¤å±‚ (Threat Protection)                       â”‚  â”‚
â”‚  â”‚                                                                               â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â”‚  â”‚   Runtime   â”‚  â”‚   Network   â”‚  â”‚   Container â”‚  â”‚   Supply    â”‚          â”‚  â”‚
â”‚  â”‚  â”‚   Security  â”‚  â”‚   Security  â”‚  â”‚   Security  â”‚  â”‚   Chain     â”‚          â”‚  â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ è¿è¡Œæ—¶é˜²æŠ¤ â”‚  â”‚ â€¢ ç½‘ç»œç­–ç•¥   â”‚  â”‚ â€¢ é•œåƒæ‰«æ   â”‚  â”‚ â€¢ ä¾èµ–æ£€æŸ¥   â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ æ¶æ„è¡Œä¸ºæ£€æµ‹â”‚  â”‚ â€¢ é›¶ä¿¡ä»»ç½‘ç»œ â”‚  â”‚ â€¢ æ¼æ´æ‰«æ   â”‚  â”‚ â€¢ SBOMç”Ÿæˆ   â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ è¿›ç¨‹ç›‘æ§   â”‚  â”‚ â€¢ æµé‡åŠ å¯†   â”‚  â”‚ â€¢ åŸºçº¿æ£€æŸ¥   â”‚  â”‚ â€¢ è®¸å¯è¯åˆè§„ â”‚          â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â”‚                                                                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 å®‰å…¨æ§åˆ¶çŸ©é˜µ

| å®‰å…¨é¢†åŸŸ | æ§åˆ¶æªæ–½ | å®æ–½ç»„ä»¶ | åˆè§„è¦æ±‚ | é‡è¦ç¨‹åº¦ |
|----------|----------|----------|----------|----------|
| **èº«ä»½è®¤è¯** | å¤šå› å­è®¤è¯ã€SSOé›†æˆ | Keycloakã€LDAP | GDPRã€SOC2 | â­â­â­â­â­ |
| **è®¿é—®æ§åˆ¶** | RBACã€ABACã€ç½‘ç»œç­–ç•¥ | Kubernetes RBACã€OPA | HIPAAã€ISO27001 | â­â­â­â­â­ |
| **æ•°æ®åŠ å¯†** | é™æ€åŠ å¯†ã€ä¼ è¾“åŠ å¯† | Vaultã€cert-manager | PCI-DSSã€GDPR | â­â­â­â­â­ |
| **æ¨¡å‹å®‰å…¨** | æ¨¡å‹ç­¾åã€å·®åˆ†éšç§ | Sigstoreã€OpenDP | AI Actã€NIST AI RMF | â­â­â­â­ |
| **å¨èƒæ£€æµ‹** | è¿è¡Œæ—¶é˜²æŠ¤ã€å¼‚å¸¸æ£€æµ‹ | Falcoã€Sysdig | NIST CSF | â­â­â­â­ |
| **åˆè§„å®¡è®¡** | æ“ä½œå®¡è®¡ã€åˆè§„æŠ¥å‘Š | Auditbeatã€ELK | SOXã€FINRA | â­â­â­ |

---

## äºŒã€èº«ä»½è®¤è¯ä¸è®¿é—®æ§åˆ¶

### 2.1 ä¼ä¸šçº§IAMé›†æˆ

```yaml
# keycloak-ai-platform.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: ai-security
---
# Keycloakéƒ¨ç½²
apiVersion: apps/v1
kind: Deployment
metadata:
  name: keycloak
  namespace: ai-security
spec:
  replicas: 3
  selector:
    matchLabels:
      app: keycloak
  template:
    metadata:
      labels:
        app: keycloak
    spec:
      containers:
      - name: keycloak
        image: quay.io/keycloak/keycloak:22.0.1
        args: ["start", "--optimized"]
        env:
        - name: KEYCLOAK_ADMIN
          value: "admin"
        - name: KEYCLOAK_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: keycloak-admin-credentials
              key: password
        - name: KC_DB
          value: "postgres"
        - name: KC_DB_URL
          value: "jdbc:postgresql://postgres-keycloak:5432/keycloak"
        - name: KC_DB_USERNAME
          valueFrom:
            secretKeyRef:
              name: postgres-keycloak-credentials
              key: username
        - name: KC_DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-keycloak-credentials
              key: password
        - name: KC_HOSTNAME
          value: "keycloak.ai-platform.local"
        - name: KC_HTTP_ENABLED
          value: "true"
        - name: KC_PROXY
          value: "edge"
        ports:
        - name: http
          containerPort: 8080
        - name: https
          containerPort: 8443
        readinessProbe:
          httpGet:
            path: /realms/master
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
          limits:
            cpu: "1"
            memory: "2Gi"
---
# AIå¹³å°Realmé…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: keycloak-ai-realm
  namespace: ai-security
data:
  ai-platform-realm.json: |
    {
      "id": "ai-platform",
      "realm": "ai-platform",
      "displayName": "AI Platform Realm",
      "enabled": true,
      "sslRequired": "external",
      "registrationAllowed": false,
      "loginWithEmailAllowed": true,
      "duplicateEmailsAllowed": false,
      "resetPasswordAllowed": true,
      "editUsernameAllowed": false,
      "roles": {
        "realm": [
          {
            "name": "ai-admin",
            "description": "AIå¹³å°ç®¡ç†å‘˜"
          },
          {
            "name": "ai-developer",
            "description": "AIå¼€å‘äººå‘˜"
          },
          {
            "name": "ai-ml-engineer",
            "description": "æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ"
          },
          {
            "name": "ai-data-scientist",
            "description": "æ•°æ®ç§‘å­¦å®¶"
          },
          {
            "name": "ai-auditor",
            "description": "AIå®¡è®¡å‘˜"
          }
        ]
      },
      "groups": [
        {
          "name": "ai-platform-admins",
          "path": "/ai-platform-admins",
          "attributes": {},
          "realmRoles": ["ai-admin"],
          "clientRoles": {}
        },
        {
          "name": "ml-teams",
          "path": "/ml-teams",
          "subGroups": [
            {
              "name": "research-team",
              "realmRoles": ["ai-ml-engineer", "ai-data-scientist"]
            },
            {
              "name": "production-team",
              "realmRoles": ["ai-developer"]
            }
          ]
        }
      ],
      "clients": [
        {
          "clientId": "kubernetes",
          "name": "Kubernetes API Server",
          "description": "K8s API Server OIDC Client",
          "enabled": true,
          "clientAuthenticatorType": "client-secret",
          "redirectUris": ["https://kubernetes.default.svc.cluster.local/*"],
          "webOrigins": [],
          "protocol": "openid-connect",
          "attributes": {
            "saml.assertion.signature": "false",
            "saml.force.post.binding": "false",
            "saml.multivalued.roles": "false",
            "saml.encrypt": "false",
            "oauth2.device.authorization.grant.enabled": "false",
            "backchannel.logout.revoke.offline.tokens": "false",
            "use.refresh.tokens": "true",
            "oidc.ciba.grant.enabled": "false",
            "backchannel.logout.session.required": "true",
            "client_credentials.use_refresh_token": "false",
            "acr.loa.map": "{}",
            "require.pushed.authorization.requests": "false",
            "tls.client.certificate.bound.access.tokens": "false",
            "display.on.consent.screen": "false",
            "token.response.type.bearer.lower-case": "false"
          }
        }
      ]
    }
```

### 2.2 Kubernetes RBACç²¾ç»†åŒ–é…ç½®

```yaml
# ai-platform-rbac.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: ai-platform
  labels:
    name: ai-platform
---
# æ ¸å¿ƒè§’è‰²å®šä¹‰
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: ai-model-operator
  namespace: ai-platform
rules:
# æ¨¡å‹éƒ¨ç½²æƒé™
- apiGroups: ["serving.kserve.io"]
  resources: ["inferenceservices", "trainedmodels"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
  
# é…ç½®ç®¡ç†æƒé™
- apiGroups: [""]
  resources: ["configmaps", "secrets"]
  verbs: ["get", "list", "watch", "create", "update", "patch"]
  
# ç›‘æ§æŸ¥çœ‹æƒé™
- apiGroups: [""]
  resources: ["pods", "services", "endpoints"]
  verbs: ["get", "list", "watch"]
  
# æ—¥å¿—æŸ¥çœ‹æƒé™
- apiGroups: [""]
  resources: ["pods/log"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: ai-security-auditor
  namespace: ai-platform
rules:
# åªè¯»æƒé™
- apiGroups: ["*"]
  resources: ["*"]
  verbs: ["get", "list", "watch"]
  
# å®¡è®¡æ—¥å¿—è®¿é—®
- apiGroups: [""]
  resources: ["events"]
  verbs: ["get", "list", "watch"]
  
# å®‰å…¨æ—¥å¿—æŸ¥çœ‹
- apiGroups: ["security.istio.io"]
  resources: ["authorizationpolicies"]
  verbs: ["get", "list", "watch"]
---
# è§’è‰²ç»‘å®š
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: ml-engineers-binding
  namespace: ai-platform
subjects:
- kind: Group
  name: oidc:ai-platform:ml-teams
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: ai-model-operator
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: security-auditors-binding
  namespace: ai-platform
subjects:
- kind: Group
  name: oidc:ai-platform:ai-auditor
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: ai-security-auditor
  apiGroup: rbac.authorization.k8s.io
```

---

## ä¸‰ã€æ•°æ®ä¿æŠ¤ä¸éšç§

### 3.1 æ•°æ®åŠ å¯†é…ç½®

```yaml
# vault-ai-encryption.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: ai-security
---
# HashiCorp Vaultéƒ¨ç½²
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: vault
  namespace: ai-security
spec:
  serviceName: vault
  replicas: 3
  selector:
    matchLabels:
      app: vault
  template:
    metadata:
      labels:
        app: vault
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - vault
            topologyKey: kubernetes.io/hostname
      containers:
      - name: vault
        image: hashicorp/vault:1.14.0
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
          capabilities:
            add: ["IPC_LOCK"]
        ports:
        - containerPort: 8200
          name: api
        - containerPort: 8201
          name: cluster
        env:
        - name: VAULT_ADDR
          value: "https://127.0.0.1:8200"
        - name: VAULT_API_ADDR
          value: "https://vault.ai-security.svc.cluster.local:8200"
        - name: VAULT_CLUSTER_ADDR
          value: "https://$(POD_IP):8201"
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        command:
        - vault
        - server
        - -config=/vault/config/vault-config.hcl
        volumeMounts:
        - name: vault-config
          mountPath: /vault/config
        - name: vault-storage
          mountPath: /vault/data
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - vault status
          initialDelaySeconds: 60
          periodSeconds: 5
        readinessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - vault status
          initialDelaySeconds: 30
          periodSeconds: 5
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
          limits:
            cpu: "1"
            memory: "2Gi"
  volumeClaimTemplates:
  - metadata:
      name: vault-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 10Gi
---
# Vaulté…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: vault-config
  namespace: ai-security
data:
  vault-config.hcl: |
    ui = true
    
    listener "tcp" {
      address = "[::]:8200"
      tls_cert_file = "/vault/certs/tls.crt"
      tls_key_file = "/vault/certs/tls.key"
      tls_disable = false
    }
    
    storage "raft" {
      path = "/vault/data"
      node_id = "node-${POD_INDEX}"
    }
    
    seal "awskms" {
      region     = "us-west-2"
      kms_key_id = "alias/vault-unseal-key"
    }
    
    api_addr = "https://vault.ai-security.svc.cluster.local:8200"
    cluster_addr = "https://$(POD_IP):8201"
    disable_mlock = true
```

### 3.2 å·®åˆ†éšç§å®æ–½

```python
# differential_privacy.py
import numpy as np
from opendp.accuracy import laplacian_scale_to_accuracy
from opendp.mod import enable_features
from opendp.typing import L1Distance, VectorDomain, AllDomain

enable_features("floating-point", "contrib")

class DifferentialPrivacyEngine:
    def __init__(self, epsilon: float = 1.0, delta: float = 1e-5):
        """
        å·®åˆ†éšç§å¼•æ“
        
        Args:
            epsilon: éšç§é¢„ç®—
            delta: Î´å€¼ï¼ˆé€šå¸¸å¾ˆå°ï¼‰
        """
        self.epsilon = epsilon
        self.delta = delta
        
    def add_laplace_noise(self, data: np.ndarray, sensitivity: float) -> np.ndarray:
        """æ·»åŠ æ‹‰æ™®æ‹‰æ–¯å™ªå£°"""
        scale = sensitivity / self.epsilon
        noise = np.random.laplace(0, scale, data.shape)
        return data + noise
        
    def add_gaussian_noise(self, data: np.ndarray, sensitivity: float) -> np.ndarray:
        """æ·»åŠ é«˜æ–¯å™ªå£°ï¼ˆé€‚ç”¨äºÎµ,Î´-DPï¼‰"""
        # è®¡ç®—é«˜æ–¯å™ªå£°çš„æ ‡å‡†å·®
        sigma = sensitivity * np.sqrt(2 * np.log(1.25 / self.delta)) / self.epsilon
        noise = np.random.normal(0, sigma, data.shape)
        return data + noise
        
    def private_mean(self, data: np.ndarray, bounds: tuple) -> float:
        """è®¡ç®—æ»¡è¶³å·®åˆ†éšç§çš„å‡å€¼"""
        # è£å‰ªæ•°æ®åˆ°æŒ‡å®šèŒƒå›´
        clipped_data = np.clip(data, bounds[0], bounds[1])
        
        # è®¡ç®—æ•æ„Ÿåº¦ï¼ˆå¯¹äºå‡å€¼æŸ¥è¯¢ï¼‰
        sensitivity = (bounds[1] - bounds[0]) / len(data)
        
        # æ·»åŠ å™ªå£°
        true_mean = np.mean(clipped_data)
        private_mean = self.add_laplace_noise(np.array([true_mean]), sensitivity)[0]
        
        return float(private_mean)
        
    def private_histogram(self, data: np.ndarray, bins: int, range_vals: tuple) -> np.ndarray:
        """è®¡ç®—æ»¡è¶³å·®åˆ†éšç§çš„ç›´æ–¹å›¾"""
        # è®¡ç®—çœŸå®ç›´æ–¹å›¾
        hist, bin_edges = np.histogram(data, bins=bins, range=range_vals)
        
        # æ•æ„Ÿåº¦ä¸º1ï¼ˆæ¯ä¸ªä¸ªä½“æœ€å¤šå½±å“ä¸€ä¸ªæ¡¶ï¼‰
        sensitivity = 1.0
        
        # æ·»åŠ å™ªå£°åˆ°æ¯ä¸ªæ¡¶
        private_hist = self.add_laplace_noise(hist.astype(float), sensitivity)
        
        # ç¡®ä¿éè´Ÿ
        private_hist = np.maximum(private_hist, 0)
        
        return private_hist

# AIæ¨¡å‹è®­ç»ƒä¸­çš„å·®åˆ†éšç§åº”ç”¨
class PrivateAITraining:
    def __init__(self, privacy_engine: DifferentialPrivacyEngine):
        self.privacy_engine = privacy_engine
        
    def train_with_dp_sgd(self, model, dataloader, optimizer, epochs: int):
        """ä½¿ç”¨å·®åˆ†éšç§SGDè®­ç»ƒæ¨¡å‹"""
        for epoch in range(epochs):
            epoch_loss = 0.0
            for batch_idx, (data, target) in enumerate(dataloader):
                # å‰å‘ä¼ æ’­
                output = model(data)
                loss = self.compute_loss(output, target)
                
                # è®¡ç®—æ¢¯åº¦
                optimizer.zero_grad()
                loss.backward()
                
                # æ·»åŠ æ¢¯åº¦å™ªå£°ï¼ˆå®ç°DP-SGDï¼‰
                self._add_gradient_noise(optimizer)
                
                # æ¢¯åº¦è£å‰ª
                self._clip_gradients(optimizer)
                
                # æ›´æ–°å‚æ•°
                optimizer.step()
                
                epoch_loss += loss.item()
                
            print(f"Epoch {epoch+1}, Average Loss: {epoch_loss/len(dataloader)}")
            
    def _add_gradient_noise(self, optimizer):
        """å‘æ¢¯åº¦æ·»åŠ å™ªå£°"""
        for param_group in optimizer.param_groups:
            for param in param_group['params']:
                if param.grad is not None:
                    # è®¡ç®—L2æ•æ„Ÿåº¦
                    sensitivity = 1.0  # å‡è®¾å·²è¿›è¡Œæ¢¯åº¦è£å‰ª
                    noise = self.privacy_engine.add_gaussian_noise(
                        param.grad.data.cpu().numpy(), 
                        sensitivity
                    )
                    param.grad.data += torch.from_numpy(noise).to(param.device)
                    
    def _clip_gradients(self, optimizer, max_norm: float = 1.0):
        """æ¢¯åº¦è£å‰ª"""
        torch.nn.utils.clip_grad_norm_(optimizer.param_groups[0]['params'], max_norm)

# ä½¿ç”¨ç¤ºä¾‹
dp_engine = DifferentialPrivacyEngine(epsilon=0.1, delta=1e-5)
private_trainer = PrivateAITraining(dp_engine)

# è®­ç»ƒæ¨¡å‹ï¼ˆæ»¡è¶³å·®åˆ†éšç§ï¼‰
private_trainer.train_with_dp_sgd(model, train_loader, optimizer, epochs=10)

# å‘å¸ƒç»Ÿè®¡ä¿¡æ¯æ—¶ä¿æŠ¤éšç§
sensitive_data = np.array([85, 92, 78, 96, 88, 73, 91, 87])
dp_mean = dp_engine.private_mean(sensitive_data, bounds=(0, 100))
print(f"å·®åˆ†éšç§ä¿æŠ¤çš„å¹³å‡åˆ†: {dp_mean}")
```

---

## å››ã€æ¨¡å‹å®‰å…¨é˜²æŠ¤

### 4.1 æ¨¡å‹å®Œæ•´æ€§ä¿æŠ¤

```yaml
# model-integrity-protection.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: model-security
---
# Sigstore Cosignéƒ¨ç½²
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cosign-server
  namespace: model-security
spec:
  replicas: 2
  selector:
    matchLabels:
      app: cosign
  template:
    metadata:
      labels:
        app: cosign
    spec:
      containers:
      - name: cosign
        image: gcr.io/projectsigstore/cosign:v2.0.0
        ports:
        - containerPort: 8080
        env:
        - name: COSIGN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: cosign-password
              key: password
        - name: COSIGN_PRIVATE_KEY
          valueFrom:
            secretKeyRef:
              name: cosign-private-key
              key: private-key
        volumeMounts:
        - name: keys-volume
          mountPath: /keys
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "200m"
            memory: "256Mi"
      volumes:
      - name: keys-volume
        secret:
          secretName: cosign-keys
---
# æ¨¡å‹ç­¾åç­–ç•¥
apiVersion: policy.sigstore.dev/v1beta1
kind: ClusterImagePolicy
metadata:
  name: ai-model-policy
spec:
  images:
  - glob: "registry.ai-platform.local/models/**"
  authorities:
  - key:
      kms: "gcpkms://projects/my-project/locations/global/keyRings/my-keyring/cryptoKeys/my-key"
    attestations:
    - name: model-integrity
      predicateType: "https://cosign.sigstore.dev/attestation/v1"
      policy:
        type: cue
        data: |
          predicateType: "https://cosign.sigstore.dev/attestation/v1"
          predicate: {
            model_hash: string
            training_data_hash: string
            timestamp: string
            signature: string
          }
```

### 4.2 å¯¹æŠ—æ ·æœ¬æ£€æµ‹

```python
# adversarial_detection.py
import torch
import torch.nn as nn
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler

class AdversarialDetector:
    def __init__(self, model, detector_type: str = "statistical"):
        self.model = model
        self.detector_type = detector_type
        self.scaler = StandardScaler()
        self.detector = None
        
    def fit_statistical_detector(self, clean_inputs, labels):
        """è®­ç»ƒç»Ÿè®¡å¼‚å¸¸æ£€æµ‹å™¨"""
        # æå–ç‰¹å¾ï¼ˆæ¿€æ´»å€¼ã€æ¢¯åº¦ç­‰ï¼‰
        features = self._extract_features(clean_inputs, labels)
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        normalized_features = self.scaler.fit_transform(features)
        
        # è®­ç»ƒå­¤ç«‹æ£®æ—æ£€æµ‹å™¨
        self.detector = IsolationForest(
            contamination=0.1,  # é¢„æœŸå¼‚å¸¸æ¯”ä¾‹
            random_state=42
        )
        self.detector.fit(normalized_features)
        
    def _extract_features(self, inputs, labels):
        """æå–è¾“å…¥æ ·æœ¬çš„ç‰¹å¾"""
        features = []
        
        with torch.no_grad():
            for input_batch, label_batch in zip(inputs, labels):
                input_tensor = torch.tensor(input_batch, dtype=torch.float32)
                label_tensor = torch.tensor(label_batch)
                
                # å‰å‘ä¼ æ’­è·å–ä¸­é—´å±‚æ¿€æ´»
                activations = []
                hooks = []
                
                def hook_fn(module, input, output):
                    activations.append(output.flatten())
                
                # æ³¨å†Œé’©å­åˆ°å…³é”®å±‚
                for name, module in self.model.named_modules():
                    if isinstance(module, (nn.Linear, nn.Conv2d)):
                        hook = module.register_forward_hook(hook_fn)
                        hooks.append(hook)
                
                # æ‰§è¡Œå‰å‘ä¼ æ’­
                output = self.model(input_tensor.unsqueeze(0))
                
                # ç§»é™¤é’©å­
                for hook in hooks:
                    hook.remove()
                
                # ç»„åˆç‰¹å¾
                sample_features = torch.cat(activations).numpy()
                features.append(sample_features)
                
        return np.array(features)
        
    def detect_adversarial(self, inputs):
        """æ£€æµ‹å¯¹æŠ—æ ·æœ¬"""
        if self.detector is None:
            raise ValueError("Detector not trained yet")
            
        # æå–ç‰¹å¾
        features = self._extract_features(inputs, None)
        normalized_features = self.scaler.transform(features)
        
        # æ£€æµ‹å¼‚å¸¸
        anomaly_scores = self.detector.decision_function(normalized_features)
        predictions = self.detector.predict(normalized_features)
        
        # è¿”å›ç»“æœ (-1è¡¨ç¤ºå¼‚å¸¸ï¼Œ1è¡¨ç¤ºæ­£å¸¸)
        return {
            'is_adversarial': predictions == -1,
            'anomaly_scores': anomaly_scores,
            'confidence': np.abs(anomaly_scores)
        }

class InputValidation:
    def __init__(self, input_shape, validation_rules=None):
        self.input_shape = input_shape
        self.validation_rules = validation_rules or self._default_rules()
        
    def _default_rules(self):
        """é»˜è®¤éªŒè¯è§„åˆ™"""
        return {
            'min_value': -10.0,
            'max_value': 10.0,
            'max_l2_norm': 5.0,
            'allowed_perturbation': 0.1
        }
        
    def validate_input(self, input_tensor, reference_tensor=None):
        """éªŒè¯è¾“å…¥çš„æœ‰æ•ˆæ€§"""
        results = {}
        
        # åŸºæœ¬èŒƒå›´æ£€æŸ¥
        min_val = torch.min(input_tensor).item()
        max_val = torch.max(input_tensor).item()
        results['range_check'] = (
            min_val >= self.validation_rules['min_value'] and
            max_val <= self.validation_rules['max_value']
        )
        
        # L2èŒƒæ•°æ£€æŸ¥
        l2_norm = torch.norm(input_tensor).item()
        results['norm_check'] = l2_norm <= self.validation_rules['max_l2_norm']
        
        # å¦‚æœæä¾›äº†å‚è€ƒè¾“å…¥ï¼Œæ£€æŸ¥æ‰°åŠ¨å¤§å°
        if reference_tensor is not None:
            perturbation = torch.norm(input_tensor - reference_tensor).item()
            results['perturbation_check'] = (
                perturbation <= self.validation_rules['allowed_perturbation']
            )
        else:
            results['perturbation_check'] = True
            
        # ç»¼åˆéªŒè¯ç»“æœ
        results['is_valid'] = all(results.values())
        
        return results

# å¯¹æŠ—è®­ç»ƒé˜²å¾¡
class AdversarialTraining:
    def __init__(self, model, epsilon: float = 0.03):
        self.model = model
        self.epsilon = epsilon
        
    def pgd_attack(self, images, labels, num_steps=10):
        """æŠ•å½±æ¢¯åº¦ä¸‹é™æ”»å‡»"""
        images = images.clone().detach()
        images.requires_grad = True
        
        # PGDè¿­ä»£
        for _ in range(num_steps):
            outputs = self.model(images)
            loss = nn.CrossEntropyLoss()(outputs, labels)
            
            # è®¡ç®—æ¢¯åº¦
            grad = torch.autograd.grad(loss, images, retain_graph=False, create_graph=False)[0]
            
            # æ›´æ–°å›¾åƒ
            images = images.detach() + self.epsilon * grad.sign()
            
            # æŠ•å½±åˆ°epsilonçƒå†…
            delta = torch.clamp(images - images, min=-self.epsilon, max=self.epsilon)
            images = torch.clamp(images + delta, min=0, max=1).detach()
            images.requires_grad = True
            
        return images.detach()
        
    def train_with_adversarial_examples(self, train_loader, optimizer, epochs: int):
        """ä½¿ç”¨å¯¹æŠ—æ ·æœ¬è¿›è¡Œè®­ç»ƒ"""
        self.model.train()
        
        for epoch in range(epochs):
            total_loss = 0
            correct = 0
            total = 0
            
            for batch_idx, (data, target) in enumerate(train_loader):
                data, target = data.cuda(), target.cuda()
                
                # ç”Ÿæˆå¯¹æŠ—æ ·æœ¬
                adv_data = self.pgd_attack(data, target)
                
                # æ­£å¸¸å’Œå¯¹æŠ—æ ·æœ¬æ··åˆè®­ç»ƒ
                combined_data = torch.cat([data, adv_data], dim=0)
                combined_target = torch.cat([target, target], dim=0)
                
                # å‰å‘ä¼ æ’­
                outputs = self.model(combined_data)
                loss = nn.CrossEntropyLoss()(outputs, combined_target)
                
                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
                _, predicted = outputs.max(1)
                total += combined_target.size(0)
                correct += predicted.eq(combined_target).sum().item()
                
            accuracy = 100. * correct / total
            print(f'Epoch {epoch+1}: Loss={total_loss/len(train_loader):.4f}, Accuracy={accuracy:.2f}%')

# ä½¿ç”¨ç¤ºä¾‹
# 1. è®­ç»ƒå¯¹æŠ—æ£€æµ‹å™¨
detector = AdversarialDetector(model)
detector.fit_statistical_detector(clean_training_data, labels)

# 2. éªŒè¯è¾“å…¥
validator = InputValidation(input_shape=(3, 224, 224))
validation_result = validator.validate_input(test_input, clean_input)

# 3. å¯¹æŠ—è®­ç»ƒ
adv_trainer = AdversarialTraining(model, epsilon=0.03)
adv_trainer.train_with_adversarial_examples(train_loader, optimizer, epochs=20)

# 4. åœ¨çº¿æ£€æµ‹
detection_result = detector.detect_adversarial(suspicious_input)
if detection_result['is_adversarial']:
    print("æ£€æµ‹åˆ°å¯¹æŠ—æ ·æœ¬ï¼")
    # æ‹’ç»æœåŠ¡æˆ–é‡‡å–å…¶ä»–æªæ–½
```

---

## äº”ã€åˆè§„å®¡è®¡ä¸ç›‘æ§

### 5.1 å®¡è®¡æ—¥å¿—é…ç½®

```yaml
# audit-logging.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: ai-audit
---
# Auditbeatéƒ¨ç½²
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: auditbeat
  namespace: ai-audit
spec:
  selector:
    matchLabels:
      app: auditbeat
  template:
    metadata:
      labels:
        app: auditbeat
    spec:
      hostPID: true
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: auditbeat
        image: docker.elastic.co/beats/auditbeat:8.11.0
        securityContext:
          runAsUser: 0
          capabilities:
            add:
            - AUDIT_CONTROL
            - AUDIT_READ
        volumeMounts:
        - name: config
          mountPath: /usr/share/auditbeat/auditbeat.yml
          readOnly: true
          subPath: auditbeat.yml
        - name: data
          mountPath: /usr/share/auditbeat/data
        - name: auditd-socket
          mountPath: /var/run/audit
        env:
        - name: ELASTICSEARCH_HOST
          value: "https://elasticsearch.ai-audit.svc.cluster.local:9200"
        - name: ELASTICSEARCH_USERNAME
          valueFrom:
            secretKeyRef:
              name: elasticsearch-credentials
              key: username
        - name: ELASTICSEARCH_PASSWORD
          valueFrom:
            secretKeyRef:
              name: elasticsearch-credentials
              key: password
        resources:
          requests:
            cpu: "100m"
            memory: "200Mi"
          limits:
            cpu: "200m"
            memory: "400Mi"
      volumes:
      - name: config
        configMap:
          name: auditbeat-config
      - name: data
        hostPath:
          path: /var/lib/auditbeat
          type: DirectoryOrCreate
      - name: auditd-socket
        hostPath:
          path: /var/run/audit
          type: Directory
---
# Auditbeaté…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: auditbeat-config
  namespace: ai-audit
data:
  auditbeat.yml: |
    auditbeat.modules:
    - module: auditd
      audit_rules: |
        # AIæ¨¡å‹æ–‡ä»¶è®¿é—®ç›‘æ§
        -w /models -p rwxa -k model_access
        -w /training-data -p rwxa -k data_access
        -w /model-registry -p rwxa -k registry_access
        
        # æ•æ„Ÿé…ç½®æ–‡ä»¶ç›‘æ§
        -w /etc/kubernetes -p rwxa -k k8s_config
        -w /var/lib/kubelet -p rwxa -k kubelet_data
        
        # ç”¨æˆ·æƒé™å˜æ›´ç›‘æ§
        -a always,exit -F arch=b64 -S chmod -F auid>=1000 -F auid!=4294967295 -k perm_mod
        -a always,exit -F arch=b64 -S chown -F auid>=1000 -F auid!=4294967295 -k perm_mod
        
        # ç½‘ç»œè¿æ¥ç›‘æ§
        -a always,exit -F arch=b64 -S connect -F auid>=1000 -F auid!=4294967295 -k network
        
    - module: file_integrity
      paths:
      - /models
      - /training-data
      - /model-registry
      scan_at_start: true
      scan_rate_per_sec: 50 MiB
      max_file_size: 100 MiB
      hash_types: [sha256]
      recursive: true
      
    processors:
    - add_cloud_metadata: ~
    - add_docker_metadata: ~
    - add_kubernetes_metadata:
        host: ${NODE_NAME}
        matchers:
        - logs_path:
            logs_path: "/var/log/containers/"
            
    output.elasticsearch:
      hosts: ["${ELASTICSEARCH_HOST}"]
      username: "${ELASTICSEARCH_USERNAME}"
      password: "${ELASTICSEARCH_PASSWORD}"
      ssl.verification_mode: none
      
    setup.kibana:
      host: "https://kibana.ai-audit.svc.cluster.local:5601"
      
    setup.template.settings:
      index.number_of_shards: 1
```

### 5.2 åˆè§„æŠ¥å‘Šç”Ÿæˆ

```python
# compliance_reporter.py
import pandas as pd
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any
import logging

logger = logging.getLogger(__name__)

class ComplianceReporter:
    def __init__(self, es_client, report_period_days: int = 30):
        self.es_client = es_client
        self.report_period = timedelta(days=report_period_days)
        self.report_date = datetime.now()
        
    def generate_ai_compliance_report(self) -> Dict[str, Any]:
        """ç”ŸæˆAIå¹³å°åˆè§„æŠ¥å‘Š"""
        
        report = {
            'report_date': self.report_date.isoformat(),
            'report_period': f"Last {self.report_period.days} days",
            'compliance_status': {},
            'findings': {},
            'recommendations': []
        }
        
        # GDPRåˆè§„æ£€æŸ¥
        report['compliance_status']['gdpr'] = self._check_gdpr_compliance()
        
        # SOC2åˆè§„æ£€æŸ¥
        report['compliance_status']['soc2'] = self._check_soc2_compliance()
        
        # AIç‰¹å®šæ³•è§„æ£€æŸ¥
        report['compliance_status']['ai_act'] = self._check_ai_act_compliance()
        
        # å®‰å…¨äº‹ä»¶ç»Ÿè®¡
        report['findings']['security_incidents'] = self._analyze_security_incidents()
        
        # è®¿é—®æ§åˆ¶å®¡è®¡
        report['findings']['access_control'] = self._analyze_access_patterns()
        
        # æ•°æ®ä¿æŠ¤æ£€æŸ¥
        report['findings']['data_protection'] = self._analyze_data_protection()
        
        # ç”Ÿæˆå»ºè®®
        report['recommendations'] = self._generate_recommendations(report)
        
        return report
        
    def _check_gdpr_compliance(self) -> Dict[str, Any]:
        """æ£€æŸ¥GDPRåˆè§„æ€§"""
        
        # æ£€æŸ¥æ•°æ®å¤„ç†è®°å½•
        data_processing_logs = self._query_audit_logs(
            query="kubernetes.labels.app:model-registry AND event.action:data_access",
            time_range=self.report_period
        )
        
        # æ£€æŸ¥ç”¨æˆ·åŒæ„è®°å½•
        consent_records = self._query_elasticsearch(
            index="consent-records-*",
            query={"exists": {"field": "user_consent"}},
            time_range=self.report_period
        )
        
        # æ£€æŸ¥æ•°æ®ä¸»ä½“æƒåˆ©è¯·æ±‚
        subject_requests = self._query_elasticsearch(
            index="subject-requests-*",
            query={"term": {"request_type": "data_deletion"}},
            time_range=self.report_period
        )
        
        return {
            'compliant': len(subject_requests) > 0,  # è‡³å°‘å¤„ç†è¿‡åˆ é™¤è¯·æ±‚
            'data_processing_records': len(data_processing_logs),
            'consent_records': len(consent_records),
            'subject_requests_handled': len(subject_requests),
            'issues': self._identify_gdpr_issues(data_processing_logs)
        }
        
    def _check_soc2_compliance(self) -> Dict[str, Any]:
        """æ£€æŸ¥SOC2åˆè§„æ€§"""
        
        # å®‰å…¨æ€§æ£€æŸ¥
        security_findings = self._query_elasticsearch(
            index="security-findings-*",
            query={"range": {"severity": {"gte": "medium"}}},
            time_range=self.report_period
        )
        
        # å¯ç”¨æ€§ç›‘æ§
        uptime_data = self._query_monitoring_metrics(
            metric="up",
            labels={"job": "ai-services"},
            time_range=self.report_period
        )
        
        # é…ç½®å˜æ›´å®¡è®¡
        config_changes = self._query_audit_logs(
            query="event.category:configuration AND event.type:change",
            time_range=self.report_period
        )
        
        return {
            'security_rating': "pass" if len(security_findings) < 5 else "fail",
            'availability_percentage': self._calculate_uptime_percentage(uptime_data),
            'configuration_changes': len(config_changes),
            'remediation_items': len([f for f in security_findings if f['status'] == 'open'])
        }
        
    def _check_ai_act_compliance(self) -> Dict[str, Any]:
        """æ£€æŸ¥AIæ³•æ¡ˆåˆè§„æ€§"""
        
        # é«˜é£é™©AIç³»ç»Ÿç™»è®°
        high_risk_models = self._query_model_registry(
            filters={"risk_level": "high"}
        )
        
        # é€æ˜åº¦è¦æ±‚æ£€æŸ¥
        transparency_docs = self._query_documentation(
            category="model-transparency"
        )
        
        # äººç±»ç›‘ç£è®°å½•
        human_oversight_logs = self._query_audit_logs(
            query="event.category:human_oversight",
            time_range=self.report_period
        )
        
        return {
            'high_risk_models_registered': len(high_risk_models),
            'transparency_documents': len(transparency_docs),
            'human_oversight_activities': len(human_oversight_logs),
            'compliance_score': self._calculate_ai_act_score(
                len(high_risk_models), 
                len(transparency_docs), 
                len(human_oversight_logs)
            )
        }
        
    def _analyze_security_incidents(self) -> Dict[str, Any]:
        """åˆ†æå®‰å…¨äº‹ä»¶"""
        
        # æŸ¥è¯¢å„ç±»å®‰å…¨äº‹ä»¶
        incident_types = {
            'unauthorized_access': 'event.category:authentication AND event.outcome:failure',
            'data_breach': 'event.category:data_security AND event.type:breach',
            'malware_detection': 'event.module:antivirus AND threat.indicator.type:malware',
            'privilege_escalation': 'event.action:user_privilege_change AND event.outcome:success'
        }
        
        incidents_summary = {}
        for incident_type, query in incident_types.items():
            incidents = self._query_elasticsearch(
                index="security-logs-*",
                query={"query_string": {"query": query}},
                time_range=self.report_period
            )
            incidents_summary[incident_type] = {
                'count': len(incidents),
                'trend': self._calculate_trend(incidents),
                'severity_distribution': self._analyze_severity(incidents)
            }
            
        return incidents_summary
        
    def _analyze_access_patterns(self) -> Dict[str, Any]:
        """åˆ†æè®¿é—®æ§åˆ¶æ¨¡å¼"""
        
        # å¼‚å¸¸è®¿é—®æ£€æµ‹
        access_logs = self._query_audit_logs(
            query="event.category:access",
            time_range=timedelta(days=7)  # è¿‘æœŸæ´»åŠ¨åˆ†æ
        )
        
        # ç”¨æˆ·è¡Œä¸ºåˆ†æ
        user_behaviors = self._analyze_user_behavior(access_logs)
        
        # æƒé™æ¼‚ç§»æ£€æµ‹
        permission_changes = self._detect_permission_drift()
        
        return {
            'anomalous_users': user_behaviors['anomalous_users'],
            'permission_drifts': permission_changes,
            'access_review_needed': user_behaviors['users_needing_review']
        }
        
    def _generate_recommendations(self, report: Dict) -> List[str]:
        """åŸºäºæŠ¥å‘Šç”Ÿæˆæ”¹è¿›å»ºè®®"""
        
        recommendations = []
        
        # GDPRç›¸å…³å»ºè®®
        gdpr_status = report['compliance_status']['gdpr']
        if not gdpr_status['compliant']:
            recommendations.append("å»ºç«‹å®Œæ•´çš„æ•°æ®å¤„ç†è®°å½•ç³»ç»Ÿ")
            recommendations.append("å®æ–½æ•°æ®ä¸»ä½“æƒåˆ©è¯·æ±‚å¤„ç†æµç¨‹")
            
        # å®‰å…¨å»ºè®®
        security_findings = report['findings']['security_incidents']
        high_severity_count = sum(
            findings['count'] 
            for findings in security_findings.values() 
            if findings.get('severity_distribution', {}).get('high', 0) > 0
        )
        
        if high_severity_count > 0:
            recommendations.append(f"ç«‹å³å¤„ç†{high_severity_count}ä¸ªé«˜ä¸¥é‡æ€§å®‰å…¨äº‹ä»¶")
            recommendations.append("åŠ å¼ºå…¥ä¾µæ£€æµ‹å’Œå“åº”èƒ½åŠ›")
            
        # AIæ²»ç†å»ºè®®
        ai_act_status = report['compliance_status']['ai_act']
        if ai_act_status['compliance_score'] < 80:
            recommendations.append("å®Œå–„é«˜é£é™©AIç³»ç»Ÿç™»è®°åˆ¶åº¦")
            recommendations.append("åŠ å¼ºæ¨¡å‹é€æ˜åº¦æ–‡æ¡£ç®¡ç†")
            
        return recommendations
        
    def export_report(self, report: Dict, format: str = "pdf") -> str:
        """å¯¼å‡ºåˆè§„æŠ¥å‘Š"""
        
        if format == "json":
            filename = f"ai_compliance_report_{self.report_date.strftime('%Y%m%d')}.json"
            with open(filename, 'w') as f:
                json.dump(report, f, indent=2, default=str)
            return filename
            
        elif format == "csv":
            # è½¬æ¢ä¸ºCSVæ ¼å¼
            df = pd.json_normalize(report)
            filename = f"ai_compliance_report_{self.report_date.strftime('%Y%m%d')}.csv"
            df.to_csv(filename, index=False)
            return filename
            
        # å¯ä»¥æ‰©å±•æ”¯æŒPDFã€HTMLç­‰æ ¼å¼
        return ""

# ä½¿ç”¨ç¤ºä¾‹
reporter = ComplianceReporter(elasticsearch_client, report_period_days=30)
compliance_report = reporter.generate_ai_compliance_report()

# å¯¼å‡ºæŠ¥å‘Š
json_file = reporter.export_report(compliance_report, format="json")
print(f"åˆè§„æŠ¥å‘Šå·²ç”Ÿæˆ: {json_file}")

# å®šæœŸæŠ¥å‘Šä»»åŠ¡
def scheduled_compliance_report():
    """å®šæœŸç”Ÿæˆåˆè§„æŠ¥å‘Šçš„ä»»åŠ¡"""
    reporter = ComplianceReporter(es_client)
    report = reporter.generate_ai_compliance_report()
    
    # å‘é€æŠ¥å‘Šç»™ç›¸å…³äººå‘˜
    send_email_report(report, recipients=["security-team@company.com"])
    
    # å­˜å‚¨åˆ°åˆè§„ç³»ç»Ÿ
    store_compliance_record(report)

# é…ç½®å®šæ—¶ä»»åŠ¡ï¼ˆä¾‹å¦‚æ¯æœˆ1å·æ‰§è¡Œï¼‰
# å¯ä»¥ä½¿ç”¨Kubernetes CronJobæˆ–Celery Beatç­‰è°ƒåº¦å™¨
```

---

## å…­ã€å®‰å…¨è¿ç»´æœ€ä½³å®è·µ

### 6.1 å®‰å…¨æ£€æŸ¥æ¸…å•

âœ… **éƒ¨ç½²å‰å®‰å…¨æ£€æŸ¥**
- [ ] ä»£ç å®‰å…¨æ‰«æå®Œæˆï¼ˆSAST/DASTï¼‰
- [ ] ç¬¬ä¸‰æ–¹ä¾èµ–æ¼æ´æ‰«æé€šè¿‡
- [ ] å®¹å™¨é•œåƒå®‰å…¨åŸºçº¿æ£€æŸ¥
- [ ] Kuberneteså®‰å…¨é…ç½®å®¡æŸ¥
- [ ] æ¨¡å‹å®‰å…¨æ€§å’Œåè§è¯„ä¼°
- [ ] æ•°æ®éšç§å½±å“è¯„ä¼°å®Œæˆ

âœ… **è¿è¡Œæ—¶å®‰å…¨ç›‘æ§**
- [ ] å®æ—¶å¨èƒæ£€æµ‹ç³»ç»Ÿè¿è¡Œæ­£å¸¸
- [ ] å¼‚å¸¸è¡Œä¸ºåˆ†æè§„åˆ™ç”Ÿæ•ˆ
- [ ] å®‰å…¨äº‹ä»¶å“åº”æµç¨‹æµ‹è¯•é€šè¿‡
- [ ] è®¿é—®æ—¥å¿—å®¡è®¡é…ç½®æ­£ç¡®
- [ ] æ¼æ´æ‰«æå®šæœŸæ‰§è¡Œ
- [ ] å®‰å…¨è¡¥ä¸åŠæ—¶æ›´æ–°

âœ… **åˆè§„æ€§æŒç»­ç›‘æ§**
- [ ] å®šæœŸåˆè§„æ€§è¯„ä¼°æ‰§è¡Œ
- [ ] å®¡è®¡æ—¥å¿—å®Œæ•´æ€§éªŒè¯
- [ ] éšç§ä¿æŠ¤æªæ–½æœ‰æ•ˆè¿è¡Œ
- [ ] å®‰å…¨åŸ¹è®­å®šæœŸå¼€å±•
- [ ] ç¬¬ä¸‰æ–¹å®¡è®¡é…åˆå®Œæˆ
- [ ] æ”¹è¿›æªæ–½è·Ÿè¸ªè½å®

### 6.2 åº”æ€¥å“åº”æµç¨‹

**å®‰å…¨äº‹ä»¶åˆ†ç±»**
- ğŸ”´ **ç´§æ€¥**: æ•°æ®æ³„éœ²ã€ç³»ç»Ÿè¢«æ”»ç ´ã€æ¨¡å‹æŠ•æ¯’
- ğŸŸ¡ **é«˜å±**: æœªæˆæƒè®¿é—®ã€æ¶æ„è½¯ä»¶æ„ŸæŸ“ã€æ‹’ç»æœåŠ¡
- ğŸŸ¢ **ä¸­ä½**: é…ç½®é”™è¯¯ã€è½»å¾®è¿è§„ã€å¯ç–‘æ´»åŠ¨

**å“åº”æ­¥éª¤**
1. **æ£€æµ‹ä¸ç¡®è®¤** - éªŒè¯äº‹ä»¶çœŸå®æ€§
2. **éåˆ¶ä¸éš”ç¦»** - é™åˆ¶å½±å“èŒƒå›´
3. **è°ƒæŸ¥ä¸åˆ†æ** - ç¡®å®šæ ¹æœ¬åŸå› 
4. **æ¸…é™¤ä¸æ¢å¤** - ç§»é™¤å¨èƒå¹¶æ¢å¤æ­£å¸¸
5. **æ€»ç»“ä¸æ”¹è¿›** - æ–‡æ¡£åŒ–æ•™è®­å¹¶æ”¹è¿›é˜²æŠ¤

---