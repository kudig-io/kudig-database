# 18-è·¨åŒºåŸŸå®¹ç¾éƒ¨ç½²

> **é€‚ç”¨èŒƒå›´**: Kubernetes v1.25-v1.32 | **ç»´æŠ¤çŠ¶æ€**: ğŸ”§ æŒç»­æ›´æ–°ä¸­ | **ä¸“å®¶çº§åˆ«**: â­â­â­â­â­

## ğŸ“‹ æ¦‚è¿°

è·¨åŒºåŸŸå®¹ç¾éƒ¨ç½²æ˜¯ä¿éšœä¸šåŠ¡è¿ç»­æ€§çš„é«˜çº§ç­–ç•¥ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»å¤šæ´»æ¶æ„è®¾è®¡ã€æ•°æ®åŒæ­¥æœºåˆ¶å’Œæ•…éšœåˆ‡æ¢æ–¹æ¡ˆã€‚

## ğŸŒ å¤šæ´»æ¶æ„è®¾è®¡

### åœ°åŸŸåˆ†å¸ƒç­–ç•¥

#### 1. ä¸‰åœ°åŸŸäº”ä¸­å¿ƒæ¶æ„
```yaml
# å¤šåœ°åŸŸé›†ç¾¤é…ç½®
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  name: primary-region-cluster
  labels:
    region: us-east-1
    role: primary
spec:
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: primary-control-plane
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  name: secondary-region-cluster
  labels:
    region: us-west-2
    role: secondary
spec:
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: secondary-control-plane
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  name: tertiary-region-cluster
  labels:
    region: eu-west-1
    role: tertiary
spec:
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: tertiary-control-plane
```

#### 2. æµé‡åˆ†å‘ç­–ç•¥
```yaml
# å…¨çƒè´Ÿè½½å‡è¡¡é…ç½®
apiVersion: v1
kind: Service
metadata:
  name: global-load-balancer
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "external"
    service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: "ip"
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"
    service.beta.kubernetes.io/aws-load-balancer-healthcheck-protocol: "HTTP"
    service.beta.kubernetes.io/aws-load-balancer-healthcheck-port: "8080"
    service.beta.kubernetes.io/aws-load-balancer-healthcheck-path: "/health"
spec:
  type: LoadBalancer
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
  selector:
    app: global-app
---
# åœ°åŸŸè·¯ç”±é…ç½®
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: regional-routing
spec:
  hosts:
  - "*.example.com"
  gateways:
  - global-gateway
  http:
  - match:
    - headers:
        region:
          exact: "us-east-1"
    route:
    - destination:
        host: app.us-east-1.svc.cluster.local
        port:
          number: 8080
      weight: 100
  - match:
    - headers:
        region:
          exact: "us-west-2"
    route:
    - destination:
        host: app.us-west-2.svc.cluster.local
        port:
          number: 8080
      weight: 100
  - route:
    - destination:
        host: app.us-east-1.svc.cluster.local
        port:
          number: 8080
      weight: 60
    - destination:
        host: app.us-west-2.svc.cluster.local
        port:
          number: 8080
      weight: 30
    - destination:
        host: app.eu-west-1.svc.cluster.local
        port:
          number: 8080
      weight: 10
```

### æ•°æ®åŒæ­¥æ¶æ„

#### 1. æ•°æ®åº“å¤šæ´»é…ç½®
```yaml
# MySQLä¸»ä¸»å¤åˆ¶é…ç½®
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-primary
spec:
  serviceName: mysql-primary
  replicas: 3
  selector:
    matchLabels:
      app: mysql
      role: primary
  template:
    metadata:
      labels:
        app: mysql
        role: primary
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: root-password
        - name: MYSQL_REPLICATION_USER
          value: "replicator"
        - name: MYSQL_REPLICATION_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: replication-password
        ports:
        - containerPort: 3306
        volumeMounts:
        - name: mysql-data
          mountPath: /var/lib/mysql
        - name: mysql-config
          mountPath: /etc/mysql/conf.d
  volumeClaimTemplates:
  - metadata:
      name: mysql-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mysql-config
data:
  master.cnf: |
    [mysqld]
    log-bin=mysql-bin
    server-id=1
    binlog-format=ROW
    gtid-mode=ON
    enforce-gtid-consistency=ON
    log-slave-updates=ON
    binlog-ignore-db=mysql
    replicate-ignore-db=mysql
```

#### 2. Redisé›†ç¾¤å¤šåœ°åŸŸéƒ¨ç½²
```yaml
# Rediså¤šåœ°åŸŸé›†ç¾¤é…ç½®
apiVersion: databases.spotahome.com/v1
kind: RedisFailover
metadata:
  name: redis-multi-region
spec:
  redis:
    replicas: 6
    resources:
      requests:
        cpu: 100m
        memory: 100Mi
      limits:
        cpu: 200m
        memory: 200Mi
    exporter:
      enabled: true
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/component: redis
          topologyKey: topology.kubernetes.io/zone
  sentinel:
    replicas: 3
    resources:
      requests:
        cpu: 100m
        memory: 100Mi
      limits:
        cpu: 200m
        memory: 200Mi
---
# Redisè·¨åœ°åŸŸåŒæ­¥é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-sync-config
data:
  redis-sync.conf: |
    # ä¸»åœ°åŸŸRedisé…ç½®
    masterauth yourpassword
    requirepass yourpassword
    
    # ä»åœ°åŸŸåŒæ­¥é…ç½®
    slaveof primary-redis-endpoint 6379
    slave-read-only yes
    
    # å“¨å…µé…ç½®
    sentinel monitor mymaster primary-redis-endpoint 6379 2
    sentinel auth-pass mymaster yourpassword
    sentinel down-after-milliseconds mymaster 5000
    sentinel failover-timeout mymaster 10000
    sentinel parallel-syncs mymaster 1
```

## ğŸ”„ æ•…éšœæ£€æµ‹ä¸åˆ‡æ¢

### æ™ºèƒ½æ•…éšœæ£€æµ‹

#### 1. å¤šç»´åº¦å¥åº·æ£€æŸ¥
```python
#!/usr/bin/env python3
# æ™ºèƒ½æ•…éšœæ£€æµ‹ç³»ç»Ÿ

import asyncio
import aiohttp
import json
from datetime import datetime, timedelta
from kubernetes import client, config
import socket

class IntelligentFailureDetector:
    def __init__(self):
        config.load_kube_config()
        self.core_v1 = client.CoreV1Api()
        self.apps_v1 = client.AppsV1Api()
        
        self.health_check_config = {
            'regions': ['us-east-1', 'us-west-2', 'eu-west-1'],
            'check_intervals': {
                'critical': 30,    # 30ç§’æ£€æŸ¥ä¸€æ¬¡å…³é”®æœåŠ¡
                'important': 60,   # 1åˆ†é’Ÿæ£€æŸ¥é‡è¦æœåŠ¡
                'routine': 300     # 5åˆ†é’Ÿå¸¸è§„æ£€æŸ¥
            },
            'failure_thresholds': {
                'network_latency': 1000,  # ms
                'http_error_rate': 0.05,  # 5%
                'database_response_time': 2000,  # ms
                'cpu_utilization': 0.85,  # 85%
                'memory_utilization': 0.90  # 90%
            }
        }
        
        self.region_status = {region: 'healthy' for region in self.health_check_config['regions']}
        self.failure_history = {}
    
    async def run_continuous_monitoring(self):
        """æŒç»­ç›‘æ§è¿è¡Œ"""
        while True:
            try:
                # å¹¶è¡Œæ‰§è¡Œå„ç±»æ£€æŸ¥
                await asyncio.gather(
                    self.check_network_connectivity(),
                    self.check_application_health(),
                    self.check_database_connectivity(),
                    self.check_infrastructure_health(),
                    self.analyze_performance_metrics()
                )
                
                # è¯„ä¼°æ•´ä½“å¥åº·çŠ¶å†µ
                await self.evaluate_overall_health()
                
                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥å‘¨æœŸ
                await asyncio.sleep(30)
                
            except Exception as e:
                print(f"Error in monitoring cycle: {e}")
                await asyncio.sleep(60)
    
    async def check_network_connectivity(self):
        """æ£€æŸ¥ç½‘ç»œè¿é€šæ€§"""
        network_checks = []
        
        for region in self.health_check_config['regions']:
            check_task = self.perform_region_network_check(region)
            network_checks.append(check_task)
        
        results = await asyncio.gather(*network_checks, return_exceptions=True)
        
        for i, result in enumerate(results):
            region = self.health_check_config['regions'][i]
            if isinstance(result, Exception):
                self.region_status[region] = 'network_failure'
                self.record_failure(region, 'network', str(result))
            elif result['latency'] > self.health_check_config['failure_thresholds']['network_latency']:
                self.region_status[region] = 'high_latency'
                self.record_failure(region, 'latency', f"Latency: {result['latency']}ms")
            else:
                # å¦‚æœä¹‹å‰æœ‰é—®é¢˜ï¼Œç°åœ¨æ¢å¤æ­£å¸¸
                if self.region_status[region] in ['network_failure', 'high_latency']:
                    self.region_status[region] = 'healthy'
    
    async def perform_region_network_check(self, region):
        """æ‰§è¡Œåœ°åŸŸç½‘ç»œæ£€æŸ¥"""
        endpoints = self.get_region_endpoints(region)
        latencies = []
        
        async with aiohttp.ClientSession() as session:
            for endpoint in endpoints:
                try:
                    start_time = datetime.now()
                    async with session.get(endpoint, timeout=5) as response:
                        end_time = datetime.now()
                        latency = (end_time - start_time).total_seconds() * 1000
                        latencies.append(latency)
                except Exception as e:
                    latencies.append(9999)  # è¡¨ç¤ºè¿æ¥å¤±è´¥
        
        return {
            'region': region,
            'latency': sum(latencies) / len(latencies) if latencies else 9999,
            'success_rate': len([l for l in latencies if l < 5000]) / len(latencies) if latencies else 0
        }
    
    async def check_application_health(self):
        """æ£€æŸ¥åº”ç”¨å¥åº·çŠ¶æ€"""
        try:
            # æ£€æŸ¥å„åœ°åŸŸçš„åº”ç”¨éƒ¨ç½²
            for region in self.health_check_config['regions']:
                deployments = await self.get_region_deployments(region)
                
                for deployment in deployments:
                    health_status = await self.check_deployment_health(deployment, region)
                    if not health_status['healthy']:
                        self.record_failure(region, 'application', 
                                          f"Deployment {deployment} unhealthy: {health_status['reason']}")
                        
        except Exception as e:
            print(f"Error checking application health: {e}")
    
    async def check_database_connectivity(self):
        """æ£€æŸ¥æ•°æ®åº“è¿é€šæ€§"""
        try:
            db_endpoints = self.get_database_endpoints()
            
            for region, endpoint in db_endpoints.items():
                db_health = await self.test_database_connection(endpoint)
                if not db_health['reachable']:
                    self.record_failure(region, 'database', 
                                      f"Database unreachable: {db_health['error']}")
                elif db_health['response_time'] > self.health_check_config['failure_thresholds']['database_response_time']:
                    self.record_failure(region, 'database', 
                                      f"Database slow response: {db_health['response_time']}ms")
                    
        except Exception as e:
            print(f"Error checking database connectivity: {e}")
    
    async def check_infrastructure_health(self):
        """æ£€æŸ¥åŸºç¡€è®¾æ–½å¥åº·"""
        try:
            nodes = self.core_v1.list_node()
            
            for node in nodes.items:
                region = self.get_node_region(node)
                if region:
                    node_health = self.evaluate_node_health(node)
                    if not node_health['healthy']:
                        self.record_failure(region, 'infrastructure', 
                                          f"Node {node.metadata.name} unhealthy: {node_health['issues']}")
                        
        except Exception as e:
            print(f"Error checking infrastructure health: {e}")
    
    async def analyze_performance_metrics(self):
        """åˆ†ææ€§èƒ½æŒ‡æ ‡"""
        try:
            # ä»ç›‘æ§ç³»ç»Ÿè·å–æ€§èƒ½æ•°æ®
            metrics = await self.fetch_performance_metrics()
            
            for region in self.health_check_config['regions']:
                region_metrics = metrics.get(region, {})
                
                # æ£€æŸ¥CPUä½¿ç”¨ç‡
                cpu_util = region_metrics.get('cpu_utilization', 0)
                if cpu_util > self.health_check_config['failure_thresholds']['cpu_utilization']:
                    self.record_failure(region, 'performance', 
                                      f"High CPU utilization: {cpu_util:.1%}")
                
                # æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡
                memory_util = region_metrics.get('memory_utilization', 0)
                if memory_util > self.health_check_config['failure_thresholds']['memory_utilization']:
                    self.record_failure(region, 'performance', 
                                      f"High memory utilization: {memory_util:.1%}")
                    
        except Exception as e:
            print(f"Error analyzing performance metrics: {e}")
    
    async def evaluate_overall_health(self):
        """è¯„ä¼°æ•´ä½“å¥åº·çŠ¶å†µ"""
        unhealthy_regions = [region for region, status in self.region_status.items() 
                           if status != 'healthy']
        
        if len(unhealthy_regions) >= 2:
            # å¤šä¸ªåœ°åŸŸåŒæ—¶å‡ºç°é—®é¢˜ï¼Œè§¦å‘ç´§æ€¥å‘Šè­¦
            await self.trigger_emergency_response(unhealthy_regions)
        elif len(unhealthy_regions) == 1:
            # å•ä¸ªåœ°åŸŸé—®é¢˜ï¼Œå‡†å¤‡æ•…éšœåˆ‡æ¢
            await self.prepare_failover(unhealthy_regions[0])
    
    def record_failure(self, region, failure_type, description):
        """è®°å½•æ•…éšœä¿¡æ¯"""
        if region not in self.failure_history:
            self.failure_history[region] = []
        
        failure_record = {
            'timestamp': datetime.now().isoformat(),
            'type': failure_type,
            'description': description,
            'severity': self.assess_failure_severity(failure_type, description)
        }
        
        self.failure_history[region].append(failure_record)
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.failure_history[region]) > 100:
            self.failure_history[region] = self.failure_history[region][-50:]
    
    def assess_failure_severity(self, failure_type, description):
        """è¯„ä¼°æ•…éšœä¸¥é‡ç¨‹åº¦"""
        critical_indicators = ['unreachable', 'failure', 'timeout', 'critical']
        warning_indicators = ['slow', 'high', 'latency', 'degraded']
        
        description_lower = description.lower()
        
        if any(indicator in description_lower for indicator in critical_indicators):
            return 'critical'
        elif any(indicator in description_lower for indicator in warning_indicators):
            return 'warning'
        else:
            return 'info'
    
    async def trigger_emergency_response(self, affected_regions):
        """è§¦å‘ç´§æ€¥å“åº”"""
        emergency_notification = {
            'type': 'emergency',
            'timestamp': datetime.now().isoformat(),
            'affected_regions': affected_regions,
            'status': 'multiple_region_failure',
            'recommended_action': 'activate_disaster_recovery_protocol'
        }
        
        print(f"EMERGENCY RESPONSE TRIGGERED: {json.dumps(emergency_notification, indent=2)}")
        
        # è¿™é‡Œåº”è¯¥é›†æˆå…·ä½“çš„å‘Šè­¦å’Œå“åº”ç³»ç»Ÿ
        await self.notify_stakeholders(emergency_notification)
        await self.activate_backup_systems()
    
    async def prepare_failover(self, failed_region):
        """å‡†å¤‡æ•…éšœåˆ‡æ¢"""
        failover_plan = {
            'failed_region': failed_region,
            'timestamp': datetime.now().isoformat(),
            'traffic_redirection_ready': await self.check_traffic_redirection_capability(),
            'backup_systems_healthy': await self.verify_backup_systems_health(),
            'estimated_switch_time': '5-10 minutes'
        }
        
        print(f"Failover preparation for {failed_region}: {json.dumps(failover_plan, indent=2)}")
        
        # é¢„çƒ­å¤‡ä»½ç³»ç»Ÿ
        await self.preheat_backup_systems(failed_region)
    
    # è¾…åŠ©æ–¹æ³•ï¼ˆç®€åŒ–å®ç°ï¼‰
    def get_region_endpoints(self, region):
        return [f"https://{region}-endpoint.example.com/health"]
    
    async def get_region_deployments(self, region):
        return [f"app-{region}"]
    
    async def check_deployment_health(self, deployment, region):
        return {'healthy': True, 'reason': ''}
    
    def get_database_endpoints(self):
        return {region: f"{region}-db.example.com" for region in self.health_check_config['regions']}
    
    async def test_database_connection(self, endpoint):
        return {'reachable': True, 'response_time': 100, 'error': ''}
    
    def get_node_region(self, node):
        return node.metadata.labels.get('topology.kubernetes.io/region')
    
    def evaluate_node_health(self, node):
        return {'healthy': True, 'issues': []}
    
    async def fetch_performance_metrics(self):
        return {region: {} for region in self.health_check_config['regions']}
    
    async def notify_stakeholders(self, notification):
        print(f"Notifying stakeholders: {notification}")
    
    async def activate_backup_systems(self):
        print("Activating backup systems...")
    
    async def check_traffic_redirection_capability(self):
        return True
    
    async def verify_backup_systems_health(self):
        return True
    
    async def preheat_backup_systems(self, failed_region):
        print(f"Preheating backup systems for {failed_region}...")

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    detector = IntelligentFailureDetector()
    await detector.run_continuous_monitoring()

if __name__ == "__main__":
    asyncio.run(main())
```

#### 2. è‡ªåŠ¨æ•…éšœåˆ‡æ¢
```yaml
# è‡ªåŠ¨æ•…éšœåˆ‡æ¢é…ç½®
apiVersion: apps/v1
kind: Deployment
metadata:
  name: failover-controller
  namespace: dr-system
spec:
  replicas: 3
  selector:
    matchLabels:
      app: failover-controller
  template:
    metadata:
      labels:
        app: failover-controller
    spec:
      containers:
      - name: controller
        image: custom/failover-controller:latest
        env:
        - name: PRIMARY_REGION
          value: "us-east-1"
        - name: SECONDARY_REGION
          value: "us-west-2"
        - name: FAILOVER_THRESHOLD
          value: "3"  # è¿ç»­3æ¬¡æ£€æŸ¥å¤±è´¥ååˆ‡æ¢
        - name: HEALTH_CHECK_INTERVAL
          value: "30"
        volumeMounts:
        - name: config
          mountPath: /config
      volumes:
      - name: config
        configMap:
          name: failover-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: failover-config
  namespace: dr-system
data:
  failover-strategy.yaml: |
    strategies:
    - name: "graceful-failover"
      trigger_conditions:
        consecutive_failures: 3
        failure_duration: "90s"
        affected_services: ["critical", "database"]
      actions:
        - "redirect-traffic"
        - "promote-secondary"
        - "notify-stakeholders"
        - "start-recovery-monitoring"
      
    - name: "emergency-failover"
      trigger_conditions:
        consecutive_failures: 1
        failure_type: "complete-outage"
        affected_regions: [">=2"]
      actions:
        - "immediate-traffic-switch"
        - "activate-hot-standby"
        - "emergency-notification"
        - "executive-briefing"
```

## ğŸ“Š æ•°æ®ä¸€è‡´æ€§ä¿éšœ

### åˆ†å¸ƒå¼äº‹åŠ¡å¤„ç†

#### 1. æœ€ç»ˆä¸€è‡´æ€§åè®®
```python
#!/usr/bin/env python3
# åˆ†å¸ƒå¼æ•°æ®ä¸€è‡´æ€§ç®¡ç†å™¨

import asyncio
import json
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Optional

class DataConsistencyManager:
    def __init__(self):
        self.regions = ['us-east-1', 'us-west-2', 'eu-west-1']
        self.consistency_config = {
            'sync_interval': 5,  # ç§’
            'consistency_window': 60,  # ç§’
            'conflict_resolution': 'timestamp_based',
            'data_validation_enabled': True
        }
        
        self.data_checksums = {region: {} for region in self.regions}
        self.sync_queue = asyncio.Queue()
        self.conflict_log = []
    
    async def run_consistency_monitoring(self):
        """è¿è¡Œä¸€è‡´æ€§ç›‘æ§"""
        tasks = [
            self.monitor_data_changes(),
            self.synchronize_data_between_regions(),
            self.validate_data_consistency(),
            self.resolve_conflicts()
        ]
        
        await asyncio.gather(*tasks)
    
    async def monitor_data_changes(self):
        """ç›‘æ§æ•°æ®å˜æ›´"""
        while True:
            try:
                # æ¨¡æ‹Ÿæ£€æµ‹å„åŒºåŸŸæ•°æ®å˜æ›´
                for region in self.regions:
                    changes = await self.detect_region_changes(region)
                    if changes:
                        await self.sync_queue.put({
                            'region': region,
                            'changes': changes,
                            'timestamp': datetime.now().isoformat()
                        })
                
                await asyncio.sleep(self.consistency_config['sync_interval'])
                
            except Exception as e:
                print(f"Error monitoring data changes: {e}")
                await asyncio.sleep(10)
    
    async def synchronize_data_between_regions(self):
        """åœ¨åœ°åŸŸé—´åŒæ­¥æ•°æ®"""
        while True:
            try:
                sync_item = await self.sync_queue.get()
                await self.propagate_changes(sync_item)
                self.sync_queue.task_done()
                
            except Exception as e:
                print(f"Error synchronizing data: {e}")
    
    async def validate_data_consistency(self):
        """éªŒè¯æ•°æ®ä¸€è‡´æ€§"""
        while True:
            try:
                # å®šæœŸéªŒè¯æ‰€æœ‰åŒºåŸŸæ•°æ®ä¸€è‡´æ€§
                inconsistencies = await self.check_global_consistency()
                
                if inconsistencies:
                    print(f"Data inconsistencies detected: {inconsistencies}")
                    for inconsistency in inconsistencies:
                        await self.handle_inconsistency(inconsistency)
                
                await asyncio.sleep(self.consistency_config['consistency_window'])
                
            except Exception as e:
                print(f"Error validating consistency: {e}")
                await asyncio.sleep(30)
    
    async def resolve_conflicts(self):
        """è§£å†³æ•°æ®å†²çª"""
        while True:
            try:
                # æ£€æŸ¥å¹¶è§£å†³å†²çª
                conflicts = await self.detect_conflicts()
                
                for conflict in conflicts:
                    resolution = await self.resolve_conflict(conflict)
                    self.conflict_log.append({
                        'conflict': conflict,
                        'resolution': resolution,
                        'resolved_at': datetime.now().isoformat()
                    })
                
                await asyncio.sleep(10)
                
            except Exception as e:
                print(f"Error resolving conflicts: {e}")
                await asyncio.sleep(15)
    
    async def detect_region_changes(self, region: str) -> Optional[List[Dict]]:
        """æ£€æµ‹åœ°åŸŸæ•°æ®å˜æ›´"""
        # æ¨¡æ‹Ÿæ•°æ®å˜æ›´æ£€æµ‹
        # å®é™…å®ç°åº”è¯¥ç›‘æ§æ•°æ®åº“å˜æ›´æ—¥å¿—æˆ–ä½¿ç”¨CDC
        import random
        
        if random.random() < 0.1:  # 10%æ¦‚ç‡æœ‰å˜æ›´
            return [
                {
                    'table': 'users',
                    'operation': 'UPDATE',
                    'key': f'user_{random.randint(1, 1000)}',
                    'timestamp': datetime.now().isoformat()
                }
            ]
        return None
    
    async def propagate_changes(self, sync_item: Dict):
        """ä¼ æ’­å˜æ›´åˆ°å…¶ä»–åœ°åŸŸ"""
        source_region = sync_item['region']
        changes = sync_item['changes']
        
        # å‘å…¶ä»–åœ°åŸŸä¼ æ’­å˜æ›´
        for target_region in self.regions:
            if target_region != source_region:
                try:
                    await self.apply_changes_to_region(target_region, changes, source_region)
                    print(f"Changes propagated from {source_region} to {target_region}")
                except Exception as e:
                    print(f"Failed to propagate changes to {target_region}: {e}")
                    await self.queue_retry(sync_item, target_region)
    
    async def apply_changes_to_region(self, region: str, changes: List[Dict], source_region: str):
        """å°†å˜æ›´åº”ç”¨åˆ°æŒ‡å®šåœ°åŸŸ"""
        # è¿™é‡Œåº”è¯¥å®ç°å…·ä½“çš„æ•°æ®åº“å˜æ›´åº”ç”¨é€»è¾‘
        # åŒ…æ‹¬å†²çªæ£€æµ‹å’Œè§£å†³
        for change in changes:
            # åº”ç”¨å˜æ›´
            await self.apply_single_change(region, change)
            
            # æ›´æ–°æ ¡éªŒå’Œ
            await self.update_data_checksum(region, change)
    
    async def apply_single_change(self, region: str, change: Dict):
        """åº”ç”¨å•ä¸ªå˜æ›´"""
        # å®ç°å…·ä½“çš„å˜æ›´åº”ç”¨é€»è¾‘
        print(f"Applying {change['operation']} to {change['table']} in {region}")
    
    async def update_data_checksum(self, region: str, change: Dict):
        """æ›´æ–°æ•°æ®æ ¡éªŒå’Œ"""
        table = change['table']
        key = change['key']
        
        if table not in self.data_checksums[region]:
            self.data_checksums[region][table] = {}
        
        # ç”Ÿæˆæ ¡éªŒå’Œï¼ˆç®€åŒ–å®ç°ï¼‰
        checksum = hashlib.md5(f"{table}:{key}:{datetime.now()}".encode()).hexdigest()
        self.data_checksums[region][table][key] = {
            'checksum': checksum,
            'timestamp': change['timestamp']
        }
    
    async def check_global_consistency(self) -> List[Dict]:
        """æ£€æŸ¥å…¨å±€æ•°æ®ä¸€è‡´æ€§"""
        inconsistencies = []
        
        # æ¯”è¾ƒå„åŒºåŸŸç›¸åŒæ•°æ®çš„æ ¡éªŒå’Œ
        all_tables = set()
        for region_checksums in self.data_checksums.values():
            all_tables.update(region_checksums.keys())
        
        for table in all_tables:
            # æ”¶é›†æ‰€æœ‰åŒºåŸŸçš„è¯¥è¡¨æ•°æ®é”®
            all_keys = set()
            for region in self.regions:
                if table in self.data_checksums[region]:
                    all_keys.update(self.data_checksums[region][table].keys())
            
            # æ£€æŸ¥æ¯ä¸ªé”®çš„ä¸€è‡´æ€§
            for key in all_keys:
                checksums = {}
                timestamps = {}
                
                for region in self.regions:
                    if (table in self.data_checksums[region] and 
                        key in self.data_checksums[region][table]):
                        checksums[region] = self.data_checksums[region][table][key]['checksum']
                        timestamps[region] = self.data_checksums[region][table][key]['timestamp']
                
                # å¦‚æœæœ‰å¤šä¸ªä¸åŒçš„æ ¡éªŒå’Œï¼Œè¯´æ˜å­˜åœ¨ä¸ä¸€è‡´
                if len(set(checksums.values())) > 1:
                    inconsistencies.append({
                        'table': table,
                        'key': key,
                        'inconsistent_regions': list(checksums.keys()),
                        'checksums': checksums,
                        'timestamps': timestamps,
                        'detected_at': datetime.now().isoformat()
                    })
        
        return inconsistencies
    
    async def handle_inconsistency(self, inconsistency: Dict):
        """å¤„ç†æ•°æ®ä¸ä¸€è‡´"""
        print(f"Handling inconsistency: {inconsistency}")
        
        # åŸºäºæ—¶é—´æˆ³è§£å†³å†²çª
        latest_region = max(inconsistency['timestamps'].items(), key=lambda x: x[1])[0]
        
        # å°†æœ€æ–°æ•°æ®åŒæ­¥åˆ°å…¶ä»–åŒºåŸŸ
        for region in inconsistency['inconsistent_regions']:
            if region != latest_region:
                await self.sync_data_from_region(region, latest_region, 
                                               inconsistency['table'], inconsistency['key'])
    
    async def sync_data_from_region(self, target_region: str, source_region: str, table: str, key: str):
        """ä»æºåœ°åŸŸåŒæ­¥æ•°æ®åˆ°ç›®æ ‡åœ°åŸŸ"""
        print(f"Syncing {table}.{key} from {source_region} to {target_region}")
        # å®ç°å…·ä½“çš„æ•°æ®åŒæ­¥é€»è¾‘
    
    async def detect_conflicts(self) -> List[Dict]:
        """æ£€æµ‹æ•°æ®å†²çª"""
        # æ£€æµ‹å¹¶å‘ä¿®æ”¹å¯¼è‡´çš„å†²çª
        conflicts = []
        
        # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥åŒä¸€æ—¶é—´æ®µå†…çš„ä¿®æ”¹
        recent_changes = self.get_recent_changes(timedelta(seconds=30))
        
        for change_group in self.group_simultaneous_changes(recent_changes):
            if len(change_group) > 1:
                conflicts.append({
                    'type': 'simultaneous_modification',
                    'changes': change_group,
                    'detected_at': datetime.now().isoformat()
                })
        
        return conflicts
    
    async def resolve_conflict(self, conflict: Dict) -> Dict:
        """è§£å†³æ•°æ®å†²çª"""
        if conflict['type'] == 'simultaneous_modification':
            # åŸºäºæ—¶é—´æˆ³è§£å†³å†²çª
            latest_change = max(conflict['changes'], key=lambda x: x['timestamp'])
            
            return {
                'strategy': 'timestamp_based',
                'winner': latest_change,
                'losers': [c for c in conflict['changes'] if c != latest_change],
                'applied_at': datetime.now().isoformat()
            }
        
        return {'strategy': 'manual_review_needed'}
    
    def get_recent_changes(self, time_window: timedelta) -> List[Dict]:
        """è·å–æœ€è¿‘çš„å˜æ›´"""
        # ç®€åŒ–å®ç°
        return []
    
    def group_simultaneous_changes(self, changes: List[Dict]) -> List[List[Dict]]:
        """å°†åŒæ—¶å‘ç”Ÿçš„å˜æ›´åˆ†ç»„"""
        # ç®€åŒ–å®ç°
        return []
    
    async def queue_retry(self, sync_item: Dict, target_region: str):
        """æ’é˜Ÿé‡è¯•å¤±è´¥çš„åŒæ­¥"""
        retry_item = {
            **sync_item,
            'retry_target': target_region,
            'retry_count': sync_item.get('retry_count', 0) + 1,
            'retry_at': (datetime.now() + timedelta(minutes=1)).isoformat()
        }
        
        if retry_item['retry_count'] <= 3:  # æœ€å¤šé‡è¯•3æ¬¡
            await asyncio.sleep(60)  # ç­‰å¾…1åˆ†é’Ÿåé‡è¯•
            await self.sync_queue.put(retry_item)

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    manager = DataConsistencyManager()
    await manager.run_consistency_monitoring()

if __name__ == "__main__":
    asyncio.run(main())
```

### è¯»å†™åˆ†ç¦»ç­–ç•¥

#### 1. æ™ºèƒ½è·¯ç”±é…ç½®
```yaml
# æ•°æ®åº“è¯»å†™åˆ†ç¦»é…ç½®
apiVersion: apps/v1
kind: Deployment
metadata:
  name: database-router
  namespace: database-system
spec:
  replicas: 3
  selector:
    matchLabels:
      app: database-router
  template:
    metadata:
      labels:
        app: database-router
    spec:
      containers:
      - name: router
        image: custom/database-router:latest
        ports:
        - containerPort: 3306
        env:
        - name: PRIMARY_REGION
          value: "us-east-1"
        - name: READ_REPLICAS
          value: "us-west-2,eu-west-1"
        - name: FAILOVER_STRATEGY
          value: "promote-closest-replica"
        - name: HEALTH_CHECK_INTERVAL
          value: "5"
        volumeMounts:
        - name: config
          mountPath: /config
      volumes:
      - name: config
        configMap:
          name: database-routing-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: database-routing-config
  namespace: database-system
data:
  routing-rules.yaml: |
    rules:
    - name: "primary-write-routing"
      condition: "operation == 'WRITE'"
      action: "route-to-primary"
      primary_region: "us-east-1"
      
    - name: "read-replica-routing"
      condition: "operation == 'READ' AND consistency == 'eventual'"
      action: "route-to-nearest-replica"
      replica_selection: "latency-based"
      
    - name: "strong-consistency-reads"
      condition: "operation == 'READ' AND consistency == 'strong'"
      action: "route-to-primary"
      
    - name: "failover-routing"
      condition: "primary_unhealthy == true"
      action: "promote-replica"
      promotion_order: ["us-west-2", "eu-west-1"]
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### å»¶è¿Ÿä¼˜åŒ–ç­–ç•¥

#### 1. CDNå’Œè¾¹ç¼˜è®¡ç®—
```yaml
# å…¨çƒCDNé…ç½®
apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: global-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - "*.example.com"
  - port:
      number: 443
      name: https
      protocol: HTTPS
    hosts:
    - "*.example.com"
    tls:
      mode: SIMPLE
      credentialName: global-tls-cert
---
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: cdn-routing
spec:
  hosts:
  - "*.example.com"
  gateways:
  - global-gateway
  http:
  - match:
    - uri:
        prefix: "/static/"
    route:
    - destination:
        host: cdn-edge-cluster
        port:
          number: 80
    headers:
      response:
        set:
          cache-control: "public, max-age=31536000"
  - match:
    - uri:
        prefix: "/api/"
    route:
    - destination:
        host: app-primary-region
        port:
          number: 8080
      weight: 70
    - destination:
        host: app-secondary-region
        port:
          number: 8080
      weight: 30
```

#### 2. ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
```yaml
# å¤šçº§ç¼“å­˜é…ç½®
apiVersion: apps/v1
kind: Deployment
metadata:
  name: multi-tier-cache
spec:
  replicas: 3
  selector:
    matchLabels:
      app: multi-tier-cache
  template:
    metadata:
      labels:
        app: multi-tier-cache
    spec:
      containers:
      - name: cache-manager
        image: custom/cache-manager:latest
        env:
        - name: L1_CACHE_TTL
          value: "300"  # 5åˆ†é’Ÿ
        - name: L2_CACHE_TTL
          value: "3600" # 1å°æ—¶
        - name: L3_CACHE_TTL
          value: "86400" # 24å°æ—¶
        - name: CACHE_INVALIDATION_STRATEGY
          value: "write-through"
        ports:
        - containerPort: 6379
        volumeMounts:
        - name: cache-storage
          mountPath: /cache
      volumes:
      - name: cache-storage
        emptyDir: {}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cache-strategy-config
data:
  cache-strategy.yaml: |
    layers:
    - name: "l1-redis"
      type: "redis"
      ttl: 300
      location: "same-region"
      use_case: "hot-data"
      
    - name: "l2-memcached"
      type: "memcached"
      ttl: 3600
      location: "regional"
      use_case: "warm-data"
      
    - name: "l3-cdn"
      type: "cdn"
      ttl: 86400
      location: "global"
      use_case: "static-content"
    
    invalidation_rules:
    - pattern: "/api/users/*"
      layers: ["l1-redis", "l2-memcached"]
      trigger: "database-update"
      
    - pattern: "/static/images/*"
      layers: ["l3-cdn"]
      trigger: "content-change"
```

## ğŸ”§ å®æ–½æ£€æŸ¥æ¸…å•

### æ¶æ„è®¾è®¡é˜¶æ®µ
- [ ] è®¾è®¡å¤šåœ°åŸŸéƒ¨ç½²æ¶æ„å’Œç½‘ç»œæ‹“æ‰‘
- [ ] è§„åˆ’æ•°æ®åŒæ­¥å’Œä¸€è‡´æ€§ç­–ç•¥
- [ ] åˆ¶å®šæ•…éšœæ£€æµ‹å’Œåˆ‡æ¢æœºåˆ¶
- [ ] è®¾è®¡å…¨çƒè´Ÿè½½å‡è¡¡å’Œè·¯ç”±ç­–ç•¥
- [ ] é…ç½®å®‰å…¨éš”ç¦»å’Œè®¿é—®æ§åˆ¶
- [ ] å»ºç«‹ç›‘æ§å‘Šè­¦å’Œè¿ç»´ä½“ç³»

### éƒ¨ç½²å®æ–½é˜¶æ®µ
- [ ] éƒ¨ç½²å¤šåœ°åŸŸKubernetesé›†ç¾¤
- [ ] é…ç½®æ•°æ®åº“å¤šæ´»å¤åˆ¶
- [ ] å®æ–½åº”ç”¨å¤šåœ°åŸŸéƒ¨ç½²
- [ ] éƒ¨ç½²æ™ºèƒ½è·¯ç”±å’Œè´Ÿè½½å‡è¡¡
- [ ] é…ç½®æ•°æ®åŒæ­¥å’Œä¸€è‡´æ€§ä¿éšœ
- [ ] å®æ–½å®‰å…¨å’Œåˆè§„æ§åˆ¶

### è¿è¥ç»´æŠ¤é˜¶æ®µ
- [ ] å»ºç«‹å¸¸æ€åŒ–æ¼”ç»ƒæœºåˆ¶
- [ ] å®æ–½æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–
- [ ] ç»´æŠ¤æ•…éšœå¤„ç†æµç¨‹
- [ ] æŒç»­æ”¹è¿›æ¶æ„è®¾è®¡
- [ ] å®šæœŸè¯„ä¼°å’Œæ›´æ–°ç­–ç•¥
- [ ] åŸ¹å…»è·¨åœ°åŸŸåä½œèƒ½åŠ›

---

*æœ¬æ–‡æ¡£ä¸ºä¼ä¸šçº§è·¨åŒºåŸŸå®¹ç¾éƒ¨ç½²æä¾›å®Œæ•´çš„æ¶æ„è®¾è®¡å’Œå®æ–½æŒ‡å¯¼*