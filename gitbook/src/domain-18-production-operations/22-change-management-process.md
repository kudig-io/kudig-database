# 22-å˜æ›´ç®¡ç†æµç¨‹

> **é€‚ç”¨èŒƒå›´**: Kubernetes v1.25-v1.32 | **ç»´æŠ¤çŠ¶æ€**: ğŸ”§ æŒç»­æ›´æ–°ä¸­ | **ä¸“å®¶çº§åˆ«**: â­â­â­â­â­

## ğŸ“‹ æ¦‚è¿°

å˜æ›´ç®¡ç†æµç¨‹æ˜¯ä¿éšœç”Ÿäº§ç¯å¢ƒç¨³å®šæ€§çš„æ ¸å¿ƒæœºåˆ¶ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»RFCæµç¨‹ã€ç°åº¦å‘å¸ƒç­–ç•¥å’Œå›æ»šæœºåˆ¶çš„æœ€ä½³å®è·µã€‚

## ğŸ¯ å˜æ›´ç®¡ç†æ¡†æ¶

### RFCæµç¨‹è®¾è®¡

#### 1. å˜æ›´è¯·æ±‚æ¨¡æ¿
```yaml
# RFCè‡ªå®šä¹‰èµ„æºå®šä¹‰
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: rfcrequests.change.example.com
spec:
  group: change.example.com
  versions:
  - name: v1
    served: true
    storage: true
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              title:
                type: string
              description:
                type: string
              changeType:
                type: string
                enum: [infrastructure, application, configuration, security, maintenance]
              priority:
                type: string
                enum: [critical, high, medium, low]
              impact:
                type: string
                enum: [none, low, medium, high, critical]
              riskLevel:
                type: string
                enum: [low, medium, high, critical]
              affectedComponents:
                type: array
                items:
                  type: string
              rollbackPlan:
                type: object
                properties:
                  procedure:
                    type: string
                  timeframe:
                    type: string
                  validation:
                    type: string
              deploymentStrategy:
                type: object
                properties:
                  type:
                    type: string
                    enum: [blue-green, canary, rolling, recreate]
                  canaryPercentage:
                    type: integer
                  rolloutDuration:
                    type: string
              approvalChain:
                type: array
                items:
                  type: object
                  properties:
                    approver:
                      type: string
                    role:
                      type: string
                    required:
                      type: boolean
              schedule:
                type: object
                properties:
                  plannedStart:
                    type: string
                    format: date-time
                  plannedEnd:
                    type: string
                    format: date-time
                  maintenanceWindow:
                    type: string
              testingEvidence:
                type: object
                properties:
                  unitTestsPassed:
                    type: boolean
                  integrationTestsPassed:
                    type: boolean
                  performanceTestsPassed:
                    type: boolean
                  securityTestsPassed:
                    type: boolean
          status:
            type: object
            properties:
              state:
                type: string
                enum: [draft, submitted, approved, rejected, scheduled, in-progress, completed, failed, rolled-back]
              approvals:
                type: object
                properties:
                  required:
                    type: integer
                  received:
                    type: integer
                  approvers:
                    type: array
                    items:
                      type: string
              deploymentStatus:
                type: object
                properties:
                  currentPhase:
                    type: string
                  progress:
                    type: integer
                  startTime:
                    type: string
                    format: date-time
                  endTime:
                    type: string
                    format: date-time
              rollbackStatus:
                type: object
                properties:
                  initiated:
                    type: boolean
                  reason:
                    type: string
                  completionTime:
                    type: string
                    format: date-time
  scope: Namespaced
  names:
    plural: rfcrequests
    singular: rfcrequest
    kind: RFCRequest
    shortNames: [rfc]
---
# RFCè¯·æ±‚ç¤ºä¾‹
apiVersion: change.example.com/v1
kind: RFCRequest
metadata:
  name: upgrade-kubernetes-cluster
  namespace: change-management
spec:
  title: "Upgrade Kubernetes cluster from v1.27 to v1.28"
  description: "Upgrade production Kubernetes cluster to latest stable version with zero downtime"
  changeType: "infrastructure"
  priority: "high"
  impact: "medium"
  riskLevel: "medium"
  affectedComponents:
  - "control-plane"
  - "worker-nodes"
  - "core-addons"
  rollbackPlan:
    procedure: "Execute rollback script to revert etcd snapshot and downgrade control plane components"
    timeframe: "30 minutes"
    validation: "Verify cluster health and application availability"
  deploymentStrategy:
    type: "blue-green"
    rolloutDuration: "2 hours"
  approvalChain:
  - approver: "platform-architect"
    role: "technical-lead"
    required: true
  - approver: "sre-manager"
    role: "operations-lead"
    required: true
  - approver: "security-officer"
    role: "security-lead"
    required: true
  schedule:
    plannedStart: "2024-02-15T02:00:00Z"
    plannedEnd: "2024-02-15T06:00:00Z"
    maintenanceWindow: "4 hours"
  testingEvidence:
    unitTestsPassed: true
    integrationTestsPassed: true
    performanceTestsPassed: true
    securityTestsPassed: true
```

#### 2. RFCå®¡æ‰¹å·¥ä½œæµ
```python
#!/usr/bin/env python3
# RFCå®¡æ‰¹å·¥ä½œæµå¼•æ“

import asyncio
from kubernetes import client, config
from datetime import datetime, timedelta
import json
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

class RFCApprovalWorkflow:
    def __init__(self):
        config.load_kube_config()
        self.custom_objects = client.CustomObjectsApi()
        self.core_v1 = client.CoreV1Api()
        
        self.approvers = {
            'platform-architect': {
                'email': 'architect@example.com',
                'role': 'technical-lead',
                'approval_threshold': 'medium'
            },
            'sre-manager': {
                'email': 'sre-manager@example.com',
                'role': 'operations-lead',
                'approval_threshold': 'high'
            },
            'security-officer': {
                'email': 'security@example.com',
                'role': 'security-lead',
                'approval_threshold': 'critical'
            }
        }
        
        self.risk_approval_mapping = {
            'low': ['platform-architect'],
            'medium': ['platform-architect', 'sre-manager'],
            'high': ['platform-architect', 'sre-manager', 'security-officer'],
            'critical': ['platform-architect', 'sre-manager', 'security-officer', 'cto']
        }
    
    async def process_rfc_submission(self, rfc_name, namespace):
        """å¤„ç†RFCæäº¤"""
        try:
            # è·å–RFCå¯¹è±¡
            rfc = self.custom_objects.get_namespaced_custom_object(
                group='change.example.com',
                version='v1',
                namespace=namespace,
                plural='rfcrequests',
                name=rfc_name
            )
            
            # éªŒè¯RFCå®Œæ•´æ€§
            validation_result = await self.validate_rfc(rfc)
            if not validation_result['valid']:
                await self.reject_rfc(rfc_name, namespace, validation_result['errors'])
                return
            
            # æ›´æ–°çŠ¶æ€ä¸ºsubmitted
            await self.update_rfc_status(rfc_name, namespace, 'submitted')
            
            # å¯åŠ¨å®¡æ‰¹æµç¨‹
            await self.initiate_approval_process(rfc)
            
            # å‘é€é€šçŸ¥
            await self.send_submission_notifications(rfc)
            
        except Exception as e:
            print(f"Error processing RFC submission: {e}")
    
    async def validate_rfc(self, rfc):
        """éªŒè¯RFCå®Œæ•´æ€§"""
        errors = []
        spec = rfc['spec']
        
        # å¿…éœ€å­—æ®µæ£€æŸ¥
        required_fields = ['title', 'description', 'changeType', 'priority', 'riskLevel']
        for field in required_fields:
            if field not in spec or not spec[field]:
                errors.append(f"Missing required field: {field}")
        
        # é£é™©çº§åˆ«å’Œå®¡æ‰¹é“¾ä¸€è‡´æ€§æ£€æŸ¥
        risk_level = spec.get('riskLevel', '')
        required_approvers = self.risk_approval_mapping.get(risk_level, [])
        
        if 'approvalChain' in spec:
            chain_approvers = [approver['approver'] for approver in spec['approvalChain']]
            for required_approver in required_approvers:
                if required_approver not in chain_approvers:
                    errors.append(f"Missing required approver: {required_approver}")
        else:
            errors.append("Missing approval chain")
        
        # æ—¶é—´çª—å£åˆç†æ€§æ£€æŸ¥
        if 'schedule' in spec:
            schedule = spec['schedule']
            if 'plannedStart' in schedule and 'plannedEnd' in schedule:
                start_time = datetime.fromisoformat(schedule['plannedStart'].replace('Z', '+00:00'))
                end_time = datetime.fromisoformat(schedule['plannedEnd'].replace('Z', '+00:00'))
                
                if end_time <= start_time:
                    errors.append("End time must be after start time")
                
                duration = end_time - start_time
                if duration > timedelta(hours=24):
                    errors.append("Maintenance window exceeds 24 hours")
        
        return {
            'valid': len(errors) == 0,
            'errors': errors
        }
    
    async def initiate_approval_process(self, rfc):
        """å¯åŠ¨å®¡æ‰¹æµç¨‹"""
        rfc_name = rfc['metadata']['name']
        namespace = rfc['metadata']['namespace']
        risk_level = rfc['spec']['riskLevel']
        
        required_approvers = self.risk_approval_mapping[risk_level]
        
        # åˆ›å»ºå®¡æ‰¹ä»»åŠ¡
        for approver_name in required_approvers:
            approver_info = self.approvers.get(approver_name)
            if approver_info:
                await self.create_approval_task(rfc_name, namespace, approver_name, approver_info)
        
        # æ›´æ–°RFCçŠ¶æ€å’Œå®¡æ‰¹è¿›åº¦
        await self.update_approval_status(rfc_name, namespace, {
            'required': len(required_approvers),
            'received': 0,
            'approvers': []
        })
    
    async def create_approval_task(self, rfc_name, namespace, approver_name, approver_info):
        """åˆ›å»ºå®¡æ‰¹ä»»åŠ¡"""
        task = {
            'apiVersion': 'batch/v1',
            'kind': 'Job',
            'metadata': {
                'name': f"approval-{rfc_name}-{approver_name}",
                'namespace': namespace,
                'labels': {
                    'rfc-name': rfc_name,
                    'approver': approver_name,
                    'approval-task': 'true'
                }
            },
            'spec': {
                'template': {
                    'spec': {
                        'containers': [{
                            'name': 'approval-notifier',
                            'image': 'custom/approval-notifier:latest',
                            'env': [
                                {'name': 'RFC_NAME', 'value': rfc_name},
                                {'name': 'APPROVER_EMAIL', 'value': approver_info['email']},
                                {'name': 'APPROVER_NAME', 'value': approver_name},
                                {'name': 'NAMESPACE', 'value': namespace}
                            ]
                        }],
                        'restartPolicy': 'Never'
                    }
                }
            }
        }
        
        # åˆ›å»ºå®¡æ‰¹é€šçŸ¥Job
        try:
            self.core_v1.create_namespaced_job(namespace=namespace, body=task)
            await self.send_approval_notification(rfc_name, approver_info)
        except Exception as e:
            print(f"Error creating approval task for {approver_name}: {e}")
    
    async def send_approval_notification(self, rfc_name, approver_info):
        """å‘é€å®¡æ‰¹é€šçŸ¥"""
        try:
            # æ„é€ é‚®ä»¶å†…å®¹
            msg = MIMEMultipart()
            msg['From'] = 'change-management@example.com'
            msg['To'] = approver_info['email']
            msg['Subject'] = f'RFC Approval Required: {rfc_name}'
            
            body = f"""
            Dear {approver_info['role']},
            
            A new RFC requires your approval:
            
            RFC Name: {rfc_name}
            Approval Required: Yes
            Deadline: 24 hours from receipt
            
            Please review and approve through the change management portal.
            
            Best regards,
            Change Management System
            """
            
            msg.attach(MIMEText(body, 'plain'))
            
            # å‘é€é‚®ä»¶ï¼ˆç®€åŒ–å®ç°ï¼‰
            print(f"Sending approval notification to {approver_info['email']}")
            # å®é™…å®ç°åº”è¯¥ä½¿ç”¨SMTPæœåŠ¡å™¨å‘é€é‚®ä»¶
            
        except Exception as e:
            print(f"Error sending approval notification: {e}")
    
    async def process_approval(self, rfc_name, namespace, approver, decision, comments=""):
        """å¤„ç†å®¡æ‰¹å†³å®š"""
        try:
            # è®°å½•å®¡æ‰¹å†³å®š
            approval_record = {
                'approver': approver,
                'decision': decision,
                'comments': comments,
                'timestamp': datetime.now().isoformat()
            }
            
            # æ›´æ–°RFCçŠ¶æ€
            rfc = self.custom_objects.get_namespaced_custom_object(
                group='change.example.com',
                version='v1',
                namespace=namespace,
                plural='rfcrequests',
                name=rfc_name
            )
            
            # æ›´æ–°å®¡æ‰¹çŠ¶æ€
            current_approvals = rfc.get('status', {}).get('approvals', {})
            current_approvals['received'] = current_approvals.get('received', 0) + 1
            current_approvals['approvers'] = current_approvals.get('approvers', []) + [approver]
            
            await self.update_approval_status(rfc_name, namespace, current_approvals)
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å¿…éœ€å®¡æ‰¹éƒ½å·²å®Œæˆ
            required_approvals = current_approvals.get('required', 0)
            received_approvals = current_approvals.get('received', 0)
            
            if decision == 'approved':
                if received_approvals >= required_approvals:
                    await self.approve_rfc(rfc_name, namespace)
                else:
                    print(f"Waiting for {required_approvals - received_approvals} more approvals")
            else:
                await self.reject_rfc(rfc_name, namespace, [f"Rejected by {approver}: {comments}"])
                
        except Exception as e:
            print(f"Error processing approval: {e}")
    
    async def approve_rfc(self, rfc_name, namespace):
        """æ‰¹å‡†RFC"""
        await self.update_rfc_status(rfc_name, namespace, 'approved')
        
        # å®‰æ’å˜æ›´æ‰§è¡Œ
        await self.schedule_change_execution(rfc_name, namespace)
        
        # å‘é€æ‰¹å‡†é€šçŸ¥
        await self.send_approval_completion_notification(rfc_name, namespace)
    
    async def reject_rfc(self, rfc_name, namespace, reasons):
        """æ‹’ç»RFC"""
        await self.update_rfc_status(rfc_name, namespace, 'rejected')
        
        # è®°å½•æ‹’ç»åŸå› 
        rejection_record = {
            'reasons': reasons,
            'rejected_at': datetime.now().isoformat()
        }
        
        # å‘é€æ‹’ç»é€šçŸ¥
        await self.send_rejection_notification(rfc_name, namespace, reasons)
    
    async def schedule_change_execution(self, rfc_name, namespace):
        """å®‰æ’å˜æ›´æ‰§è¡Œ"""
        try:
            rfc = self.custom_objects.get_namespaced_custom_object(
                group='change.example.com',
                version='v1',
                namespace=namespace,
                plural='rfcrequests',
                name=rfc_name
            )
            
            # åˆ›å»ºCronJobæ¥æ‰§è¡Œå˜æ›´
            schedule_time = rfc['spec']['schedule']['plannedStart']
            
            cron_job = {
                'apiVersion': 'batch/v1',
                'kind': 'CronJob',
                'metadata': {
                    'name': f"execute-{rfc_name}",
                    'namespace': namespace
                },
                'spec': {
                    'schedule': self.convert_to_cron_expression(schedule_time),
                    'jobTemplate': {
                        'spec': {
                            'template': {
                                'spec': {
                                    'containers': [{
                                        'name': 'change-executor',
                                        'image': 'custom/change-executor:latest',
                                        'env': [
                                            {'name': 'RFC_NAME', 'value': rfc_name},
                                            {'name': 'NAMESPACE', 'value': namespace}
                                        ]
                                    }],
                                    'restartPolicy': 'Never'
                                }
                            }
                        }
                    }
                }
            }
            
            self.core_v1.create_namespaced_cron_job(namespace=namespace, body=cron_job)
            await self.update_rfc_status(rfc_name, namespace, 'scheduled')
            
        except Exception as e:
            print(f"Error scheduling change execution: {e}")
    
    def convert_to_cron_expression(self, iso_time):
        """å°†ISOæ—¶é—´è½¬æ¢ä¸ºCronè¡¨è¾¾å¼"""
        dt = datetime.fromisoformat(iso_time.replace('Z', '+00:00'))
        return f"{dt.minute} {dt.hour} {dt.day} {dt.month} *"
    
    async def update_rfc_status(self, rfc_name, namespace, status):
        """æ›´æ–°RFCçŠ¶æ€"""
        try:
            # è¿™é‡Œåº”è¯¥ä½¿ç”¨PATCHæ“ä½œæ›´æ–°çŠ¶æ€
            print(f"Updating RFC {rfc_name} status to {status}")
            
        except Exception as e:
            print(f"Error updating RFC status: {e}")
    
    async def update_approval_status(self, rfc_name, namespace, approval_status):
        """æ›´æ–°å®¡æ‰¹çŠ¶æ€"""
        try:
            print(f"Updating approval status for {rfc_name}: {approval_status}")
            
        except Exception as e:
            print(f"Error updating approval status: {e}")
    
    async def send_submission_notifications(self, rfc):
        """å‘é€æäº¤é€šçŸ¥"""
        print(f"Sending submission notifications for RFC {rfc['metadata']['name']}")
    
    async def send_approval_completion_notification(self, rfc_name, namespace):
        """å‘é€å®¡æ‰¹å®Œæˆé€šçŸ¥"""
        print(f"Sending approval completion notification for {rfc_name}")
    
    async def send_rejection_notification(self, rfc_name, namespace, reasons):
        """å‘é€æ‹’ç»é€šçŸ¥"""
        print(f"Sending rejection notification for {rfc_name}: {reasons}")

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    workflow = RFCApprovalWorkflow()
    
    # å¤„ç†RFCæäº¤
    await workflow.process_rfc_submission('upgrade-kubernetes-cluster', 'change-management')
    
    # æ¨¡æ‹Ÿå®¡æ‰¹è¿‡ç¨‹
    await asyncio.sleep(5)  # ç­‰å¾…å®¡æ‰¹ä»»åŠ¡åˆ›å»º
    
    # å¤„ç†å®¡æ‰¹å†³å®š
    await workflow.process_approval(
        'upgrade-kubernetes-cluster', 
        'change-management', 
        'platform-architect', 
        'approved', 
        'Change looks good, proceed with caution'
    )

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ¨ ç°åº¦å‘å¸ƒç­–ç•¥

### æ¸è¿›å¼éƒ¨ç½²é…ç½®

#### 1. Argo Rolloutsé…ç½®
```yaml
# Argo Rolloutsç°åº¦å‘å¸ƒé…ç½®
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: progressive-deployment
  namespace: production
spec:
  replicas: 10
  strategy:
    canary:
      steps:
      # é˜¶æ®µ1: 10%æµé‡ï¼ŒæŒç»­10åˆ†é’Ÿ
      - setWeight: 10
      - pause: {duration: 10m}
      - analysis:
          templates:
          - templateName: error-rate
          - templateName: latency
          startingStep: 1
      
      # é˜¶æ®µ2: 30%æµé‡ï¼ŒæŒç»­15åˆ†é’Ÿ
      - setWeight: 30
      - pause: {duration: 15m}
      - analysis:
          templates:
          - templateName: error-rate
          - templateName: latency
          - templateName: business-metrics
          startingStep: 4
      
      # é˜¶æ®µ3: 60%æµé‡ï¼ŒæŒç»­20åˆ†é’Ÿ
      - setWeight: 60
      - pause: {duration: 20m}
      - analysis:
          templates:
          - templateName: comprehensive-analysis
          startingStep: 7
      
      # é˜¶æ®µ4: 100%æµé‡
      - setWeight: 100
      - pause: {duration: 30m}  # æœ€ç»ˆè§‚å¯ŸæœŸ
      
      # è‡ªåŠ¨å›æ»šé…ç½®
      trafficRouting:
        istio:
          virtualService:
            name: app-vsvc
            routes:
            - primary
      scaleDownDelaySeconds: 300
      
  revisionHistoryLimit: 3
  selector:
    matchLabels:
      app: progressive-app
  template:
    metadata:
      labels:
        app: progressive-app
    spec:
      containers:
      - name: app
        image: myapp:v2.0.0
        ports:
        - containerPort: 8080
        resources:
          requests:
            memory: "64Mi"
            cpu: "250m"
          limits:
            memory: "128Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
---
# åˆ†ææ¨¡æ¿é…ç½®
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: error-rate
spec:
  args:
  - name: service-name
  - name: namespace
  metrics:
  - name: error-rate
    interval: 1m
    count: 5
    # é”™è¯¯ç‡è¶…è¿‡1%åˆ™å¤±è´¥
    failureCondition: result[0] > 0.01
    provider:
      prometheus:
        address: http://prometheus:9090
        query: |
          sum(rate(http_requests_total{job="{{args.service-name}}",status=~"5.."}[5m]))
          /
          sum(rate(http_requests_total{job="{{args.service-name}}"}[5m]))
---
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: latency
spec:
  args:
  - name: service-name
  - name: namespace
  metrics:
  - name: latency-p95
    interval: 1m
    count: 5
    # 95%å»¶è¿Ÿè¶…è¿‡500msåˆ™å¤±è´¥
    failureCondition: result[0] > 0.5
    provider:
      prometheus:
        address: http://prometheus:9090
        query: |
          histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="{{args.service-name}}"}[5m]))
---
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: business-metrics
spec:
  args:
  - name: service-name
  metrics:
  - name: conversion-rate
    interval: 2m
    count: 3
    # è½¬åŒ–ç‡ä¸‹é™è¶…è¿‡20%åˆ™å¤±è´¥
    failureCondition: (result[0] - result[1]) / result[1] < -0.2
    provider:
      prometheus:
        address: http://prometheus:9090
        query: |
          sum(rate(business_conversion_total[10m])) / sum(rate(business_visitors_total[10m]))
---
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: comprehensive-analysis
spec:
  metrics:
  - name: error-rate
    interval: 30s
    count: 10
    failureCondition: result[0] > 0.005
    provider:
      prometheus:
        address: http://prometheus:9090
        query: sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m]))
        
  - name: cpu-usage
    interval: 1m
    count: 5
    failureCondition: result[0] > 0.8
    provider:
      prometheus:
        address: http://prometheus:9090
        query: avg(rate(container_cpu_usage_seconds_total[5m]))
        
  - name: memory-usage
    interval: 1m
    count: 5
    failureCondition: result[0] > 0.85
    provider:
      prometheus:
        address: http://prometheus:9090
        query: avg(container_memory_working_set_bytes) / avg(kube_pod_container_resource_limits{resource="memory"})
```

#### 2. Istioæµé‡ç®¡ç†é…ç½®
```yaml
# Istioè™šæ‹ŸæœåŠ¡é…ç½®
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: app-canary
  namespace: production
spec:
  hosts:
  - app.example.com
  gateways:
  - app-gateway
  http:
  - route:
    - destination:
        host: app-stable.production.svc.cluster.local
        port:
          number: 80
      weight: 90
    - destination:
        host: app-canary.production.svc.cluster.local
        port:
          number: 80
      weight: 10
    retries:
      attempts: 3
      perTryTimeout: 2s
    timeout: 5s
---
# Istioç›®æ ‡è§„åˆ™é…ç½®
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: app-destination-rule
  namespace: production
spec:
  host: app.production.svc.cluster.local
  subsets:
  - name: stable
    labels:
      version: v1.0.0
  - name: canary
    labels:
      version: v2.0.0
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 1000
        maxRequestsPerConnection: 10
    outlierDetection:
      consecutive5xxErrors: 5
      interval: 30s
      baseEjectionTime: 30s
```

## ğŸ” å›æ»šæœºåˆ¶

### è‡ªåŠ¨åŒ–å›æ»šé…ç½®

#### 1. å›æ»šè§¦å‘å™¨
```python
#!/usr/bin/env python3
# è‡ªåŠ¨åŒ–å›æ»šæ§åˆ¶å™¨

import asyncio
from kubernetes import client, config
from datetime import datetime, timedelta
import json

class AutomatedRollbackController:
    def __init__(self):
        config.load_kube_config()
        self.apps_v1 = client.AppsV1Api()
        self.core_v1 = client.CoreV1Api()
        self.custom_objects = client.CustomObjectsApi()
        
        self.rollback_triggers = {
            'error_rate': {
                'threshold': 0.02,  # 2%é”™è¯¯ç‡
                'window': '5m',
                'consecutive_periods': 3
            },
            'latency': {
                'threshold': 1.0,   # 1ç§’å»¶è¿Ÿ
                'window': '5m',
                'consecutive_periods': 3
            },
            'availability': {
                'threshold': 0.95,  # 95%å¯ç”¨æ€§
                'window': '10m',
                'consecutive_periods': 2
            },
            'business_impact': {
                'threshold': -0.15, # 15%ä¸šåŠ¡æŒ‡æ ‡ä¸‹é™
                'window': '15m',
                'consecutive_periods': 2
            }
        }
        
        self.rollback_history = {}
    
    async def monitor_deployment_health(self, deployment_name, namespace):
        """ç›‘æ§éƒ¨ç½²å¥åº·çŠ¶æ€"""
        while True:
            try:
                # æ£€æŸ¥éƒ¨ç½²çŠ¶æ€
                deployment = self.apps_v1.read_namespaced_deployment(deployment_name, namespace)
                
                # è·å–ç›¸å…³æŒ‡æ ‡
                metrics = await self.collect_deployment_metrics(deployment_name, namespace)
                
                # è¯„ä¼°æ˜¯å¦éœ€è¦å›æ»š
                rollback_needed, reason = await self.evaluate_rollback_condition(
                    deployment, metrics
                )
                
                if rollback_needed:
                    await self.execute_rollback(deployment_name, namespace, reason, metrics)
                
                # æ£€æŸ¥å›æ»šåçŠ¶æ€
                await self.monitor_post_rollback_health(deployment_name, namespace)
                
                await asyncio.sleep(60)  # 1åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                print(f"Error monitoring deployment health: {e}")
                await asyncio.sleep(300)  # å‡ºé”™æ—¶ç­‰å¾…5åˆ†é’Ÿ
    
    async def collect_deployment_metrics(self, deployment_name, namespace):
        """æ”¶é›†éƒ¨ç½²æŒ‡æ ‡"""
        metrics = {
            'error_rate': await self.get_error_rate(deployment_name, namespace),
            'latency_p95': await self.get_latency(deployment_name, namespace),
            'availability': await self.get_availability(deployment_name, namespace),
            'business_metrics': await self.get_business_metrics(deployment_name, namespace),
            'resource_usage': await self.get_resource_usage(deployment_name, namespace)
        }
        
        return metrics
    
    async def get_error_rate(self, deployment_name, namespace):
        """è·å–é”™è¯¯ç‡"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”æŸ¥è¯¢Prometheus
        import random
        return random.uniform(0, 0.05)
    
    async def get_latency(self, deployment_name, namespace):
        """è·å–å»¶è¿ŸæŒ‡æ ‡"""
        import random
        return random.uniform(0.1, 2.0)
    
    async def get_availability(self, deployment_name, namespace):
        """è·å–å¯ç”¨æ€§"""
        import random
        return random.uniform(0.90, 1.0)
    
    async def get_business_metrics(self, deployment_name, namespace):
        """è·å–ä¸šåŠ¡æŒ‡æ ‡"""
        import random
        return {
            'conversion_rate': random.uniform(0.02, 0.08),
            'revenue_per_user': random.uniform(10, 50),
            'user_satisfaction': random.uniform(0.7, 0.95)
        }
    
    async def get_resource_usage(self, deployment_name, namespace):
        """è·å–èµ„æºä½¿ç”¨ç‡"""
        import random
        return {
            'cpu_usage': random.uniform(0.3, 0.9),
            'memory_usage': random.uniform(0.4, 0.85),
            'disk_usage': random.uniform(0.2, 0.7)
        }
    
    async def evaluate_rollback_condition(self, deployment, metrics):
        """è¯„ä¼°å›æ»šæ¡ä»¶"""
        reasons = []
        
        # é”™è¯¯ç‡æ£€æŸ¥
        if metrics['error_rate'] > self.rollback_triggers['error_rate']['threshold']:
            reasons.append(f"High error rate: {metrics['error_rate']:.2%}")
        
        # å»¶è¿Ÿæ£€æŸ¥
        if metrics['latency_p95'] > self.rollback_triggers['latency']['threshold']:
            reasons.append(f"High latency: {metrics['latency_p95']:.2f}s")
        
        # å¯ç”¨æ€§æ£€æŸ¥
        if metrics['availability'] < self.rollback_triggers['availability']['threshold']:
            reasons.append(f"Low availability: {metrics['availability']:.1%}")
        
        # ä¸šåŠ¡å½±å“æ£€æŸ¥
        business_change = self.calculate_business_impact_change(metrics['business_metrics'])
        if business_change < self.rollback_triggers['business_impact']['threshold']:
            reasons.append(f"Negative business impact: {business_change:.1%}")
        
        return len(reasons) > 0, '; '.join(reasons)
    
    def calculate_business_impact_change(self, current_metrics):
        """è®¡ç®—ä¸šåŠ¡å½±å“å˜åŒ–"""
        # ç®€åŒ–å®ç°ï¼Œæ¯”è¾ƒå½“å‰å’Œå†å²æ•°æ®
        baseline_conversion = 0.05  # åŸºçº¿è½¬åŒ–ç‡
        current_conversion = current_metrics.get('conversion_rate', 0)
        
        if baseline_conversion > 0:
            return (current_conversion - baseline_conversion) / baseline_conversion
        return 0
    
    async def execute_rollback(self, deployment_name, namespace, reason, metrics):
        """æ‰§è¡Œå›æ»š"""
        try:
            print(f"Executing rollback for {deployment_name} in {namespace}")
            print(f"Reason: {reason}")
            print(f"Metrics: {json.dumps(metrics, indent=2)}")
            
            # è®°å½•å›æ»šäº‹ä»¶
            rollback_event = {
                'deployment': deployment_name,
                'namespace': namespace,
                'timestamp': datetime.now().isoformat(),
                'reason': reason,
                'triggering_metrics': metrics,
                'rollback_method': 'automated'
            }
            
            # æ‰§è¡Œå›æ»šæ“ä½œ
            await self.perform_deployment_rollback(deployment_name, namespace)
            
            # æ›´æ–°å›æ»šå†å²
            if deployment_name not in self.rollback_history:
                self.rollback_history[deployment_name] = []
            self.rollback_history[deployment_name].append(rollback_event)
            
            # å‘é€å‘Šè­¦é€šçŸ¥
            await self.send_rollback_notification(deployment_name, namespace, reason)
            
            # è®°å½•åˆ°å®¡è®¡æ—¥å¿—
            await self.log_rollback_event(rollback_event)
            
        except Exception as e:
            print(f"Error executing rollback: {e}")
            await self.handle_rollback_failure(deployment_name, namespace, str(e))
    
    async def perform_deployment_rollback(self, deployment_name, namespace):
        """æ‰§è¡Œéƒ¨ç½²å›æ»š"""
        try:
            # æ–¹æ³•1: å›æ»šåˆ°ä¸Šä¸€ä¸ªä¿®è®¢ç‰ˆæœ¬
            rollback_body = {
                'kind': 'DeploymentRollback',
                'apiVersion': 'apps/v1',
                'name': deployment_name,
                'rollbackTo': {
                    'revision': 0  # 0è¡¨ç¤ºå›æ»šåˆ°ä¸Šä¸€ä¸ªç‰ˆæœ¬
                }
            }
            
            # æ³¨æ„: DeploymentRollback APIå·²è¢«å¼ƒç”¨ï¼Œä½¿ç”¨ä»¥ä¸‹æ›¿ä»£æ–¹æ¡ˆ
            
            # æ–¹æ³•2: ä½¿ç”¨ä¿®è®¢å†å²å›æ»š
            deployment = self.apps_v1.read_namespaced_deployment(deployment_name, namespace)
            
            # è·å–ä¿®è®¢å†å²
            rs_list = self.apps_v1.list_namespaced_replica_set(
                namespace,
                label_selector=f'app={deployment.spec.selector.match_labels["app"]}'
            )
            
            # æ‰¾åˆ°ä¸Šä¸€ä¸ªç¨³å®šçš„ä¿®è®¢ç‰ˆæœ¬
            previous_revision = self.find_previous_stable_revision(rs_list.items, deployment)
            
            if previous_revision:
                # æ›´æ–°éƒ¨ç½²åˆ°ä¹‹å‰çš„ç‰ˆæœ¬
                deployment.spec.template = previous_revision.spec.template
                self.apps_v1.patch_namespaced_deployment(
                    deployment_name, namespace, deployment
                )
                print(f"Rolled back to revision: {previous_revision.metadata.name}")
            else:
                print("No previous stable revision found")
                
        except Exception as e:
            print(f"Error performing deployment rollback: {e}")
            raise
    
    def find_previous_stable_revision(self, replica_sets, current_deployment):
        """æ‰¾åˆ°ä¹‹å‰ç¨³å®šçš„ä¿®è®¢ç‰ˆæœ¬"""
        # è¿‡æ»¤å‡ºæˆåŠŸçš„ReplicaSet
        successful_rs = [
            rs for rs in replica_sets
            if rs.status.replicas == rs.status.ready_replicas
            and rs.metadata.name != current_deployment.metadata.name
        ]
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„ç¨³å®šç‰ˆæœ¬
        if successful_rs:
            return sorted(successful_rs, key=lambda x: x.metadata.creation_timestamp)[-1]
        return None
    
    async def monitor_post_rollback_health(self, deployment_name, namespace):
        """ç›‘æ§å›æ»šåå¥åº·çŠ¶æ€"""
        print(f"Monitoring post-rollback health for {deployment_name}")
        
        # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©ç³»ç»Ÿç¨³å®š
        await asyncio.sleep(300)  # 5åˆ†é’Ÿ
        
        # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦æ¢å¤æ­£å¸¸
        metrics = await self.collect_deployment_metrics(deployment_name, namespace)
        is_stable, stability_reason = await self.evaluate_system_stability(metrics)
        
        if is_stable:
            print(f"System stabilized after rollback: {stability_reason}")
        else:
            print(f"System still unstable after rollback: {stability_reason}")
            # å¯èƒ½éœ€è¦è¿›ä¸€æ­¥çš„äººå·¥å¹²é¢„
    
    async def evaluate_system_stability(self, metrics):
        """è¯„ä¼°ç³»ç»Ÿç¨³å®šæ€§"""
        stable_indicators = []
        
        if metrics['error_rate'] < 0.01:
            stable_indicators.append("Error rate normalized")
        
        if metrics['latency_p95'] < 0.5:
            stable_indicators.append("Latency improved")
        
        if metrics['availability'] > 0.98:
            stable_indicators.append("High availability restored")
        
        is_stable = len(stable_indicators) >= 2
        reason = "; ".join(stable_indicators) if stable_indicators else "Multiple metrics still problematic"
        
        return is_stable, reason
    
    async def send_rollback_notification(self, deployment_name, namespace, reason):
        """å‘é€å›æ»šé€šçŸ¥"""
        notification = {
            'type': 'rollback_executed',
            'deployment': f"{namespace}/{deployment_name}",
            'reason': reason,
            'timestamp': datetime.now().isoformat(),
            'recipients': ['sre-team@example.com', 'platform-team@example.com']
        }
        
        print(f"ROLLBACK NOTIFICATION: {json.dumps(notification, indent=2)}")
        # å®é™…å®ç°åº”è¯¥å‘é€é‚®ä»¶æˆ–Slacké€šçŸ¥
    
    async def log_rollback_event(self, rollback_event):
        """è®°å½•å›æ»šäº‹ä»¶åˆ°å®¡è®¡æ—¥å¿—"""
        try:
            # å†™å…¥å®¡è®¡æ—¥å¿—
            log_entry = {
                'event_type': 'automated_rollback',
                'timestamp': rollback_event['timestamp'],
                'deployment': rollback_event['deployment'],
                'namespace': rollback_event['namespace'],
                'reason': rollback_event['reason'],
                'triggering_metrics': rollback_event['triggering_metrics']
            }
            
            # è¿™é‡Œåº”è¯¥å†™å…¥åˆ°ä¸“é—¨çš„å®¡è®¡æ—¥å¿—ç³»ç»Ÿ
            print(f"Audit log entry: {json.dumps(log_entry)}")
            
        except Exception as e:
            print(f"Error logging rollback event: {e}")
    
    async def handle_rollback_failure(self, deployment_name, namespace, error):
        """å¤„ç†å›æ»šå¤±è´¥"""
        print(f"Rollback failed for {deployment_name}: {error}")
        
        # å‘é€ç´§æ€¥é€šçŸ¥
        emergency_notification = {
            'type': 'rollback_failure',
            'deployment': f"{namespace}/{deployment_name}",
            'error': error,
            'timestamp': datetime.now().isoformat(),
            'recipients': ['oncall-engineer@example.com', 'sre-manager@example.com']
        }
        
        print(f"EMERGENCY NOTIFICATION: {json.dumps(emergency_notification, indent=2)}")
        
        # å¯èƒ½éœ€è¦å¯åŠ¨äººå·¥å¹²é¢„æµç¨‹

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    controller = AutomatedRollbackController()
    
    # ç›‘æ§ç‰¹å®šéƒ¨ç½²çš„å¥åº·çŠ¶æ€
    await controller.monitor_deployment_health('my-app', 'production')

if __name__ == "__main__":
    asyncio.run(main())
```

#### 2. æ‰‹åŠ¨å›æ»šè„šæœ¬
```bash
#!/bin/bash
# æ‰‹åŠ¨å›æ»šè„šæœ¬

set -e

DEPLOYMENT_NAME="$1"
NAMESPACE="${2:-default}"

# éªŒè¯å‚æ•°
if [[ -z "$DEPLOYMENT_NAME" ]]; then
    echo "Usage: $0 <deployment-name> [namespace]"
    exit 1
fi

echo "Starting manual rollback for deployment: $DEPLOYMENT_NAME in namespace: $NAMESPACE"

# å‡½æ•°å®šä¹‰
check_deployment_exists() {
    if ! kubectl get deployment "$DEPLOYMENT_NAME" -n "$NAMESPACE" >/dev/null 2>&1; then
        echo "Error: Deployment $DEPLOYMENT_NAME not found in namespace $NAMESPACE"
        exit 1
    fi
}

get_current_revision() {
    kubectl rollout history deployment/"$DEPLOYMENT_NAME" -n "$NAMESPACE" | \
        grep -E "^[0-9]+" | tail -1 | awk '{print $1}'
}

perform_rollback() {
    local revision="$1"
    echo "Rolling back to revision: $revision"
    
    kubectl rollout undo deployment/"$DEPLOYMENT_NAME" -n "$NAMESPACE" \
        --to-revision="$revision"
    
    echo "Rollback initiated. Waiting for completion..."
}

monitor_rollback_progress() {
    local timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
    local interval=10
    local elapsed=0
    
    while [[ $elapsed -lt $timeout ]]; do
        local status=$(kubectl rollout status deployment/"$DEPLOYMENT_NAME" -n "$NAMESPACE" --timeout=30s 2>&1)
        
        if [[ $? -eq 0 ]]; then
            echo "Rollback completed successfully!"
            return 0
        fi
        
        if echo "$status" | grep -q "timed out"; then
            echo "Warning: Rollback taking longer than expected..."
        fi
        
        sleep $interval
        elapsed=$((elapsed + interval))
    done
    
    echo "Error: Rollback timed out after ${timeout} seconds"
    return 1
}

verify_rollback_success() {
    echo "Verifying rollback success..."
    
    # æ£€æŸ¥PodçŠ¶æ€
    local unhealthy_pods=$(kubectl get pods -n "$NAMESPACE" -l app="$DEPLOYMENT_NAME" \
        --field-selector=status.phase!=Running 2>/dev/null | wc -l)
    
    if [[ $unhealthy_pods -gt 0 ]]; then
        echo "Warning: Found $unhealthy_pods unhealthy pods"
        kubectl get pods -n "$NAMESPACE" -l app="$DEPLOYMENT_NAME" \
            --field-selector=status.phase!=Running
    fi
    
    # æ£€æŸ¥æœåŠ¡ç«¯ç‚¹
    if kubectl get service -n "$NAMESPACE" "$DEPLOYMENT_NAME" >/dev/null 2>&1; then
        local endpoints=$(kubectl get endpoints -n "$NAMESPACE" "$DEPLOYMENT_NAME" -o jsonpath='{.subsets[*].addresses[*].ip}' 2>/dev/null | wc -w)
        echo "Service endpoints available: $endpoints"
    fi
    
    echo "Rollback verification completed"
}

create_rollback_report() {
    local report_file="rollback-report-$(date +%Y%m%d-%H%M%S).json"
    
    cat > "$report_file" << EOF
{
    "deployment": "$DEPLOYMENT_NAME",
    "namespace": "$NAMESPACE",
    "rollback_time": "$(date -Iseconds)",
    "rollback_initiator": "$(whoami)",
    "rollback_method": "manual",
    "status": "completed",
    "post_rollback_state": {
        "replicas": $(kubectl get deployment "$DEPLOYMENT_NAME" -n "$NAMESPACE" -o jsonpath='{.status.replicas}' 2>/dev/null || echo "null"),
        "ready_replicas": $(kubectl get deployment "$DEPLOYMENT_NAME" -n "$NAMESPACE" -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo "null"),
        "unavailable_replicas": $(kubectl get deployment "$DEPLOYMENT_NAME" -n "$NAMESPACE" -o jsonpath='{.status.unavailableReplicas}' 2>/dev/null || echo "null")
    }
}
EOF
    
    echo "Rollback report created: $report_file"
}

# ä¸»æ‰§è¡Œæµç¨‹
main() {
    check_deployment_exists
    
    # è·å–å½“å‰ä¿®è®¢ç‰ˆæœ¬
    local current_rev=$(get_current_revision)
    echo "Current revision: $current_rev"
    
    # ç¡®è®¤å›æ»š
    echo "This will rollback deployment $DEPLOYMENT_NAME to the previous version."
    read -p "Continue? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo "Rollback cancelled"
        exit 0
    fi
    
    # æ‰§è¡Œå›æ»š
    perform_rollback "$((current_rev - 1))"
    
    # ç›‘æ§è¿›åº¦
    if monitor_rollback_progress; then
        verify_rollback_success
        create_rollback_report
        echo "Manual rollback completed successfully!"
    else
        echo "Manual rollback failed!"
        exit 1
    fi
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
```

## ğŸ“Š å˜æ›´æ•ˆæœè¯„ä¼°

### å˜æ›´åéªŒè¯

#### 1. å˜æ›´éªŒè¯æ£€æŸ¥æ¸…å•
```yaml
# å˜æ›´éªŒè¯é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: change-verification-checklist
  namespace: change-management
data:
  verification-template.yaml: |
    verification:
      pre_change_checks:
        - name: "backup_verification"
          description: "Verify backups are current and restorable"
          critical: true
          timeout: "30m"
          
        - name: "capacity_check"
          description: "Verify sufficient capacity for change"
          critical: true
          timeout: "15m"
          
        - name: "dependency_check"
          description: "Verify all dependencies are available"
          critical: false
          timeout: "10m"
      
      during_change_checks:
        - name: "deployment_progress"
          description: "Monitor deployment progress and health"
          critical: true
          interval: "30s"
          timeout: "2h"
          
        - name: "system_metrics"
          description: "Monitor system performance metrics"
          critical: true
          interval: "1m"
          timeout: "2h"
          
        - name: "application_health"
          description: "Verify application functionality"
          critical: true
          interval: "2m"
          timeout: "1h"
      
      post_change_validations:
        - name: "smoke_tests"
          description: "Execute smoke tests to verify basic functionality"
          critical: true
          timeout: "15m"
          
        - name: "integration_tests"
          description: "Run integration tests for affected components"
          critical: true
          timeout: "30m"
          
        - name: "performance_benchmark"
          description: "Compare performance against baseline"
          critical: false
          timeout: "45m"
          
        - name: "security_scan"
          description: "Perform security scanning of deployed components"
          critical: true
          timeout: "60m"
          
        - name: "user_acceptance"
          description: "Validate with key stakeholders"
          critical: false
          timeout: "2h"
```

#### 2. å˜æ›´æ•ˆæœè¯„ä¼°è„šæœ¬
```python
#!/usr/bin/env python3
# å˜æ›´æ•ˆæœè¯„ä¼°å·¥å…·

import asyncio
from kubernetes import client, config
from datetime import datetime, timedelta
import json
import statistics

class ChangeEffectivenessEvaluator:
    def __init__(self):
        config.load_kube_config()
        self.apps_v1 = client.AppsV1Api()
        self.core_v1 = client.CoreV1Api()
        self.custom_objects = client.CustomObjectsApi()
        
        self.evaluation_criteria = {
            'availability': {
                'target': 0.999,  # 99.9%å¯ç”¨æ€§
                'weight': 0.3
            },
            'performance': {
                'target': 1.0,    # æ— æ€§èƒ½ä¸‹é™
                'weight': 0.25
            },
            'reliability': {
                'target': 0.995,  # 99.5%å¯é æ€§
                'weight': 0.2
            },
            'user_satisfaction': {
                'target': 0.9,    # 90%ç”¨æˆ·æ»¡æ„åº¦
                'weight': 0.15
            },
            'business_impact': {
                'target': 1.05,   # 5%ä¸šåŠ¡å¢é•¿
                'weight': 0.1
            }
        }
    
    async def evaluate_change_effectiveness(self, change_id, namespace, evaluation_period_hours=24):
        """è¯„ä¼°å˜æ›´æ•ˆæœ"""
        evaluation_start = datetime.now() - timedelta(hours=evaluation_period_hours)
        
        evaluation_report = {
            'change_id': change_id,
            'namespace': namespace,
            'evaluation_period': {
                'start': evaluation_start.isoformat(),
                'end': datetime.now().isoformat(),
                'duration_hours': evaluation_period_hours
            },
            'metrics': {},
            'scores': {},
            'effectiveness_rating': '',
            'recommendations': []
        }
        
        try:
            # æ”¶é›†å„é¡¹æŒ‡æ ‡
            tasks = [
                self.evaluate_availability(change_id, namespace, evaluation_start),
                self.evaluate_performance(change_id, namespace, evaluation_start),
                self.evaluate_reliability(change_id, namespace, evaluation_start),
                self.evaluate_user_satisfaction(change_id, namespace, evaluation_start),
                self.evaluate_business_impact(change_id, namespace, evaluation_start)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†ç»“æœ
            metric_names = ['availability', 'performance', 'reliability', 'user_satisfaction', 'business_impact']
            
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    evaluation_report['metrics'][metric_names[i]] = {
                        'status': 'error',
                        'error': str(result)
                    }
                else:
                    evaluation_report['metrics'][metric_names[i]] = result
                    evaluation_report['scores'][metric_names[i]] = self.calculate_score(
                        metric_names[i], result
                    )
            
            # è®¡ç®—æ€»ä½“æ•ˆæœè¯„åˆ†
            evaluation_report['overall_score'] = self.calculate_overall_score(evaluation_report['scores'])
            evaluation_report['effectiveness_rating'] = self.get_effectiveness_rating(
                evaluation_report['overall_score']
            )
            
            # ç”Ÿæˆå»ºè®®
            evaluation_report['recommendations'] = self.generate_recommendations(
                evaluation_report['metrics'], 
                evaluation_report['scores']
            )
            
        except Exception as e:
            evaluation_report['error'] = str(e)
        
        return evaluation_report
    
    async def evaluate_availability(self, change_id, namespace, start_time):
        """è¯„ä¼°å¯ç”¨æ€§"""
        try:
            # è·å–éƒ¨ç½²ä¿¡æ¯
            deployment = self.apps_v1.read_namespaced_deployment(change_id, namespace)
            
            # è®¡ç®—å¯ç”¨æ€§æŒ‡æ ‡
            total_replicas = deployment.status.replicas or 0
            ready_replicas = deployment.status.ready_replicas or 0
            unavailable_replicas = deployment.status.unavailable_replicas or 0
            
            if total_replicas > 0:
                availability = (ready_replicas / total_replicas) * 100
            else:
                availability = 0
            
            # è·å–å†å²å¯ç”¨æ€§æ•°æ®
            historical_availability = await self.get_historical_availability(change_id, namespace, start_time)
            
            return {
                'current': round(availability, 2),
                'historical_average': round(historical_availability, 2),
                'trend': self.calculate_trend(availability, historical_availability),
                'status': 'healthy' if availability >= 99.5 else 'degraded'
            }
            
        except Exception as e:
            return {'status': 'error', 'error': str(e)}
    
    async def evaluate_performance(self, change_id, namespace, start_time):
        """è¯„ä¼°æ€§èƒ½"""
        try:
            # è·å–æ€§èƒ½æŒ‡æ ‡ï¼ˆç®€åŒ–å®ç°ï¼‰
            current_latency = await self.get_current_latency(change_id, namespace)
            baseline_latency = await self.get_baseline_latency(change_id, namespace)
            
            if baseline_latency > 0:
                performance_ratio = current_latency / baseline_latency
                performance_impact = (1 - performance_ratio) * 100
            else:
                performance_ratio = 1.0
                performance_impact = 0
            
            return {
                'current_latency': round(current_latency, 3),
                'baseline_latency': round(baseline_latency, 3),
                'performance_ratio': round(performance_ratio, 3),
                'performance_impact': round(performance_impact, 2),
                'status': 'improved' if performance_impact > 5 else ('degraded' if performance_impact < -5 else 'stable')
            }
            
        except Exception as e:
            return {'status': 'error', 'error': str(e)}
    
    async def evaluate_reliability(self, change_id, namespace, start_time):
        """è¯„ä¼°å¯é æ€§"""
        try:
            # è®¡ç®—é‡å¯ç‡å’Œé”™è¯¯ç‡
            restart_rate = await self.get_pod_restart_rate(change_id, namespace, start_time)
            error_rate = await self.get_error_rate(change_id, namespace, start_time)
            
            # ç»¼åˆå¯é æ€§è¯„åˆ†
            reliability_score = 100 - (restart_rate * 10) - (error_rate * 100)
            reliability_score = max(0, min(100, reliability_score))
            
            return {
                'restart_rate': round(restart_rate, 4),
                'error_rate': round(error_rate, 4),
                'reliability_score': round(reliability_score, 2),
                'status': 'high' if reliability_score >= 95 else ('medium' if reliability_score >= 85 else 'low')
            }
            
        except Exception as e:
            return {'status': 'error', 'error': str(e)}
    
    async def evaluate_user_satisfaction(self, change_id, namespace, start_time):
        """è¯„ä¼°ç”¨æˆ·æ»¡æ„åº¦"""
        try:
            # ä»ç›‘æ§ç³»ç»Ÿè·å–ç”¨æˆ·æ»¡æ„åº¦æŒ‡æ ‡
            satisfaction_score = await self.get_user_satisfaction_score(change_id, namespace)
            response_time_satisfaction = await self.get_response_time_satisfaction(change_id, namespace)
            error_satisfaction = await self.get_error_satisfaction(change_id, namespace)
            
            # ç»¼åˆæ»¡æ„åº¦è¯„åˆ†
            composite_satisfaction = (satisfaction_score * 0.5 + 
                                    response_time_satisfaction * 0.3 + 
                                    error_satisfaction * 0.2)
            
            return {
                'overall_satisfaction': round(composite_satisfaction, 2),
                'satisfaction_score': round(satisfaction_score, 2),
                'response_time_satisfaction': round(response_time_satisfaction, 2),
                'error_satisfaction': round(error_satisfaction, 2),
                'status': 'high' if composite_satisfaction >= 85 else ('medium' if composite_satisfaction >= 70 else 'low')
            }
            
        except Exception as e:
            return {'status': 'error', 'error': str(e)}
    
    async def evaluate_business_impact(self, change_id, namespace, start_time):
        """è¯„ä¼°ä¸šåŠ¡å½±å“"""
        try:
            # è·å–ä¸šåŠ¡æŒ‡æ ‡
            current_revenue = await self.get_current_revenue(change_id, namespace)
            baseline_revenue = await self.get_baseline_revenue(change_id, namespace)
            
            if baseline_revenue > 0:
                revenue_growth = ((current_revenue - baseline_revenue) / baseline_revenue) * 100
            else:
                revenue_growth = 0
            
            # è·å–å…¶ä»–ä¸šåŠ¡æŒ‡æ ‡
            conversion_rate = await self.get_conversion_rate(change_id, namespace)
            user_engagement = await self.get_user_engagement(change_id, namespace)
            
            return {
                'revenue_growth': round(revenue_growth, 2),
                'conversion_rate': round(conversion_rate, 4),
                'user_engagement': round(user_engagement, 2),
                'status': 'positive' if revenue_growth > 2 else ('negative' if revenue_growth < -2 else 'neutral')
            }
            
        except Exception as e:
            return {'status': 'error', 'error': str(e)}
    
    def calculate_score(self, metric_name, metric_data):
        """è®¡ç®—å•é¡¹è¯„åˆ†"""
        if 'status' in metric_data and metric_data['status'] == 'error':
            return 0
        
        target = self.evaluation_criteria[metric_name]['target']
        weight = self.evaluation_criteria[metric_name]['weight']
        
        if metric_name == 'availability':
            score = min(100, metric_data['current'])
        elif metric_name == 'performance':
            # æ€§èƒ½æ¯”å€¼è¶Šæ¥è¿‘1è¶Šå¥½
            score = max(0, min(100, (2 - abs(metric_data['performance_ratio'] - 1)) * 100))
        elif metric_name == 'reliability':
            score = metric_data['reliability_score']
        elif metric_name == 'user_satisfaction':
            score = metric_data['overall_satisfaction']
        elif metric_name == 'business_impact':
            # ä¸šåŠ¡å¢é•¿ä¸ºç›®æ ‡çš„ç™¾åˆ†æ¯”
            score = max(0, min(100, (metric_data['revenue_growth'] / (target - 1) * 100) + 50))
        
        return round(score * weight, 3)
    
    def calculate_overall_score(self, scores):
        """è®¡ç®—æ€»ä½“è¯„åˆ†"""
        total_score = sum(scores.values())
        return round(total_score, 2)
    
    def get_effectiveness_rating(self, overall_score):
        """è·å–æ•ˆæœè¯„çº§"""
        if overall_score >= 85:
            return 'excellent'
        elif overall_score >= 70:
            return 'good'
        elif overall_score >= 50:
            return 'fair'
        else:
            return 'poor'
    
    def generate_recommendations(self, metrics, scores):
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # åŸºäºä½åˆ†æŒ‡æ ‡ç”Ÿæˆå»ºè®®
        for metric_name, score in scores.items():
            if score < (self.evaluation_criteria[metric_name]['weight'] * 70):  # ä½äº70%æƒé‡åˆ†æ•°
                recommendation = self.get_metric_recommendation(metric_name, metrics[metric_name])
                recommendations.append(recommendation)
        
        # åŸºäºæ€»ä½“è¯„åˆ†ç”Ÿæˆå»ºè®®
        overall_score = sum(scores.values())
        if overall_score < 60:
            recommendations.append({
                'priority': 'high',
                'category': 'overall_improvement',
                'description': 'Overall change effectiveness needs improvement',
                'actions': [
                    'Conduct detailed root cause analysis',
                    'Implement additional monitoring',
                    'Consider rollback if issues persist',
                    'Enhance testing procedures'
                ]
            })
        elif overall_score > 90:
            recommendations.append({
                'priority': 'low',
                'category': 'best_practices',
                'description': 'Change was highly effective',
                'actions': [
                    'Document successful practices',
                    'Share learnings with team',
                    'Consider applying similar approaches to other changes'
                ]
            })
        
        return recommendations
    
    def get_metric_recommendation(self, metric_name, metric_data):
        """è·å–ç‰¹å®šæŒ‡æ ‡çš„å»ºè®®"""
        recommendations_map = {
            'availability': {
                'priority': 'high',
                'category': 'availability_optimization',
                'description': 'Improve system availability',
                'actions': [
                    'Implement better health checks',
                    'Add redundancy mechanisms',
                    'Optimize resource allocation',
                    'Improve error handling'
                ]
            },
            'performance': {
                'priority': 'medium',
                'category': 'performance_optimization',
                'description': 'Address performance degradation',
                'actions': [
                    'Profile application performance',
                    'Optimize database queries',
                    'Implement caching strategies',
                    'Review resource limits'
                ]
            },
            'reliability': {
                'priority': 'high',
                'category': 'reliability_improvement',
                'description': 'Enhance system reliability',
                'actions': [
                    'Implement circuit breakers',
                    'Add retry mechanisms',
                    'Improve logging and monitoring',
                    'Conduct chaos engineering experiments'
                ]
            }
        }
        
        return recommendations_map.get(metric_name, {
            'priority': 'medium',
            'category': 'general_improvement',
            'description': f'Improve {metric_name} metrics',
            'actions': ['Review relevant system components', 'Implement targeted optimizations']
        })
    
    def calculate_trend(self, current, historical):
        """è®¡ç®—è¶‹åŠ¿"""
        if historical == 0:
            return 'new_metric'
        elif current > historical:
            return 'improving'
        elif current < historical:
            return 'degrading'
        else:
            return 'stable'
    
    # è¾…åŠ©æ–¹æ³•ï¼ˆç®€åŒ–å®ç°ï¼‰
    async def get_historical_availability(self, change_id, namespace, start_time):
        return 99.2  # æ¨¡æ‹Ÿå†å²æ•°æ®
    
    async def get_current_latency(self, change_id, namespace):
        return 0.234  # æ¨¡æ‹Ÿå½“å‰å»¶è¿Ÿ
    
    async def get_baseline_latency(self, change_id, namespace):
        return 0.200  # æ¨¡æ‹ŸåŸºçº¿å»¶è¿Ÿ
    
    async def get_pod_restart_rate(self, change_id, namespace, start_time):
        return 0.001  # æ¨¡æ‹Ÿé‡å¯ç‡
    
    async def get_error_rate(self, change_id, namespace, start_time):
        return 0.005  # æ¨¡æ‹Ÿé”™è¯¯ç‡
    
    async def get_user_satisfaction_score(self, change_id, namespace):
        return 87.5  # æ¨¡æ‹Ÿæ»¡æ„åº¦åˆ†æ•°
    
    async def get_response_time_satisfaction(self, change_id, namespace):
        return 82.3  # æ¨¡æ‹Ÿå“åº”æ—¶é—´æ»¡æ„åº¦
    
    async def get_error_satisfaction(self, change_id, namespace):
        return 91.2  # æ¨¡æ‹Ÿé”™è¯¯ç‡æ»¡æ„åº¦
    
    async def get_current_revenue(self, change_id, namespace):
        return 105000  # æ¨¡æ‹Ÿå½“å‰æ”¶å…¥
    
    async def get_baseline_revenue(self, change_id, namespace):
        return 100000  # æ¨¡æ‹ŸåŸºçº¿æ”¶å…¥
    
    async def get_conversion_rate(self, change_id, namespace):
        return 0.035  # æ¨¡æ‹Ÿè½¬åŒ–ç‡
    
    async def get_user_engagement(self, change_id, namespace):
        return 78.4  # æ¨¡æ‹Ÿç”¨æˆ·å‚ä¸åº¦

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    evaluator = ChangeEffectivenessEvaluator()
    report = await evaluator.evaluate_change_effectiveness('my-app-deployment', 'production')
    
    print("Change Effectiveness Evaluation Report:")
    print(json.dumps(report, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ”§ å®æ–½æ£€æŸ¥æ¸…å•

### å˜æ›´ç®¡ç†ä½“ç³»å»ºè®¾
- [ ] å»ºç«‹RFCæµç¨‹å’Œå®¡æ‰¹æœºåˆ¶
- [ ] å®æ–½ç°åº¦å‘å¸ƒå’Œæ¸è¿›å¼éƒ¨ç½²
- [ ] é…ç½®è‡ªåŠ¨åŒ–å›æ»šæœºåˆ¶
- [ ] å»ºç«‹å˜æ›´éªŒè¯å’Œæµ‹è¯•æµç¨‹
- [ ] å®æ–½å˜æ›´æ•ˆæœè¯„ä¼°ä½“ç³»
- [ ] å»ºç«‹å˜æ›´ç®¡ç†æ–‡æ¡£å’ŒåŸ¹è®­

### æŠ€æœ¯å®æ–½
- [ ] éƒ¨ç½²å˜æ›´ç®¡ç†å·¥å…·é“¾
- [ ] é…ç½®ç›‘æ§å‘Šè­¦å’Œé€šçŸ¥ç³»ç»Ÿ
- [ ] å®æ–½è‡ªåŠ¨åŒ–æµ‹è¯•å’ŒéªŒè¯
- [ ] å»ºç«‹å›æ»šå’Œç¾éš¾æ¢å¤æœºåˆ¶
- [ ] é…ç½®å˜æ›´å®¡è®¡å’Œåˆè§„æ£€æŸ¥
- [ ] å®æ–½å˜æ›´é£é™©ç®¡ç†ç­–ç•¥

### è¿è¥ç»´æŠ¤
- [ ] åˆ¶å®šå˜æ›´ç®¡ç†æ“ä½œæ‰‹å†Œ
- [ ] å»ºç«‹å˜æ›´å®¡æ‰¹å’Œæ‰§è¡Œæ ‡å‡†
- [ ] å®æ–½å˜æ›´åè¯„ä¼°å’Œæ”¹è¿›
- [ ] ç»´æŠ¤å˜æ›´å†å²å’ŒçŸ¥è¯†åº“
- [ ] å®šæœŸå®¡æŸ¥å’Œä¼˜åŒ–å˜æ›´æµç¨‹
- [ ] åŸ¹å…»å˜æ›´ç®¡ç†æ–‡åŒ–

---

*æœ¬æ–‡æ¡£ä¸ºä¼ä¸šçº§å˜æ›´ç®¡ç†æµç¨‹æä¾›å®Œæ•´çš„æ¡†æ¶è®¾è®¡å’Œå®æ–½æŒ‡å¯¼*