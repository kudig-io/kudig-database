# GPU ä¸è®¾å¤‡æ’ä»¶æ•…éšœæ’æŸ¥æŒ‡å—

> **é€‚ç”¨ç‰ˆæœ¬**: Kubernetes v1.25 - v1.32, NVIDIA Driver 470+, Device Plugin v0.13+ | **æœ€åæ›´æ–°**: 2026-01 | **éš¾åº¦**: é«˜çº§
>
> **ç‰ˆæœ¬è¯´æ˜**:
> - v1.26+ DRA (Dynamic Resource Allocation) Alpha
> - v1.31+ DRA è¿›å…¥ Beta
> - NVIDIA MIG éœ€è¦ Driver 450+ å’Œ Device Plugin v0.12+
> - æ—¶é—´ç‰‡å…±äº«éœ€è¦ Device Plugin v0.13+

## ğŸ¯ æœ¬æ–‡æ¡£ä»·å€¼

| è¯»è€…å¯¹è±¡ | ä»·å€¼ä½“ç° |
| :--- | :--- |
| **åˆå­¦è€…** | ææ¸…æ¥š GPU èµ„æºåœ¨ Kubernetes ä¸­æ˜¯å¦‚ä½•è¢«å‘ç°å’Œåˆ†é…çš„ï¼Œå­¦ä¼šä½¿ç”¨ `nvidia-smi` éªŒè¯åŸºç¡€é©±åŠ¨ç¯å¢ƒï¼ŒæŒæ¡ GPU Pod çš„æ ‡å‡†é…ç½®æ¨¡æ¿ã€‚ |
| **èµ„æ·±ä¸“å®¶** | æ·±å…¥ç†è§£ Device Plugin çš„ gRPC æ³¨å†Œä¸ ListAndWatch æœºåˆ¶ã€MIGï¼ˆå¤šå®ä¾‹ GPUï¼‰çš„åˆ†åŒºé€»è¾‘ã€æ—¶é—´ç‰‡å…±äº«ï¼ˆTime-Slicingï¼‰çš„è°ƒåº¦æƒè¡¡ï¼Œä»¥åŠ DRAï¼ˆåŠ¨æ€èµ„æºåˆ†é…ï¼‰æ¶æ„å¯¹ AI æ¨ç†é›†ç¾¤çš„æ¼”è¿›æ–¹å‘ã€‚ |

---

## 0. 10 åˆ†é’Ÿå¿«é€Ÿè¯Šæ–­

1. **ç»„ä»¶ä¸èµ„æºå¯è§æ€§**ï¼š`kubectl -n kube-system get ds -l name=nvidia-device-plugin-daemonset -o wide`ï¼ˆæˆ–å¯¹åº”å‚å•†æ’ä»¶ï¼‰ï¼›`kubectl get node <name> -o jsonpath='{.status.allocatable.nvidia\.com/gpu}'`ã€‚
2. **é©±åŠ¨å¥åº·**ï¼šèŠ‚ç‚¹æ‰§è¡Œ `nvidia-smi`ï¼Œè‹¥æŠ¥é”™æ£€æŸ¥é©±åŠ¨/XIDï¼›`dmesg | grep -i nvidia | tail`ã€‚
3. **Pod äº‹ä»¶**ï¼šå¯¹ Pending/å¤±è´¥çš„ GPU Pod `kubectl describe pod`ï¼ŒæŸ¥çœ‹è°ƒåº¦åŸå› ï¼ˆèµ„æºä¸è¶³/æ‹“æ‰‘/äº²å’Œæ€§ï¼‰æˆ–å¯åŠ¨é”™è¯¯ï¼ˆæŒ‚è½½/ç¯å¢ƒå˜é‡ç¼ºå¤±ï¼‰ã€‚
4. **æ’ä»¶æ—¥å¿—ä¸æ³¨å†Œ**ï¼š`kubectl logs -n kube-system ds/nvidia-device-plugin-daemonset -c nvidia-device-plugin-ctr --tail=50`ï¼Œç¡®è®¤ `ListAndWatch`/`Allocate` æ˜¯å¦æŠ¥é”™ï¼›æŸ¥çœ‹ `/var/lib/kubelet/device-plugins/kubelet_internal_checkpoint`ã€‚
5. **MIG/æ—¶é—´ç‰‡/NUMA**ï¼šæ£€æŸ¥æ˜¯å¦å¼€å¯ MIGï¼Œè§„æ ¼æ˜¯å¦åŒ¹é…ï¼›æ—¶é—´ç‰‡å…±äº«éœ€æ’ä»¶ç‰ˆæœ¬ â‰¥0.13ï¼›è·¨ NUMA éƒ¨ç½²å¯éœ€ `TopologyManager` è®¾ç½®ã€‚
6. **å¿«é€Ÿç¼“è§£**ï¼š
   - å•èŠ‚ç‚¹å¼‚å¸¸ï¼š`cordon` èŠ‚ç‚¹ï¼Œé‡è½½é©±åŠ¨æˆ–é‡å¯æ’ä»¶ DaemonSetï¼›è‹¥ XID æŒç»­ï¼Œé‡å¯æœºå™¨æˆ–ä¸‹æ¶ GPUã€‚
   - èµ„æºç¢ç‰‡ï¼šæ‰§è¡Œæ’ç©ºé‡è°ƒåº¦ï¼Œæˆ–è°ƒæ•´è¯·æ±‚è§„æ ¼/å…³é—­ MIG åˆ†ç‰‡ä»¥é‡Šæ”¾è¿ç»­èµ„æºã€‚
   - é…ç½®é”™è¯¯ï¼šå›æ»šè‡ªå®šä¹‰æ’ä»¶é•œåƒ/å‚æ•°ï¼Œæ¢å¤å®˜æ–¹é»˜è®¤ DaemonSetã€‚
7. **è¯æ®ç•™å­˜**ï¼šä¿å­˜æ’ä»¶æ—¥å¿—ã€`nvidia-smi` è¾“å‡ºã€Pod äº‹ä»¶ã€Node allocatable/å·²åˆ†é…å¿«ç…§ã€XID ä»£ç åŠ dmesg ç‰‡æ®µã€‚

---

## 1. æ ¸å¿ƒåŸç†è§£æï¼šå¼‚æ„èµ„æºæ¥å…¥

### 1.1 è®¾å¤‡æ’ä»¶ (Device Plugin) æ³¨å†Œæœºåˆ¶

Kubernetes ä¸åŸç”Ÿæ„ŸçŸ¥ GPUã€‚æ¥å…¥è¿‡ç¨‹å¦‚ä¸‹ï¼š
1. **æ¢æµ‹ä¸æ³¨å†Œ**ï¼šè®¾å¤‡æ’ä»¶ï¼ˆå¦‚ NVIDIA Device Pluginï¼‰æ‰«æå®¿ä¸»æœº `/dev` ä¸‹çš„ç‰¹æ®Šæ–‡ä»¶ï¼Œå¹¶é€šè¿‡ Unix Domain Socket å‘ kubelet æ³¨å†Œè‡ªå·±ç®¡ç†çš„èµ„æºåç§°ï¼ˆå¦‚ `nvidia.com/gpu`ï¼‰ã€‚
2. **å®¹é‡ä¸ŠæŠ¥**ï¼škubelet å°†è¿™äº›èµ„æºä½œä¸ºâ€œå¯åˆ†é…å®¹é‡â€æ›´æ–°åˆ° Node å¯¹è±¡çš„ `Status`ã€‚
3. **åˆ†é…å†³ç­–**ï¼šè°ƒåº¦å™¨æ ¹æ® Pod çš„ `limits` è¯·æ±‚è¿›è¡Œè¿‡æ»¤ã€‚åœ¨ Pod çœŸæ­£å¯åŠ¨å‰ï¼Œkubelet è°ƒç”¨æ’ä»¶çš„ `Allocate` æ–¹æ³•ï¼Œè·å–è¯¥ Pod ä¸“å±çš„è®¾å¤‡ç¯å¢ƒå˜é‡ï¼ˆå¦‚ `NVIDIA_VISIBLE_DEVICES`ï¼‰å’ŒæŒ‚è½½è·¯å¾„ã€‚

### 1.2 ç”Ÿäº§ç¯å¢ƒå…¸å‹â€œAI ç®—åŠ›å‘â€

1. **GPU ç¢ç‰‡åŒ–ä¸æŠ¢å å¤±è´¥**ï¼š
   - **ç°è±¡**ï¼šNode ä¸Šæ˜¾ç¤ºæœ‰ 1 ä¸ªç©ºé—² GPUï¼Œä½† Pod ä¾ç„¶ Pendingã€‚
   - **æ·±å±‚åŸå› **ï¼šè¯¥ GPU å¯èƒ½è¢«åˆ†é…ç»™äº†æŸä¸ªæ­£åœ¨åˆ›å»ºæˆ– Terminating ä¸­çš„ Podï¼Œæˆ–è€…å› ä¸º MIG æ¨¡å¼ä¸‹ï¼Œç‰©ç† GPU çš„å‰©ä½™ç©ºé—´ä¸è¶³ä»¥åˆ‡åˆ†å‡ºè¯·æ±‚çš„å®ä¾‹è§„æ ¼ã€‚
2. **XID Errorsï¼ˆé©±åŠ¨/ç¡¬ä»¶æ•…éšœï¼‰**ï¼š
   - **ç°è±¡**ï¼š`nvidia-smi` æŠ¥é”™ `Unable to determine the device handle`ã€‚
   - **å¯¹ç­–**ï¼šæŸ¥çœ‹å†…æ ¸ `dmesg`ã€‚XID é”™è¯¯ä»£ç ï¼ˆå¦‚ XID 31 ä¸ºå†…å­˜é”™è¯¯ï¼‰ç›´æ¥å†³å®šäº†æ˜¯éœ€è¦é‡å¯é©±åŠ¨è¿˜æ˜¯æ›´æ¢ç‰©ç†ç¡¬ä»¶ã€‚

# ä¸“å®¶çº§è§‚æµ‹å·¥å…·é“¾ï¼ˆExpert's Toolboxï¼‰

```bash
# ä¸“å®¶çº§ï¼šéªŒè¯ kubelet ä¸æ’ä»¶çš„ Socket é€šä¿¡
# æŸ¥çœ‹ kubelet å†…éƒ¨è®¾å¤‡ç®¡ç†å™¨çŠ¶æ€
cat /var/lib/kubelet/device-plugins/kubelet_internal_checkpoint

# ä¸“å®¶çº§ï¼šç›‘æ§ GPU æ ¸å¿ƒæŒ‡æ ‡ï¼ˆéœ€éƒ¨ç½² DCGM Exporterï¼‰
curl localhost:9400/metrics | grep DCGM_FI_DEV_GPU_UTIL

# ä¸“å®¶çº§ï¼šæ·±åº¦æ£€æŸ¥ NVIDIA è¿è¡Œæ—¶çš„é…ç½®æ–‡ä»¶
# ç¡®è®¤è·¯å¾„æ˜ å°„å’Œåº“æ–‡ä»¶åŠ è½½é€»è¾‘
cat /etc/nvidia-container-runtime/config.toml
```

---

## ç›®å½•

1. [å¼‚æ„èµ„æºæ¥å…¥é€»è¾‘](#1-æ ¸å¿ƒåŸç†è§£æå¼‚æ„èµ„æºæ¥å…¥)
2. [ä¸“å®¶è§‚æµ‹å·¥å…·é“¾](#ä¸“å®¶çº§è§‚æµ‹å·¥å…·é“¾experts-toolbox)
3. [æ•…éšœç°è±¡ä¸åˆ†é…é€»è¾‘è§£æ](#12-å¸¸è§é—®é¢˜ç°è±¡)
4. [åŸºç¡€æ’æŸ¥æ­¥éª¤ï¼ˆåˆå­¦è€…ï¼‰](#22-æ’æŸ¥å‘½ä»¤é›†)
5. [æ·±åº¦æ²»ç†æ–¹æ¡ˆ](#ç¬¬ä¸‰éƒ¨åˆ†è§£å†³æ–¹æ¡ˆä¸é£é™©æ§åˆ¶)

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šé—®é¢˜ç°è±¡ä¸å½±å“åˆ†æ

### 1.1 Kubernetes è®¾å¤‡æ’ä»¶æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Kubernetes Node                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                        kubelet                               â”‚   â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚   â”‚  â”‚            Device Plugin Manager                      â”‚   â”‚   â”‚
â”‚   â”‚  â”‚  - ç›‘å¬ /var/lib/kubelet/device-plugins/             â”‚   â”‚   â”‚
â”‚   â”‚  â”‚  - ç®¡ç†è®¾å¤‡æ’ä»¶æ³¨å†Œ                                   â”‚   â”‚   â”‚
â”‚   â”‚  â”‚  - å¤„ç†è®¾å¤‡åˆ†é…è¯·æ±‚                                   â”‚   â”‚   â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                       â”‚
â”‚              gRPC (Unix Socket)                                      â”‚
â”‚                              â”‚                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                   Device Plugins                             â”‚   â”‚
â”‚   â”‚                                                              â”‚   â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚   â”‚  â”‚  NVIDIA GPU    â”‚  â”‚  AMD GPU       â”‚  â”‚  RDMA/InfiniBandâ”‚ â”‚   â”‚
â”‚   â”‚  â”‚  Plugin        â”‚  â”‚  Plugin        â”‚  â”‚  Plugin        â”‚ â”‚   â”‚
â”‚   â”‚  â”‚                â”‚  â”‚                â”‚  â”‚                â”‚ â”‚   â”‚
â”‚   â”‚  â”‚ nvidia.com/gpu â”‚  â”‚ amd.com/gpu    â”‚  â”‚ rdma/hca       â”‚ â”‚   â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚   â”‚          â”‚                   â”‚                   â”‚          â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚              â”‚                   â”‚                   â”‚              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                     Hardware Layer                          â”‚   â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚
â”‚   â”‚  â”‚  NVIDIA    â”‚    â”‚  AMD       â”‚    â”‚  Mellanox  â”‚        â”‚   â”‚
â”‚   â”‚  â”‚  GPU Cards â”‚    â”‚  GPU Cards â”‚    â”‚  NICs      â”‚        â”‚   â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è®¾å¤‡æ’ä»¶æ³¨å†Œæµç¨‹:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    1. å¯åŠ¨å¹¶è¿æ¥    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Device   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚   kubelet  â”‚
â”‚   Plugin   â”‚                    â”‚  (Manager) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                  â”‚
      â”‚    2. Register(ResourceName)     â”‚
      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>   â”‚
      â”‚                                  â”‚
      â”‚    3. ListAndWatch()             â”‚
      â”‚ <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
      â”‚                                  â”‚
      â”‚    4. è¿”å›è®¾å¤‡åˆ—è¡¨               â”‚
      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>   â”‚
      â”‚                                  â”‚
      â”‚    5. Allocate() on Pod request  â”‚
      â”‚ <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
      â”‚                                  â”‚
      â”‚    6. è¿”å›æŒ‚è½½/ç¯å¢ƒå˜é‡é…ç½®      â”‚
      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 å¸¸è§é—®é¢˜ç°è±¡

| é—®é¢˜ç±»å‹ | ç°è±¡æè¿° | é”™è¯¯ä¿¡æ¯ | æŸ¥çœ‹æ–¹å¼ |
|----------|----------|----------|----------|
| GPU ä¸å¯è§ | Node ä¸Šçœ‹ä¸åˆ° GPU èµ„æº | Capacity ä¸­æ—  nvidia.com/gpu | `kubectl describe node` |
| Pod è°ƒåº¦å¤±è´¥ | GPU Pod ä¸€ç›´ Pending | Insufficient nvidia.com/gpu | `kubectl describe pod` |
| è®¾å¤‡æ’ä»¶å´©æºƒ | æ’ä»¶ Pod CrashLoopBackOff | plugin registration failed | `kubectl logs` |
| é©±åŠ¨é—®é¢˜ | å®¹å™¨å†…æ— æ³•ä½¿ç”¨ GPU | CUDA driver version insufficient | åº”ç”¨æ—¥å¿— |
| è®¾å¤‡åˆ†é…å¤±è´¥ | Pod å¯åŠ¨å¤±è´¥ | failed to allocate device | kubelet æ—¥å¿— |
| è®¾å¤‡å¥åº·æ£€æŸ¥ | GPU æ ‡è®°ä¸º unhealthy | device marked as unhealthy | æ’ä»¶æ—¥å¿— |
| å…±äº« GPU | èµ„æºç¢ç‰‡åŒ– | æ— æ³•ç²¾ç»†åˆ†é… GPU èµ„æº | Node èµ„æºçŠ¶æ€ |
| MIG é—®é¢˜ | MIG è®¾å¤‡ä¸å¯ç”¨ | MIG mode enabled but no instances | nvidia-smi |

### 1.3 å½±å“åˆ†æ

| é—®é¢˜ç±»å‹ | ç›´æ¥å½±å“ | é—´æ¥å½±å“ | å½±å“èŒƒå›´ |
|----------|----------|----------|----------|
| GPU ä¸å¯è§ | ML å·¥ä½œè´Ÿè½½æ— æ³•è°ƒåº¦ | æ¨¡å‹è®­ç»ƒ/æ¨ç†åœæ» | æ‰€æœ‰ GPU å·¥ä½œè´Ÿè½½ |
| è®¾å¤‡æ’ä»¶å´©æºƒ | æ–° Pod æ— æ³•è·å– GPU | å·²è¿è¡Œ Pod ä¸å—å½±å“ | æ–°è°ƒåº¦çš„ Pod |
| é©±åŠ¨ä¸å…¼å®¹ | CUDA ç¨‹åºè¿è¡Œå¤±è´¥ | åº”ç”¨å´©æºƒ | ç‰¹å®š CUDA ç‰ˆæœ¬åº”ç”¨ |
| è®¾å¤‡åˆ†é…å¤±è´¥ | Pod å¯åŠ¨å¤±è´¥ | å·¥ä½œè´Ÿè½½ä¸å¯ç”¨ | è¯·æ±‚è¯¥è®¾å¤‡çš„ Pod |

## ç¬¬äºŒéƒ¨åˆ†ï¼šæ’æŸ¥æ–¹æ³•ï¼ˆåŸºç¡€ä¸è¿›é˜¶ï¼‰

### 2.1 æ’æŸ¥å†³ç­–æ ‘

```
GPU/è®¾å¤‡ Pod é—®é¢˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pod çŠ¶æ€æ˜¯ä»€ä¹ˆï¼Ÿ  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€ Pending â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                                  â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚   â”‚ æ£€æŸ¥è°ƒåº¦äº‹ä»¶                            â”‚   â”‚
        â”‚   â”‚ kubectl describe pod <pod>              â”‚   â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â”‚                  â”‚                               â”‚
        â”‚                  â–¼                               â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚   â”‚ Insufficient nvidia.com/gpu?            â”‚   â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â”‚          â”‚                â”‚                      â”‚
        â”‚         æ˜¯               å¦                      â”‚
        â”‚          â”‚                â”‚                      â”‚
        â”‚          â–¼                â–¼                      â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
        â”‚   â”‚ æ£€æŸ¥ Node  â”‚   â”‚ æ£€æŸ¥å…¶ä»–èµ„æº   â”‚           â”‚
        â”‚   â”‚ GPU å®¹é‡   â”‚   â”‚ æˆ– affinity    â”‚           â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
        â”‚          â”‚                                       â”‚
        â”‚          â–¼                                       â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚   â”‚ Node æœ‰ GPU Capacity?                   â”‚   â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â”‚          â”‚                â”‚                      â”‚
        â”‚         å¦               æ˜¯                      â”‚
        â”‚          â”‚                â”‚                      â”‚
        â”‚          â–¼                â–¼                      â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
        â”‚   â”‚ è®¾å¤‡æ’ä»¶   â”‚   â”‚ æ£€æŸ¥å·²åˆ†é…     â”‚           â”‚
        â”‚   â”‚ é—®é¢˜       â”‚   â”‚ vs å¯ç”¨æ•°é‡    â”‚           â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
        â”‚                                                  â”‚
        â”œâ”€â”€ ContainerCreating â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚                                                  â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚   â”‚ æ£€æŸ¥ kubelet æ—¥å¿—                       â”‚   â”‚
        â”‚   â”‚ journalctl -u kubelet | grep -i gpu     â”‚   â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â”‚                  â”‚                               â”‚
        â”‚                  â–¼                               â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚   â”‚ device allocation é”™è¯¯?                 â”‚   â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â”‚          â”‚                â”‚                      â”‚
        â”‚         æ˜¯               å¦                      â”‚
        â”‚          â”‚                â”‚                      â”‚
        â”‚          â–¼                â–¼                      â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
        â”‚   â”‚ è®¾å¤‡æ’ä»¶   â”‚   â”‚ æ£€æŸ¥å…¶ä»–å®¹å™¨   â”‚           â”‚
        â”‚   â”‚ Allocate   â”‚   â”‚ å¯åŠ¨é—®é¢˜       â”‚           â”‚
        â”‚   â”‚ å¤±è´¥       â”‚   â”‚                â”‚           â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
        â”‚                                                  â”‚
        â””â”€â”€ Running ä½† GPU ä¸å·¥ä½œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                                           â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
            â”‚ å®¹å™¨å†…æ£€æŸ¥ nvidia-smi                   â”‚   â”‚
            â”‚ kubectl exec <pod> -- nvidia-smi        â”‚   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                           â”‚                               â”‚
                           â–¼                               â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
            â”‚ nvidia-smi èƒ½å¦æ­£å¸¸è¿è¡Œ?                â”‚   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                   â”‚                â”‚                      â”‚
                  å¦               æ˜¯                      â”‚
                   â”‚                â”‚                      â”‚
                   â–¼                â–¼                      â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
            â”‚ é©±åŠ¨/è®¾å¤‡  â”‚   â”‚ åº”ç”¨å±‚ CUDA    â”‚           â”‚
            â”‚ æŒ‚è½½é—®é¢˜   â”‚   â”‚ ç‰ˆæœ¬å…¼å®¹é—®é¢˜   â”‚           â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                                                           â”‚
                                                           â–¼
                                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                    â”‚ é—®é¢˜å®šä½   â”‚
                                                    â”‚ å®Œæˆ       â”‚
                                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ’æŸ¥å‘½ä»¤é›†

#### è®¾å¤‡æ’ä»¶çŠ¶æ€æ£€æŸ¥

```bash
# æ£€æŸ¥è®¾å¤‡æ’ä»¶ DaemonSet çŠ¶æ€
kubectl get ds -n kube-system | grep -E "nvidia|gpu|device"

# æ£€æŸ¥è®¾å¤‡æ’ä»¶ Pod çŠ¶æ€
kubectl get pods -n kube-system -l app=nvidia-device-plugin-daemonset
kubectl get pods -n gpu-operator-resources

# æŸ¥çœ‹è®¾å¤‡æ’ä»¶æ—¥å¿—
kubectl logs -n kube-system -l app=nvidia-device-plugin-daemonset --tail=100

# æ£€æŸ¥ NVIDIA GPU Operator ç»„ä»¶ (å¦‚æœä½¿ç”¨)
kubectl get pods -n gpu-operator -o wide
```

#### Node GPU èµ„æºæ£€æŸ¥

```bash
# æŸ¥çœ‹èŠ‚ç‚¹ GPU èµ„æº
kubectl get nodes -o json | jq '.items[] | {name: .metadata.name, capacity: .status.capacity, allocatable: .status.allocatable}' | grep -A5 -B1 gpu

# è¯¦ç»†æŸ¥çœ‹å•ä¸ªèŠ‚ç‚¹
kubectl describe node <node-name> | grep -A10 "Capacity\|Allocatable\|Allocated"

# æŸ¥çœ‹ GPU èµ„æºåˆ†é…æƒ…å†µ
kubectl get pods -A -o json | jq '.items[] | select(.spec.containers[].resources.limits."nvidia.com/gpu" != null) | {namespace: .metadata.namespace, name: .metadata.name, node: .spec.nodeName, gpu: .spec.containers[].resources.limits."nvidia.com/gpu"}'
```

#### ä¸»æœºå±‚ GPU æ£€æŸ¥

```bash
# SSH åˆ° GPU èŠ‚ç‚¹åæ‰§è¡Œ

# NVIDIA GPU çŠ¶æ€
nvidia-smi

# è¯¦ç»† GPU ä¿¡æ¯
nvidia-smi -q

# GPU è¿›ç¨‹
nvidia-smi pmon -c 1

# é©±åŠ¨ç‰ˆæœ¬
cat /proc/driver/nvidia/version

# æ£€æŸ¥ NVIDIA è®¾å¤‡æ–‡ä»¶
ls -la /dev/nvidia*

# æ£€æŸ¥ NVIDIA å†…æ ¸æ¨¡å—
lsmod | grep nvidia

# æ£€æŸ¥è®¾å¤‡æ’ä»¶ socket
ls -la /var/lib/kubelet/device-plugins/

# æ£€æŸ¥å®¹å™¨è¿è¡Œæ—¶ GPU é…ç½®
# containerd
cat /etc/containerd/config.toml | grep -A10 nvidia

# Docker
cat /etc/docker/daemon.json | jq '.runtimes'
```

#### kubelet è®¾å¤‡ç›¸å…³æ—¥å¿—

```bash
# kubelet è®¾å¤‡æ’ä»¶ç›¸å…³æ—¥å¿—
journalctl -u kubelet | grep -i "device\|plugin\|gpu\|nvidia" | tail -50

# è®¾å¤‡åˆ†é…æ—¥å¿—
journalctl -u kubelet | grep -i "allocate" | tail -20

# ListAndWatch ç›¸å…³
journalctl -u kubelet | grep -i "ListAndWatch" | tail -20
```

### 2.3 æ’æŸ¥æ³¨æ„äº‹é¡¹

| æ³¨æ„äº‹é¡¹ | è¯´æ˜ | é£é™©ç­‰çº§ |
|----------|------|----------|
| ä¸è¦éšæ„é‡å¯è®¾å¤‡æ’ä»¶ | ä¼šå½±å“æ­£åœ¨è¿è¡Œçš„ GPU å·¥ä½œè´Ÿè½½çš„ç›‘æ§ | ä¸­ |
| é©±åŠ¨å‡çº§éœ€è¦æ’ç©ºèŠ‚ç‚¹ | å‡çº§é©±åŠ¨éœ€è¦å…ˆè¿ç§» GPU å·¥ä½œè´Ÿè½½ | é«˜ |
| MIG é…ç½®å˜æ›´éœ€é‡å¯ | æ›´æ”¹ MIG æ¨¡å¼éœ€è¦é‡å¯ GPU | é«˜ |
| æ—¶é—´ç‰‡é…ç½®è°¨æ…è°ƒæ•´ | å½±å“æ‰€æœ‰å…±äº« GPU çš„ Pod æ€§èƒ½ | ä¸­ |
| æ£€æŸ¥ CUDA ç‰ˆæœ¬å…¼å®¹æ€§ | é©±åŠ¨ç‰ˆæœ¬å†³å®šæ”¯æŒçš„æœ€é«˜ CUDA ç‰ˆæœ¬ | ä¸­ |

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šè§£å†³æ–¹æ¡ˆä¸é£é™©æ§åˆ¶

### 3.1 è®¾å¤‡æ’ä»¶æœªæ³¨å†Œ/ä¸å¯ç”¨

**é—®é¢˜ç°è±¡**ï¼šNode ä¸Šçœ‹ä¸åˆ° GPU èµ„æºï¼Œ`kubectl describe node` ä¸­ Capacity æ—  `nvidia.com/gpu`ã€‚

**è§£å†³æ­¥éª¤**ï¼š

```bash
# æ­¥éª¤ 1: æ£€æŸ¥è®¾å¤‡æ’ä»¶ DaemonSet æ˜¯å¦å­˜åœ¨ä¸”è¿è¡Œæ­£å¸¸
kubectl get ds -n kube-system nvidia-device-plugin-daemonset
kubectl get pods -n kube-system -l app=nvidia-device-plugin-daemonset -o wide

# å¦‚æœæ²¡æœ‰å®‰è£…ï¼Œéƒ¨ç½² NVIDIA Device Plugin
kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.14.0/nvidia-device-plugin.yml

# æ­¥éª¤ 2: æ£€æŸ¥æ’ä»¶ Pod æ—¥å¿—
kubectl logs -n kube-system -l app=nvidia-device-plugin-daemonset

# æ­¥éª¤ 3: åœ¨èŠ‚ç‚¹ä¸Šæ£€æŸ¥åŸºç¡€è®¾æ–½
# SSH åˆ°èŠ‚ç‚¹
nvidia-smi  # ç¡®è®¤é©±åŠ¨å·¥ä½œæ­£å¸¸

# æ£€æŸ¥è®¾å¤‡æ’ä»¶ socket ç›®å½•
ls -la /var/lib/kubelet/device-plugins/

# æ£€æŸ¥ nvidia è¿è¡Œæ—¶æ˜¯å¦é…ç½®
# å¯¹äº containerd
cat /etc/containerd/config.toml | grep -A20 "\[plugins.*containerd.*runtimes.*nvidia\]"

# æ­¥éª¤ 4: å¦‚æœè¿è¡Œæ—¶æœªé…ç½®ï¼Œé…ç½® nvidia-container-runtime
# /etc/containerd/config.toml æ·»åŠ :
```

**containerd é…ç½®ç¤ºä¾‹**ï¼š

```toml
# /etc/containerd/config.toml

version = 2

[plugins."io.containerd.grpc.v1.cri".containerd]
  default_runtime_name = "nvidia"

[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia]
  runtime_type = "io.containerd.runc.v2"

[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia.options]
  BinaryName = "/usr/bin/nvidia-container-runtime"
```

```bash
# é‡å¯ containerd (éœ€è¦æ’ç©ºèŠ‚ç‚¹ä¸Šçš„å·¥ä½œè´Ÿè½½)
systemctl restart containerd

# æ­¥éª¤ 5: é‡å¯è®¾å¤‡æ’ä»¶
kubectl delete pods -n kube-system -l app=nvidia-device-plugin-daemonset

# æ­¥éª¤ 6: éªŒè¯ GPU èµ„æºå‡ºç°
kubectl describe node <gpu-node> | grep -i nvidia
```

### 3.2 GPU Pod è°ƒåº¦å¤±è´¥ (Insufficient)

**é—®é¢˜ç°è±¡**ï¼šGPU Pod ä¸€ç›´ Pendingï¼Œäº‹ä»¶æ˜¾ç¤º `Insufficient nvidia.com/gpu`ã€‚

**è§£å†³æ­¥éª¤**ï¼š

```bash
# æ­¥éª¤ 1: æ£€æŸ¥é›†ç¾¤ GPU èµ„æºæ€»é‡
kubectl get nodes -o custom-columns=NAME:.metadata.name,GPU:.status.allocatable."nvidia\.com/gpu"

# æ­¥éª¤ 2: æ£€æŸ¥ GPU èµ„æºä½¿ç”¨æƒ…å†µ
kubectl get pods -A -o json | jq -r '
  .items[] | 
  select(.spec.containers[].resources.limits."nvidia.com/gpu" != null) |
  [.metadata.namespace, .metadata.name, .spec.nodeName, 
   (.spec.containers[] | .resources.limits."nvidia.com/gpu" // "0")] | 
  @tsv' | column -t

# æ­¥éª¤ 3: è®¡ç®—å¯ç”¨ GPU
# æ€»å®¹é‡ - å·²åˆ†é… = å¯ç”¨

# æ­¥éª¤ 4: å¦‚æœèµ„æºä¸è¶³ï¼Œè€ƒè™‘ä»¥ä¸‹é€‰é¡¹:
# a. ç­‰å¾…å…¶ä»– GPU å·¥ä½œè´Ÿè½½å®Œæˆ
# b. æ·»åŠ æ›´å¤š GPU èŠ‚ç‚¹
# c. ä½¿ç”¨ GPU å…±äº«æ–¹æ¡ˆ (MIG, æ—¶é—´ç‰‡)
# d. ä¼˜åŒ–è¯·æ±‚çš„ GPU æ•°é‡
```

**æ£€æŸ¥ Pod æ˜¯å¦è¯·æ±‚è¿‡å¤š GPU**ï¼š

```yaml
# æ£€æŸ¥ Pod é…ç½®
apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  containers:
  - name: cuda-container
    image: nvidia/cuda:12.0-runtime
    resources:
      limits:
        nvidia.com/gpu: 1  # ç¡®è®¤æ˜¯å¦çœŸçš„éœ€è¦è¿™ä¹ˆå¤š
```

### 3.3 è®¾å¤‡æ’ä»¶ Allocate å¤±è´¥

**é—®é¢˜ç°è±¡**ï¼šPod åœ¨ ContainerCreating çŠ¶æ€å¡ä½ï¼Œkubelet æ—¥å¿—æ˜¾ç¤º allocate å¤±è´¥ã€‚

**è§£å†³æ­¥éª¤**ï¼š

```bash
# æ­¥éª¤ 1: æŸ¥çœ‹ kubelet æ—¥å¿—å®šä½å…·ä½“é”™è¯¯
journalctl -u kubelet | grep -i "allocate\|device" | tail -50

# æ­¥éª¤ 2: æ£€æŸ¥è®¾å¤‡æ’ä»¶å¥åº·çŠ¶æ€
kubectl logs -n kube-system -l app=nvidia-device-plugin-daemonset | grep -i "health\|error\|fail"

# æ­¥éª¤ 3: åœ¨èŠ‚ç‚¹ä¸Šæ£€æŸ¥ GPU è®¾å¤‡çŠ¶æ€
nvidia-smi -q | grep -A5 "GPU Current Temp\|Power Draw\|ECC"

# æ­¥éª¤ 4: æ£€æŸ¥è®¾å¤‡æ–‡ä»¶æƒé™
ls -la /dev/nvidia*

# æ­¥éª¤ 5: å¦‚æœè®¾å¤‡ä¸å¥åº·ï¼Œå¯èƒ½éœ€è¦:
# a. é‡ç½® GPU
nvidia-smi --gpu-reset -i 0  # å±é™©æ“ä½œï¼Œä¼šå½±å“ä½¿ç”¨è¯¥ GPU çš„æ‰€æœ‰è¿›ç¨‹

# b. æ£€æŸ¥ç¡¬ä»¶é—®é¢˜
nvidia-smi -q | grep -i "retired\|error"

# æ­¥éª¤ 6: é‡å¯è®¾å¤‡æ’ä»¶åˆ·æ–°è®¾å¤‡åˆ—è¡¨
kubectl delete pods -n kube-system -l app=nvidia-device-plugin-daemonset
```

### 3.4 å®¹å™¨å†… GPU ä¸å¯ç”¨

**é—®é¢˜ç°è±¡**ï¼šPod è¿è¡Œä¸­ï¼Œä½†å®¹å™¨å†… `nvidia-smi` å¤±è´¥æˆ– CUDA ç¨‹åºæŠ¥é”™ã€‚

**è§£å†³æ­¥éª¤**ï¼š

```bash
# æ­¥éª¤ 1: è¿›å…¥å®¹å™¨æ£€æŸ¥
kubectl exec -it <pod-name> -- bash

# å®¹å™¨å†…æ‰§è¡Œ
nvidia-smi
# å¦‚æœå¤±è´¥ï¼Œæ£€æŸ¥è®¾å¤‡æ˜¯å¦æŒ‚è½½
ls -la /dev/nvidia*

# æ£€æŸ¥ç¯å¢ƒå˜é‡
env | grep -i nvidia
env | grep -i cuda

# æ­¥éª¤ 2: æ£€æŸ¥ Pod é…ç½®æ˜¯å¦æ­£ç¡®è¯·æ±‚äº† GPU
kubectl get pod <pod-name> -o yaml | grep -A10 resources

# æ­¥éª¤ 3: æ£€æŸ¥å®¹å™¨è¿è¡Œæ—¶æ˜¯å¦æ­£ç¡®é…ç½®
# åœ¨èŠ‚ç‚¹ä¸Š
crictl inspect <container-id> | grep -i nvidia

# æ­¥éª¤ 4: å¦‚æœç¯å¢ƒå˜é‡ç¼ºå¤±ï¼Œæ£€æŸ¥è®¾å¤‡æ’ä»¶é…ç½®
# è®¾å¤‡æ’ä»¶åº”è¯¥è¿”å›æ­£ç¡®çš„ç¯å¢ƒå˜é‡
```

**æ­£ç¡®çš„ GPU Pod é…ç½®ç¤ºä¾‹**ï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: gpu-test
spec:
  restartPolicy: OnFailure
  containers:
  - name: cuda-test
    image: nvidia/cuda:12.0-base-ubuntu22.04
    command: ["nvidia-smi"]
    resources:
      limits:
        nvidia.com/gpu: 1  # å¿…é¡»åœ¨ limits ä¸­æŒ‡å®š
```

### 3.5 CUDA ç‰ˆæœ¬ä¸å…¼å®¹

**é—®é¢˜ç°è±¡**ï¼šåº”ç”¨æŠ¥é”™ `CUDA driver version is insufficient for CUDA runtime version`ã€‚

**è§£å†³æ­¥éª¤**ï¼š

```bash
# æ­¥éª¤ 1: æ£€æŸ¥èŠ‚ç‚¹é©±åŠ¨ç‰ˆæœ¬æ”¯æŒçš„ CUDA ç‰ˆæœ¬
nvidia-smi  # å³ä¸Šè§’æ˜¾ç¤ºæ”¯æŒçš„æœ€é«˜ CUDA ç‰ˆæœ¬

# æ­¥éª¤ 2: æ£€æŸ¥åº”ç”¨ä½¿ç”¨çš„ CUDA ç‰ˆæœ¬
kubectl exec <pod-name> -- cat /usr/local/cuda/version.txt
# æˆ–
kubectl exec <pod-name> -- nvcc --version

# æ­¥éª¤ 3: ç¡®è®¤å…¼å®¹æ€§
# NVIDIA é©±åŠ¨ç‰ˆæœ¬ä¸ CUDA ç‰ˆæœ¬å¯¹åº”å…³ç³»:
# https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html

# æ­¥éª¤ 4: è§£å†³æ–¹æ¡ˆ
# a. å‡çº§èŠ‚ç‚¹é©±åŠ¨ (éœ€è¦æ’ç©ºèŠ‚ç‚¹)
# b. ä½¿ç”¨è¾ƒä½ç‰ˆæœ¬çš„ CUDA é•œåƒ
```

**ç‰ˆæœ¬å…¼å®¹æ€§å‚è€ƒ**ï¼š

| CUDA Version | Minimum Driver Version |
|--------------|------------------------|
| CUDA 12.x    | >= 525.60.13           |
| CUDA 11.8    | >= 520.61.05           |
| CUDA 11.7    | >= 515.43.04           |
| CUDA 11.6    | >= 510.39.01           |

### 3.6 MIG (Multi-Instance GPU) é—®é¢˜

**é—®é¢˜ç°è±¡**ï¼šMIG æ¨¡å¼å¯ç”¨ä½†è®¾å¤‡ä¸å¯ç”¨ï¼Œæˆ– MIG å®ä¾‹ä¸ç¬¦åˆé¢„æœŸã€‚

**è§£å†³æ­¥éª¤**ï¼š

```bash
# æ­¥éª¤ 1: æ£€æŸ¥ GPU æ˜¯å¦æ”¯æŒ MIG (A100, A30, H100 ç­‰)
nvidia-smi -q | grep "MIG Mode"

# æ­¥éª¤ 2: æŸ¥çœ‹å½“å‰ MIG é…ç½®
nvidia-smi mig -lgi  # åˆ—å‡º GPU Instances
nvidia-smi mig -lci  # åˆ—å‡º Compute Instances

# æ­¥éª¤ 3: å¦‚æœéœ€è¦é‡æ–°é…ç½® MIG
# é¦–å…ˆæ’ç©ºèŠ‚ç‚¹ä¸Šçš„ GPU å·¥ä½œè´Ÿè½½
kubectl drain <node> --ignore-daemonsets

# å¯ç”¨ MIG æ¨¡å¼ (éœ€è¦é‡å¯)
nvidia-smi -mig 1 -i 0

# é‡å¯èŠ‚ç‚¹æˆ–é‡ç½® GPU
# é‡å¯ååˆ›å»º MIG å®ä¾‹
nvidia-smi mig -cgi 9,9,9,9,9,9,9 -i 0  # åˆ›å»º 7 ä¸ª 1g.5gb å®ä¾‹
nvidia-smi mig -cci -i 0  # åˆ›å»ºè®¡ç®—å®ä¾‹

# æ­¥éª¤ 4: éªŒè¯ MIG è®¾å¤‡
nvidia-smi -L

# æ­¥éª¤ 5: é‡å¯è®¾å¤‡æ’ä»¶ä»¥å‘ç°æ–°çš„ MIG è®¾å¤‡
kubectl delete pods -n kube-system -l app=nvidia-device-plugin-daemonset

# æ­¥éª¤ 6: æ¢å¤èŠ‚ç‚¹
kubectl uncordon <node>
```

**MIG è®¾å¤‡è¯·æ±‚ç¤ºä¾‹**ï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mig-pod
spec:
  containers:
  - name: mig-container
    image: nvidia/cuda:12.0-runtime
    resources:
      limits:
        # MIG è®¾å¤‡èµ„æºåç§°æ ¼å¼
        nvidia.com/mig-1g.5gb: 1  # è¯·æ±‚ 1 ä¸ª 1g.5gb MIG å®ä¾‹
```

### 3.7 GPU æ—¶é—´ç‰‡å…±äº«é—®é¢˜

**é—®é¢˜ç°è±¡**ï¼šä½¿ç”¨æ—¶é—´ç‰‡å…±äº«æ—¶æ€§èƒ½ä¸‹é™æˆ–è°ƒåº¦å¼‚å¸¸ã€‚

**é…ç½®æ—¶é—´ç‰‡å…±äº«**ï¼š

```yaml
# NVIDIA Device Plugin ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: nvidia-device-plugin-config
  namespace: kube-system
data:
  config.yaml: |
    version: v1
    sharing:
      timeSlicing:
        renameByDefault: false
        failRequestsGreaterThanOne: false
        resources:
        - name: nvidia.com/gpu
          replicas: 4  # æ¯ä¸ª GPU è™šæ‹Ÿæˆ 4 ä¸ª
```

**è§£å†³æ­¥éª¤**ï¼š

```bash
# æ­¥éª¤ 1: åº”ç”¨æ—¶é—´ç‰‡é…ç½®
kubectl apply -f nvidia-device-plugin-config.yaml

# æ­¥éª¤ 2: é‡å¯è®¾å¤‡æ’ä»¶ä½¿é…ç½®ç”Ÿæ•ˆ
kubectl rollout restart ds/nvidia-device-plugin-daemonset -n kube-system

# æ­¥éª¤ 3: éªŒè¯è™šæ‹Ÿ GPU æ•°é‡
kubectl describe node <gpu-node> | grep nvidia.com/gpu
# åº”è¯¥çœ‹åˆ° Capacity å˜æˆåŸæ¥çš„ 4 å€

# æ­¥éª¤ 4: ç›‘æ§æ—¶é—´ç‰‡ä½¿ç”¨æƒ…å†µ
# æ—¶é—´ç‰‡å…±äº«ä¼šå¯¼è‡´ GPU åˆ©ç”¨ç‡æ˜¾ç¤ºå¼‚å¸¸ï¼Œéœ€è¦å…³æ³¨å®é™…æ€§èƒ½
```

### 3.8 RDMA/InfiniBand è®¾å¤‡é—®é¢˜

**é—®é¢˜ç°è±¡**ï¼šé«˜æ€§èƒ½ç½‘ç»œè®¾å¤‡ä¸å¯ç”¨ï¼Œåˆ†å¸ƒå¼è®­ç»ƒæ€§èƒ½å·®ã€‚

**è§£å†³æ­¥éª¤**ï¼š

```bash
# æ­¥éª¤ 1: æ£€æŸ¥ RDMA è®¾å¤‡æ’ä»¶
kubectl get ds -n kube-system | grep rdma

# æ­¥éª¤ 2: åœ¨èŠ‚ç‚¹ä¸Šæ£€æŸ¥ RDMA è®¾å¤‡
ibstat
ibv_devices
rdma link

# æ­¥éª¤ 3: æ£€æŸ¥èŠ‚ç‚¹èµ„æº
kubectl describe node <node> | grep -i rdma

# æ­¥éª¤ 4: éƒ¨ç½² RDMA è®¾å¤‡æ’ä»¶ (å¦‚æœæœªéƒ¨ç½²)
# ä»¥ k8s-rdma-shared-dev-plugin ä¸ºä¾‹
kubectl apply -f https://raw.githubusercontent.com/Mellanox/k8s-rdma-shared-dev-plugin/master/images/k8s-rdma-shared-dev-plugin-ds.yaml
```

**RDMA Pod é…ç½®ç¤ºä¾‹**ï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: rdma-pod
spec:
  containers:
  - name: rdma-container
    image: your-rdma-app
    resources:
      limits:
        rdma/hca_shared_devices_a: 1  # RDMA è®¾å¤‡èµ„æº
        nvidia.com/gpu: 1             # GPU è®¾å¤‡
    securityContext:
      capabilities:
        add: ["IPC_LOCK"]  # RDMA éœ€è¦çš„èƒ½åŠ›
```

### 3.9 å®‰å…¨ç”Ÿäº§é£é™©æç¤º

| æ“ä½œ | é£é™©ç­‰çº§ | æ½œåœ¨é£é™© | å»ºè®®æªæ–½ |
|------|----------|----------|----------|
| å‡çº§ GPU é©±åŠ¨ | é«˜ | æ‰€æœ‰ GPU å·¥ä½œè´Ÿè½½ä¸­æ–­ | æ’ç©ºèŠ‚ç‚¹ï¼Œç°åº¦å‡çº§ |
| é‡ç½® GPU (`nvidia-smi --gpu-reset`) | é«˜ | æ€æ­»æ‰€æœ‰ä½¿ç”¨è¯¥ GPU çš„è¿›ç¨‹ | ç¡®ä¿æ— è¿è¡Œå·¥ä½œè´Ÿè½½ |
| ä¿®æ”¹ MIG é…ç½® | é«˜ | éœ€è¦é‡å¯ï¼Œå½±å“æ‰€æœ‰ GPU Pod | æ’ç©ºèŠ‚ç‚¹åæ“ä½œ |
| é‡å¯è®¾å¤‡æ’ä»¶ | ä¸­ | æ–° Pod çŸ­æ—¶æ— æ³•è°ƒåº¦ | é€‰æ‹©ä½å³°æœŸ |
| ä¿®æ”¹æ—¶é—´ç‰‡é…ç½® | ä¸­ | å½±å“ GPU èµ„æºè®¡ç®—å’Œè°ƒåº¦ | å……åˆ†æµ‹è¯•åä¸Šçº¿ |
| ä¿®æ”¹å®¹å™¨è¿è¡Œæ—¶é…ç½® | ä¸­ | éœ€é‡å¯ containerd | æ’ç©ºèŠ‚ç‚¹åæ“ä½œ |

### é™„å½•ï¼šå¿«é€Ÿè¯Šæ–­å‘½ä»¤

```bash
# ===== ä¸€é”®è¯Šæ–­è„šæœ¬ =====

echo "=== GPU Node çŠ¶æ€ ==="
kubectl get nodes -o custom-columns=NAME:.metadata.name,GPU:.status.allocatable."nvidia\.com/gpu"

echo -e "\n=== è®¾å¤‡æ’ä»¶çŠ¶æ€ ==="
kubectl get pods -n kube-system -l app=nvidia-device-plugin-daemonset -o wide

echo -e "\n=== GPU Pod åˆ†å¸ƒ ==="
kubectl get pods -A -o json | jq -r '
  .items[] | 
  select(.spec.containers[].resources.limits."nvidia.com/gpu" != null) |
  [.metadata.namespace, .metadata.name, .spec.nodeName, .status.phase] | 
  @tsv' | column -t

echo -e "\n=== Pending GPU Pods ==="
kubectl get pods -A --field-selector=status.phase=Pending -o json | jq -r '
  .items[] | 
  select(.spec.containers[].resources.limits."nvidia.com/gpu" != null) |
  [.metadata.namespace, .metadata.name] | 
  @tsv'

echo -e "\n=== è®¾å¤‡æ’ä»¶æ—¥å¿— (æœ€è¿‘ 10 æ¡) ==="
kubectl logs -n kube-system -l app=nvidia-device-plugin-daemonset --tail=10 2>/dev/null || echo "æ— æ³•è·å–æ—¥å¿—"

# ===== èŠ‚ç‚¹çº§æ£€æŸ¥ (éœ€è¦ SSH åˆ°èŠ‚ç‚¹) =====
# nvidia-smi
# ls -la /var/lib/kubelet/device-plugins/
# journalctl -u kubelet | grep -i gpu | tail -20
```

### é™„å½•ï¼šå¸¸ç”¨è®¾å¤‡æ’ä»¶éƒ¨ç½²

```yaml
# NVIDIA Device Plugin (æ ‡å‡†éƒ¨ç½²)
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nvidia-device-plugin-daemonset
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: nvidia-device-plugin-ds
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        name: nvidia-device-plugin-ds
    spec:
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      priorityClassName: system-node-critical
      containers:
      - image: nvcr.io/nvidia/k8s-device-plugin:v0.14.0
        name: nvidia-device-plugin-ctr
        env:
        - name: FAIL_ON_INIT_ERROR
          value: "false"
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]
        volumeMounts:
        - name: device-plugin
          mountPath: /var/lib/kubelet/device-plugins
      volumes:
      - name: device-plugin
        hostPath:
          path: /var/lib/kubelet/device-plugins
      nodeSelector:
        # åªåœ¨æœ‰ GPU çš„èŠ‚ç‚¹ä¸Šè¿è¡Œ
        nvidia.com/gpu.present: "true"
```
