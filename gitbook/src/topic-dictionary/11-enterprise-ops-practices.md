# ä¼ä¸šçº§è¿ç»´æœ€ä½³å®è·µ

> **ç›®æ ‡**: æ„å»ºä¸‡çº§èŠ‚ç‚¹è§„æ¨¡çš„ä¼ä¸šçº§Kubernetesè¿ç»´ä½“ç³»ï¼Œå®ç°é«˜å¯ç”¨ã€é«˜æ€§èƒ½ã€é«˜å®‰å…¨çš„ç”Ÿäº§ç¯å¢ƒè¿ç»´

---

## çŸ¥è¯†åœ°å›¾

| å±æ€§ | è¯´æ˜ |
|------|------|
| **æ–‡ä»¶è§’è‰²** | ä¼ä¸šçº§è¿ç»´æœ€ä½³å®è·µ â€” ä¸‡çº§èŠ‚ç‚¹è§„æ¨¡K8sé›†ç¾¤çš„è¿ç»´æŒ‡å— |
| **é€‚åˆè¯»è€…** | ä¸­å°å›¢é˜Ÿè¿ç»´â†’å¤§è§„æ¨¡é›†ç¾¤ç®¡ç†â†’ä¼ä¸šå¹³å°å·¥ç¨‹ |
| **å‰ç½®çŸ¥è¯†** | 01(è¿ç»´å®è·µåŸºç¡€)ã€04(SREæˆç†Ÿåº¦) |
| **å…³è”æ–‡ä»¶** | 01(åŸºç¡€è¿ç»´)ã€04(SRE)ã€12(äº‹æ•…ç®¡ç†)ã€14(å˜æ›´ç®¡ç†) |

---

## ğŸ¢ å¤§è§„æ¨¡é›†ç¾¤ç®¡ç†

> **ğŸ”° åˆå­¦è€…å¯¼è¯»**: å½“é›†ç¾¤ä»å‡ åä¸ªèŠ‚ç‚¹å¢é•¿åˆ°æ•°åƒä¸ªèŠ‚ç‚¹æ—¶ï¼Œç®¡ç†æ–¹å¼å¿…é¡»æ”¹å˜ã€‚å°±åƒä»ç®¡ç†ä¸€ä¸ªå°åº—é“ºåˆ°ç®¡ç†è¿é”è¶…å¸‚ï¼Œéœ€è¦æ ‡å‡†åŒ–æµç¨‹ã€è‡ªåŠ¨åŒ–å·¥å…·å’Œåˆ†å±‚ç®¡ç†æ¶æ„ã€‚

### ä¸‡çº§èŠ‚ç‚¹è¿ç»´æ¶æ„

#### é›†ç¾¤åˆ†å±‚ç®¡ç†ç­–ç•¥
```yaml
# å¤§è§„æ¨¡é›†ç¾¤åˆ†å±‚æ¶æ„
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-tier-config
data:
  # æ ¸å¿ƒå±‚ - æ§åˆ¶å¹³é¢
  control-plane:
    node-count: "300"
    instance-type: "c6i.4xlarge"
    redundancy: "3 AZ"
    monitoring-interval: "1s"
  
  # æ•°æ®å±‚ - å­˜å‚¨èŠ‚ç‚¹
  data-layer:
    node-count: "2000"
    instance-type: "i4i.4xlarge"
    storage-type: "local NVMe"
    replication-factor: "3"
  
  # è®¡ç®—å±‚ - å·¥ä½œèŠ‚ç‚¹
  compute-layer:
    node-count: "8000"
    instance-type: "c6i.2xlarge"
    autoscaling: "enabled"
    spot-ratio: "70%"
  
  # è¾¹ç¼˜å±‚ - è¾¹ç¼˜è®¡ç®—
  edge-layer:
    node-count: "500"
    instance-type: "t3.medium"
    latency-target: "<10ms"
    offline-tolerance: "24h"
```

**ğŸ”° åˆå­¦è€…ç†è§£**
é›†ç¾¤åˆ†ç‰‡å°±åƒè¿é”è¶…å¸‚çš„åˆ†åŒºç®¡ç†â€”â€”ç”Ÿé²œåŒºã€ç™¾è´§åŒºã€ç”µå™¨åŒºå„è‡ªç‹¬ç«‹è¿è¥ï¼Œäº’ä¸å¹²æ‰°ã€‚æ ¸å¿ƒæ€æƒ³ï¼š**å°†å¤§é›†ç¾¤æŒ‰åŠŸèƒ½/åœ°åŸŸæ‹†åˆ†æˆå¤šä¸ªå°é›†ç¾¤ï¼Œé™ä½å¤æ‚åº¦**ã€‚

**ğŸ”§ å·¥ä½œåŸç†**
- **åŠŸèƒ½åˆ†ç‰‡**: æ ¸å¿ƒä¸šåŠ¡é›†ç¾¤/æµ‹è¯•é›†ç¾¤/è¾¹ç¼˜è®¡ç®—é›†ç¾¤å„è‡ªç‹¬ç«‹
- **åœ°åŸŸåˆ†ç‰‡**: åŒ—ç¾/æ¬§æ´²/äºšæ´²æ•°æ®ä¸­å¿ƒå„ç»´æŠ¤ç‹¬ç«‹é›†ç¾¤
- **å›¢é˜Ÿåˆ†ç‰‡**: ä¸åŒä¸šåŠ¡å›¢é˜Ÿæ‹¥æœ‰ç‹¬ç«‹é›†ç¾¤ï¼Œé¿å…èµ„æºæŠ¢å 
- **ç»Ÿä¸€ç®¡ç†**: é€šè¿‡Federation/Hubæ¨¡å¼å®ç°è·¨é›†ç¾¤ç»Ÿä¸€é…ç½®å’Œç›‘æ§
- **æ•…éšœéš”ç¦»**: å•ä¸ªåˆ†ç‰‡æ•…éšœä¸å½±å“å…¶ä»–åˆ†ç‰‡ï¼Œçˆ†ç‚¸åŠå¾„å¯æ§

**ğŸ“ æœ€å°ç¤ºä¾‹**
```yaml
# ä½¿ç”¨ Cluster API åˆ›å»ºåˆ†ç‰‡é›†ç¾¤
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  name: shard-us-production
  labels:
    region: us-east-1
    env: production
spec:
  clusterNetwork:
    pods:
      cidrBlocks: ["10.100.0.0/16"]
    services:
      cidrBlocks: ["10.200.0.0/16"]
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: shard-us-control-plane
---
# è·¨é›†ç¾¤æœåŠ¡å‘ç°é…ç½®
apiVersion: v1
kind: Service
metadata:
  name: cross-cluster-service
  annotations:
    # Submariner è·¨é›†ç¾¤æœåŠ¡å‘ç°
    submariner.io/globalnet: "true"
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 8080
```

**âš ï¸ å¸¸è§è¯¯åŒº**
1. âŒ **è¯¯åŒº**: æŠŠæ‰€æœ‰ä¸šåŠ¡å¡åœ¨ä¸€ä¸ªè¶…å¤§é›†ç¾¤é‡Œâ€”â€”"ä¸€ä¸ªé›†ç¾¤ç®¡ç†æ‰€æœ‰"
   âœ… **æ­£ç¡®**: 10000èŠ‚ç‚¹åº”æ‹†åˆ†ä¸º10ä¸ª1000èŠ‚ç‚¹é›†ç¾¤ï¼Œé™ä½ç®¡ç†å¤æ‚åº¦å’Œæ•…éšœå½±å“èŒƒå›´
   
2. âŒ **è¯¯åŒº**: åˆ†ç‰‡åå®Œå…¨ç‹¬ç«‹ï¼Œæ²¡æœ‰ç»Ÿä¸€ç®¡ç†â€”â€”"å„è‡ªä¸ºæ”¿"
   âœ… **æ­£ç¡®**: ä½¿ç”¨Federation/Fleet Managerå®ç°ç»Ÿä¸€é…ç½®åˆ†å‘ã€ç›‘æ§èšåˆã€ç­–ç•¥ç®¡ç†
   
3. âŒ **è¯¯åŒº**: æŒ‰ç…§æŠ€æœ¯æ¶æ„åˆ†ç‰‡(å¦‚æŒ‰Layeråˆ†)â€”â€”"æ§åˆ¶é¢ä¸€ä¸ªé›†ç¾¤ï¼Œæ•°æ®é¢ä¸€ä¸ªé›†ç¾¤"
   âœ… **æ­£ç¡®**: åº”æŒ‰ä¸šåŠ¡åŸŸ/åœ°åŸŸ/ç¯å¢ƒåˆ†ç‰‡ï¼Œæ¯ä¸ªåˆ†ç‰‡éƒ½æ˜¯å®Œæ•´çš„K8sé›†ç¾¤(åŒ…å«æ§åˆ¶é¢å’Œæ•°æ®é¢)

#### æ€§èƒ½è°ƒä¼˜é»„é‡‘é…ç½®
```bash
#!/bin/bash
# ä¸‡çº§èŠ‚ç‚¹æ€§èƒ½è°ƒä¼˜è„šæœ¬

# å†…æ ¸å‚æ•°ä¼˜åŒ–
cat > /etc/sysctl.d/99-k8s-performance.conf << EOF
# ç½‘ç»œæ€§èƒ½ä¼˜åŒ–
net.core.rmem_max = 134217728
net.core.wmem_max = 134217728
net.ipv4.tcp_rmem = 4096 87380 134217728
net.ipv4.tcp_wmem = 4096 65536 134217728
net.ipv4.tcp_congestion_control = bbr

# æ–‡ä»¶ç³»ç»Ÿä¼˜åŒ–
fs.file-max = 2097152
fs.inotify.max_user_watches = 1048576
fs.inotify.max_user_instances = 8192

# å†…å­˜ç®¡ç†ä¼˜åŒ–
vm.swappiness = 1
vm.dirty_ratio = 15
vm.dirty_background_ratio = 5
EOF

# kubelet å‚æ•°ä¼˜åŒ–
cat > /etc/default/kubelet << EOF
KUBELET_EXTRA_ARGS="--max-pods=250 \
  --kube-api-qps=100 \
  --kube-api-burst=200 \
  --serialize-image-pulls=false \
  --eviction-hard=memory.available<500Mi,nodefs.available<10% \
  --eviction-soft=memory.available<1Gi,nodefs.available<15% \
  --eviction-soft-grace-period=memory.available=1m30s,nodefs.available=1m30s"
EOF
```

### å¤šé›†ç¾¤è”é‚¦ç®¡ç†

#### Cluster API å¤§è§„æ¨¡éƒ¨ç½²
```yaml
# å¤šé›†ç¾¤è”é‚¦ç®¡ç†é…ç½®
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  name: enterprise-federation
spec:
  # ä¸»é›†ç¾¤é…ç½®
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: main-control-plane
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: AWSCluster
    name: main-infrastructure
  
---
apiVersion: addons.cluster.x-k8s.io/v1alpha1
kind: ClusterResourceSet
metadata:
  name: enterprise-addons
spec:
  clusterSelector:
    matchLabels:
      cluster-type: production
  resources:
  - name: monitoring-stack
    kind: ConfigMap
  - name: security-policies
    kind: Secret
  - name: backup-configuration
    kind: ConfigMap
```

**ğŸ”° åˆå­¦è€…ç†è§£**
è‡ªåŠ¨åŒ–å·¡æ£€å°±åƒå·¥å‚çš„è´¨æ£€æµæ°´çº¿â€”â€”æ¯ä¸ªäº§å“éƒ½è¦ç»è¿‡æ ‡å‡†åŒ–æ£€æµ‹ï¼Œå‘ç°é—®é¢˜è‡ªåŠ¨æŠ¥è­¦ã€‚æ ¸å¿ƒæ€æƒ³ï¼š**ç”¨æœºå™¨ä»£æ›¿äººå·¥ï¼Œè‡ªåŠ¨å‘ç°éšæ‚£**ã€‚

**ğŸ”§ å·¥ä½œåŸç†**
- **å®šæ—¶æ‰«æ**: CronJobå®šæ—¶æ‰§è¡Œå¥åº·æ£€æŸ¥è„šæœ¬ï¼Œè¦†ç›–èŠ‚ç‚¹/Pod/ç½‘ç»œ/å­˜å‚¨
- **å¤šç»´åº¦æ£€æµ‹**: CPU/å†…å­˜/ç£ç›˜ä½¿ç”¨ç‡ã€è¯ä¹¦æœ‰æ•ˆæœŸã€APIå“åº”æ—¶é—´ã€æ—¥å¿—é”™è¯¯ç‡
- **æ™ºèƒ½å‘Šè­¦**: ä¸æ˜¯æ‰€æœ‰å¼‚å¸¸éƒ½å‘Šè­¦ï¼Œéœ€è¦åŸºäºé˜ˆå€¼/è¶‹åŠ¿/ä¸šåŠ¡å½±å“åº¦åˆ¤æ–­
- **è‡ªåŠ¨ä¿®å¤**: å‘ç°å¸¸è§é—®é¢˜(å¦‚ç£ç›˜æ¸…ç†ã€Podé‡å¯)å¯è§¦å‘è‡ªåŠ¨åŒ–ä¿®å¤æµç¨‹
- **å·¡æ£€æŠ¥å‘Š**: ç”Ÿæˆæ¯æ—¥/æ¯å‘¨å·¡æ£€æŠ¥å‘Šï¼Œè¿½è¸ªé—®é¢˜ä¿®å¤è¿›åº¦

**ğŸ“ æœ€å°ç¤ºä¾‹**
```yaml
# é›†ç¾¤å¥åº·å·¡æ£€ CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cluster-health-check
  namespace: ops-system
spec:
  schedule: "*/10 * * * *"  # æ¯10åˆ†é’Ÿæ‰§è¡Œ
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: cluster-inspector
          containers:
          - name: inspector
            image: kudig/cluster-inspector:v2.0
            env:
            - name: CHECK_ITEMS
              value: "nodes,pods,pv,certificates,etcd"
            - name: ALERT_WEBHOOK
              value: "https://alert.company.com/webhook"
            command:
            - /bin/bash
            - -c
            - |
              #!/bin/bash
              # èŠ‚ç‚¹å¥åº·æ£€æŸ¥
              kubectl get nodes -o json | jq '.items[] | select(.status.conditions[] | select(.type=="Ready" and .status!="True")) | .metadata.name'
              
              # è¯ä¹¦æœ‰æ•ˆæœŸæ£€æŸ¥(è­¦å‘Š<30å¤©)
              for cert in /etc/kubernetes/pki/*.crt; do
                expiry=$(openssl x509 -in $cert -noout -enddate | cut -d= -f2)
                echo "è¯ä¹¦ $cert è¿‡æœŸæ—¶é—´: $expiry"
              done
              
              # etcd æ€§èƒ½æ£€æŸ¥
              ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
                --cert=/etc/kubernetes/pki/etcd/server.crt \
                --key=/etc/kubernetes/pki/etcd/server.key \
                --cacert=/etc/kubernetes/pki/etcd/ca.crt \
                check perf
              
              # Podå¼‚å¸¸æ£€æŸ¥
              kubectl get pods -A --field-selector=status.phase!=Running,status.phase!=Succeeded
          restartPolicy: OnFailure
---
# å·¡æ£€ç»“æœå‘Šè­¦ PrometheusRule
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: inspection-alerts
spec:
  groups:
  - name: cluster-health
    interval: 30s
    rules:
    - alert: NodeNotReady
      expr: kube_node_status_condition{condition="Ready",status="true"} == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "èŠ‚ç‚¹ {{ $labels.node }} ä¸å¯ç”¨"
        
    - alert: CertificateExpiringSoon
      expr: (apiserver_client_certificate_expiration_seconds_count > 0) and (time() + 30*24*3600 > apiserver_client_certificate_expiration_seconds_bucket)
      for: 1h
      labels:
        severity: warning
      annotations:
        summary: "è¯ä¹¦å°†åœ¨30å¤©å†…è¿‡æœŸ"
```

**âš ï¸ å¸¸è§è¯¯åŒº**
1. âŒ **è¯¯åŒº**: åªæ£€æŸ¥"å½“å‰æ˜¯å¦æ­£å¸¸"ï¼Œä¸çœ‹è¶‹åŠ¿â€”â€”"ç£ç›˜è¿˜æœ‰10GBï¼Œæ²¡é—®é¢˜"
   âœ… **æ­£ç¡®**: ç›‘æ§å¢é•¿è¶‹åŠ¿ï¼Œç£ç›˜æ¯å¤©å¢é•¿2GBï¼Œ5å¤©åå°±æ»¡äº†ï¼Œéœ€è¦æå‰å‘Šè­¦
   
2. âŒ **è¯¯åŒº**: å·¡æ£€å‘ç°é—®é¢˜å°±å‘å‘Šè­¦ï¼Œæ‰€æœ‰äººéƒ½è¢«éªšæ‰°â€”â€”"ç‹¼æ¥äº†æ•ˆåº”"
   âœ… **æ­£ç¡®**: å‘Šè­¦åˆ†çº§(P0ç«‹å³å¤„ç†/P1å·¥ä½œæ—¶é—´/P2é‚®ä»¶é€šçŸ¥)ï¼Œæ ¹æ®å½±å“é¢å’Œç´§æ€¥åº¦è·¯ç”±
   
3. âŒ **è¯¯åŒº**: å·¡æ£€è„šæœ¬è·‘åœ¨masterèŠ‚ç‚¹ä¸Šâ€”â€”"æ§åˆ¶é¢æ•…éšœæ—¶å·¡æ£€ä¹Ÿåœäº†"
   âœ… **æ­£ç¡®**: å·¡æ£€ç³»ç»Ÿåº”éƒ¨ç½²åœ¨ç‹¬ç«‹çš„ç›‘æ§é›†ç¾¤æˆ–å¤–éƒ¨æœåŠ¡å™¨ä¸Šï¼Œç¡®ä¿é›†ç¾¤æ•…éšœæ—¶ä»èƒ½ç›‘æ§

## ğŸš€ å˜æ›´ç®¡ç†ä¸å‘å¸ƒç­–ç•¥

> **ğŸ”° åˆå­¦è€…å¯¼è¯»**: åœ¨ä¼ä¸šç¯å¢ƒä¸­ï¼Œæ¯æ¬¡å˜æ›´éƒ½å¯èƒ½å½±å“æˆåƒä¸Šä¸‡çš„ç”¨æˆ·ã€‚å˜æ›´ç®¡ç†å°±åƒèˆªç©ºç®¡åˆ¶â€”â€”æ¯æ¬¡"èµ·é£"éƒ½éœ€è¦å®¡æ‰¹ã€æ£€æŸ¥å’Œè·Ÿè¸ªã€‚é‡‘èã€åŒ»ç–—ç­‰è¡Œä¸šè¿˜éœ€æ»¡è¶³åˆè§„è¦æ±‚ã€‚

### æ¸è¿›å¼äº¤ä»˜æµæ°´çº¿

#### è“ç»¿éƒ¨ç½²æ¶æ„
```yaml
# è“ç»¿éƒ¨ç½²ç­–ç•¥é…ç½®
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: enterprise-blue-green
spec:
  source:
    repoURL: https://github.com/enterprise/apps.git
    targetRevision: HEAD
    path: production/
  destination:
    server: https://kubernetes.default.svc
    namespace: production
    
  strategy:
    blueGreen:
      activeService: production-service
      previewService: preview-service
      autoPromotionEnabled: false
      autoPromotionSeconds: 300
      
      # æ¸è¿›å¼æµé‡åˆ‡æ¢
      trafficRouting:
        smi:
          trafficSplitName: production-split
          rootService: production-root
          
---
# æµé‡åˆ†å‰²é…ç½®
apiVersion: split.smi-spec.io/v1alpha2
kind: TrafficSplit
metadata:
  name: production-split
spec:
  service: production-root
  backends:
  - service: production-blue
    weight: 90  # ä¸»è¦æµé‡
  - service: production-green
    weight: 10  # æ–°ç‰ˆæœ¬æµé‡
```

#### é‡‘ä¸é›€å‘å¸ƒç­–ç•¥
```yaml
# æ™ºèƒ½é‡‘ä¸é›€å‘å¸ƒ
apiVersion: flagger.app/v1beta1
kind: Canary
metadata:
  name: enterprise-canary
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: enterprise-app
    
  service:
    port: 80
    targetPort: 8080
    portName: http
    
  analysis:
    interval: 1m
    threshold: 5
    maxWeight: 100
    stepWeight: 10
    stepWeights: [1, 5, 10, 25, 50, 75, 100]
    
    # å¤šç»´åº¦æŒ‡æ ‡æ£€æŸ¥
    metrics:
    - name: request-success-rate
      interval: 1m
      thresholdRange:
        min: 99
      provider:
        type: prometheus
        address: http://prometheus:9090
        
    - name: request-duration
      interval: 1m
      thresholdRange:
        max: 500
      provider:
        type: prometheus
        address: http://prometheus:9090
        
    # ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§
    - name: business-transaction-success
      interval: 1m
      thresholdRange:
        min: 99.5
      provider:
        type: datadog
        query: avg:kubernetes_state.container.restarts{service:enterprise} < 1
        
    # ç”¨æˆ·ä½“éªŒæŒ‡æ ‡
    - name: frontend-load-time
      interval: 1m
      thresholdRange:
        max: 2000
      provider:
        type: newrelic
        query: SELECT average(duration) FROM PageView WHERE appName = 'enterprise'
```

**ğŸ”° åˆå­¦è€…ç†è§£**
å˜æ›´çª—å£å°±åƒé«˜é€Ÿå…¬è·¯çš„æ–½å·¥æ—¶é—´æ®µâ€”â€”åªèƒ½åœ¨å‡Œæ™¨2-5ç‚¹ç»´æŠ¤ï¼Œç™½å¤©ä¸èƒ½å½±å“é€šè¡Œã€‚æ ¸å¿ƒæ€æƒ³ï¼š**åœ¨ä¸šåŠ¡ä½å³°æœŸæ‰§è¡Œé«˜é£é™©å˜æ›´**ã€‚

**ğŸ”§ å·¥ä½œåŸç†**
- **æ—¶é—´åˆ†çº§**: ä½é£é™©å˜æ›´(é…ç½®æ›´æ–°)éšæ—¶å¯åšï¼Œé«˜é£é™©(æ•°æ®åº“å‡çº§)åªèƒ½åœ¨çª—å£æœŸ
- **ä¸šåŠ¡å¯¹é½**: æ ¹æ®ä¸šåŠ¡ç‰¹ç‚¹å®šä¹‰çª—å£ï¼Œç”µå•†é¿å¼€618/åŒ11ï¼Œé‡‘èé¿å¼€æœˆæœ«ç»“ç®—
- **å®¡æ‰¹æµç¨‹**: å˜æ›´éœ€æå‰3å¤©ç”³è¯·ï¼ŒåŒ…å«å›æ»šé¢„æ¡ˆã€å½±å“è¯„ä¼°ã€æµ‹è¯•æŠ¥å‘Š
- **å†»ç»“æœŸç®¡ç†**: é‡å¤§æ´»åŠ¨å‰1å‘¨è¿›å…¥å˜æ›´å†»ç»“ï¼Œåªå…è®¸P0çº§åˆ«ä¿®å¤
- **ä¾‹å¤–å¤„ç†**: ç´§æ€¥å®‰å…¨æ¼æ´ä¿®å¤å¯èµ°åº”æ€¥æµç¨‹ï¼Œäº‹åè¡¥å……å˜æ›´è®°å½•

**ğŸ“ æœ€å°ç¤ºä¾‹**
```yaml
# å˜æ›´çª—å£é…ç½® (å­˜å‚¨åœ¨ ConfigMap)
apiVersion: v1
kind: ConfigMap
metadata:
  name: change-windows
  namespace: ops-system
data:
  # æ ‡å‡†å˜æ›´çª—å£
  standard-windows: |
    - name: "weekly-maintenance"
      schedule: "0 2 * * 0"  # æ¯å‘¨æ—¥å‡Œæ™¨2ç‚¹
      duration: "3h"
      allowed-change-types: ["infrastructure", "database", "network"]
      
    - name: "daily-deployment"
      schedule: "0 22 * * 1-5"  # å·¥ä½œæ—¥æ™š10ç‚¹
      duration: "1h"
      allowed-change-types: ["application", "configuration"]
  
  # å˜æ›´å†»ç»“æœŸ
  freeze-periods: |
    - name: "Q4-shopping-festival"
      start: "2024-11-01"
      end: "2024-11-12"
      reason: "åŒ11å¤§ä¿ƒ"
      emergency-only: true
      
    - name: "year-end-close"
      start: "2024-12-28"
      end: "2025-01-03"
      reason: "å¹´åº¦ç»“ç®—"
      emergency-only: true

---
# å˜æ›´å®¡æ‰¹ CR (è‡ªå®šä¹‰èµ„æº)
apiVersion: ops.company.com/v1
kind: ChangeRequest
metadata:
  name: cr-2024-001
spec:
  title: "å‡çº§ç”Ÿäº§ç¯å¢ƒ Kubernetes åˆ° v1.30"
  change-type: "infrastructure"
  risk-level: "high"
  
  schedule:
    planned-start: "2024-03-17T02:00:00Z"
    planned-end: "2024-03-17T05:00:00Z"
    window: "weekly-maintenance"
  
  impact:
    affected-services: ["all"]
    expected-downtime: "30min"
    user-impact: "API çŸ­æš‚ä¸å¯ç”¨"
  
  rollback-plan: |
    1. å¦‚æœå‡çº§å¤±è´¥ï¼Œå›é€€åˆ° v1.29.2
    2. æ¢å¤ etcd å¿«ç…§
    3. é¢„ä¼°å›æ»šæ—¶é—´: 20åˆ†é’Ÿ
  
  approval:
    required-approvers: ["ops-lead", "cto"]
    status: "pending"
```

**âš ï¸ å¸¸è§è¯¯åŒº**
1. âŒ **è¯¯åŒº**: æ‰€æœ‰å˜æ›´éƒ½è¦èµ°å˜æ›´çª—å£â€”â€”"æ”¹ä¸ªé…ç½®ä¹Ÿè¦ç­‰åˆ°å‘¨æ—¥å‡Œæ™¨"
   âœ… **æ­£ç¡®**: åŒºåˆ†é«˜/ä¸­/ä½é£é™©å˜æ›´ï¼Œä½é£é™©(åªè¯»é…ç½®ã€æ—¥å¿—çº§åˆ«)å¯éšæ—¶å˜æ›´ï¼Œé«˜é£é™©æ‰éœ€è¦çª—å£
   
2. âŒ **è¯¯åŒº**: å˜æ›´çª—å£å†…å¯ä»¥"éšä¾¿æ”¹"â€”â€”"åæ­£æ˜¯ç»´æŠ¤æ—¶é—´ï¼Œå‡ºé—®é¢˜ä¹Ÿæ­£å¸¸"
   âœ… **æ­£ç¡®**: çª—å£æœŸåªæ˜¯é™ä½ç”¨æˆ·å½±å“ï¼Œä»éœ€ä¸¥æ ¼æµ‹è¯•ã€å®¡æ‰¹ã€ç›‘æ§ï¼Œå¹¶å‡†å¤‡å›æ»šé¢„æ¡ˆ
   
3. âŒ **è¯¯åŒº**: å˜æ›´å†»ç»“æœŸ"ä¸€åˆ€åˆ‡"â€”â€”"å†»ç»“æœŸé—´ä»»ä½•å˜æ›´éƒ½ç¦æ­¢"
   âœ… **æ­£ç¡®**: å†»ç»“æœŸåº”å…è®¸ç´§æ€¥å®‰å…¨è¡¥ä¸å’ŒP0çº§åˆ«æ•…éšœä¿®å¤ï¼Œåªæ˜¯éœ€è¦æ›´é«˜çº§åˆ«å®¡æ‰¹

### è‡ªåŠ¨åŒ–å›æ»šæœºåˆ¶

#### æ™ºèƒ½å›æ»šç­–ç•¥
```yaml
# è‡ªåŠ¨å›æ»šé…ç½®
apiVersion: rollouts.argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: smart-rollback
spec:
  replicas: 100
  strategy:
    canary:
      steps:
      - setWeight: 20
        pause: {duration: 10m}
      - setWeight: 50
        pause: {}
      - setWeight: 100
      
      # å›æ»šè§¦å‘æ¡ä»¶
      rollbackConditions:
      - metricName: error-rate
        threshold: 2.0
        operator: GreaterThan
        duration: 5m
        
      - metricName: latency-p99
        threshold: 1000
        operator: GreaterThan
        duration: 3m
        
      - metricName: cpu-utilization
        threshold: 80
        operator: GreaterThan
        duration: 2m
        
  # å¥åº·æ£€æŸ¥é…ç½®
  selector:
    matchLabels:
      app: enterprise-app
  template:
    metadata:
      labels:
        app: enterprise-app
    spec:
      containers:
      - name: app
        image: enterprise/app:v2.0
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
```

**ğŸ”° åˆå­¦è€…ç†è§£**
ç°åº¦å‘å¸ƒå°±åƒæ–°è¯çš„ä¸´åºŠè¯•éªŒâ€”â€”å…ˆç»™å°‘æ•°äººè¯•ç”¨(IæœŸ)ï¼Œå†æ‰©å¤§åˆ°æ›´å¤šäºº(IIæœŸ)ï¼Œæœ€åå…¨é¢æ¨å¹¿(IIIæœŸ)ã€‚æ¯ä¸ªé˜¶æ®µéƒ½ç›‘æ§å‰¯ä½œç”¨ï¼Œå‘ç°é—®é¢˜ç«‹å³åœæ­¢ã€‚æ ¸å¿ƒæ€æƒ³ï¼š**å°èŒƒå›´éªŒè¯ï¼Œé€æ­¥æ‰©å¤§ï¼Œéšæ—¶å¯å›é€€**ã€‚

**ğŸ”§ å·¥ä½œåŸç†**
- **æµé‡åˆ†é˜¶æ®µ**: 1% â†’ 5% â†’ 10% â†’ 25% â†’ 50% â†’ 100%ï¼Œæ¯ä¸ªé˜¶æ®µæŒç»­è§‚å¯Ÿ
- **ç”¨æˆ·åˆ†ç»„**: å¯ä»¥åŸºäºç”¨æˆ·ID/åœ°åŸŸ/è®¾å¤‡ç±»å‹å®šå‘ç°åº¦ï¼Œä¾‹å¦‚"å…ˆç»™å†…éƒ¨å‘˜å·¥"
- **å¤šç»´åº¦ç›‘æ§**: ä¸ä»…çœ‹é”™è¯¯ç‡ï¼Œè¿˜è¦çœ‹ä¸šåŠ¡æŒ‡æ ‡(è®¢å•è½¬åŒ–ç‡ã€æ”¯ä»˜æˆåŠŸç‡)
- **è‡ªåŠ¨å†³ç­–**: æŒ‡æ ‡å¼‚å¸¸è‡ªåŠ¨åœæ­¢ç°åº¦å¹¶å›æ»šï¼Œæ— éœ€äººå·¥å¹²é¢„
- **A/Bå¯¹æ¯”**: æ–°æ—§ç‰ˆæœ¬åŒæ—¶è¿è¡Œï¼Œå®æ—¶å¯¹æ¯”æ€§èƒ½å·®å¼‚

**ğŸ“ æœ€å°ç¤ºä¾‹**
```yaml
# Flagger ç°åº¦å‘å¸ƒé…ç½®
apiVersion: flagger.app/v1beta1
kind: Canary
metadata:
  name: payment-service
  namespace: production
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: payment-service
  
  service:
    port: 8080
  
  analysis:
    interval: 2m           # æ¯2åˆ†é’Ÿè¯„ä¼°ä¸€æ¬¡
    threshold: 3           # è¿ç»­3æ¬¡å¤±è´¥åˆ™å›æ»š
    maxWeight: 50          # æœ€å¤§æµé‡æƒé‡50%
    stepWeight: 10         # æ¯æ¬¡å¢åŠ 10%æµé‡
    
    metrics:
    - name: request-success-rate
      thresholdRange:
        min: 99            # æˆåŠŸç‡å¿…é¡»>99%
      interval: 1m
      
    - name: request-duration-p99
      thresholdRange:
        max: 500           # P99å»¶è¿Ÿ<500ms
      interval: 1m
    
    # Webhook ä¸šåŠ¡æŒ‡æ ‡æ£€æŸ¥
    webhooks:
    - name: payment-success-check
      url: http://metrics-service/check-payment
      timeout: 5s
      metadata:
        threshold: "95"    # æ”¯ä»˜æˆåŠŸç‡>95%

---
# Istio VirtualService æµé‡åˆ†å‰²
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: payment-service
spec:
  hosts:
  - payment-service
  http:
  - match:
    - headers:
        user-group:
          exact: "internal"  # å†…éƒ¨å‘˜å·¥å…ˆä½“éªŒæ–°ç‰ˆæœ¬
    route:
    - destination:
        host: payment-service
        subset: canary
      weight: 100
  - route:
    - destination:
        host: payment-service
        subset: stable
      weight: 90             # å¤–éƒ¨ç”¨æˆ·90%æµé‡èµ°ç¨³å®šç‰ˆ
    - destination:
        host: payment-service
        subset: canary
      weight: 10             # 10%æµé‡èµ°é‡‘ä¸é›€ç‰ˆæœ¬
```

**âš ï¸ å¸¸è§è¯¯åŒº**
1. âŒ **è¯¯åŒº**: ç°åº¦å‘å¸ƒåªçœ‹æŠ€æœ¯æŒ‡æ ‡(é”™è¯¯ç‡ã€å»¶è¿Ÿ)â€”â€”"é”™è¯¯ç‡æ­£å¸¸å°±ç»§ç»­æ¨"
   âœ… **æ­£ç¡®**: å¿…é¡»ç›‘æ§ä¸šåŠ¡æŒ‡æ ‡ï¼ŒæŠ€æœ¯ä¸Šæ­£å¸¸ä½†è®¢å•è½¬åŒ–ç‡ä¸‹é™10%ä¹Ÿè¦å›æ»š
   
2. âŒ **è¯¯åŒº**: ç°åº¦æ¯”ä¾‹é€’å¢å¤ªæ¿€è¿›â€”â€”"1% â†’ 10% â†’ 100%ï¼Œ3æ­¥å®Œæˆ"
   âœ… **æ­£ç¡®**: æ ¸å¿ƒæœåŠ¡åº”è¯¥æ›´ä¿å®ˆï¼Œå»ºè®®1% â†’ 5% â†’ 10% â†’ 25% â†’ 50% â†’ 100%ï¼Œæ¯æ­¥é—´éš”è‡³å°‘30åˆ†é’Ÿ
   
3. âŒ **è¯¯åŒº**: ç°åº¦ç”¨æˆ·é€‰æ‹©ä¸åˆç†â€”â€”"éšæœºåˆ†é…æµé‡"
   âœ… **æ­£ç¡®**: åº”ä¼˜å…ˆç°åº¦ç»™å†…éƒ¨å‘˜å·¥ã€æµ‹è¯•è´¦å·ã€ä½ä»·å€¼ç”¨æˆ·ï¼Œæ ¸å¿ƒå¤§å®¢æˆ·æœ€ååˆ‡æ¢

## ğŸ”¥ æ•…éšœåº”æ€¥ä¸ç¾éš¾æ¢å¤

> **ğŸ”° åˆå­¦è€…å¯¼è¯»**: ä¼ä¸šçº§æ•…éšœåº”æ€¥ä¸æ˜¯"ä¸€ä¸ªäººä¿®bug"ï¼Œè€Œæ˜¯åƒæ¶ˆé˜²é˜Ÿä¸€æ ·çš„åè°ƒä½œæˆ˜ã€‚éœ€è¦é¢„æ¡ˆã€æ¼”ç»ƒã€åˆ†å·¥æ˜ç¡®çš„å“åº”å›¢é˜Ÿï¼Œä»¥åŠäº‹åå¤ç›˜æ”¹è¿›ã€‚

### SREæ•…éšœå“åº”ä½“ç³»

#### æ•…éšœç­‰çº§å®šä¹‰
```yaml
# æ•…éšœç­‰çº§åˆ†ç±»æ ‡å‡†
incidentLevels:
  P0-Critical:
    responseTime: "15åˆ†é’Ÿ"
    resolutionTime: "2å°æ—¶"
    impact: "æ ¸å¿ƒä¸šåŠ¡å®Œå…¨ä¸­æ–­"
    examples:
      - "ç”¨æˆ·æ— æ³•è®¿é—®æ ¸å¿ƒæœåŠ¡"
      - "æ•°æ®åº“å®Œå…¨ä¸å¯ç”¨"
      - "æ”¯ä»˜ç³»ç»Ÿæ•…éšœ"
      
  P1-High:
    responseTime: "1å°æ—¶"
    resolutionTime: "8å°æ—¶"
    impact: "é‡è¦åŠŸèƒ½å—é™"
    examples:
      - "éƒ¨åˆ†ç”¨æˆ·æ— æ³•ä½¿ç”¨"
      - "æ€§èƒ½ä¸¥é‡ä¸‹é™"
      - "æ¬¡è¦åŠŸèƒ½æ•…éšœ"
      
  P2-Medium:
    responseTime: "4å°æ—¶"
    resolutionTime: "24å°æ—¶"
    impact: "ä¸€èˆ¬æ€§é—®é¢˜"
    examples:
      - "éå…³é”®åŠŸèƒ½å¼‚å¸¸"
      - "è½»å¾®æ€§èƒ½é—®é¢˜"
      - "ç”¨æˆ·ä½“éªŒä¸‹é™"
      
  P3-Low:
    responseTime: "1ä¸ªå·¥ä½œæ—¥"
    resolutionTime: "72å°æ—¶"
    impact: "è½»å¾®é—®é¢˜"
    examples:
      - "ç•Œé¢æ˜¾ç¤ºé—®é¢˜"
      - "æ–‡æ¡£é”™è¯¯"
      - "ä½ä¼˜å…ˆçº§éœ€æ±‚"
```

#### åº”æ€¥å“åº”æµç¨‹
```mermaid
graph TD
    A[æ•…éšœæ£€æµ‹] --> B{æ•…éšœç­‰çº§åˆ¤å®š}
    B -->|P0| C[P0å“åº”æµç¨‹]
    B -->|P1| D[P1å“åº”æµç¨‹]
    B -->|P2| E[P2å“åº”æµç¨‹]
    B -->|P3| F[P3å¤„ç†æµç¨‹]
    
    C --> G[ç«‹å³é€šçŸ¥å€¼ç­å›¢é˜Ÿ]
    G --> H[å¯åŠ¨War Room]
    H --> I[æ‰§è¡Œåº”æ€¥é¢„æ¡ˆ]
    I --> J[å®æ—¶çŠ¶æ€åŒæ­¥]
    J --> K[æ•…éšœè§£å†³ç¡®è®¤]
    
    D --> L[é€šçŸ¥ç›¸å…³å›¢é˜Ÿ]
    L --> M[åˆ¶å®šè§£å†³æ–¹æ¡ˆ]
    M --> N[æ‰§è¡Œä¿®å¤]
    N --> O[éªŒè¯ä¿®å¤æ•ˆæœ]
    
    subgraph WarRoom["War Room ç»„æˆ"]
        WR1[å€¼ç­ç»ç†]
        WR2[æŠ€æœ¯è´Ÿè´£äºº]
        WR3[è¿ç»´å·¥ç¨‹å¸ˆ]
        WR4[å¼€å‘å·¥ç¨‹å¸ˆ]
        WR5[äº§å“è´Ÿè´£äºº]
    end
    
    subgraph åº”æ€¥é¢„æ¡ˆ["æ ‡å‡†åº”æ€¥é¢„æ¡ˆ"]
        EP1[æ•°æ®åº“è¿æ¥æ± è€—å°½]
        EP2[å­˜å‚¨ç©ºé—´ä¸è¶³]
        EP3[ç½‘ç»œåˆ†åŒºæ•…éšœ]
        EP4[è®¤è¯æœåŠ¡å¼‚å¸¸]
        EP5[ç¬¬ä¸‰æ–¹APIæ•…éšœ]
    end
```

**ğŸ”° åˆå­¦è€…ç†è§£**
åº”æ€¥é¢„æ¡ˆå°±åƒæ¶ˆé˜²æ¼”ä¹ è®¡åˆ’â€”â€”æå‰å†™å¥½"å‘ç”Ÿç«ç¾æ—¶è°åšä»€ä¹ˆ"ï¼Œä¸æ˜¯ä¸´æ—¶ä¹±è·‘ã€‚æ ¸å¿ƒæ€æƒ³ï¼š**æå‰å‡†å¤‡å¸¸è§æ•…éšœçš„SOPï¼Œå‡å°‘åº”æ€¥æ—¶çš„å†³ç­–æ—¶é—´**ã€‚

**ğŸ”§ å·¥ä½œåŸç†**
- **åœºæ™¯åˆ†ç±»**: é’ˆå¯¹é«˜é¢‘æ•…éšœåœºæ™¯ç¼–å†™é¢„æ¡ˆ(æ•°æ®åº“æ•…éšœ/ç½‘ç»œä¸­æ–­/å­˜å‚¨æ»¡/è®¤è¯å¼‚å¸¸ç­‰)
- **åˆ†æ­¥æŒ‡å¼•**: æ¯ä¸ªé¢„æ¡ˆåŒ…å«è¯Šæ–­æ­¥éª¤ã€ä¿®å¤å‘½ä»¤ã€éªŒè¯æ–¹æ³•ã€å›æ»šæ–¹æ¡ˆ
- **æƒé™é¢„é…**: é¢„æ¡ˆä¸­æ¶‰åŠçš„è´¦å·ã€æƒé™ã€å·¥å…·æå‰å‡†å¤‡å¥½ï¼Œä¸åœ¨æ•…éšœæ—¶ä¸´æ—¶ç”³è¯·
- **å®šæœŸæ¼”ç»ƒ**: æ¯å­£åº¦æ¨¡æ‹Ÿæ•…éšœæ¼”ç»ƒï¼ŒéªŒè¯é¢„æ¡ˆæœ‰æ•ˆæ€§ï¼ŒåŸ¹è®­æ–°äºº
- **æŒç»­æ›´æ–°**: æ¯æ¬¡æ•…éšœåreviewé¢„æ¡ˆï¼Œè¡¥å……æ–°çš„caseå’Œç»éªŒ

**ğŸ“ æœ€å°ç¤ºä¾‹**
```yaml
# åº”æ€¥é¢„æ¡ˆ Runbook (ä»¥ ConfigMap å­˜å‚¨)
apiVersion: v1
kind: ConfigMap
metadata:
  name: incident-runbooks
  namespace: ops-system
data:
  etcd-full-disk.md: |
    # åº”æ€¥é¢„æ¡ˆ: etcd ç£ç›˜ç©ºé—´ä¸è¶³
    
    ## è§¦å‘æ¡ä»¶
    - etcd ç£ç›˜ä½¿ç”¨ç‡ > 85%
    - å‘Šè­¦: EtcdDiskSpaceHigh
    
    ## å½±å“èŒƒå›´
    - é›†ç¾¤æ— æ³•å†™å…¥æ–°æ•°æ®
    - API Server å“åº”å˜æ…¢æˆ–è¶…æ—¶
    - å½±å“ç­‰çº§: P0
    
    ## è¯Šæ–­æ­¥éª¤
    1. æ£€æŸ¥ etcd ç£ç›˜ä½¿ç”¨æƒ…å†µ
       ```bash
       df -h /var/lib/etcd
       du -sh /var/lib/etcd/*
       ```
    
    2. æŸ¥çœ‹ etcd æ•°æ®åº“å¤§å°
       ```bash
       ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
         --cert=/etc/kubernetes/pki/etcd/server.crt \
         --key=/etc/kubernetes/pki/etcd/server.key \
         --cacert=/etc/kubernetes/pki/etcd/ca.crt \
         endpoint status --write-out=table
       ```
    
    ## åº”æ€¥å¤„ç†
    
    ### æ–¹æ¡ˆ1: æ¸…ç†å†å²æ•°æ®(< 5åˆ†é’Ÿ)
    ```bash
    # å‹ç¼©å†å²ç‰ˆæœ¬
    rev=$(ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
      --cert=/etc/kubernetes/pki/etcd/server.crt \
      --key=/etc/kubernetes/pki/etcd/server.key \
      --cacert=/etc/kubernetes/pki/etcd/ca.crt \
      endpoint status --write-out="json" | jq -r '.[] | .Status.header.revision')
    
    ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
      --cert=/etc/kubernetes/pki/etcd/server.crt \
      --key=/etc/kubernetes/pki/etcd/server.key \
      --cacert=/etc/kubernetes/pki/etcd/ca.crt \
      compact $rev
    
    # ç¢ç‰‡æ•´ç†
    ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
      --cert=/etc/kubernetes/pki/etcd/server.crt \
      --key=/etc/kubernetes/pki/etcd/server.key \
      --cacert=/etc/kubernetes/pki/etcd/ca.crt \
      defrag --command-timeout=30s
    ```
    
    ### æ–¹æ¡ˆ2: æ‰©å±•ç£ç›˜(15-30åˆ†é’Ÿ)
    - AWS: ä¿®æ”¹ EBS å·å¤§å°å¹¶æ‰©å±•æ–‡ä»¶ç³»ç»Ÿ
    - å‚è€ƒæ–‡æ¡£: https://wiki.company.com/extend-ebs-volume
    
    ## éªŒè¯ä¿®å¤
    ```bash
    # æ£€æŸ¥ç£ç›˜ä½¿ç”¨ç‡
    df -h /var/lib/etcd
    
    # éªŒè¯é›†ç¾¤å¥åº·
    ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
      --cert=/etc/kubernetes/pki/etcd/server.crt \
      --key=/etc/kubernetes/pki/etcd/server.key \
      --cacert=/etc/kubernetes/pki/etcd/ca.crt \
      endpoint health
    
    # æµ‹è¯• K8s API
    kubectl get nodes
    ```
    
    ## é•¿æœŸé¢„é˜²
    - è°ƒæ•´ etcd è‡ªåŠ¨å‹ç¼©ç­–ç•¥
    - é…ç½®ç£ç›˜å‘Šè­¦é˜ˆå€¼ä¸º 75%
    - æ¯å‘¨è‡ªåŠ¨æ‰§è¡Œ compact + defrag
    
    ## è”ç³»æ–¹å¼
    - On-Call: +1-555-ONCALL
    - Slack: #incident-war-room
    - å‡çº§è·¯å¾„: å€¼ç­å·¥ç¨‹å¸ˆ â†’ æ¶æ„å¸ˆ â†’ CTO

---
# åº”æ€¥é¢„æ¡ˆç´¢å¼• CRD
apiVersion: ops.company.com/v1
kind: Runbook
metadata:
  name: etcd-disk-full
  labels:
    severity: P0
    component: etcd
    category: storage
spec:
  title: "etcd ç£ç›˜ç©ºé—´ä¸è¶³åº”æ€¥é¢„æ¡ˆ"
  triggerConditions:
  - "etcd_disk_usage > 85%"
  - "AlertName: EtcdDiskSpaceHigh"
  
  estimatedDuration: "5-30min"
  requiredPermissions:
  - "etcd-admin"
  - "node-ssh-access"
  
  relatedRunbooks:
  - "etcd-performance-degradation"
  - "apiserver-timeout"
```

**âš ï¸ å¸¸è§è¯¯åŒº**
1. âŒ **è¯¯åŒº**: é¢„æ¡ˆå†™å¾—å¤ªç®€å•â€”â€”"etcdæ•…éšœï¼šé‡å¯etcd"
   âœ… **æ­£ç¡®**: é¢„æ¡ˆéœ€è¦åŒ…å«è¯Šæ–­å‘½ä»¤ã€å¤šç§ä¿®å¤æ–¹æ¡ˆ(å¿«é€Ÿæ–¹æ¡ˆ/å½»åº•æ–¹æ¡ˆ)ã€éªŒè¯æ­¥éª¤ã€æƒé™è¦æ±‚
   
2. âŒ **è¯¯åŒº**: é¢„æ¡ˆä»ä¸æ¼”ç»ƒâ€”â€”"å†™äº†å°±æ”¾é‚£å„¿ï¼Œå‡ºäº‹å†çœ‹"
   âœ… **æ­£ç¡®**: æ¯å­£åº¦è¿›è¡Œæ•…éšœæ¼”ç»ƒ(Chaos Engineering)ï¼ŒéªŒè¯é¢„æ¡ˆæœ‰æ•ˆæ€§ï¼Œè®©æ–°äººç†Ÿæ‚‰æµç¨‹
   
3. âŒ **è¯¯åŒº**: æ‰€æœ‰æ•…éšœéƒ½å†™é¢„æ¡ˆâ€”â€”"è¦†ç›–100%çš„æ•…éšœåœºæ™¯"
   âœ… **æ­£ç¡®**: ä¼˜å…ˆè¦†ç›–é«˜é¢‘(æ¯æœˆ>1æ¬¡)å’Œé«˜å½±å“(P0/P1)çš„åœºæ™¯ï¼Œé•¿å°¾é—®é¢˜é å·¥ç¨‹å¸ˆèƒ½åŠ›

### ç¾éš¾æ¢å¤ç­–ç•¥

#### å¤šæ´»æ•°æ®ä¸­å¿ƒæ¶æ„
```yaml
# å¤šæ´»æ•°æ®ä¸­å¿ƒé…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: disaster-recovery-config
data:
  # åœ°ç†åˆ†å¸ƒ
  regions:
    primary: "us-east-1"
    secondary: "us-west-2"
    tertiary: "eu-central-1"
  
  # RTO/RPO è¦æ±‚
  recovery-objectives:
    rto: "15åˆ†é’Ÿ"  # æ¢å¤æ—¶é—´ç›®æ ‡
    rpo: "5åˆ†é’Ÿ"   # æ¢å¤ç‚¹ç›®æ ‡
    
  # æ•°æ®åŒæ­¥ç­–ç•¥
  data-replication:
    realtime-sync: true
    sync-frequency: "5s"
    consistency-level: "strong"
    
---
# ç¾éš¾æ¢å¤æ¼”ç»ƒè®¡åˆ’
apiVersion: batch/v1
kind: CronJob
metadata:
  name: dr-drill
spec:
  schedule: "0 2 * * 0"  # æ¯å‘¨æ—¥å‡Œæ™¨2ç‚¹
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: dr-test
            image: enterprise/dr-test:latest
            env:
            - name: TARGET_REGION
              value: "us-west-2"
            - name: TEST_DURATION
              value: "2h"
            command:
            - /bin/sh
            - -c
            - |
              echo "å¼€å§‹ç¾éš¾æ¢å¤æ¼”ç»ƒ"
              # åˆ‡æ¢æµé‡åˆ°å¤‡ç”¨åŒºåŸŸ
              kubectl apply -f dr-failover.yaml
              # éªŒè¯æœåŠ¡å¯ç”¨æ€§
              ./verify-services.sh
              # æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
              ./check-data-consistency.sh
              # æ€§èƒ½åŸºå‡†æµ‹è¯•
              ./performance-baseline.sh
          restartPolicy: OnFailure
```

**ğŸ”° åˆå­¦è€…ç†è§£**
War Roomå°±åƒå†›äº‹ä½œæˆ˜æŒ‡æŒ¥éƒ¨â€”â€”æ‰€æœ‰å…³é”®äººå‘˜èšåœ¨ä¸€ä¸ªæˆ¿é—´(æˆ–è§†é¢‘ä¼šè®®)é‡Œï¼Œç»Ÿä¸€æŒ‡æŒ¥ã€å®æ—¶æ²Ÿé€šï¼Œé¿å…"å„è‡ªä¸ºæˆ˜"ã€‚æ ¸å¿ƒæ€æƒ³ï¼š**é›†ä¸­å†³ç­–ï¼Œå¿«é€Ÿå“åº”ï¼Œä¿¡æ¯é€æ˜**ã€‚

**ğŸ”§ å·¥ä½œåŸç†**
- **è§¦å‘æ¡ä»¶**: P0çº§åˆ«æ•…éšœè‡ªåŠ¨æ‹‰èµ·War Roomï¼Œé€šçŸ¥æ‰€æœ‰On-Calläººå‘˜
- **è§’è‰²åˆ†å·¥**: æŒ‡æŒ¥å®˜(å†³ç­–)ã€æŠ€æœ¯è´Ÿè´£äºº(ä¿®å¤)ã€æ²Ÿé€šè´Ÿè´£äºº(å¯¹å¤–é€šæŠ¥)ã€è®°å½•å‘˜(æ—¶é—´çº¿)
- **é€šè®¯å·¥å…·**: ä¸“ç”¨Slacké¢‘é“ + è§†é¢‘ä¼šè®® + å…±äº«æ–‡æ¡£(å®æ—¶æ›´æ–°æ•…éšœçŠ¶æ€)
- **æ—¶é—´çº¿è®°å½•**: æ¯ä¸ªæ“ä½œéƒ½è®°å½•æ—¶é—´æˆ³ï¼Œä¾¿äºäº‹ååˆ†æ
- **å®šæœŸæ›´æ–°**: æ¯15åˆ†é’Ÿå‘ç®¡ç†å±‚/ç”¨æˆ·é€šæŠ¥æœ€æ–°è¿›å±•ï¼Œå³ä½¿"æ²¡æœ‰è¿›å±•"ä¹Ÿè¦é€šæŠ¥

**ğŸ“ æœ€å°ç¤ºä¾‹**
```yaml
# War Room è‡ªåŠ¨åŒ–é…ç½®
apiVersion: ops.company.com/v1
kind: IncidentResponse
metadata:
  name: war-room-automation
spec:
  # è§¦å‘æ¡ä»¶
  triggers:
  - alertName: "ServiceDown"
    severity: "P0"
  - alertName: "DataLoss"
    severity: "P0"
  
  # è‡ªåŠ¨åŒ–æ“ä½œ
  actions:
  - type: "create-slack-channel"
    config:
      channelName: "incident-{{ .IncidentID }}"
      inviteUsers:
      - "@oncall-sre"
      - "@oncall-dev"
      - "@engineering-manager"
      - "@product-owner"
      pinnedMessage: |
        ğŸš¨ P0 æ•…éšœå“åº” - {{ .IncidentTitle }}
        
        **æ•…éšœç­‰çº§**: P0 (Critical)
        **å¼€å§‹æ—¶é—´**: {{ .StartTime }}
        **æŒ‡æŒ¥å®˜**: {{ .IncidentCommander }}
        
        **è§’è‰²åˆ†å·¥**:
        - ğŸ¯ æŒ‡æŒ¥å®˜: ç»Ÿä¸€å†³ç­–ã€å¯¹å¤–é€šæŠ¥
        - ğŸ”§ æŠ€æœ¯è´Ÿè´£äºº: æ‰§è¡Œä¿®å¤æ“ä½œ
        - ğŸ“ è®°å½•å‘˜: ç»´æŠ¤æ—¶é—´çº¿
        - ğŸ’¬ æ²Ÿé€šè´Ÿè´£äºº: ç”¨æˆ·/ç®¡ç†å±‚é€šæŠ¥
        
        **å®æ—¶æ–‡æ¡£**: https://docs.company.com/incidents/{{ .IncidentID }}
  
  - type: "create-zoom-meeting"
    config:
      meetingName: "War Room - {{ .IncidentID }}"
      autoRecord: true
  
  - type: "create-incident-doc"
    config:
      template: "war-room-template"
      sharedWith: ["engineering-team", "management"]
  
  - type: "page-oncall"
    config:
      escalationPolicy: "p0-escalation"
      message: "P0æ•…éšœ: {{ .IncidentTitle }} - ç«‹å³åŠ å…¥War Room"
  
  # å®šæœŸæ›´æ–°
  periodicUpdates:
    interval: "15m"
    channels: ["#incidents", "#management"]
    template: |
      â° æ•…éšœæ›´æ–° ({{ .ElapsedTime }})
      
      **å½“å‰çŠ¶æ€**: {{ .CurrentStatus }}
      **å—å½±å“ç”¨æˆ·**: {{ .AffectedUsers }}
      **ä¸‹ä¸€æ­¥è®¡åˆ’**: {{ .NextSteps }}
      **é¢„è®¡æ¢å¤æ—¶é—´**: {{ .ETA }}

---
# War Room æ¨¡æ¿æ–‡æ¡£ç»“æ„
apiVersion: v1
kind: ConfigMap
metadata:
  name: war-room-template
data:
  template.md: |
    # P0 æ•…éšœå“åº”: {{ .IncidentID }}
    
    ## åŸºæœ¬ä¿¡æ¯
    - **æ•…éšœç­‰çº§**: P0
    - **å¼€å§‹æ—¶é—´**: {{ .StartTime }}
    - **æ£€æµ‹æ–¹å¼**: {{ .DetectionMethod }}
    - **å½±å“èŒƒå›´**: {{ .ImpactScope }}
    
    ## è§’è‰²åˆ†å·¥
    | è§’è‰² | å§“å | è”ç³»æ–¹å¼ |
    |------|------|---------|
    | æŒ‡æŒ¥å®˜ | | |
    | æŠ€æœ¯è´Ÿè´£äºº | | |
    | æ²Ÿé€šè´Ÿè´£äºº | | |
    | è®°å½•å‘˜ | | |
    
    ## æ—¶é—´çº¿ (æŒç»­æ›´æ–°)
    | æ—¶é—´ | äº‹ä»¶ | è´Ÿè´£äºº |
    |------|------|--------|
    | {{ .StartTime }} | æ•…éšœæ£€æµ‹ | ç›‘æ§ç³»ç»Ÿ |
    | | | |
    
    ## ä¿®å¤æ“ä½œè®°å½•
    ```
    [æ—¶é—´æˆ³] æ‰§è¡Œçš„å‘½ä»¤/æ“ä½œ
    [æ—¶é—´æˆ³] è§‚å¯Ÿåˆ°çš„ç°è±¡
    ```
    
    ## å¯¹å¤–é€šæŠ¥è®°å½•
    - [ ] T+15min: é¦–æ¬¡é€šæŠ¥(æ•…éšœç¡®è®¤)
    - [ ] T+30min: ç¬¬äºŒæ¬¡æ›´æ–°(ä¿®å¤è¿›å±•)
    - [ ] T+60min: æŒç»­æ›´æ–°
    - [ ] æ•…éšœè§£å†³: æ¢å¤é€šæŠ¥
    
    ## æ ¹å› åˆ†æ (äº‹åå¡«å†™)
    - **ç›´æ¥åŸå› **: 
    - **æ ¹æœ¬åŸå› **: 
    - **æ”¹è¿›æªæ–½**:
```

**âš ï¸ å¸¸è§è¯¯åŒº**
1. âŒ **è¯¯åŒº**: War Roomé‡Œæ‰€æœ‰äººéƒ½åœ¨"æ•‘ç«"â€”â€”"10ä¸ªäººåŒæ—¶æ‰§è¡Œå‘½ä»¤"
   âœ… **æ­£ç¡®**: åªæœ‰æŠ€æœ¯è´Ÿè´£äººæ‰§è¡Œæ“ä½œï¼Œå…¶ä»–äººæä¾›æ”¯æŒ/å†³ç­–/æ²Ÿé€šï¼Œé¿å…"å¤šäººåŒæ—¶æ”¹é…ç½®"
   
2. âŒ **è¯¯åŒº**: åªæœ‰æ•…éšœè§£å†³äº†æ‰é€šæŠ¥â€”â€”"ä¿®å¥½äº†å†å‘å…¬å‘Š"
   âœ… **æ­£ç¡®**: æ¯15-30åˆ†é’Ÿæ›´æ–°è¿›å±•ï¼Œå³ä½¿"è¿˜åœ¨æ’æŸ¥ä¸­"ä¹Ÿè¦é€šæŠ¥ï¼Œè®©ç”¨æˆ·çŸ¥é“ä½ åœ¨å¤„ç†
   
3. âŒ **è¯¯åŒº**: War Roomå¼€åˆ°æ•…éšœè§£å†³ä¸ºæ­¢â€”â€”"ä¿®å¥½äº†å°±æ•£ä¼š"
   âœ… **æ­£ç¡®**: ä¿®å¤åè¿˜è¦éªŒè¯ã€è§‚å¯Ÿ30-60åˆ†é’Ÿï¼Œç¡®è®¤ç¨³å®šåæ‰è§£æ•£ï¼Œå¹¶å®‰æ’äº‹åå¤ç›˜ä¼šè®®

## ğŸ‘¥ å›¢é˜Ÿåä½œä¸çŸ¥è¯†ä¼ æ‰¿

> **ğŸ”° åˆå­¦è€…å¯¼è¯»**: è¿ç»´çŸ¥è¯†ä¸èƒ½åªåœ¨ä¸ªäººè„‘ä¸­â€”â€”å…³é”®äººå‘˜ç¦»èŒæ€ä¹ˆåŠï¼ŸçŸ¥è¯†ä¼ æ‰¿åŒ…æ‹¬æ–‡æ¡£åŒ–ã€åŸ¹è®­ä½“ç³»ã€å¯¼å¸ˆåˆ¶åº¦å’ŒçŸ¥è¯†åº“å»ºè®¾ã€‚åƒåŒ»é™¢çš„"ä½é™¢åŒ»å¸ˆåŸ¹è®­åˆ¶åº¦"ä¸€æ ·ç³»ç»ŸåŒ–ã€‚

### è¿ç»´æ–‡åŒ–å»ºè®¾

#### DevOps æˆç†Ÿåº¦è¯„ä¼°
```yaml
# DevOps æˆç†Ÿåº¦æ¨¡å‹
devopsMaturity:
  culture:
    collaboration-score: 8.5/10
    blameless-postmortems: true
    knowledge-sharing: weekly
    
  automation:
    ci-cd-coverage: 95%
    infrastructure-as-code: 100%
    automated-testing: 90%
    
  measurement:
    deployment-frequency: "daily"
    lead-time: "<1å°æ—¶"
    mean-time-to-recovery: "<30åˆ†é’Ÿ"
    change-failure-rate: "<5%"
    
  sharing:
    cross-team-collaboration: monthly
    community-contributions: quarterly
    open-source-involvement: active
```

#### çŸ¥è¯†ç®¡ç†ä½“ç³»
```markdown
## ä¼ä¸šè¿ç»´çŸ¥è¯†åº“ç»“æ„

### æŠ€æœ¯æ–‡æ¡£å±‚çº§
â”œâ”€â”€ æ ‡å‡†æ“ä½œç¨‹åº (SOP)
â”‚   â”œâ”€â”€ ç³»ç»Ÿéƒ¨ç½²æŒ‡å—
â”‚   â”œâ”€â”€ æ•…éšœå¤„ç†æ‰‹å†Œ
â”‚   â”œâ”€â”€ å®‰å…¨æ“ä½œè§„ç¨‹
â”‚   â””â”€â”€ å˜æ›´ç®¡ç†æµç¨‹
â”‚
â”œâ”€â”€ æœ€ä½³å®è·µé›†
â”‚   â”œâ”€â”€ æ€§èƒ½ä¼˜åŒ–æ¡ˆä¾‹
â”‚   â”œâ”€â”€ å®‰å…¨åŠ å›ºæ–¹æ¡ˆ
â”‚   â”œâ”€â”€ æˆæœ¬æ§åˆ¶ç­–ç•¥
â”‚   â””â”€â”€ ç›‘æ§å‘Šè­¦æ¨¡æ¿
â”‚
â”œâ”€â”€ æ•…éšœæ¡ˆä¾‹åº“
â”‚   â”œâ”€â”€ P0çº§åˆ«äº‹æ•…æŠ¥å‘Š
â”‚   â”œâ”€â”€ é‡å¤æ€§é—®é¢˜åˆ†æ
â”‚   â”œâ”€â”€ æ ¹å› åˆ†ææ¨¡æ¿
â”‚   â””â”€â”€ é¢„é˜²æªæ–½æ€»ç»“
â”‚
â””â”€â”€ åŸ¹è®­ææ–™
    â”œâ”€â”€ æ–°å‘˜å·¥å…¥èŒåŸ¹è®­
    â”œâ”€â”€ æŠ€æœ¯ä¸“é¡¹åŸ¹è®­
    â”œâ”€â”€ è®¤è¯è€ƒè¯•èµ„æ–™
    â””â”€â”€ å¤–éƒ¨æŠ€æœ¯åˆ†äº«
```

**ğŸ”° åˆå­¦è€…ç†è§£**
On-Callè½®å€¼å°±åƒåŒ»é™¢çš„å€¼ç­åˆ¶åº¦â€”â€”æ¯å‘¨è½®æµè´Ÿè´£å¤œé—´/å‘¨æœ«çš„ç´§æ€¥æƒ…å†µï¼Œä¸èƒ½è®©åŒä¸€ä¸ªäººä¸€ç›´å¾…å‘½ã€‚æ ¸å¿ƒæ€æƒ³ï¼š**åˆ†æ‹…è´£ä»»ï¼Œä¿éšœå“åº”ï¼Œé¿å…ç–²åŠ³**ã€‚

**ğŸ”§ å·¥ä½œåŸç†**
- **è½®å€¼å‘¨æœŸ**: é€šå¸¸1å‘¨ä¸ºä¸€ä¸ªå‘¨æœŸï¼Œè‡ªåŠ¨è½®æ¢ï¼ŒèŠ‚å‡æ—¥å¯åå•†äº’æ¢
- **åˆ†çº§å“åº”**: Primary On-Call(ä¸€çº¿)å¤„ç†å¸¸è§é—®é¢˜ï¼Œå‡çº§ç»™Secondary(äºŒçº¿ä¸“å®¶)
- **å“åº”æ—¶é—´**: P0æ•…éšœ15åˆ†é’Ÿå†…å“åº”ï¼ŒP1æ•…éšœ1å°æ—¶å†…å“åº”
- **è¡¥å¿æœºåˆ¶**: On-CallæœŸé—´æŒ‰å¤©è¡¥è´´ï¼Œå¤„ç†æ•…éšœé¢å¤–è¡¥å¿å·¥æ—¶
- **å·¥å…·æ”¯æŒ**: PagerDuty/Opsgenieè‡ªåŠ¨å‘¼å«ï¼Œé›†æˆSlack/ç”µè¯/çŸ­ä¿¡å¤šæ¸ é“

**ğŸ“ æœ€å°ç¤ºä¾‹**
```yaml
# PagerDuty On-Call é…ç½®
apiVersion: ops.company.com/v1
kind: OnCallSchedule
metadata:
  name: sre-oncall-schedule
spec:
  # è½®å€¼è¡¨
  rotation:
    type: "weekly"
    startDate: "2024-01-01"
    timezone: "America/Los_Angeles"
    
    members:
    - name: "Alice"
      email: "alice@company.com"
      phone: "+1-555-0001"
    - name: "Bob"
      email: "bob@company.com"
      phone: "+1-555-0002"
    - name: "Carol"
      email: "carol@company.com"
      phone: "+1-555-0003"
  
  # å‡çº§ç­–ç•¥
  escalationPolicy:
    - level: 1
      name: "Primary On-Call"
      timeout: "15m"
      notifyMethods: ["sms", "phone", "push"]
      
    - level: 2
      name: "Secondary On-Call (Tech Lead)"
      timeout: "15m"
      notifyMethods: ["phone"]
      
    - level: 3
      name: "Engineering Manager"
      timeout: "30m"
      notifyMethods: ["phone"]
  
  # å…æ‰“æ‰°æ—¶æ®µ(éP0)
  quietHours:
    enabled: true
    start: "22:00"
    end: "08:00"
    onlyForSeverity: ["P2", "P3"]

---
# Grafana OnCall é›†æˆå‘Šè­¦è·¯ç”±
apiVersion: v1
kind: ConfigMap
metadata:
  name: oncall-alert-routing
data:
  routing-rules.yaml: |
    routes:
    # P0 å‘Šè­¦ - ç«‹å³å‘¼å«
    - match:
        severity: P0
      receiver: oncall-phone-primary
      continue: true
      repeat_interval: 5m
    
    # P1 å‘Šè­¦ - SMS + Slack
    - match:
        severity: P1
      receiver: oncall-sms-slack
      repeat_interval: 30m
    
    # P2/P3 - ä»… Slack(å·¥ä½œæ—¶é—´)
    - match:
        severity: P2|P3
      receiver: oncall-slack-only
      repeat_interval: 4h
      active_time_intervals:
      - business_hours

---
# On-Call Runbook å¿«é€Ÿç´¢å¼•
apiVersion: v1
kind: ConfigMap
metadata:
  name: oncall-runbook-index
data:
  quick-reference.md: |
    # On-Call å¿«é€Ÿå‚è€ƒæ‰‹å†Œ
    
    ## ç´§æ€¥è”ç³»æ–¹å¼
    - **ä¸€çº¿ On-Call**: æŸ¥çœ‹ PagerDuty App
    - **äºŒçº¿ä¸“å®¶**: Slack #oncall-escalation
    - **ç®¡ç†å±‚**: +1-555-MGMT (ä»…P0)
    
    ## å¸¸è§æ•…éšœå¿«é€Ÿå¤„ç†
    
    ### 1. Pod CrashLoopBackOff
    ```bash
    kubectl logs <pod> --previous
    kubectl describe pod <pod>
    # å¿«é€Ÿé‡å¯
    kubectl rollout restart deployment/<name>
    ```
    
    ### 2. Node NotReady
    ```bash
    kubectl get nodes
    kubectl describe node <node>
    ssh <node> "sudo systemctl status kubelet"
    # å¦‚éœ€é‡å¯èŠ‚ç‚¹ï¼Œå…ˆé©±é€ Pod
    kubectl drain <node> --ignore-daemonsets
    ```
    
    ### 3. Disk Full
    ```bash
    df -h
    docker system prune -af --volumes  # æ¸…ç†é•œåƒ
    kubectl delete pod --field-selector status.phase=Succeeded -A
    ```
    
    ## å‡çº§å†³ç­–æ ‘
    - âœ… å¯ä»¥ç‹¬ç«‹è§£å†³ â†’ å¤„ç†å¹¶è®°å½•
    - â“ ä¸ç¡®å®šå¦‚ä½•å¤„ç† â†’ å‡çº§åˆ°äºŒçº¿
    - ğŸš¨ å½±å“èŒƒå›´æ‰©å¤§ â†’ ç«‹å³å‡çº§å¹¶æ‹‰War Room
    
    ## å¤„ç†åå¿…åšäº‹é¡¹
    1. æ›´æ–°æ•…éšœå·¥å•çŠ¶æ€
    2. åœ¨ Slack é€šæŠ¥ç»“æœ
    3. è¯„ä¼°æ˜¯å¦éœ€è¦Post-Mortem
    4. è¡¥å……/æ›´æ–° Runbook
```

**âš ï¸ å¸¸è§è¯¯åŒº**
1. âŒ **è¯¯åŒº**: On-CallæœŸé—´å¿…é¡»24å°æ—¶ååœ¨ç”µè„‘å‰â€”â€”"ä¸èƒ½å‡ºé—¨ç©"
   âœ… **æ­£ç¡®**: åªéœ€ä¿è¯15åˆ†é’Ÿå†…èƒ½å“åº”(å¸¦ç¬”è®°æœ¬+æ‰‹æœºçƒ­ç‚¹)ï¼Œæ­£å¸¸ç”Ÿæ´»ä¸å—å½±å“
   
2. âŒ **è¯¯åŒº**: æ‰€æœ‰å‘Šè­¦éƒ½æ‰“ç”µè¯å«é†’â€”â€”"åŠå¤œè¢«å«é†’10æ¬¡"
   âœ… **æ­£ç¡®**: åªæœ‰P0/P1æ‰ç”µè¯å‘¼å«ï¼ŒP2/P3èµ°Slack/é‚®ä»¶ï¼Œå¹¶è®¾ç½®å…æ‰“æ‰°æ—¶æ®µ
   
3. âŒ **è¯¯åŒº**: On-Callåªæœ‰ä¸€ä¸ªäººè´Ÿè´£â€”â€”"å•ç‚¹æ•…éšœ"
   âœ… **æ­£ç¡®**: åº”è®¾ç½®Primary/Secondaryä¸¤çº§ï¼ŒPrimaryæä¸å®šè‡ªåŠ¨å‡çº§ï¼Œé¿å…"ä¸€ä¸ªäººæ‰›ä¸ä½"

### æŠ€èƒ½å‘å±•è·¯å¾„

#### è¿ç»´å·¥ç¨‹å¸ˆæˆé•¿è·¯çº¿å›¾
```mermaid
graph LR
    A[åˆçº§è¿ç»´å·¥ç¨‹å¸ˆ] --> B[ä¸­çº§è¿ç»´å·¥ç¨‹å¸ˆ]
    B --> C[é«˜çº§è¿ç»´å·¥ç¨‹å¸ˆ]
    C --> D[è¿ç»´ä¸“å®¶]
    D --> E[é¦–å¸­è¿ç»´å®˜]
    
    subgraph æŠ€èƒ½è¦æ±‚
        A1[åŸºç¡€Linuxæ“ä½œ]
        A2[Docker/K8såŸºç¡€]
        A3[ç›‘æ§å‘Šè­¦é…ç½®]
        
        B1[è‡ªåŠ¨åŒ–è„šæœ¬ç¼–å†™]
        B2[CI/CDæµç¨‹è®¾è®¡]
        B3[æ€§èƒ½è°ƒä¼˜å®è·µ]
        
        C1[æ¶æ„è®¾è®¡èƒ½åŠ›]
        C2[æ•…éšœæ ¹å› åˆ†æ]
        C3[å®‰å…¨é£é™©è¯„ä¼°]
        
        D1[æŠ€æœ¯åˆ›æ–°å¼•é¢†]
        D2[å›¢é˜ŸæŠ€æœ¯æŒ‡å¯¼]
        D3[æˆ˜ç•¥è§„åˆ’åˆ¶å®š]
        
        E1[ç»„ç»‡å˜é©æ¨åŠ¨]
        E2[è¡Œä¸šæ ‡å‡†åˆ¶å®š]
        E3[æŠ€æœ¯ç”Ÿæ€å»ºè®¾]
    end
    
    A -.-> A1 & A2 & A3
    B -.-> B1 & B2 & B3
    C -.-> C1 & C2 & C3
    D -.-> D1 & D2 & D3
    E -.-> E1 & E2 & E3
```

#### æŒç»­å­¦ä¹ æœºåˆ¶
```yaml
# æŠ€èƒ½å‘å±•è®¡åˆ’
learningPath:
  quarterly-training:
    technical-workshops:
      - kubernetes-advanced
      - cloud-security
      - ai-platform-ops
      - multi-cloud-management
      
    certification-programs:
      - CKA (Certified Kubernetes Administrator)
      - AWS Certified Solutions Architect
      - Google Cloud Professional
      - CNCF Security Specialist
      
  knowledge-sharing:
    tech-talks:
      frequency: bi-weekly
      duration: 60 minutes
      audience: engineering-team
      
    book-clubs:
      books-per-quarter: 2
      discussion-format: interactive
      
    mentoring-program:
      senior-junior-pairs: 6
      meeting-frequency: weekly
      duration: 6 months
```

**ğŸ”° åˆå­¦è€…ç†è§£**
Runbookæ ‡å‡†åŒ–å°±åƒé£è¡Œæ‰‹å†Œâ€”â€”é£è¡Œå‘˜ä¸æ˜¯é ç»éªŒéšæœºåº”å˜,è€Œæ˜¯ä¸¥æ ¼æŒ‰ç…§æ‰‹å†Œæ“ä½œã€‚æ ¸å¿ƒæ€æƒ³ï¼š**å°†ä¸“å®¶ç»éªŒå›ºåŒ–ä¸ºå¯å¤åˆ¶çš„æ“ä½œæ­¥éª¤**ã€‚

**ğŸ”§ å·¥ä½œåŸç†**
- **ç»“æ„ç»Ÿä¸€**: æ‰€æœ‰RunbookåŒ…å«ç›¸åŒç« èŠ‚(è§¦å‘æ¡ä»¶/è¯Šæ–­/ä¿®å¤/éªŒè¯/é¢„é˜²)
- **å‘½ä»¤å°±ç»ª**: æ¯ä¸ªæ­¥éª¤éƒ½æ˜¯å¯ç›´æ¥æ‰§è¡Œçš„å‘½ä»¤,ä¸æ˜¯"æ£€æŸ¥æ—¥å¿—"è¿™ç§æ¨¡ç³Šæè¿°
- **ç‰ˆæœ¬ç®¡ç†**: Runbookå­˜å‚¨åœ¨Gitä¸­,æ¯æ¬¡æ›´æ–°éƒ½æœ‰reviewå’Œç‰ˆæœ¬è®°å½•
- **æµ‹è¯•éªŒè¯**: å®šæœŸåœ¨æµ‹è¯•ç¯å¢ƒæ‰§è¡ŒRunbook,ç¡®ä¿å‘½ä»¤æœ‰æ•ˆ
- **æŒç»­æ”¹è¿›**: æ¯æ¬¡æ•…éšœåæ›´æ–°Runbook,è¡¥å……æ–°çš„è¯Šæ–­ç‚¹å’Œä¿®å¤æ–¹æ³•

**ğŸ“ æœ€å°ç¤ºä¾‹**
```markdown
# Runbook æ ‡å‡†æ¨¡æ¿

---
title: "[ç»„ä»¶åç§°] - [æ•…éšœåœºæ™¯]"
component: etcd / apiserver / kubelet / ...
severity: P0 / P1 / P2 / P3
last-updated: 2024-03-15
owner: SRE-Team
---

## ğŸ¯ è§¦å‘æ¡ä»¶

**å‘Šè­¦åç§°**: EtcdHighNumberOfLeaderChanges

**å‘Šè­¦é˜ˆå€¼**: etcd leaderåˆ‡æ¢æ¬¡æ•° > 3æ¬¡/å°æ—¶

**å½±å“èŒƒå›´**: 
- é›†ç¾¤æ§åˆ¶å¹³é¢ä¸ç¨³å®š
- APIè¯·æ±‚å¯èƒ½å¤±è´¥æˆ–è¶…æ—¶
- å½±å“æ‰€æœ‰ä¸šåŠ¡

---

## ğŸ” è¯Šæ–­æ­¥éª¤

### 1. ç¡®è®¤ etcd é›†ç¾¤çŠ¶æ€
```bash
# æ£€æŸ¥ etcd æˆå‘˜åˆ—è¡¨
ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  member list -w table

# é¢„æœŸè¾“å‡º: 3ä¸ªæˆå‘˜,çŠ¶æ€éƒ½æ˜¯ started
```

### 2. æŸ¥çœ‹ leader åˆ‡æ¢å†å²
```bash
kubectl logs -n kube-system etcd-master-01 | grep "elected leader"

# é¢„æœŸè¾“å‡º: æŸ¥çœ‹åˆ‡æ¢æ—¶é—´ç‚¹å’Œé¢‘ç‡
```

### 3. æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ
```bash
# æ£€æŸ¥ etcd æˆå‘˜é—´ç½‘ç»œå»¶è¿Ÿ
for ip in 10.0.1.10 10.0.1.11 10.0.1.12; do
  echo "Ping $ip:"
  ping -c 5 $ip | grep avg
done

# é¢„æœŸè¾“å‡º: å»¶è¿Ÿ < 10ms
```

---

## ğŸ”§ ä¿®å¤æ­¥éª¤

### åœºæ™¯1: ç½‘ç»œå»¶è¿Ÿé«˜ (> 50ms)

**æ ¹å› **: è·¨AZç½‘ç»œæŠ–åŠ¨

**ä¿®å¤æ–¹æ¡ˆ**:
```bash
# 1. ä¸´æ—¶å¢åŠ  etcd å¿ƒè·³è¶…æ—¶
kubectl -n kube-system edit pod etcd-master-01
# ä¿®æ”¹ --heartbeat-interval=500 ä¸º --heartbeat-interval=1000

# 2. é•¿æœŸæ–¹æ¡ˆ: è¿ç§»etcdåˆ°åŒä¸€AZ
# å‚è€ƒæ–‡æ¡£: https://wiki.company.com/etcd-migration
```

### åœºæ™¯2: etcd è¿›ç¨‹ CPU é«˜

**æ ¹å› **: å¤§é‡ watch è¯·æ±‚

**ä¿®å¤æ–¹æ¡ˆ**:
```bash
# 1. æŸ¥çœ‹ watch æ•°é‡
ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  endpoint status -w table

# 2. å¦‚æœ watch > 10000,æ‰§è¡Œæ•°æ®å‹ç¼©
# (å‚è€ƒåº”æ€¥é¢„æ¡ˆ: etcd-performance-tuning.md)
```

---

## âœ… éªŒè¯ä¿®å¤

```bash
# 1. ç¡®è®¤ leader ç¨³å®š(è§‚å¯Ÿ10åˆ†é’Ÿ)
watch -n 10 'ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  endpoint status -w table'

# 2. æ£€æŸ¥å‘Šè­¦æ˜¯å¦æ¢å¤
# è®¿é—® Grafana: https://grafana.company.com/alerts
```

---

## ğŸ›¡ï¸ é•¿æœŸé¢„é˜²

1. **ç›‘æ§æ”¹è¿›**:
   - æ·»åŠ  etcd ç½‘ç»œå»¶è¿Ÿç›‘æ§
   - è®¾ç½® leader åˆ‡æ¢ç‡åŸºçº¿å‘Šè­¦

2. **æ¶æ„ä¼˜åŒ–**:
   - etcd èŠ‚ç‚¹éƒ¨ç½²åœ¨åŒä¸€AZ
   - ä½¿ç”¨ç‹¬å å®ä¾‹,é¿å… noisy neighbor

3. **å®šæœŸç»´æŠ¤**:
   - æ¯æœˆæ‰§è¡Œ etcd defrag
   - æ¯å­£åº¦ review etcd æ€§èƒ½æŒ‡æ ‡

---

## ğŸ“ å‡çº§è·¯å¾„

- **ä¸€çº¿å¤„ç†**: æŒ‰ç…§è¯Šæ–­æ­¥éª¤æ’æŸ¥,å¸¸è§åœºæ™¯å¯ç›´æ¥ä¿®å¤
- **å‡çº§åˆ°äºŒçº¿**: å¦‚æœ20åˆ†é’Ÿæœªå®šä½é—®é¢˜,å‡çº§ç»™ @etcd-expert
- **æ‹‰War Room**: å¦‚æœ leader åˆ‡æ¢å¯¼è‡´ API å¤§é‡å¤±è´¥,ç«‹å³æ‹‰ War Room

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [etcd æ€§èƒ½è°ƒä¼˜æŒ‡å—](https://wiki.company.com/etcd-tuning)
- [etcd ç½‘ç»œè¦æ±‚](https://etcd.io/docs/v3.5/op-guide/hardware/)
- [å†å²æ•…éšœæ¡ˆä¾‹: INC-2024-0312](https://jira.company.com/INC-2024-0312)
```

**âš ï¸ å¸¸è§è¯¯åŒº**
1. âŒ **è¯¯åŒº**: Runbookå†™æˆæŠ€æœ¯åšå®¢â€”â€”"é¦–å…ˆæˆ‘ä»¬è¦ç†è§£etcdçš„Raftåè®®..."
   âœ… **æ­£ç¡®**: Runbookæ˜¯æ“ä½œæ‰‹å†Œ,ç›´æ¥ç»™å‘½ä»¤å’Œé¢„æœŸè¾“å‡º,ç†è®ºçŸ¥è¯†æ”¾åˆ°åŸ¹è®­æ–‡æ¡£é‡Œ
   
2. âŒ **è¯¯åŒº**: Runbooké‡Œçš„å‘½ä»¤"ä¼ªä»£ç "â€”â€”"æ£€æŸ¥æ—¥å¿—æ˜¯å¦æœ‰ERROR"
   âœ… **æ­£ç¡®**: å¿…é¡»æ˜¯å¯ç›´æ¥å¤åˆ¶ç²˜è´´æ‰§è¡Œçš„å®Œæ•´å‘½ä»¤,åŒ…æ‹¬æ‰€æœ‰å‚æ•°å’Œè·¯å¾„
   
3. âŒ **è¯¯åŒº**: å†™å®ŒRunbookå°±ä¸ç®¡äº†â€”â€”"ä¸€å¹´æ²¡æ›´æ–°"
   âœ… **æ­£ç¡®**: æ¯æ¬¡æ•…éšœåå¿…é¡»reviewç›¸å…³Runbook,è¡¥å……æ–°çš„è¯Šæ–­ç‚¹/å‘½ä»¤/åœºæ™¯

## ğŸ“Š è¿è¥æŒ‡æ ‡ä¸æŒç»­æ”¹è¿›

> **ğŸ”° åˆå­¦è€…å¯¼è¯»**: "æ— æ³•è¡¡é‡å°±æ— æ³•æ”¹è¿›"â€”â€”è¿è¥æŒ‡æ ‡å¸®ä½ é‡åŒ–è¿ç»´è´¨é‡ã€‚æ ¸å¿ƒæŒ‡æ ‡åŒ…æ‹¬MTTR(æ•…éšœæ¢å¤æ—¶é—´)ã€å˜æ›´æˆåŠŸç‡ã€SLOè¾¾æˆç‡ç­‰ã€‚å®šæœŸreviewé©±åŠ¨æŒç»­æ”¹è¿›ã€‚

### å…³é”®ç»©æ•ˆæŒ‡æ ‡(KPI)

#### æœåŠ¡è´¨é‡æŒ‡æ ‡
```yaml
# ä¼ä¸šçº§SLI/SLOå®šä¹‰
serviceLevelIndicators:
  availability:
    sli: "uptime_percentage"
    sli-query: |
      sum(up{job=~"application.*"}) / count(up{job=~"application.*"}) * 100
    slo-target: 99.95
    alert-threshold: 99.9
    
  latency:
    sli: "request_duration_p95"
    sli-query: |
      histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
    slo-target: 200ms
    alert-threshold: 500ms
    
  throughput:
    sli: "requests_per_second"
    sli-query: |
      sum(rate(http_requests_total[5m]))
    slo-target: 10000
    alert-threshold: 5000
    
  correctness:
    sli: "error_rate_percentage"
    sli-query: |
      sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m])) * 100
    slo-target: 0.1
    alert-threshold: 1.0

---
# è¿ç»´æ•ˆèƒ½æŒ‡æ ‡
operationalMetrics:
  deployment-frequency:
    target: daily
    current: "4.2/day"
    trend: increasing
    
  lead-time-for-changes:
    target: "<1å°æ—¶"
    current: "45åˆ†é’Ÿ"
    trend: decreasing
    
  mean-time-to-recovery:
    target: "<30åˆ†é’Ÿ"
    current: "22åˆ†é’Ÿ"
    trend: decreasing
    
  change-failure-rate:
    target: "<5%"
    current: "2.3%"
    trend: decreasing
```

**ğŸ”° åˆå­¦è€…ç†è§£**
SLOè¿½è¸ªçœ‹æ¿å°±åƒä¼ä¸šçš„KPIä»ªè¡¨ç›˜â€”â€”CEOéšæ—¶èƒ½çœ‹åˆ°"æœ¬å­£åº¦é”€å”®é¢å®Œæˆåº¦"ã€‚SLOçœ‹æ¿è®©ç®¡ç†å±‚å’Œç”¨æˆ·éšæ—¶äº†è§£"æœåŠ¡å¯é æ€§"ã€‚æ ¸å¿ƒæ€æƒ³ï¼š**å¯è§†åŒ–æœåŠ¡å¥åº·åº¦ï¼Œé€æ˜åŒ–è¿ç»´è´¨é‡**ã€‚

**ğŸ”§ å·¥ä½œåŸç†**
- **SLIå®šä¹‰**: é€‰æ‹©å¯è¡¡é‡çš„æœåŠ¡æŒ‡æ ‡(å¯ç”¨æ€§/å»¶è¿Ÿ/é”™è¯¯ç‡)ä½œä¸ºService Level Indicator
- **SLOç›®æ ‡**: è®¾å®šç›®æ ‡å€¼(å¦‚"å¯ç”¨æ€§99.9%")å’Œè§‚å¯Ÿçª—å£(30å¤©æ»šåŠ¨)
- **Error Budget**: è®¡ç®—å…è®¸çš„æ•…éšœæ—¶é—´(99.9% â†’ 43.2åˆ†é’Ÿ/æœˆå¯ä»¥æ•…éšœ)
- **å®æ—¶å±•ç¤º**: Grafanaçœ‹æ¿å®æ—¶æ˜¾ç¤ºå½“å‰è¾¾æˆç‡å’Œå‰©ä½™å®¹é”™é¢„ç®—
- **å†³ç­–ä¾æ®**: Error Budgetè€—å°½æ—¶å†»ç»“æ–°åŠŸèƒ½å‘å¸ƒï¼Œä¼˜å…ˆä¿®å¤ç¨³å®šæ€§

**ğŸ“ æœ€å°ç¤ºä¾‹**
```yaml
# Sloth SLO å®šä¹‰ (è‡ªåŠ¨ç”Ÿæˆ Prometheus è§„åˆ™)
apiVersion: sloth.slok.dev/v1
kind: PrometheusServiceLevel
metadata:
  name: payment-service-slo
  namespace: monitoring
spec:
  service: "payment-service"
  labels:
    team: "payments"
    tier: "critical"
  
  slos:
  # SLO 1: å¯ç”¨æ€§ç›®æ ‡
  - name: "availability"
    objective: 99.9           # ç›®æ ‡ 99.9%
    description: "æ”¯ä»˜æœåŠ¡å¯ç”¨æ€§"
    
    sli:
      events:
        errorQuery: |
          sum(rate(http_requests_total{service="payment",status=~"5.."}[{{.window}}]))
        totalQuery: |
          sum(rate(http_requests_total{service="payment"}[{{.window}}]))
    
    alerting:
      name: PaymentSLOBurn
      labels:
        severity: critical
      annotations:
        summary: "æ”¯ä»˜æœåŠ¡ Error Budget å³å°†è€—å°½"
      
      # å¤šçª—å£å¤šç‡ƒçƒ§ç‡å‘Šè­¦ (Google SRE æœ€ä½³å®è·µ)
      pageAlert:
        labels:
          severity: page
        annotations:
          summary: "æ”¯ä»˜æœåŠ¡ä¸¥é‡è¿å SLO"
      ticketAlert:
        labels:
          severity: warning
        annotations:
          summary: "æ”¯ä»˜æœåŠ¡ SLO é¢„è­¦"

---
# Grafana Dashboard JSON (SLOçœ‹æ¿)
apiVersion: v1
kind: ConfigMap
metadata:
  name: slo-dashboard
data:
  dashboard.json: |
    {
      "dashboard": {
        "title": "ä¼ä¸šçº§ SLO è¿½è¸ªçœ‹æ¿",
        "panels": [
          {
            "title": "SLO è¾¾æˆç‡ (30å¤©æ»šåŠ¨)",
            "type": "gauge",
            "targets": [{
              "expr": "(1 - (sum(rate(http_requests_total{status=~\"5..\"}[30d])) / sum(rate(http_requests_total[30d])))) * 100"
            }],
            "fieldConfig": {
              "thresholds": [
                {"value": 0, "color": "red"},
                {"value": 99.5, "color": "yellow"},
                {"value": 99.9, "color": "green"}
              ]
            }
          },
          {
            "title": "Error Budget å‰©ä½™",
            "type": "stat",
            "description": "æœ¬æœˆè¿˜å¯ä»¥æ•…éšœå¤šå°‘åˆ†é’Ÿ",
            "targets": [{
              "expr": "slo_error_budget_remaining_seconds{service=\"payment\"} / 60"
            }],
            "unit": "åˆ†é’Ÿ"
          },
          {
            "title": "SLO è¶‹åŠ¿ (è¿‡å»90å¤©)",
            "type": "timeseries",
            "targets": [{
              "expr": "slo:sli:availability:ratio_rate30d{service=\"payment\"} * 100",
              "legendFormat": "å®é™…å¯ç”¨æ€§"
            }],
            "thresholds": [
              {"value": 99.9, "color": "green", "line": true}
            ]
          }
        ]
      }
    }

---
# è‡ªåŠ¨åŒ– SLO æŠ¥å‘Š CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: slo-weekly-report
spec:
  schedule: "0 9 * * 1"  # æ¯å‘¨ä¸€ä¸Šåˆ9ç‚¹
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: reporter
            image: company/slo-reporter:latest
            env:
            - name: SLACK_WEBHOOK
              value: "https://hooks.slack.com/services/XXX"
            - name: EMAIL_LIST
              value: "engineering@company.com,management@company.com"
            command:
            - /bin/bash
            - -c
            - |
              #!/bin/bash
              # æŸ¥è¯¢ä¸Šå‘¨ SLO è¾¾æˆæƒ…å†µ
              AVAILABILITY=$(promql "slo:sli:availability:ratio_rate7d * 100")
              ERROR_BUDGET=$(promql "slo_error_budget_remaining_ratio")
              
              # å‘é€æŠ¥å‘Š
              cat <<EOF | slack-webhook
              ğŸ“Š *æœ¬å‘¨ SLO æŠ¥å‘Š ($(date +%Y-%m-%d))*
              
              *æ ¸å¿ƒæœåŠ¡ SLO è¾¾æˆæƒ…å†µ:*
              âœ… æ”¯ä»˜æœåŠ¡: ${AVAILABILITY}% (ç›®æ ‡ 99.9%)
              âš ï¸  Error Budget å‰©ä½™: ${ERROR_BUDGET}%
              
              *æœ¬å‘¨æ•…éšœç»Ÿè®¡:*
              - P0 æ•…éšœ: 0 æ¬¡
              - P1 æ•…éšœ: 1 æ¬¡ (MTTR: 18åˆ†é’Ÿ)
              
              *æ”¹è¿›å»ºè®®:*
              - Error Budget å‰©ä½™ < 20%, å»ºè®®å†»ç»“æ–°åŠŸèƒ½å‘å¸ƒ
              - ä¼˜å…ˆä¿®å¤é‡å¤æ€§ P1 æ•…éšœ
              
              ğŸ“ˆ è¯¦ç»†çœ‹æ¿: https://grafana.company.com/d/slo-dashboard
              EOF
          restartPolicy: OnFailure
```

**âš ï¸ å¸¸è§è¯¯åŒº**
1. âŒ **è¯¯åŒº**: SLOè®¾å®šå¾—è¿‡é«˜â€”â€”"å¿…é¡»è¾¾åˆ°99.999%äº”ä¸ª9"
   âœ… **æ­£ç¡®**: SLOåº”è¯¥åŸºäºä¸šåŠ¡éœ€è¦å’Œæˆæœ¬å¹³è¡¡ï¼Œå¤§å¤šæ•°ä¸šåŠ¡99.9%å°±å¤Ÿäº†ï¼Œè¿‡é«˜çš„SLOä¼šå¯¼è‡´è¿‡åº¦å·¥ç¨‹åŒ–
   
2. âŒ **è¯¯åŒº**: åªçœ‹æ•´ä½“SLOâ€”â€”"æ‰€æœ‰æ¥å£æ··åœ¨ä¸€èµ·ç®—"
   âœ… **æ­£ç¡®**: åº”è¯¥æŒ‰å…³é”®ä¸šåŠ¡è·¯å¾„æ‹†åˆ†SLOï¼Œæ”¯ä»˜/ç™»å½•/æœç´¢åˆ†åˆ«å®šä¹‰ï¼Œä¼˜å…ˆä¿éšœæ ¸å¿ƒä¸šåŠ¡
   
3. âŒ **è¯¯åŒº**: Error Budgetè€—å°½äº†ä¹Ÿç»§ç»­å‘å¸ƒâ€”â€”"åæ­£å·²ç»è¶…æ ‡äº†"
   âœ… **æ­£ç¡®**: Error Budgetæ˜¯"åˆ¹è½¦æœºåˆ¶"ï¼Œè€—å°½ååº”åœæ­¢åŠŸèƒ½å‘å¸ƒï¼ŒAll hands on deckä¿®å¤ç¨³å®šæ€§

### æŒç»­æ”¹è¿›å¾ªç¯

#### PDCA æ”¹è¿›æ¡†æ¶
```mermaid
graph LR
    P[Plan-è®¡åˆ’] --> D[Do-æ‰§è¡Œ]
    D --> C[Check-æ£€æŸ¥]
    C --> A[Act-è¡ŒåŠ¨]
    A --> P
    
    subgraph è®¡åˆ’é˜¶æ®µ
        PA1[è¯†åˆ«æ”¹è¿›æœºä¼š]
        PA2[è®¾å®šæ”¹è¿›ç›®æ ‡]
        PA3[åˆ¶å®šè¡ŒåŠ¨è®¡åˆ’]
    end
    
    subgraph æ‰§è¡Œé˜¶æ®µ
        DA1[å®æ–½æ”¹è¿›æªæ–½]
        DA2[æ”¶é›†è¿‡ç¨‹æ•°æ®]
        DA3[ç›‘æ§æ‰§è¡Œè¿›åº¦]
    end
    
    subgraph æ£€æŸ¥é˜¶æ®µ
        CA1[è¯„ä¼°æ”¹è¿›æ•ˆæœ]
        CA2[å¯¹æ¯”ç›®æ ‡ç»“æœ]
        CA3[è¯†åˆ«åå·®åŸå› ]
    end
    
    subgraph è¡ŒåŠ¨é˜¶æ®µ
        AA1[æ ‡å‡†åŒ–æˆåŠŸåšæ³•]
        AA2[æ¨å¹¿æœ‰æ•ˆç»éªŒ]
        AA3[è§„åˆ’ä¸‹ä¸€è½®æ”¹è¿›]
    end
```

#### æ”¹è¿›é¡¹ç›®ç®¡ç†
```yaml
# æŒç»­æ”¹è¿›é¡¹ç›®è·Ÿè¸ª
improvementProjects:
  - name: "ç›‘æ§ç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–"
    owner: "è¿ç»´å›¢é˜Ÿ"
    startDate: "2024-01-15"
    endDate: "2024-03-15"
    status: "completed"
    results:
      - "æŸ¥è¯¢æ€§èƒ½æå‡60%"
      - "å­˜å‚¨æˆæœ¬é™ä½25%"
      - "å‘Šè­¦å‡†ç¡®æ€§æé«˜40%"
      
  - name: "è‡ªåŠ¨æ‰©ç¼©å®¹ç­–ç•¥ä¼˜åŒ–"
    owner: "å¹³å°å·¥ç¨‹å›¢é˜Ÿ"
    startDate: "2024-02-01"
    endDate: "2024-04-01"
    status: "in-progress"
    targets:
      - "æˆæœ¬èŠ‚çº¦20%"
      - "å“åº”æ—¶é—´å‡å°‘50%"
      - "èµ„æºåˆ©ç”¨ç‡æå‡è‡³75%"
      
  - name: "å®‰å…¨æ¼æ´å¿«é€Ÿå“åº”"
    owner: "å®‰å…¨å›¢é˜Ÿ"
    startDate: "2024-03-01"
    endDate: "2024-05-01"
    status: "planned"
    objectives:
      - "æ¼æ´ä¿®å¤æ—¶é—´<24å°æ—¶"
      - "å®‰å…¨äº‹ä»¶0é—æ¼"
      - "åˆè§„æ£€æŸ¥100%é€šè¿‡"
```

**ğŸ”° åˆå­¦è€…ç†è§£**
å®¹é‡è§„åˆ’å°±åƒåŸå¸‚ç”¨ç”µè´Ÿè·é¢„æµ‹â€”â€”æ ¹æ®å†å²ç”¨ç”µé‡å’Œäººå£å¢é•¿ï¼Œé¢„æµ‹æ˜å¹´éœ€è¦å»ºå¤šå°‘å‘ç”µç«™ã€‚æ ¸å¿ƒæ€æƒ³ï¼š**æå‰é¢„æµ‹èµ„æºéœ€æ±‚ï¼Œé¿å…çªç„¶ä¸å¤Ÿç”¨**ã€‚

**ğŸ”§ å·¥ä½œåŸç†**
- **å†å²æ•°æ®åˆ†æ**: æ”¶é›†è¿‡å»6-12ä¸ªæœˆçš„èµ„æºä½¿ç”¨è¶‹åŠ¿(CPU/å†…å­˜/ç½‘ç»œ/å­˜å‚¨)
- **ä¸šåŠ¡å¢é•¿é¢„æµ‹**: ç»“åˆä¸šåŠ¡è§„åˆ’(å¦‚"Q4å¤§ä¿ƒé¢„è®¡æµé‡2å€")è°ƒæ•´é¢„æµ‹æ¨¡å‹
- **å®¹é‡å»ºæ¨¡**: è€ƒè™‘å†—ä½™(N+2)ã€å³°å€¼(P99)ã€çªå‘å¢é•¿ï¼Œè®¡ç®—æ‰€éœ€èµ„æº
- **æˆæœ¬ä¼˜åŒ–**: å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬ï¼Œä½¿ç”¨Spotå®ä¾‹/é¢„ç•™å®ä¾‹/æ‰¿è¯ºä½¿ç”¨æŠ˜æ‰£
- **æå‰æ‰©å®¹**: åœ¨èµ„æºè¾¾åˆ°70%ä½¿ç”¨ç‡æ—¶è§¦å‘æ‰©å®¹ï¼Œç•™å‡ºç¼“å†²æ—¶é—´

**ğŸ“ æœ€å°ç¤ºä¾‹**
```yaml
# å®¹é‡è§„åˆ’é…ç½®
apiVersion: ops.company.com/v1
kind: CapacityPlan
metadata:
  name: production-capacity-2024
spec:
  # å½“å‰å®¹é‡
  currentCapacity:
    compute:
      nodes: 100
      totalCPU: 400
      totalMemory: 1600Gi
      utilization:
        cpu: 65%
        memory: 72%
    
    storage:
      totalCapacity: 50Ti
      usedCapacity: 35Ti
      growthRate: 2Ti/month
  
  # ä¸šåŠ¡é¢„æµ‹
  businessForecast:
    q2-2024:
      expectedGrowth: 20%
      reason: "æ–°äº§å“ä¸Šçº¿"
    q4-2024:
      expectedGrowth: 150%
      reason: "åŒ11å¤§ä¿ƒ"
  
  # æ‰©å®¹è®¡åˆ’
  expansionPlan:
  - timeline: "2024-06-01"
    reason: "Q2ä¸šåŠ¡å¢é•¿"
    actions:
    - type: "add-nodes"
      quantity: 20
      instanceType: "c6i.4xlarge"
      estimatedCost: "$15,000/month"
    
  - timeline: "2024-10-01"
    reason: "åŒ11å¤§ä¿ƒå‡†å¤‡"
    actions:
    - type: "add-nodes"
      quantity: 100
      instanceType: "c6i.2xlarge"
      spotRatio: 70%
      estimatedCost: "$40,000/month"
    - type: "expand-storage"
      capacity: "+20Ti"
      storageType: "gp3"
      estimatedCost: "$2,000/month"
  
  # å‘Šè­¦é˜ˆå€¼
  alerts:
  - metric: "cluster_cpu_utilization"
    threshold: 70%
    action: "é€šçŸ¥å®¹é‡è§„åˆ’å›¢é˜Ÿ"
  - metric: "storage_usage"
    threshold: 75%
    action: "å¯åŠ¨æ‰©å®¹æµç¨‹"

---
# è‡ªåŠ¨åŒ–å®¹é‡æŠ¥å‘Š CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: capacity-monthly-report
spec:
  schedule: "0 9 1 * *"  # æ¯æœˆ1å·ä¸Šåˆ9ç‚¹
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: reporter
            image: company/capacity-reporter:latest
            env:
            - name: PROMETHEUS_URL
              value: "http://prometheus:9090"
            - name: SLACK_WEBHOOK
              valueFrom:
                secretKeyRef:
                  name: slack-webhook
                  key: url
            command:
            - python3
            - /app/capacity_report.py
            - --lookback=30d
            - --forecast=90d

---
# Python å®¹é‡é¢„æµ‹è„šæœ¬
apiVersion: v1
kind: ConfigMap
metadata:
  name: capacity-forecast-script
data:
  forecast.py: |
    #!/usr/bin/env python3
    import requests
    import pandas as pd
    from prophet import Prophet  # æ—¶é—´åºåˆ—é¢„æµ‹åº“
    
    # æŸ¥è¯¢ Prometheus å†å²æ•°æ®
    def fetch_metrics(query, days=180):
        url = "http://prometheus:9090/api/v1/query_range"
        params = {
            "query": query,
            "start": f"-{days}d",
            "end": "now",
            "step": "1h"
        }
        resp = requests.get(url, params=params).json()
        return resp["data"]["result"][0]["values"]
    
    # é¢„æµ‹æœªæ¥å®¹é‡éœ€æ±‚
    def forecast_capacity():
        # è·å– CPU ä½¿ç”¨ç‡æ•°æ®
        cpu_data = fetch_metrics("avg(node_cpu_usage)")
        df = pd.DataFrame(cpu_data, columns=["ds", "y"])
        df["ds"] = pd.to_datetime(df["ds"], unit="s")
        
        # Prophet æ—¶é—´åºåˆ—é¢„æµ‹
        model = Prophet(yearly_seasonality=True)
        model.fit(df)
        
        # é¢„æµ‹æœªæ¥90å¤©
        future = model.make_future_dataframe(periods=90)
        forecast = model.predict(future)
        
        # è®¡ç®—ä½•æ—¶éœ€è¦æ‰©å®¹ (è¾¾åˆ°80%é˜ˆå€¼)
        expansion_date = forecast[forecast["yhat"] > 80].iloc[0]["ds"]
        
        print(f"é¢„æµ‹åœ¨ {expansion_date} éœ€è¦æ‰©å®¹")
        print(f"å»ºè®®æå‰30å¤©(å³ {expansion_date - pd.Timedelta(days=30)})å¯åŠ¨é‡‡è´­æµç¨‹")
        
        return forecast
    
    if __name__ == "__main__":
        forecast_capacity()
```

**âš ï¸ å¸¸è§è¯¯åŒº**
1. âŒ **è¯¯åŒº**: å®¹é‡è§„åˆ’åªçœ‹æŠ€æœ¯æŒ‡æ ‡â€”â€”"CPUä½¿ç”¨ç‡70%ï¼Œè¿˜èƒ½æ’‘3ä¸ªæœˆ"
   âœ… **æ­£ç¡®**: å¿…é¡»ç»“åˆä¸šåŠ¡è§„åˆ’ï¼Œå¦‚æœä¸‹æœˆæœ‰å¤§ä¿ƒæ´»åŠ¨ï¼Œç°åœ¨å°±è¦å¼€å§‹æ‰©å®¹
   
2. âŒ **è¯¯åŒº**: ç­‰èµ„æºä¸å¤Ÿäº†å†æ‰©å®¹â€”â€”"ç£ç›˜95%äº†ï¼Œèµ¶ç´§ä¹°"
   âœ… **æ­£ç¡®**: åº”è¯¥åœ¨70-80%æ—¶å°±å¯åŠ¨æ‰©å®¹ï¼Œç¡¬ä»¶é‡‡è´­/å®¡æ‰¹/éƒ¨ç½²éœ€è¦æ—¶é—´ï¼Œç­‰95%å°±æ¥ä¸åŠäº†
   
3. âŒ **è¯¯åŒº**: å®¹é‡è§„åˆ’ä¸€å¹´åšä¸€æ¬¡â€”â€”"å¹´åˆåšä¸ªè®¡åˆ’ï¼Œå…¨å¹´æŒ‰è®¡åˆ’æ‰§è¡Œ"
   âœ… **æ­£ç¡®**: åº”è¯¥æ¯æœˆreviewä¸€æ¬¡å®é™…ä½¿ç”¨æƒ…å†µï¼Œæ ¹æ®ä¸šåŠ¡å˜åŒ–åŠ¨æ€è°ƒæ•´ï¼Œé‡å¤§æ´»åŠ¨å‰é¢å¤–è¯„ä¼°

## ğŸ”§ é™„å½•ï¼šä¼ä¸šçº§è¿ç»´å·¥å…·é“¾

### æ ¸å¿ƒå·¥å…·æ¨è

#### ç›‘æ§ä¸å¯è§‚æµ‹æ€§
- **Prometheus + Grafana**: æ ¸å¿ƒç›‘æ§å¹³å°
- **Elastic Stack**: æ—¥å¿—åˆ†æä¸æœç´¢
- **Datadog/New Relic**: å•†ä¸šAPMè§£å†³æ–¹æ¡ˆ
- **Jaeger/OpenTelemetry**: åˆ†å¸ƒå¼è¿½è¸ª

#### è‡ªåŠ¨åŒ–ä¸ç¼–æ’
- **Ansible/Terraform**: åŸºç¡€è®¾æ–½å³ä»£ç 
- **Argo CD/Flux**: GitOpsæŒç»­äº¤ä»˜
- **Jenkins/GitLab CI**: CI/CDæµæ°´çº¿
- **Spinnaker**: å¤šäº‘äº¤ä»˜å¹³å°

#### å®‰å…¨ä¸åˆè§„
- **Falco/Sysdig**: è¿è¡Œæ—¶å®‰å…¨ç›‘æ§
- **Aqua Security**: å®¹å™¨å®‰å…¨å¹³å°
- **HashiCorp Vault**: å¯†é’¥ç®¡ç†
- **SonarQube**: ä»£ç è´¨é‡ä¸å®‰å…¨æ‰«æ

è¿™ä»½ä¼ä¸šçº§è¿ç»´æœ€ä½³å®è·µæ–‡æ¡£ä¸ºä¼ä¸šæ„å»ºäº†å®Œæ•´çš„è¿ç»´ä½“ç³»æ¡†æ¶ï¼Œæ¶µç›–äº†ä»å¤§è§„æ¨¡é›†ç¾¤ç®¡ç†åˆ°å›¢é˜Ÿåä½œçš„å„ä¸ªæ–¹é¢ï¼Œç¡®ä¿èƒ½å¤Ÿæ”¯æ’‘ä¸‡çº§èŠ‚ç‚¹è§„æ¨¡çš„ç”Ÿäº§ç¯å¢ƒç¨³å®šè¿è¡Œã€‚

---

**è¡¨æ ¼åº•éƒ¨æ ‡è®°**: Kusheet Project | ä½œè€…: Allen Galler (allengaller@gmail.com) | æœ€åæ›´æ–°: 2026-02 | ç‰ˆæœ¬: v1.25-v1.32 | è´¨é‡ç­‰çº§: â­â­â­â­â­ ä¸“å®¶çº§