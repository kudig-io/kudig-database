# èŠ‚ç‚¹æ•…éšœä¸“é¡¹æ’æŸ¥æŒ‡å—

> **é€‚ç”¨ç‰ˆæœ¬**: Kubernetes v1.25 - v1.32 | **æœ€åæ›´æ–°**: 2026-01 | **éš¾åº¦**: é«˜çº§
>
> **ç‰ˆæœ¬è¯´æ˜**:
> - v1.25+ æ”¯æŒ PodDisruptionConditions ç‰¹æ€§
> - v1.26+ GracefulNodeShutdown é»˜è®¤å¯ç”¨
> - v1.28+ SidecarContainers æ”¯æŒä¼˜é›…ç»ˆæ­¢

## ğŸ¯ æœ¬æ–‡æ¡£ä»·å€¼

| è¯»è€…å¯¹è±¡ | ä»·å€¼ä½“ç° |
| :--- | :--- |
| **åˆå­¦è€…** | æŒæ¡ Kubernetes èŠ‚ç‚¹çš„äº”ç§æ ¸å¿ƒçŠ¶æ€æ¡ä»¶ï¼ˆConditionsï¼‰ï¼Œå­¦ä¼šè¯†åˆ«æ±¡ç‚¹ï¼ˆTaintsï¼‰ä¸å®¹å¿ï¼ˆTolerationsï¼‰çš„åŒ¹é…é€»è¾‘ï¼ŒæŒæ¡å®‰å…¨ç»´æŠ¤èŠ‚ç‚¹ï¼ˆCordon/Drainï¼‰çš„æ ‡å‡†æµç¨‹ã€‚ |
| **èµ„æ·±ä¸“å®¶** | æ·±å…¥ç†è§£èŠ‚ç‚¹ç”Ÿå‘½å‘¨æœŸæ§åˆ¶å™¨ï¼ˆNode Lifecycle Controllerï¼‰çš„åˆ¤æ´»æœºåˆ¶ã€åœ¨ä¸åŒç½‘ç»œåˆ†åŒºä¸‹çš„é©±é€ä¿æŠ¤ç­–ç•¥ã€Graceful Node Shutdown çš„å®ç°ç»†èŠ‚ï¼Œä»¥åŠé’ˆå¯¹ CPU/å†…å­˜ç¢ç‰‡åŒ–çš„è°ƒåº¦ä¼˜åŒ–æ–¹æ¡ˆã€‚ |

---

## 0. 10 åˆ†é’Ÿå¿«é€Ÿè¯Šæ–­

1. **ç¡®è®¤å½±å“é¢**ï¼š`kubectl get nodes -o wide`ï¼Œç»Ÿè®¡ NotReady/Unknown èŠ‚ç‚¹æ¯”ä¾‹ï¼ŒåŒºåˆ†å•ç‚¹ vs æ‰¹é‡ã€‚
2. **æŠ½æ ·æ·±æ**ï¼šå¯¹ 1-2 ä¸ªå¼‚å¸¸èŠ‚ç‚¹æ‰§è¡Œ `kubectl describe node <name>`ï¼Œå…³æ³¨ Conditionsã€Taintsã€Allocatable/Capacityã€è¿‘æœŸäº‹ä»¶ï¼ˆå¿ƒè·³è¶…æ—¶/é©±é€ï¼‰ã€‚
3. **èµ„æºä¸å‹åŠ›**ï¼šç™»é™†èŠ‚ç‚¹ `free -m`ã€`df -h`ã€`df -i`ã€`pidstat -p $(pgrep kubelet)`ï¼ŒæŸ¥ Memory/Disk/PIDPressureï¼›`dmesg | tail` è¯†åˆ«ç¡¬ä»¶/IO æŠ¥é”™ã€‚
4. **ç½‘ç»œè¿é€š**ï¼šèŠ‚ç‚¹åˆ° API Server `curl -k https://$APISERVER:6443/healthz`ï¼Œæ£€æŸ¥å®‰å…¨ç»„/é˜²ç«å¢™/è·¯ç”±ï¼›æ‰¹é‡æŠ–åŠ¨æ—¶è€ƒè™‘ä¸Šæ¸¸ç½‘ç»œåˆ†åŒºã€‚
5. **é©±é€/ç»´æŠ¤çŠ¶æ€**ï¼šç¡®è®¤æ˜¯å¦è¢« `cordon`/`drain` æˆ–è‡ªåŠ¨æ±¡ç‚¹ï¼›æ£€æŸ¥ `GracefulNodeShutdown`ï¼ˆv1.26+ï¼‰å’Œ PodDisruptionConditionsã€‚
6. **å¿«é€Ÿç¼“è§£**ï¼š
   - å•èŠ‚ç‚¹å¼‚å¸¸ï¼š`cordon` å¹¶ä¿®å¤èµ„æº/ç½‘ç»œ/ç£ç›˜ï¼Œå¿…è¦æ—¶æ¢æœºæˆ–è¿ç§»å·¥ä½œè´Ÿè½½ã€‚
   - æ‰¹é‡æ³¢åŠ¨ï¼šé™ä½é©±é€é€Ÿç‡ï¼ˆè°ƒæ•´ Node Controller å‚æ•°ï¼‰ï¼Œæš‚åœå¤§è§„æ¨¡å˜æ›´ï¼Œä¼˜å…ˆæ¢å¤ç½‘ç»œ/APIServerã€‚
   - æ±¡æŸ“/å¹½çµèŠ‚ç‚¹ï¼šæ¸…ç†å¤±è”èŠ‚ç‚¹ (`kubectl delete node <name>`) å‰å…ˆç¡®è®¤æ— è·‘åŠ¨ Podã€‚
7. **è¯æ®ç•™å­˜**ï¼šè®°å½• describe è¾“å‡ºã€Conditions/Taints å¿«ç…§ã€ç³»ç»Ÿæ—¥å¿—ã€ç½‘ç»œæ¢æµ‹ç»“æœï¼Œä¾¿äºå¤ç›˜ã€‚

## 1. æ ¸å¿ƒåŸç†è§£æï¼šèŠ‚ç‚¹æ²»ç†çš„é€»è¾‘

### 1.1 èŠ‚ç‚¹â€œäºšå¥åº·â€çŠ¶æ€åˆ¤å®š

èŠ‚ç‚¹ä¸åªæ˜¯ Ready æˆ– NotReadyã€‚Kubernetes é€šè¿‡ `NodeConditions` æè¿°èŠ‚ç‚¹çš„å¥åº·ç»´åº¦ï¼š
- **èµ„æºå‹åŠ›ï¼ˆPressureï¼‰**ï¼šå½“èŠ‚ç‚¹å¯ç”¨å†…å­˜æˆ–ç£ç›˜ä½äº kubelet è®¾å®šçš„ `eviction-hard` é˜ˆå€¼æ—¶ï¼ŒèŠ‚ç‚¹ä¼šè¢«æ‰“ä¸Šå¯¹åº”çš„ Conditionã€‚
- **è‡ªåŠ¨æ±¡ç‚¹ï¼ˆAuto-Taintsï¼‰**ï¼šNode Controller ä¼šæ ¹æ® Condition è‡ªåŠ¨ä¸ºèŠ‚ç‚¹æ‰“ä¸Šæ±¡ç‚¹ï¼ˆå¦‚ `NoSchedule` æˆ– `NoExecute`ï¼‰ï¼Œé˜²æ­¢æ–°çš„ Pod è°ƒåº¦è¿›æ¥ï¼Œæˆ–è€…é©±é€å·²æœ‰ Podã€‚

### 1.2 èŠ‚ç‚¹é©±é€ä¿æŠ¤æœºåˆ¶ï¼ˆ à¤à¤•à¥à¤¸à¤ªà¤°à¥à¤Ÿ's Perspectiveï¼‰

åœ¨å¤§è§„æ¨¡é›†ç¾¤ä¸­ï¼ŒèŠ‚ç‚¹æ‰¹é‡ NotReady æ˜¯æåº¦å±é™©çš„åœºæ™¯ã€‚
1. **é©±é€é€Ÿç‡é™åˆ¶**ï¼šå½“é›†ç¾¤ä¸­è¶…è¿‡ 20% çš„èŠ‚ç‚¹ NotReady æ—¶ï¼ŒNode Controller ä¼šè¿›å…¥â€œéƒ¨åˆ†æ•…éšœâ€æ¨¡å¼ï¼Œå°†é©±é€é€Ÿç‡é™è‡³æ¯ç§’ 0.01 ä¸ªèŠ‚ç‚¹ï¼Œé˜²æ­¢å› ç½‘ç»œæ³¢åŠ¨å¯¼è‡´å…¨é›†ç¾¤ Pod é‡æ–°è°ƒåº¦ã€‚
2. **Graceful Node Shutdown**ï¼šv1.26+ é»˜è®¤å¼€å¯ã€‚kubelet èƒ½å¤Ÿæ„ŸçŸ¥èŠ‚ç‚¹å…³æœºä¿¡å·ï¼Œå¹¶ä¼˜å…ˆç»ˆæ­¢ Podï¼Œç»™äºˆå…³é”®åº”ç”¨ï¼ˆå¦‚æ•°æ®åº“ï¼‰æ•°æ®åˆ·ç›˜çš„æ—¶é—´ã€‚

### 1.3 ç”Ÿäº§ç¯å¢ƒå…¸å‹â€œèŠ‚ç‚¹é™·é˜±â€

1. **CPU èŠ‚æµï¼ˆThrottlingï¼‰å¯¼è‡´çš„æœåŠ¡æŠ–åŠ¨**ï¼š
   - **ç°è±¡**ï¼šèŠ‚ç‚¹ CPU ä½¿ç”¨ç‡ä¸é«˜ï¼Œä½† Pod å“åº”å˜æ…¢ï¼Œç›‘æ§æ˜¾ç¤º CPU Throttlingã€‚
   - **åŸå› **ï¼šCFS è°ƒåº¦å™¨çš„å‘¨æœŸé™åˆ¶ä¸ Pod çš„ CPU Limit å†²çªã€‚
   - **å¯¹ç­–**ï¼šæ¨èä½¿ç”¨ CPU Manager è®¾ç½® `static` ç­–ç•¥ï¼Œæˆ–åœ¨ v1.22+ å°è¯• `CPUManagerPolicyAlphaOptions`ã€‚
2. **Ghost Nodesï¼ˆå¹½çµèŠ‚ç‚¹ï¼‰**ï¼š
   - **ç°è±¡**ï¼šèŠ‚ç‚¹å·²åœ¨äº‘ç«¯åˆ é™¤ï¼Œä½† `kubectl get nodes` ä»ç„¶å¯è§ä¸”æ˜¾ç¤º NotReadyã€‚
   - **åŸå› **ï¼šCloud Controller Manager (CCM) åŒæ­¥å¼‚å¸¸æˆ–æœªæ­£ç¡®é…ç½®ã€‚

# ä¸“å®¶çº§è§‚æµ‹å·¥å…·é“¾ï¼ˆExpert's Toolboxï¼‰

```bash
# ä¸“å®¶çº§ï¼šæŸ¥çœ‹èŠ‚ç‚¹æ‰€æœ‰ Conditionsï¼ˆåŒ…æ‹¬éšå½¢è‡ªå®šä¹‰æ¡ä»¶ï¼‰
kubectl get node <node-name> -o json | jq '.status.conditions'

# ä¸“å®¶çº§ï¼šåˆ†æèŠ‚ç‚¹èµ„æºåˆ†é…ç¢ç‰‡åŒ–ç¨‹åº¦
# ä½¿ç”¨ kubectl-view-allocations æ’ä»¶ï¼ˆæ¨èå®‰è£…ï¼‰
kubectl view-allocations

# ä¸“å®¶çº§ï¼šè¿½è¸ª Node Controller çš„é©±é€å†³ç­–æ—¥å¿—
kubectl logs -n kube-system -l component=kube-controller-manager | grep "NodeLifecycleController"
```

---

## ç›®å½•

1. [èŠ‚ç‚¹æ²»ç†é€»è¾‘](#1-æ ¸å¿ƒåŸç†è§£æèŠ‚ç‚¹æ²»ç†çš„é€»è¾‘)
2. [ä¸“å®¶è§‚æµ‹å·¥å…·é“¾](#ä¸“å®¶çº§è§‚æµ‹å·¥å…·é“¾experts-toolbox)
3. [æ•…éšœç°è±¡ä¸åˆ†çº§å½±å“](#12-å¸¸è§é—®é¢˜ç°è±¡)
4. [åŸºç¡€æ’æŸ¥æ­¥éª¤ï¼ˆåˆå­¦è€…ï¼‰](#22-æ’æŸ¥å‘½ä»¤é›†)
5. [æ·±åº¦æ²»ç†æ–¹æ¡ˆ](#ç¬¬ä¸‰éƒ¨åˆ†è§£å†³æ–¹æ¡ˆä¸é£é™©æ§åˆ¶)

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šé—®é¢˜ç°è±¡ä¸å½±å“åˆ†æ

### 1.1 èŠ‚ç‚¹çŠ¶æ€ä¸æ¡ä»¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      èŠ‚ç‚¹çŠ¶æ€æ¡ä»¶                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Node Conditions                        â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ Ready              â”‚ kubelet æ­£å¸¸ï¼Œå¯è°ƒåº¦ Pod            â”‚   â”‚
â”‚  â”‚ MemoryPressure     â”‚ èŠ‚ç‚¹å†…å­˜ä¸è¶³                        â”‚   â”‚
â”‚  â”‚ DiskPressure       â”‚ èŠ‚ç‚¹ç£ç›˜ç©ºé—´ä¸è¶³                    â”‚   â”‚
â”‚  â”‚ PIDPressure        â”‚ èŠ‚ç‚¹ PID æ•°é‡ä¸è¶³                   â”‚   â”‚
â”‚  â”‚ NetworkUnavailable â”‚ èŠ‚ç‚¹ç½‘ç»œé…ç½®ä¸æ­£ç¡®                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Node Taints                            â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ ç³»ç»Ÿè‡ªåŠ¨æ·»åŠ :                                              â”‚   â”‚
â”‚  â”‚ - node.kubernetes.io/not-ready                            â”‚   â”‚
â”‚  â”‚ - node.kubernetes.io/unreachable                          â”‚   â”‚
â”‚  â”‚ - node.kubernetes.io/memory-pressure                      â”‚   â”‚
â”‚  â”‚ - node.kubernetes.io/disk-pressure                        â”‚   â”‚
â”‚  â”‚ - node.kubernetes.io/pid-pressure                         â”‚   â”‚
â”‚  â”‚ - node.kubernetes.io/network-unavailable                  â”‚   â”‚
â”‚  â”‚ - node.kubernetes.io/unschedulable                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 å¸¸è§é—®é¢˜ç°è±¡

| é—®é¢˜ç±»å‹ | ç°è±¡æè¿° | å¯èƒ½åŸå›  | æŸ¥çœ‹æ–¹å¼ |
|---------|---------|---------|---------|
| èŠ‚ç‚¹ NotReady | èŠ‚ç‚¹çŠ¶æ€ä¸æ­£å¸¸ | kubelet æ•…éšœ/ç½‘ç»œé—®é¢˜/èµ„æºå‹åŠ› | `kubectl get nodes` |
| å†…å­˜å‹åŠ› | MemoryPressure=True | å†…å­˜ä½¿ç”¨è¿‡é«˜/æ³„æ¼ | `kubectl describe node` |
| ç£ç›˜å‹åŠ› | DiskPressure=True | ç£ç›˜ç©ºé—´ä¸è¶³/inode è€—å°½ | `kubectl describe node` |
| PID å‹åŠ› | PIDPressure=True | è¿›ç¨‹æ•°è¿‡å¤š | `kubectl describe node` |
| Pod æ— æ³•è°ƒåº¦ | Pod Pending | æ±¡ç‚¹/äº²å’Œæ€§/èµ„æºä¸è¶³ | `kubectl describe pod` |
| Pod è¢«é©±é€ | Pod Evicted | èŠ‚ç‚¹èµ„æºå‹åŠ› | `kubectl get pods` |
| èŠ‚ç‚¹ä¸å¯è°ƒåº¦ | SchedulingDisabled | èŠ‚ç‚¹è¢« cordon | `kubectl get nodes` |

### 1.3 å½±å“åˆ†æ

| æ•…éšœç±»å‹ | ç›´æ¥å½±å“ | é—´æ¥å½±å“ | å½±å“èŒƒå›´ |
|---------|---------|---------|---------|
| èŠ‚ç‚¹ NotReady | èŠ‚ç‚¹ä¸Š Pod çŠ¶æ€æœªçŸ¥ | æœåŠ¡å¯ç”¨æ€§ä¸‹é™ | å•èŠ‚ç‚¹æ‰€æœ‰ Pod |
| èµ„æºå‹åŠ› | Pod è¢«é©±é€ | æœåŠ¡ä¸­æ–­ï¼Œæ•°æ®å¯èƒ½ä¸¢å¤± | å•èŠ‚ç‚¹ä¼˜å…ˆçº§ä½çš„ Pod |
| ç½‘ç»œä¸å¯ç”¨ | Pod æ— æ³•é€šä¿¡ | Service ä¸å¯è¾¾ | å•èŠ‚ç‚¹æ‰€æœ‰ Pod |
| å¤šèŠ‚ç‚¹æ•…éšœ | å¤§é‡ Pod ä¸å¯ç”¨ | æœåŠ¡å®Œå…¨ä¸­æ–­ | å—å½±å“èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰æœåŠ¡ |

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šæ’æŸ¥æ–¹æ³•ï¼ˆåŸºç¡€ä¸è¿›é˜¶ï¼‰

### 2.1 æ’æŸ¥å†³ç­–æ ‘

```
èŠ‚ç‚¹æ•…éšœ
    â”‚
    â”œâ”€â”€â”€ èŠ‚ç‚¹ NotReadyï¼Ÿ
    â”‚         â”‚
    â”‚         â”œâ”€ kubelet çŠ¶æ€ â”€â”€â†’ systemctl status kubelet
    â”‚         â”œâ”€ å®¹å™¨è¿è¡Œæ—¶ â”€â”€â†’ systemctl status containerd
    â”‚         â”œâ”€ ç½‘ç»œé—®é¢˜ â”€â”€â†’ æ£€æŸ¥èŠ‚ç‚¹ç½‘ç»œè¿é€šæ€§
    â”‚         â””â”€ èµ„æºå‹åŠ› â”€â”€â†’ æ£€æŸ¥ Conditions
    â”‚
    â”œâ”€â”€â”€ èµ„æºå‹åŠ›ï¼Ÿ
    â”‚         â”‚
    â”‚         â”œâ”€ MemoryPressure â”€â”€â†’ æ£€æŸ¥å†…å­˜ä½¿ç”¨/OOM
    â”‚         â”œâ”€ DiskPressure â”€â”€â†’ æ£€æŸ¥ç£ç›˜/inode
    â”‚         â””â”€ PIDPressure â”€â”€â†’ æ£€æŸ¥è¿›ç¨‹æ•°
    â”‚
    â”œâ”€â”€â”€ Pod æ— æ³•è°ƒåº¦ï¼Ÿ
    â”‚         â”‚
    â”‚         â”œâ”€ æ±¡ç‚¹é—®é¢˜ â”€â”€â†’ æ£€æŸ¥èŠ‚ç‚¹æ±¡ç‚¹å’Œ Pod å®¹å¿
    â”‚         â”œâ”€ äº²å’Œæ€§é—®é¢˜ â”€â”€â†’ æ£€æŸ¥èŠ‚ç‚¹æ ‡ç­¾å’Œäº²å’Œæ€§è§„åˆ™
    â”‚         â”œâ”€ èµ„æºä¸è¶³ â”€â”€â†’ æ£€æŸ¥å¯ç”¨èµ„æº
    â”‚         â””â”€ æ‹“æ‰‘çº¦æŸ â”€â”€â†’ æ£€æŸ¥ topologySpreadConstraints
    â”‚
    â””â”€â”€â”€ Pod è¢«é©±é€ï¼Ÿ
              â”‚
              â”œâ”€ ä¼˜å…ˆçº§ â”€â”€â†’ æ£€æŸ¥ PriorityClass
              â”œâ”€ QoS ç±»åˆ« â”€â”€â†’ æ£€æŸ¥èµ„æºé…ç½®
              â””â”€ é©±é€ç­–ç•¥ â”€â”€â†’ æ£€æŸ¥ kubelet é…ç½®
```

### 2.2 æ’æŸ¥å‘½ä»¤é›†

#### 2.2.1 èŠ‚ç‚¹çŠ¶æ€æ£€æŸ¥

```bash
# æŸ¥çœ‹æ‰€æœ‰èŠ‚ç‚¹çŠ¶æ€
kubectl get nodes -o wide

# æŸ¥çœ‹èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
kubectl describe node <node-name>

# æŸ¥çœ‹èŠ‚ç‚¹æ¡ä»¶
kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.conditions[?(@.status=="True")].type}{"\n"}{end}'

# æŸ¥çœ‹èŠ‚ç‚¹èµ„æºä½¿ç”¨
kubectl top nodes

# æŸ¥çœ‹èŠ‚ç‚¹ä¸Šçš„ Pod
kubectl get pods --all-namespaces --field-selector spec.nodeName=<node-name>

# æŸ¥çœ‹èŠ‚ç‚¹æ ‡ç­¾
kubectl get nodes --show-labels

# æŸ¥çœ‹èŠ‚ç‚¹æ±¡ç‚¹
kubectl get nodes -o custom-columns=NAME:.metadata.name,TAINTS:.spec.taints
```

#### 2.2.2 èµ„æºå‹åŠ›æ£€æŸ¥

```bash
# å†…å­˜ä½¿ç”¨è¯¦æƒ…
kubectl describe node <node-name> | grep -A5 "Allocated resources"

# SSH åˆ°èŠ‚ç‚¹æ£€æŸ¥
ssh <node>

# å†…å­˜ä½¿ç”¨
free -h
cat /proc/meminfo | grep -E "MemTotal|MemFree|MemAvailable|Buffers|Cached"

# ç£ç›˜ä½¿ç”¨
df -h
df -i  # inode ä½¿ç”¨

# è¿›ç¨‹æ•°
ps aux | wc -l
cat /proc/sys/kernel/pid_max

# æ£€æŸ¥ OOM äº‹ä»¶
dmesg | grep -i "oom\|out of memory"
journalctl -k | grep -i oom

# kubelet èµ„æºé¢„ç•™é…ç½®
cat /var/lib/kubelet/config.yaml | grep -A10 "eviction\|system"
```

#### 2.2.3 è°ƒåº¦ç›¸å…³æ£€æŸ¥

```bash
# æ£€æŸ¥èŠ‚ç‚¹å¯è°ƒåº¦æ€§
kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.unschedulable}{"\n"}{end}'

# æ£€æŸ¥èŠ‚ç‚¹æ±¡ç‚¹
kubectl describe node <node-name> | grep -A10 Taints

# æ£€æŸ¥èŠ‚ç‚¹æ ‡ç­¾
kubectl get node <node-name> -o jsonpath='{.metadata.labels}' | jq

# æ£€æŸ¥èŠ‚ç‚¹èµ„æºå®¹é‡å’Œå¯åˆ†é…
kubectl describe node <node-name> | grep -A15 "Capacity:\|Allocatable:"

# æ£€æŸ¥ Pod çš„ nodeSelector
kubectl get pod <pod-name> -o jsonpath='{.spec.nodeSelector}'

# æ£€æŸ¥ Pod çš„äº²å’Œæ€§
kubectl get pod <pod-name> -o jsonpath='{.spec.affinity}' | jq

# æ£€æŸ¥ Pod çš„å®¹å¿
kubectl get pod <pod-name> -o jsonpath='{.spec.tolerations}' | jq
```

#### 2.2.4 é©±é€ç›¸å…³æ£€æŸ¥

```bash
# æŸ¥çœ‹è¢«é©±é€çš„ Pod
kubectl get pods --all-namespaces --field-selector=status.phase=Failed | grep Evicted

# æŸ¥çœ‹é©±é€äº‹ä»¶
kubectl get events --field-selector reason=Evicted

# æ£€æŸ¥ kubelet é©±é€é…ç½®
cat /var/lib/kubelet/config.yaml | grep -A20 eviction
```

### 2.3 æ’æŸ¥æ³¨æ„äº‹é¡¹

| æ³¨æ„äº‹é¡¹ | è¯´æ˜ |
|---------|-----|
| NotReady è¶…æ—¶ | é»˜è®¤ 40s åèŠ‚ç‚¹æ ‡è®°ä¸º NotReady |
| é©±é€ä¿æŠ¤ | è®¾ç½® PodDisruptionBudget é˜²æ­¢è¿‡åº¦é©±é€ |
| ç³»ç»Ÿé¢„ç•™ | kubelet åº”é…ç½® system-reserved å’Œ kube-reserved |
| è½¯é©±é€/ç¡¬é©±é€ | è½¯é©±é€æœ‰å®½é™æœŸï¼Œç¡¬é©±é€ç«‹å³æ‰§è¡Œ |
| ä¼˜å…ˆçº§é©±é€ | ä½ä¼˜å…ˆçº§ Pod å…ˆè¢«é©±é€ |

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šè§£å†³æ–¹æ¡ˆä¸é£é™©æ§åˆ¶

### 3.1 èŠ‚ç‚¹ NotReady é—®é¢˜

#### åœºæ™¯ 1ï¼škubelet æœåŠ¡å¼‚å¸¸

**è§£å†³æ­¥éª¤ï¼š**

```bash
# 1. SSH åˆ°èŠ‚ç‚¹æ£€æŸ¥ kubelet çŠ¶æ€
systemctl status kubelet

# 2. æŸ¥çœ‹ kubelet æ—¥å¿—
journalctl -u kubelet -n 100 --no-pager
journalctl -u kubelet -f  # å®æ—¶æŸ¥çœ‹

# 3. å¸¸è§é—®é¢˜åŠè§£å†³

# é—®é¢˜ A: kubelet é…ç½®é”™è¯¯
cat /var/lib/kubelet/config.yaml
# ä¿®å¤é…ç½®åé‡å¯
systemctl restart kubelet

# é—®é¢˜ B: è¯ä¹¦è¿‡æœŸ
ls -la /var/lib/kubelet/pki/
openssl x509 -in /var/lib/kubelet/pki/kubelet-client-current.pem -noout -enddate
# é‡æ–°åŠ å…¥é›†ç¾¤æˆ–æ‰‹åŠ¨æ›´æ–°è¯ä¹¦

# é—®é¢˜ C: ç£ç›˜ç©ºé—´ä¸è¶³
df -h
# æ¸…ç†ç©ºé—´
crictl rmi --prune
docker system prune -af  # å¦‚æœä½¿ç”¨ Docker
journalctl --vacuum-size=500M

# 4. é‡å¯ kubelet
systemctl restart kubelet

# 5. éªŒè¯èŠ‚ç‚¹çŠ¶æ€
kubectl get node <node-name> -w
```

#### åœºæ™¯ 2ï¼šç½‘ç»œä¸å¯è¾¾

**è§£å†³æ­¥éª¤ï¼š**

```bash
# 1. æ£€æŸ¥èŠ‚ç‚¹ç½‘ç»œ
ping <master-ip>
nc -zv <master-ip> 6443

# 2. æ£€æŸ¥é˜²ç«å¢™è§„åˆ™
iptables -L -n
firewall-cmd --list-all

# 3. æ£€æŸ¥ CNI çŠ¶æ€
ls /etc/cni/net.d/
ls /opt/cni/bin/
kubectl get pods -n kube-system -l k8s-app=calico-node -o wide

# 4. é‡å¯ç½‘ç»œç»„ä»¶
systemctl restart NetworkManager
# æˆ–é‡å¯ CNI Pod
kubectl delete pod -n kube-system -l k8s-app=calico-node --field-selector spec.nodeName=<node>
```

### 3.2 èµ„æºå‹åŠ›é—®é¢˜

#### åœºæ™¯ 1ï¼šå†…å­˜å‹åŠ› (MemoryPressure)

**é—®é¢˜ç°è±¡ï¼š**
```bash
$ kubectl describe node <node>
Conditions:
  MemoryPressure   True
```

**è§£å†³æ­¥éª¤ï¼š**

```bash
# 1. æ£€æŸ¥å†…å­˜ä½¿ç”¨
kubectl top pods --all-namespaces --sort-by=memory | head -20

# 2. åœ¨èŠ‚ç‚¹ä¸Šæ£€æŸ¥
ssh <node>
free -h
ps aux --sort=-%mem | head -20

# 3. æ‰¾å‡ºå†…å­˜å ç”¨é«˜çš„ Pod
kubectl get pods --all-namespaces -o json | jq -r '.items[] | select(.spec.nodeName=="<node>") | "\(.metadata.namespace)/\(.metadata.name)"'

# 4. è§£å†³æ–¹æ¡ˆ

# æ–¹æ¡ˆ A: é©±é€ä½ä¼˜å…ˆçº§ Pod
kubectl delete pod <pod-name> -n <namespace>

# æ–¹æ¡ˆ B: è°ƒæ•´ Pod å†…å­˜é™åˆ¶
kubectl patch deployment <name> --type='json' -p='[
  {"op": "replace", "path": "/spec/template/spec/containers/0/resources/limits/memory", "value": "512Mi"}
]'

# æ–¹æ¡ˆ C: æ¸…ç†ç³»ç»Ÿç¼“å­˜ (ä¸´æ—¶)
sync; echo 3 > /proc/sys/vm/drop_caches

# æ–¹æ¡ˆ D: è°ƒæ•´ kubelet é©±é€é˜ˆå€¼
# /var/lib/kubelet/config.yaml
# evictionHard:
#   memory.available: "500Mi"
# evictionSoft:
#   memory.available: "1Gi"
# evictionSoftGracePeriod:
#   memory.available: "1m"

systemctl restart kubelet
```

#### åœºæ™¯ 2ï¼šç£ç›˜å‹åŠ› (DiskPressure)

**è§£å†³æ­¥éª¤ï¼š**

```bash
# 1. æ£€æŸ¥ç£ç›˜ä½¿ç”¨
df -h
df -i  # inode

# 2. æ‰¾å‡ºå¤§æ–‡ä»¶/ç›®å½•
du -sh /var/log/*
du -sh /var/lib/docker/*  # Docker
du -sh /var/lib/containerd/*  # containerd

# 3. æ¸…ç†æ–¹æ¡ˆ

# æ¸…ç†å®¹å™¨æ—¥å¿—
find /var/log/containers -name "*.log" -mtime +7 -delete
truncate -s 0 /var/log/containers/*.log

# æ¸…ç†æœªä½¿ç”¨çš„é•œåƒ
crictl rmi --prune
# æˆ–
docker system prune -af

# æ¸…ç†å·²å®Œæˆçš„å®¹å™¨
crictl rm $(crictl ps -a -q --state exited)

# æ¸…ç†ç³»ç»Ÿæ—¥å¿—
journalctl --vacuum-size=500M
journalctl --vacuum-time=7d

# 4. è°ƒæ•´ kubelet é©±é€é˜ˆå€¼
# evictionHard:
#   imagefs.available: "15%"
#   nodefs.available: "10%"

# 5. é…ç½®é•œåƒåƒåœ¾å›æ”¶
# imageGCHighThresholdPercent: 85
# imageGCLowThresholdPercent: 80
```

#### åœºæ™¯ 3ï¼šPID å‹åŠ› (PIDPressure)

**è§£å†³æ­¥éª¤ï¼š**

```bash
# 1. æ£€æŸ¥ PID ä½¿ç”¨
cat /proc/sys/kernel/pid_max
ps aux | wc -l

# 2. æ‰¾å‡ºè¿›ç¨‹æ•°å¤šçš„åº”ç”¨
ps aux --sort=-nlwp | head -20

# 3. æ£€æŸ¥å®¹å™¨è¿›ç¨‹
for container in $(crictl ps -q); do
  echo "Container $container: $(crictl exec $container ps aux 2>/dev/null | wc -l) processes"
done

# 4. å¢åŠ ç³»ç»Ÿ PID é™åˆ¶ (ä¸´æ—¶)
echo 65536 > /proc/sys/kernel/pid_max

# 5. æ°¸ä¹…ä¿®æ”¹
echo "kernel.pid_max = 65536" >> /etc/sysctl.conf
sysctl -p

# 6. è°ƒæ•´ kubelet é…ç½®
# podPidsLimit: 4096  # æ¯ä¸ª Pod æœ€å¤§ PID æ•°
```

### 3.3 è°ƒåº¦é—®é¢˜

#### åœºæ™¯ 1ï¼šæ±¡ç‚¹é˜»æ­¢è°ƒåº¦

**é—®é¢˜ç°è±¡ï¼š**
```
Events:
  Warning  FailedScheduling  0/3 nodes are available: 3 node(s) had taints that the pod didn't tolerate
```

**è§£å†³æ­¥éª¤ï¼š**

```bash
# 1. æŸ¥çœ‹èŠ‚ç‚¹æ±¡ç‚¹
kubectl get nodes -o custom-columns=NAME:.metadata.name,TAINTS:.spec.taints

# 2. æŸ¥çœ‹å…·ä½“èŠ‚ç‚¹æ±¡ç‚¹
kubectl describe node <node> | grep -A5 Taints

# 3. æ–¹æ¡ˆ A: ä¸º Pod æ·»åŠ å®¹å¿
kubectl patch deployment <name> --type='json' -p='[
  {"op": "add", "path": "/spec/template/spec/tolerations", "value": [
    {"key": "node-type", "operator": "Equal", "value": "special", "effect": "NoSchedule"}
  ]}
]'

# 4. æ–¹æ¡ˆ B: ç§»é™¤èŠ‚ç‚¹æ±¡ç‚¹
kubectl taint nodes <node> key:NoSchedule-

# 5. å¸¸è§æ±¡ç‚¹å®¹å¿é…ç½®
# tolerations:
# - key: "node-role.kubernetes.io/master"
#   operator: "Exists"
#   effect: "NoSchedule"
# - key: "node.kubernetes.io/not-ready"
#   operator: "Exists"
#   effect: "NoExecute"
#   tolerationSeconds: 300
```

#### åœºæ™¯ 2ï¼šäº²å’Œæ€§å¯¼è‡´æ— æ³•è°ƒåº¦

**é—®é¢˜ç°è±¡ï¼š**
```
Events:
  Warning  FailedScheduling  0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector
```

**è§£å†³æ­¥éª¤ï¼š**

```bash
# 1. æŸ¥çœ‹ Pod çš„ nodeSelector
kubectl get pod <pod-name> -o jsonpath='{.spec.nodeSelector}'

# 2. æŸ¥çœ‹ Pod çš„ nodeAffinity
kubectl get pod <pod-name> -o jsonpath='{.spec.affinity.nodeAffinity}' | jq

# 3. æŸ¥çœ‹èŠ‚ç‚¹æ ‡ç­¾
kubectl get nodes --show-labels

# 4. æ–¹æ¡ˆ A: ä¸ºèŠ‚ç‚¹æ·»åŠ æ‰€éœ€æ ‡ç­¾
kubectl label nodes <node> <key>=<value>

# 5. æ–¹æ¡ˆ B: ä¿®æ”¹ Pod çš„ nodeSelector
kubectl patch deployment <name> --type='json' -p='[
  {"op": "remove", "path": "/spec/template/spec/nodeSelector"}
]'

# 6. æ–¹æ¡ˆ C: ä½¿ç”¨è½¯äº²å’Œæ€§ (preferredDuringScheduling)
# è€Œéç¡¬äº²å’Œæ€§ (requiredDuringScheduling)
```

#### åœºæ™¯ 3ï¼šæ‹“æ‰‘åˆ†å¸ƒçº¦æŸå¯¼è‡´æ— æ³•è°ƒåº¦

**é—®é¢˜ç°è±¡ï¼š**
```
Events:
  Warning  FailedScheduling  doesn't satisfy spreadConstraint
```

**è§£å†³æ­¥éª¤ï¼š**

```bash
# 1. æŸ¥çœ‹ Pod çš„æ‹“æ‰‘çº¦æŸ
kubectl get pod <pod-name> -o jsonpath='{.spec.topologySpreadConstraints}' | jq

# 2. æ£€æŸ¥èŠ‚ç‚¹æ‹“æ‰‘æ ‡ç­¾
kubectl get nodes -L topology.kubernetes.io/zone

# 3. è°ƒæ•´çº¦æŸé…ç½®
# topologySpreadConstraints:
# - maxSkew: 1
#   topologyKey: topology.kubernetes.io/zone
#   whenUnsatisfiable: ScheduleAnyway  # æ”¹ä¸ºè½¯çº¦æŸ
#   labelSelector:
#     matchLabels:
#       app: myapp
```

### 3.4 èŠ‚ç‚¹ç»´æŠ¤æ“ä½œ

#### åœºæ™¯ 1ï¼šå®‰å…¨åœ°ç»´æŠ¤èŠ‚ç‚¹

```bash
# 1. æ ‡è®°èŠ‚ç‚¹ä¸å¯è°ƒåº¦
kubectl cordon <node>

# 2. é©±é€èŠ‚ç‚¹ä¸Šçš„ Pod (ä¼˜é›…)
kubectl drain <node> --ignore-daemonsets --delete-emptydir-data

# 3. å¦‚æœæœ‰ä¸å¯é©±é€çš„ Pod
kubectl drain <node> --ignore-daemonsets --delete-emptydir-data --force

# 4. æ‰§è¡Œç»´æŠ¤æ“ä½œ
# ...

# 5. æ¢å¤èŠ‚ç‚¹
kubectl uncordon <node>

# 6. éªŒè¯
kubectl get nodes
kubectl get pods -o wide | grep <node>
```

#### åœºæ™¯ 2ï¼šå¤„ç†èŠ‚ç‚¹æ•…éšœ

```bash
# 1. å¦‚æœèŠ‚ç‚¹æ°¸ä¹…æ•…éšœï¼Œåˆ é™¤èŠ‚ç‚¹
kubectl delete node <node>

# 2. Pod ä¼šè¢«é‡æ–°è°ƒåº¦ (å¦‚æœæœ‰å‰¯æœ¬æ§åˆ¶å™¨)
kubectl get pods -o wide

# 3. å¼ºåˆ¶åˆ é™¤å¡åœ¨æ•…éšœèŠ‚ç‚¹çš„ Pod
kubectl delete pod <pod-name> --force --grace-period=0

# 4. å¦‚æœèŠ‚ç‚¹æ¢å¤ï¼Œé‡æ–°åŠ å…¥é›†ç¾¤
kubeadm token create --print-join-command
# åœ¨èŠ‚ç‚¹ä¸Šæ‰§è¡Œ join å‘½ä»¤
```

### 3.5 å®Œæ•´çš„èŠ‚ç‚¹è°ƒåº¦é…ç½®ç¤ºä¾‹

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 3
  template:
    spec:
      # èŠ‚ç‚¹é€‰æ‹©å™¨ (ç®€å•åŒ¹é…)
      nodeSelector:
        node-type: worker
        disk: ssd
      
      # èŠ‚ç‚¹äº²å’Œæ€§ (å¤æ‚è§„åˆ™)
      affinity:
        nodeAffinity:
          # ç¡¬äº²å’Œæ€§: å¿…é¡»æ»¡è¶³
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/arch
                operator: In
                values:
                - amd64
          # è½¯äº²å’Œæ€§: ä¼˜å…ˆæ»¡è¶³
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: zone
                operator: In
                values:
                - zone-a
        
        # Pod åäº²å’Œæ€§: åˆ†æ•£éƒ¨ç½²
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: myapp
              topologyKey: kubernetes.io/hostname
      
      # æ‹“æ‰‘åˆ†å¸ƒçº¦æŸ
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: myapp
      
      # æ±¡ç‚¹å®¹å¿
      tolerations:
      - key: "node-role.kubernetes.io/master"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "node.kubernetes.io/not-ready"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 300
      - key: "node.kubernetes.io/unreachable"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 300
      
      containers:
      - name: app
        image: myapp:v1
```

---

### 3.6 èŠ‚ç‚¹å¥åº·æ£€æŸ¥è„šæœ¬

```bash
#!/bin/bash
# èŠ‚ç‚¹å¥åº·æ£€æŸ¥è„šæœ¬

echo "=== Kubernetes Node Health Check ==="

# æ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€
echo -e "\n--- Node Status ---"
kubectl get nodes -o wide

# æ£€æŸ¥èŠ‚ç‚¹æ¡ä»¶
echo -e "\n--- Node Conditions ---"
kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.conditions[?(@.status=="True")].type}{"\n"}{end}'

# æ£€æŸ¥èµ„æºä½¿ç”¨
echo -e "\n--- Node Resources ---"
kubectl top nodes

# æ£€æŸ¥èŠ‚ç‚¹æ±¡ç‚¹
echo -e "\n--- Node Taints ---"
kubectl get nodes -o custom-columns=NAME:.metadata.name,TAINTS:.spec.taints

# æ£€æŸ¥ä¸å¯è°ƒåº¦èŠ‚ç‚¹
echo -e "\n--- Unschedulable Nodes ---"
kubectl get nodes -o jsonpath='{range .items[?(@.spec.unschedulable==true)]}{.metadata.name}{"\n"}{end}'

# æ£€æŸ¥è¢«é©±é€çš„ Pod
echo -e "\n--- Evicted Pods ---"
kubectl get pods --all-namespaces --field-selector=status.phase=Failed | grep Evicted | head -10

echo -e "\n=== Check Complete ==="
```

---

### 3.7 å®‰å…¨ç”Ÿäº§é£é™©æç¤º

| æ“ä½œ | é£é™©ç­‰çº§ | é£é™©è¯´æ˜ | å»ºè®® |
|-----|---------|---------|-----|
| kubectl drain | ä¸­ | Pod è¢«é©±é€ï¼ŒæœåŠ¡çŸ­æš‚ä¸­æ–­ | ç¡®ä¿æœ‰è¶³å¤Ÿå‰¯æœ¬ï¼Œè®¾ç½® PDB |
| kubectl delete node | é«˜ | èŠ‚ç‚¹ä¸Š Pod å˜ä¸º Terminating | å…ˆ drainï¼Œç¡®ä¿ Pod å·²è¿ç§» |
| ç§»é™¤æ±¡ç‚¹ | ä¸­ | å¯èƒ½å¯¼è‡´å¤§é‡ Pod è°ƒåº¦åˆ°èŠ‚ç‚¹ | è¯„ä¼°èŠ‚ç‚¹å®¹é‡ |
| ä¿®æ”¹ kubelet é…ç½® | ä¸­ | éœ€è¦é‡å¯ kubelet | ä½å³°æœŸæ“ä½œ |
| å¼ºåˆ¶é©±é€ | é«˜ | æ•°æ®å¯èƒ½ä¸¢å¤± | ä»…åœ¨å¿…è¦æ—¶ä½¿ç”¨ |
| æ¸…ç†ç³»ç»Ÿç¼“å­˜ | ä½ | çŸ­æš‚æ€§èƒ½ä¸‹é™ | ç›‘æ§ç³»ç»ŸçŠ¶æ€ |

---

## é™„å½•

### å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

```bash
# èŠ‚ç‚¹çŠ¶æ€
kubectl get nodes -o wide
kubectl describe node <node>
kubectl top nodes

# æ±¡ç‚¹ç®¡ç†
kubectl taint nodes <node> key=value:NoSchedule
kubectl taint nodes <node> key:NoSchedule-

# æ ‡ç­¾ç®¡ç†
kubectl label nodes <node> key=value
kubectl label nodes <node> key-

# ç»´æŠ¤æ“ä½œ
kubectl cordon <node>
kubectl drain <node> --ignore-daemonsets
kubectl uncordon <node>

# èµ„æºæ£€æŸ¥
kubectl describe node <node> | grep -A15 "Allocated resources"
kubectl get pods --field-selector spec.nodeName=<node>
```

### ç›¸å…³æ–‡æ¡£

- [kubelet æ•…éšœæ’æŸ¥](./01-kubelet-troubleshooting.md)
- [Scheduler æ•…éšœæ’æŸ¥](../01-control-plane/03-scheduler-troubleshooting.md)
- [èµ„æºé…é¢æ•…éšœæ’æŸ¥](../07-resources-scheduling/01-resources-quota-troubleshooting.md)
- [Pod æ•…éšœæ’æŸ¥](../05-workloads/01-pod-troubleshooting.md)
