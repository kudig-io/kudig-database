# å¯è§‚æµ‹æ€§æ•…éšœæ’æŸ¥æŒ‡å—

> **é€‚ç”¨ç‰ˆæœ¬**: Kubernetes v1.25 - v1.32 | **æœ€åæ›´æ–°**: 2026-02 | **æ–‡æ¡£ç±»å‹**: å…¨æ ˆå¯è§‚æµ‹æ€§ä¿éšœ

## ğŸ‘ï¸ å¯è§‚æµ‹æ€§å¸¸è§é—®é¢˜ä¸å½±å“åˆ†æ

### å¯è§‚æµ‹æ€§æ ¸å¿ƒç»„ä»¶æ•…éšœç°è±¡

| é—®é¢˜ç±»å‹ | å…¸å‹ç°è±¡ | å½±å“ç¨‹åº¦ | ç´§æ€¥çº§åˆ« |
|---------|---------|---------|---------|
| Prometheus æ•°æ®é‡‡é›†å¤±è´¥ | `scrape failed` æŒç»­å‡ºç° | â­â­â­ é«˜ | P0 |
| Grafana ä»ªè¡¨æ¿æ— æ³•åŠ è½½ | `dashboard not found` æˆ–ç©ºç™½é¡µé¢ | â­â­ ä¸­ | P1 |
| Loki æ—¥å¿—æŸ¥è¯¢è¶…æ—¶ | `query timeout` æˆ– `context deadline exceeded` | â­â­â­ é«˜ | P0 |
| Jaeger é“¾è·¯è¿½è¸ªä¸å®Œæ•´ | `trace not found` æˆ– spans ç¼ºå¤± | â­â­ ä¸­ | P1 |
| AlertManager å‘Šè­¦é£æš´ | å¤§é‡é‡å¤å‘Šè­¦æˆ–å‘Šè­¦ä¸¢å¤± | â­â­â­ é«˜ | P0 |
| Metrics Server ä¸å¯ç”¨ | `metrics not available` å¯¼è‡´ HPA å¤±æ•ˆ | â­â­â­ é«˜ | P0 |
| ç›‘æ§æ•°æ®å­˜å‚¨çˆ†æ»¡ | `disk full` æˆ– `retention exceeded` | â­â­â­ é«˜ | P0 |
| å¤šé›†ç¾¤ç›‘æ§æ•°æ®å­¤å²› | è·¨é›†ç¾¤æŒ‡æ ‡æ— æ³•èšåˆæŸ¥è¯¢ | â­â­ ä¸­ | P1 |

### å¯è§‚æµ‹æ€§çŠ¶æ€æ£€æŸ¥å‘½ä»¤

```bash
# Prometheus çŠ¶æ€æ£€æŸ¥
echo "=== Prometheus çŠ¶æ€æ£€æŸ¥ ==="
kubectl get pods -n monitoring -l app=prometheus
kubectl get servicemonitors -A | wc -l
prometheus_url=$(kubectl get svc prometheus-k8s -n monitoring -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}')
curl -s http://$prometheus_url/-/healthy && echo " âœ“ Prometheus å¥åº·" || echo " âœ— Prometheus ä¸å¥åº·"

# Grafana çŠ¶æ€æ£€æŸ¥
echo "=== Grafana çŠ¶æ€æ£€æŸ¥ ==="
kubectl get pods -n monitoring -l app=grafana
grafana_url=$(kubectl get svc grafana -n monitoring -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}')
curl -s http://$grafana_url/api/health && echo " âœ“ Grafana å¥åº·" || echo " âœ— Grafana ä¸å¥åº·"

# Loki çŠ¶æ€æ£€æŸ¥
echo "=== Loki çŠ¶æ€æ£€æŸ¥ ==="
kubectl get pods -n logging -l app=loki
loki_url=$(kubectl get svc loki -n logging -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}')
curl -s http://$loki_url/ready && echo " âœ“ Loki å°±ç»ª" || echo " âœ— Loki æœªå°±ç»ª"

# Jaeger çŠ¶æ€æ£€æŸ¥
echo "=== Jaeger çŠ¶æ€æ£€æŸ¥ ==="
kubectl get pods -n tracing -l app=jaeger
jaeger_query_url=$(kubectl get svc jaeger-query -n tracing -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}')
curl -s http://$jaeger_query_url/api/services && echo " âœ“ Jaeger æŸ¥è¯¢æœåŠ¡æ­£å¸¸" || echo " âœ— Jaeger æŸ¥è¯¢æœåŠ¡å¼‚å¸¸"

# AlertManager çŠ¶æ€æ£€æŸ¥
echo "=== AlertManager çŠ¶æ€æ£€æŸ¥ ==="
kubectl get pods -n monitoring -l app=alertmanager
alertmanager_url=$(kubectl get svc alertmanager-main -n monitoring -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}')
curl -s http://$alertmanager_url/api/v2/status && echo " âœ“ AlertManager æ­£å¸¸" || echo " âœ— AlertManager å¼‚å¸¸"
```

## ğŸ” å¯è§‚æµ‹æ€§é—®é¢˜è¯Šæ–­æ–¹æ³•

### è¯Šæ–­åŸç†è¯´æ˜

å¯è§‚æµ‹æ€§æ•…éšœè¯Šæ–­éœ€è¦ä»æ•°æ®æµå‘çš„è§’åº¦è¿›è¡Œåˆ†æï¼š

1. **æ•°æ®é‡‡é›†å±‚**ï¼šExporterã€ServiceMonitorã€æ¢é’ˆé…ç½®
2. **æ•°æ®å­˜å‚¨å±‚**ï¼šPrometheusã€Lokiã€Jaeger å­˜å‚¨çŠ¶æ€
3. **æ•°æ®æŸ¥è¯¢å±‚**ï¼šGrafanaã€API æŸ¥è¯¢æ€§èƒ½ã€ç¼“å­˜æœºåˆ¶
4. **å‘Šè­¦å¤„ç†å±‚**ï¼šAlertManager è·¯ç”±ã€æŠ‘åˆ¶ã€é™é»˜è§„åˆ™
5. **å¯è§†åŒ–å±‚**ï¼šä»ªè¡¨æ¿é…ç½®ã€æ•°æ®æºè¿æ¥ã€æƒé™è®¾ç½®

### å¯è§‚æµ‹æ€§é—®é¢˜è¯Šæ–­å†³ç­–æ ‘

```
å¯è§‚æµ‹æ€§æ•…éšœ
    â”œâ”€â”€ æ•°æ®é‡‡é›†é—®é¢˜
    â”‚   â”œâ”€â”€ Exporter çŠ¶æ€å¼‚å¸¸
    â”‚   â”œâ”€â”€ ServiceMonitor é…ç½®é”™è¯¯
    â”‚   â”œâ”€â”€ ç½‘ç»œç­–ç•¥é˜»æ­¢é‡‡é›†
    â”‚   â””â”€â”€ ç›®æ ‡æœåŠ¡ä¸å¯è¾¾
    â”œâ”€â”€ æ•°æ®å­˜å‚¨é—®é¢˜
    â”‚   â”œâ”€â”€ å­˜å‚¨ç©ºé—´ä¸è¶³
    â”‚   â”œâ”€â”€ æ•°æ®ä¿ç•™ç­–ç•¥ä¸å½“
    â”‚   â”œâ”€â”€ å­˜å‚¨æ€§èƒ½ç“¶é¢ˆ
    â”‚   â””â”€â”€ æ•°æ®æŸåæˆ–ä¸¢å¤±
    â”œâ”€â”€ æŸ¥è¯¢æ€§èƒ½é—®é¢˜
    â”‚   â”œâ”€â”€ æŸ¥è¯¢è¯­å¥å¤æ‚åº¦è¿‡é«˜
    â”‚   â”œâ”€â”€ ç¼“å­˜å‘½ä¸­ç‡ä½
    â”‚   â”œâ”€â”€ å¹¶å‘æŸ¥è¯¢é™åˆ¶
    â”‚   â””â”€â”€ ç´¢å¼•æ•ˆç‡ä½ä¸‹
    â””â”€â”€ å‘Šè­¦ç®¡ç†é—®é¢˜
        â”œâ”€â”€ å‘Šè­¦è§„åˆ™é…ç½®é”™è¯¯
        â”œâ”€â”€ è·¯ç”±é…ç½®ä¸å½“
        â”œâ”€â”€ æŠ‘åˆ¶è§„åˆ™å†²çª
        â””â”€â”€ é€šçŸ¥æ¸ é“å¤±æ•ˆ
```

### è¯¦ç»†è¯Šæ–­å‘½ä»¤

#### 1. Prometheus æ•…éšœè¯Šæ–­

```bash
#!/bin/bash
# Prometheus æ•…éšœè¯Šæ–­è„šæœ¬

echo "=== Prometheus æ•…éšœè¯Šæ–­ ==="

# 1. Prometheus åŸºç¡€çŠ¶æ€æ£€æŸ¥
echo "1. Prometheus åŸºç¡€çŠ¶æ€æ£€æŸ¥:"
kubectl get pods -n monitoring -l app=prometheus -o wide

# æ£€æŸ¥ Prometheus çŠ¶æ€ç«¯ç‚¹
PROMETHEUS_POD=$(kubectl get pods -n monitoring -l app=prometheus -o name | head -1)
echo "Prometheus çŠ¶æ€æ£€æŸ¥:"
kubectl exec -n monitoring $PROMETHEUS_POD -- wget -qO- http://localhost:9090/-/healthy && echo "âœ“ Healthy" || echo "âœ— Unhealthy"
kubectl exec -n monitoring $PROMETHEUS_POD -- wget -qO- http://localhost:9090/-/ready && echo "âœ“ Ready" || echo "âœ— Not Ready"

# 2. ç›®æ ‡æŠ“å–çŠ¶æ€æ£€æŸ¥
echo "2. ç›®æ ‡æŠ“å–çŠ¶æ€æ£€æŸ¥:"
TARGETS_DATA=$(kubectl exec -n monitoring $PROMETHEUS_POD -- wget -qO- http://localhost:9090/api/v1/targets)
echo "æŠ“å–ç›®æ ‡ç»Ÿè®¡:"
echo "$TARGETS_DATA" | jq -r '.data.activeTargets | group_by(.health) | map({health: .[0].health, count: length})[] | "\(.health): \(.count)"'

# æ£€æŸ¥ä¸å¥åº·çš„æŠ“å–ç›®æ ‡
UNHEALTHY_TARGETS=$(echo "$TARGETS_DATA" | jq -r '.data.activeTargets[] | select(.health != "up") | "\(.scrapeUrl): \(.lastError)"' | head -10)
if [ -n "$UNHEALTHY_TARGETS" ]; then
  echo "ä¸å¥åº·çš„æŠ“å–ç›®æ ‡:"
  echo "$UNHEALTHY_TARGETS"
fi

# 3. è§„åˆ™è¯„ä¼°çŠ¶æ€æ£€æŸ¥
echo "3. è§„åˆ™è¯„ä¼°çŠ¶æ€æ£€æŸ¥:"
RULES_DATA=$(kubectl exec -n monitoring $PROMETHEUS_POD -- wget -qO- http://localhost:9090/api/v1/rules)
echo "å‘Šè­¦è§„åˆ™çŠ¶æ€:"
echo "$RULES_DATA" | jq -r '.data.groups[] | "\(.name): \(.rules | length) rules, \(.rules | map(select(.state == "firing")) | length) firing"'

# 4. å­˜å‚¨å’Œæ€§èƒ½æ£€æŸ¥
echo "4. å­˜å‚¨å’Œæ€§èƒ½æ£€æŸ¥:"
STORAGE_STATS=$(kubectl exec -n monitoring $PROMETHEUS_POD -- wget -qO- http://localhost:9090/api/v1/status/tsdb)
echo "TSDB å­˜å‚¨ç»Ÿè®¡:"
echo "$STORAGE_STATS" | jq -r '
  "ç³»åˆ—æ•°é‡: \(.data.headStats.numSeries)",
  "åŒºå—æ•°é‡: \(.data.blockStats.numBlocks)",
  "é‡‡æ ·ç‡: \(.data.headStats.chunks / .data.headStats.samples * 100)%"
'

# æ£€æŸ¥å­˜å‚¨ä½¿ç”¨æƒ…å†µ
echo "å­˜å‚¨ä½¿ç”¨æƒ…å†µ:"
kubectl exec -n monitoring $PROMETHEUS_POD -- df -h /prometheus

# 5. é…ç½®æ£€æŸ¥
echo "5. é…ç½®æ£€æŸ¥:"
CONFIG_DATA=$(kubectl exec -n monitoring $PROMETHEUS_POD -- wget -qO- http://localhost:9090/api/v1/status/config)
GLOBAL_CONFIG=$(echo "$CONFIG_DATA" | jq -r '.data.yaml' | yq '.global')
echo "å…¨å±€é…ç½®æ‘˜è¦:"
echo "$GLOBAL_CONFIG"

# 6. æ€§èƒ½æŒ‡æ ‡æ£€æŸ¥
echo "6. æ€§èƒ½æŒ‡æ ‡æ£€æŸ¥:"
PERFORMANCE_METRICS=$(kubectl exec -n monitoring $PROMETHEUS_POD -- wget -qO- http://localhost:9090/metrics | grep -E "(prometheus_tsdb_head_series|prometheus_target_scrapes_sample_out_of_bounds_total|prometheus_rule_evaluation_failures_total)")
echo "$PERFORMANCE_METRICS"
```

#### 2. Grafana æ•…éšœè¯Šæ–­

```bash
#!/bin/bash
# Grafana æ•…éšœè¯Šæ–­è„šæœ¬

echo "=== Grafana æ•…éšœè¯Šæ–­ ==="

# 1. Grafana åŸºç¡€çŠ¶æ€æ£€æŸ¥
echo "1. Grafana åŸºç¡€çŠ¶æ€æ£€æŸ¥:"
kubectl get pods -n monitoring -l app=grafana -o wide

GRAFANA_POD=$(kubectl get pods -n monitoring -l app=grafana -o name | head -1)

# 2. æ•°æ®æºè¿æ¥æ£€æŸ¥
echo "2. æ•°æ®æºè¿æ¥æ£€æŸ¥:"
DATASOURCES=$(kubectl exec -n monitoring $GRAFANA_POD -- curl -s http://admin:admin@localhost:3000/api/datasources)
echo "æ•°æ®æºåˆ—è¡¨:"
echo "$DATASOURCES" | jq -r '.[] | "\(.name) (\(.type)): \(.url) - \(.jsonData.httpMethod // "GET")"'

# æ£€æŸ¥æ•°æ®æºå¥åº·çŠ¶æ€
echo "æ•°æ®æºå¥åº·æ£€æŸ¥:"
for datasource in $(echo "$DATASOURCES" | jq -r '.[].id'); do
  HEALTH_STATUS=$(kubectl exec -n monitoring $GRAFANA_POD -- curl -s -X GET http://admin:admin@localhost:3000/api/datasources/$datasource/health)
  DS_NAME=$(echo "$DATASOURCES" | jq -r ".[] | select(.id==$datasource) | .name")
  echo "  $DS_NAME: $(echo "$HEALTH_STATUS" | jq -r '.message')"
done

# 3. ä»ªè¡¨æ¿çŠ¶æ€æ£€æŸ¥
echo "3. ä»ªè¡¨æ¿çŠ¶æ€æ£€æŸ¥:"
DASHBOARDS=$(kubectl exec -n monitoring $GRAFANA_POD -- curl -s http://admin:admin@localhost:3000/api/search)
echo "ä»ªè¡¨æ¿ç»Ÿè®¡:"
echo "$DASHBOARDS" | jq -r 'group_by(.type) | map({type: .[0].type, count: length})[] | "\(.type): \(.count)"'

# æ£€æŸ¥æœ‰é—®é¢˜çš„ä»ªè¡¨æ¿
PROBLEM_DASHBOARDS=$(echo "$DASHBOARDS" | jq -r '.[] | select(.type == "dash-db") | select(.folderTitle == null or .folderTitle == "") | .title')
if [ -n "$PROBLEM_DASHBOARDS" ]; then
  echo "æœªåˆ†ç±»çš„ä»ªè¡¨æ¿:"
  echo "$PROBLEM_DASHBOARDS"
fi

# 4. ç”¨æˆ·å’Œæƒé™æ£€æŸ¥
echo "4. ç”¨æˆ·å’Œæƒé™æ£€æŸ¥:"
USERS=$(kubectl exec -n monitoring $GRAFANA_POD -- curl -s http://admin:admin@localhost:3000/api/users)
echo "ç”¨æˆ·ç»Ÿè®¡:"
echo "$USERS" | jq -r 'length as $total | "æ€»ç”¨æˆ·æ•°: \($total)"'

ADMIN_USERS=$(echo "$USERS" | jq -r '[.[] | select(.isAdmin == true)] | length')
echo "ç®¡ç†å‘˜ç”¨æˆ·æ•°: $ADMIN_USERS"

# 5. æ’ä»¶çŠ¶æ€æ£€æŸ¥
echo "5. æ’ä»¶çŠ¶æ€æ£€æŸ¥:"
PLUGINS=$(kubectl exec -n monitoring $GRAFANA_POD -- curl -s http://admin:admin@localhost:3000/api/plugins)
ENABLED_PLUGINS=$(echo "$PLUGINS" | jq -r '[.[] | select(.enabled == true)] | length')
TOTAL_PLUGINS=$(echo "$PLUGINS" | jq -r 'length')
echo "æ’ä»¶çŠ¶æ€: $ENABLED_PLUGINS/$TOTAL_PLUGINS å·²å¯ç”¨"

# 6. æ€§èƒ½å’Œæ—¥å¿—æ£€æŸ¥
echo "6. æ€§èƒ½å’Œæ—¥å¿—æ£€æŸ¥:"
echo "Grafana æ—¥å¿—æ‘˜è¦ (æœ€è¿‘50è¡Œ):"
kubectl logs -n monitoring $GRAFANA_POD --tail=50 | grep -i -E "(error|warning|failed)" | tail -10

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
echo "å†…å­˜ä½¿ç”¨æƒ…å†µ:"
kubectl top pod -n monitoring $GRAFANA_POD
```

#### 3. Loki æ•…éšœè¯Šæ–­

```bash
#!/bin/bash
# Loki æ•…éšœè¯Šæ–­è„šæœ¬

echo "=== Loki æ•…éšœè¯Šæ–­ ==="

# 1. Loki åŸºç¡€çŠ¶æ€æ£€æŸ¥
echo "1. Loki åŸºç¡€çŠ¶æ€æ£€æŸ¥:"
kubectl get pods -n logging -l app=loki -o wide

LOKI_POD=$(kubectl get pods -n logging -l app=loki -o name | head -1)

# 2. Loki æ„å»ºå™¨å’Œè¯»å–å™¨çŠ¶æ€
echo "2. Loki ç»„ä»¶çŠ¶æ€æ£€æŸ¥:"
kubectl exec -n logging $LOKI_POD -- wget -qO- http://localhost:3100/ready && echo "âœ“ Loki å°±ç»ª" || echo "âœ— Loki æœªå°±ç»ª"
kubectl exec -n logging $LOKI_POD -- wget -qO- http://localhost:3100/metrics | grep -E "(loki_ingester|loki_querier)" | head -10

# 3. æ—¥å¿—æ‘„å…¥æ£€æŸ¥
echo "3. æ—¥å¿—æ‘„å…¥æ£€æŸ¥:"
INGESTER_METRICS=$(kubectl exec -n logging $LOKI_POD -- wget -qO- http://localhost:3100/metrics | grep loki_ingester)
echo "æ‘„å…¥æŒ‡æ ‡:"
echo "$INGESTER_METRICS" | grep -E "(lines_received_total|bytes_received_total)" | head -5

# æ£€æŸ¥æ‘„å…¥é”™è¯¯
INGEST_ERRORS=$(echo "$INGESTER_METRICS" | grep "loki_ingester_chunks_flush_failed_total" | awk '{print $2}')
if [ "$INGEST_ERRORS" != "0" ]; then
  echo "âš  å‘ç°æ‘„å…¥é”™è¯¯: $INGEST_ERRORS"
fi

# 4. æŸ¥è¯¢æ€§èƒ½æ£€æŸ¥
echo "4. æŸ¥è¯¢æ€§èƒ½æ£€æŸ¥:"
QUERY_METRICS=$(kubectl exec -n logging $LOKI_POD -- wget -qO- http://localhost:3100/metrics | grep loki_querier)
echo "æŸ¥è¯¢æŒ‡æ ‡:"
echo "$QUERY_METRICS" | grep -E "(query_duration_seconds|queried_streams)" | head -5

# æ£€æŸ¥æŸ¥è¯¢é”™è¯¯
QUERY_ERRORS=$(echo "$QUERY_METRICS" | grep "loki_querier_query_frontend_errors_total" | awk '{print $2}')
if [ "$QUERY_ERRORS" != "0" ]; then
  echo "âš  å‘ç°æŸ¥è¯¢é”™è¯¯: $QUERY_ERRORS"
fi

# 5. å­˜å‚¨çŠ¶æ€æ£€æŸ¥
echo "5. å­˜å‚¨çŠ¶æ€æ£€æŸ¥:"
STORAGE_METRICS=$(kubectl exec -n logging $LOKI_POD -- wget -qO- http://localhost:3100/metrics | grep loki_storage)
echo "å­˜å‚¨æŒ‡æ ‡:"
echo "$STORAGE_METRICS" | head -10

# æ£€æŸ¥å­˜å‚¨ä½¿ç”¨æƒ…å†µ
echo "å­˜å‚¨ä½¿ç”¨æƒ…å†µ:"
kubectl exec -n logging $LOKI_POD -- df -h /var/loki

# 6. é…ç½®æ£€æŸ¥
echo "6. é…ç½®æ£€æŸ¥:"
CONFIG=$(kubectl exec -n logging $LOKI_POD -- cat /etc/loki/loki.yaml)
echo "ä¿ç•™ç­–ç•¥:"
echo "$CONFIG" | grep -A5 retention_period

echo "å­˜å‚¨é…ç½®:"
echo "$CONFIG" | grep -A10 storage_config

# 7. æ—¥å¿—æµæ£€æŸ¥
echo "7. æ—¥å¿—æµæ£€æŸ¥:"
# æ£€æŸ¥æœ€è¿‘çš„æ—¥å¿—æµ
STREAMS=$(kubectl exec -n logging $LOKI_POD -- wget -qO- "http://localhost:3100/loki/api/v1/series?match[]={job!=\"\"}&start=$(date -d '1 hour ago' +%s)000000000&end=$(date +%s)000000000")
echo "æœ€è¿‘1å°æ—¶å†…çš„æ—¥å¿—æµæ•°é‡:"
echo "$STREAMS" | jq -r '.data | length'
```

#### 4. Jaeger æ•…éšœè¯Šæ–­

```bash
#!/bin/bash
# Jaeger æ•…éšœè¯Šæ–­è„šæœ¬

echo "=== Jaeger æ•…éšœè¯Šæ–­ ==="

# 1. Jaeger ç»„ä»¶çŠ¶æ€æ£€æŸ¥
echo "1. Jaeger ç»„ä»¶çŠ¶æ€æ£€æŸ¥:"
kubectl get pods -n tracing -l app=jaeger -o wide

JAEGER_QUERY_POD=$(kubectl get pods -n tracing -l app=jaeger-component,component=query -o name | head -1)
JAEGER_COLLECTOR_POD=$(kubectl get pods -n tracing -l app=jaeger-component,component=collector -o name | head -1)

# 2. æœåŠ¡å‘ç°æ£€æŸ¥
echo "2. æœåŠ¡å‘ç°æ£€æŸ¥:"
SERVICES=$(kubectl exec -n tracing $JAEGER_QUERY_POD -- wget -qO- http://localhost:16686/api/services)
SERVICE_COUNT=$(echo "$SERVICES" | jq -r '.data | length')
echo "å‘ç°çš„æœåŠ¡æ•°é‡: $SERVICE_COUNT"

if [ $SERVICE_COUNT -lt 5 ]; then
  echo "âš  æœåŠ¡æ•°é‡è¾ƒå°‘ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜"
  echo "æœåŠ¡åˆ—è¡¨:"
  echo "$SERVICES" | jq -r '.data[]'
fi

# 3. è¿½è¸ªæ•°æ®æ£€æŸ¥
echo "3. è¿½è¸ªæ•°æ®æ£€æŸ¥:"
# æ£€æŸ¥æœ€è¿‘1å°æ—¶çš„è¿½è¸ªæ•°æ®
RECENT_TRACES=$(kubectl exec -n tracing $JAEGER_QUERY_POD -- wget -qO- "http://localhost:16686/api/traces?service=jaeger-query&lookback=1h&limit=10")
TRACE_COUNT=$(echo "$RECENT_TRACES" | jq -r '.data | length')
echo "æœ€è¿‘1å°æ—¶è¿½è¸ªæ•°é‡: $TRACE_COUNT"

# 4. Collector çŠ¶æ€æ£€æŸ¥
echo "4. Collector çŠ¶æ€æ£€æŸ¥:"
COLLECTOR_METRICS=$(kubectl exec -n tracing $JAEGER_COLLECTOR_POD -- wget -qO- http://localhost:14269/metrics)
echo "Collector æŒ‡æ ‡æ‘˜è¦:"
echo "$COLLECTOR_METRICS" | grep -E "(spans_received|batch_size|save_latency)" | head -5

# æ£€æŸ¥ Collector é”™è¯¯
COLLECTOR_ERRORS=$(echo "$COLLECTOR_METRICS" | grep " spans_dropped_total " | awk '{print $2}')
if [ "$COLLECTOR_ERRORS" != "0" ]; then
  echo "âš  Collector ä¸¢å¼ƒçš„ spans æ•°é‡: $COLLECTOR_ERRORS"
fi

# 5. å­˜å‚¨åç«¯æ£€æŸ¥
echo "5. å­˜å‚¨åç«¯æ£€æŸ¥:"
# å¦‚æœä½¿ç”¨ Elasticsearch
if kubectl get pods -n tracing -l app=elasticsearch &>/dev/null; then
  ES_POD=$(kubectl get pods -n tracing -l app=elasticsearch -o name | head -1)
  ES_HEALTH=$(kubectl exec -n tracing $ES_POD -- curl -s http://localhost:9200/_cluster/health)
  echo "Elasticsearch é›†ç¾¤çŠ¶æ€:"
  echo "$ES_HEALTH" | jq -r '"çŠ¶æ€: \(.status), èŠ‚ç‚¹æ•°: \(.number_of_nodes), åˆ†ç‰‡æ•°: \(.active_shards)"'
fi

# 6. é‡‡æ ·é…ç½®æ£€æŸ¥
echo "6. é‡‡æ ·é…ç½®æ£€æŸ¥:"
SAMPLING_CONFIG=$(kubectl get configmap jaeger-sampling-strategies -n tracing -o yaml 2>/dev/null)
if [ -n "$SAMPLING_CONFIG" ]; then
  echo "é‡‡æ ·ç­–ç•¥é…ç½®:"
  echo "$SAMPLING_CONFIG" | grep -A20 "default_strategy"
else
  echo "æœªæ‰¾åˆ°é‡‡æ ·é…ç½®"
fi
```

## ğŸ”§ å¯è§‚æµ‹æ€§é—®é¢˜è§£å†³æ–¹æ¡ˆ

### Prometheus é—®é¢˜è§£å†³

#### æ–¹æ¡ˆä¸€ï¼šPrometheus é…ç½®ä¼˜åŒ–

```yaml
# Prometheus ä¼˜åŒ–é…ç½®
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: prometheus
  namespace: monitoring
spec:
  replicas: 2
  retention: 30d
  retentionSize: "50GB"
  ruleSelector:
    matchLabels:
      prometheus: prometheus
  serviceAccountName: prometheus-k8s
  serviceMonitorSelector:
    matchExpressions:
    - key: prometheus
      operator: In
      values:
      - prometheus
  resources:
    requests:
      memory: "2Gi"
      cpu: "1"
    limits:
      memory: "8Gi"
      cpu: "2"
  storage:
    volumeClaimTemplate:
      spec:
        storageClassName: fast-ssd
        resources:
          requests:
            storage: 100Gi
  # æ€§èƒ½ä¼˜åŒ–é…ç½®
  enableAdminAPI: false
  evaluationInterval: 30s
  scrapeInterval: 30s
  scrapeTimeout: 10s
  externalLabels:
    cluster: production
  remoteWrite:
  - url: http://thanos-receive:19291/api/v1/receive
    writeRelabelConfigs:
    - sourceLabels: [__name__]
      regex: '(up|scrape_samples_scraped)'
      action: drop
```

#### æ–¹æ¡ˆäºŒï¼šå‘Šè­¦è§„åˆ™ä¼˜åŒ–

```yaml
# Prometheus å‘Šè­¦è§„åˆ™ä¼˜åŒ–
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: prometheus-rules
  namespace: monitoring
spec:
  groups:
  - name: prometheus.rules
    rules:
    # å‘Šè­¦æŠ‘åˆ¶è§„åˆ™
    - alert: PrometheusTargetMissing
      expr: up == 0
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Prometheus ç›®æ ‡ä¸å¯è¾¾"
        description: "{{ $labels.instance }} ç›®æ ‡åœ¨5åˆ†é’Ÿå†…æŒç»­ä¸å¯è¾¾"
        
    - alert: PrometheusScrapeFailed
      expr: rate(prometheus_target_scrapes_sample_out_of_bounds_total[5m]) > 0.01
      for: 10m
      labels:
        severity: critical
      annotations:
        summary: "Prometheus æŠ“å–å¤±è´¥ç‡è¿‡é«˜"
        description: "æŠ“å–å¤±è´¥ç‡è¶…è¿‡1%ï¼Œå¯èƒ½å½±å“ç›‘æ§æ•°æ®å®Œæ•´æ€§"
        
    - alert: PrometheusStorageFull
      expr: (node_filesystem_avail_bytes{mountpoint="/prometheus"} / node_filesystem_size_bytes{mountpoint="/prometheus"}) * 100 < 10
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Prometheus å­˜å‚¨ç©ºé—´ä¸è¶³"
        description: "Prometheus å­˜å‚¨å‰©ä½™ç©ºé—´å°äº10%"
        
    # æŠ‘åˆ¶è§„åˆ™ç¤ºä¾‹
    - alert: HighMemoryUsage
      expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes * 100) > 90
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "å®¹å™¨å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
        
    - alert: CriticalMemoryUsage
      expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes * 100) > 95
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "å®¹å™¨å†…å­˜ä½¿ç”¨ç‡è¾¾åˆ°ä¸´ç•Œå€¼"
```

### Grafana é—®é¢˜è§£å†³

#### æ–¹æ¡ˆä¸€ï¼šGrafana æ€§èƒ½ä¼˜åŒ–é…ç½®

```yaml
# Grafana æ€§èƒ½ä¼˜åŒ–é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-config
  namespace: monitoring
data:
  grafana.ini: |
    [server]
    domain = grafana.example.com
    root_url = %(protocol)s://%(domain)s:%(http_port)s
    
    [database]
    type = postgres
    host = postgres.monitoring:5432
    name = grafana
    user = grafana
    ssl_mode = disable
    
    [remote_cache]
    type = redis
    connstr = addr=redis.monitoring:6379,pool_size=100,db=0,ssl=false
    
    [dataproxy]
    timeout = 30
    keep_alive_seconds = 300
    send_user_header = false
    
    [panels]
    disable_sanitize_html = false
    
    [plugins]
    enable_alpha = false
    app_tls_skip_verify_insecure = false
    
    [rendering]
    server_url = http://grafana-renderer:8081/render
    callback_url = http://grafana:3000/
    
    [analytics]
    reporting_enabled = false
    check_for_updates = false
    
    [log]
    mode = console
    level = info
    
    [auth.anonymous]
    enabled = false
    
    [users]
    allow_sign_up = false
    auto_assign_org = true
    auto_assign_org_role = Viewer

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:10.2.2
        ports:
        - containerPort: 3000
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-admin-credentials
              key: admin-password
        - name: GF_DATABASE_TYPE
          value: postgres
        - name: GF_DATABASE_HOST
          value: postgres.monitoring:5432
        - name: GF_DATABASE_NAME
          value: grafana
        - name: GF_DATABASE_USER
          value: grafana
        - name: GF_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-db-credentials
              key: password
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        volumeMounts:
        - name: config
          mountPath: /etc/grafana/grafana.ini
          subPath: grafana.ini
        - name: storage
          mountPath: /var/lib/grafana
      volumes:
      - name: config
        configMap:
          name: grafana-config
      - name: storage
        persistentVolumeClaim:
          claimName: grafana-storage
```

#### æ–¹æ¡ˆäºŒï¼šä»ªè¡¨æ¿ä¼˜åŒ–é…ç½®

```json
{
  "dashboard": {
    "id": null,
    "title": "Kubernetes Cluster Overview",
    "timezone": "browser",
    "schemaVersion": 38,
    "version": 1,
    "refresh": "30s",
    "templating": {
      "list": [
        {
          "name": "datasource",
          "type": "datasource",
          "pluginId": "prometheus"
        },
        {
          "name": "cluster",
          "type": "query",
          "datasource": "${datasource}",
          "refresh": 1,
          "query": "label_values(kube_node_info, cluster)"
        }
      ]
    },
    "panels": [
      {
        "type": "graph",
        "title": "Cluster CPU Usage",
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 0
        },
        "targets": [
          {
            "expr": "sum(rate(container_cpu_usage_seconds_total{cluster=\"$cluster\", namespace!=\"\"}[5m])) by (namespace)",
            "legendFormat": "{{namespace}}",
            "refId": "A"
          }
        ],
        "options": {
          "tooltip": {
            "mode": "multi",
            "sort": "desc"
          }
        }
      },
      {
        "type": "stat",
        "title": "Node Status",
        "gridPos": {
          "h": 4,
          "w": 6,
          "x": 12,
          "y": 0
        },
        "targets": [
          {
            "expr": "count(kube_node_status_condition{condition=\"Ready\", status=\"true\", cluster=\"$cluster\"})",
            "refId": "A"
          }
        ],
        "options": {
          "reduceOptions": {
            "calcs": ["lastNotNull"]
          }
        }
      }
    ]
  }
}
```

### Loki é—®é¢˜è§£å†³

#### æ–¹æ¡ˆä¸€ï¼šLoki å­˜å‚¨å’Œæ€§èƒ½ä¼˜åŒ–

```yaml
# Loki ä¼˜åŒ–é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: logging
data:
  loki.yaml: |
    auth_enabled: false
    
    server:
      http_listen_port: 3100
      grpc_listen_port: 9096
    
    common:
      path_prefix: /var/loki
      storage:
        filesystem:
          chunks_directory: /var/loki/chunks
          rules_directory: /var/loki/rules
      replication_factor: 1
      ring:
        kvstore:
          store: inmemory
    
    schema_config:
      configs:
        - from: 2020-05-15
          store: boltdb-shipper
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h
    
    storage_config:
      boltdb_shipper:
        active_index_directory: /var/loki/index
        cache_location: /var/loki/cache
        cache_ttl: 24h
        shared_store: filesystem
      filesystem:
        directory: /var/loki/chunks
    
    chunk_store_config:
      max_look_back_period: 0s
      chunk_cache_config:
        embedded_cache:
          enabled: true
          max_size_mb: 100
    
    table_manager:
      retention_deletes_enabled: true
      retention_period: 168h  # 7å¤©
    
    limits_config:
      ingestion_rate_mb: 10
      ingestion_burst_size_mb: 20
      max_entries_limit_per_query: 10000
      max_streams_matchers_per_query: 1000
      max_concurrent_tail_requests: 10
      split_queries_by_interval: 15m
    
    query_scheduler:
      max_outstanding_requests_per_tenant: 2048
    
    frontend:
      max_outstanding_per_tenant: 2048
      compress_responses: true
      tail_proxy_url: http://loki-canary:3100
    
    query_range:
      split_queries_by_interval: 15m
      parallelise_shardable_queries: true

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki
  namespace: logging
spec:
  serviceName: loki-headless
  replicas: 1
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
    spec:
      containers:
      - name: loki
        image: grafana/loki:2.9.2
        args:
        - "-config.file=/etc/loki/loki.yaml"
        ports:
        - name: http-metrics
          containerPort: 3100
        - name: grpc
          containerPort: 9096
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 45
          timeoutSeconds: 1
        livenessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 45
          timeoutSeconds: 1
        resources:
          requests:
            cpu: "100m"
            memory: "256Mi"
          limits:
            cpu: "2"
            memory: "2Gi"
        volumeMounts:
        - name: config
          mountPath: /etc/loki
        - name: storage
          mountPath: /var/loki
      volumes:
      - name: config
        configMap:
          name: loki-config
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 50Gi
```

#### æ–¹æ¡ˆäºŒï¼šæ—¥å¿—æ”¶é›†ä¼˜åŒ–é…ç½®

```yaml
# Promtail ä¼˜åŒ–é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: logging
data:
  promtail.yaml: |
    server:
      http_listen_port: 9080
      grpc_listen_port: 0
    
    clients:
      - url: http://loki-headless.logging.svc.cluster.local:3100/loki/api/v1/push
    
    positions:
      filename: /var/log/promtail/positions.yaml
    
    scrape_configs:
      - job_name: kubernetes-pods-name
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels:
              - __meta_kubernetes_pod_annotation_promtail_io_scrape
            action: keep
            regex: true
          - source_labels:
              - __meta_kubernetes_pod_label_app
            target_label: app
          - source_labels:
              - __meta_kubernetes_namespace
            target_label: namespace
          - source_labels:
              - __meta_kubernetes_pod_name
            target_label: pod
          - source_labels:
              - __meta_kubernetes_pod_container_name
            target_label: container
          - replacement: /var/log/pods/*$1/*.log
            separator: /
            source_labels:
              - __meta_kubernetes_pod_uid
              - __meta_kubernetes_pod_container_name
            target_label: __path__
    
    limits_config:
      max_streams: 100000
      max_line_size: 1048576
      max_entries_per_query: 10000
    
    tracing:
      enabled: true

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: logging
spec:
  selector:
    matchLabels:
      app: promtail
  template:
    metadata:
      labels:
        app: promtail
    spec:
      serviceAccountName: promtail
      containers:
      - name: promtail
        image: grafana/promtail:2.9.2
        args:
        - "-config.file=/etc/promtail/promtail.yaml"
        env:
        - name: HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        volumeMounts:
        - name: config
          mountPath: /etc/promtail
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: runlogjournal
          mountPath: /run/log/journal
          readOnly: true
        - name: positions
          mountPath: /var/log/promtail
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
      volumes:
      - name: config
        configMap:
          name: promtail-config
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: runlogjournal
        hostPath:
          path: /run/log/journal
      - name: positions
        hostPath:
          path: /var/log/promtail
```

### Jaeger é—®é¢˜è§£å†³

#### æ–¹æ¡ˆä¸€ï¼šJaeger é«˜å¯ç”¨é…ç½®

```yaml
# Jaeger é«˜å¯ç”¨é…ç½®
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: jaeger-prod
  namespace: tracing
spec:
  strategy: production
  collector:
    replicas: 3
    image: jaegertracing/jaeger-collector:1.52
    options:
      collector.queue-size: 2000
      collector.num-workers: 50
      es.server-urls: http://elasticsearch.tracing:9200
      es.username: elastic
      es.password: changeme
      sampling.strategies-file: /etc/jaeger/sampling/sampling.json
    volumeMounts:
    - name: sampling-config
      mountPath: /etc/jaeger/sampling
    resources:
      requests:
        memory: "512Mi"
        cpu: "250m"
      limits:
        memory: "2Gi"
        cpu: "1"
  query:
    replicas: 2
    image: jaegertracing/jaeger-query:1.52
    options:
      query.base-path: /jaeger
      es.server-urls: http://elasticsearch.tracing:9200
      es.username: elastic
      es.password: changeme
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "1Gi"
        cpu: "500m"
  agent:
    strategy: DaemonSet
    image: jaegertracing/jaeger-agent:1.52
    options:
      processor.jaeger-binary.server-host-port: :6832
      processor.jaeger-compact.server-host-port: :6831
      processor.jaeger-thrift.server-host-port: :5775
      reporter.grpc.host-port: jaeger-collector-headless.tracing:14250
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "200m"
  storage:
    type: elasticsearch
    options:
      es:
        server-urls: http://elasticsearch.tracing:9200
        username: elastic
        password: changeme
        use-aliases: true
        create-index-templates: true
  ingress:
    enabled: true
    hosts:
    - jaeger.example.com
    tls:
    - hosts:
      - jaeger.example.com
      secretName: jaeger-tls
  volumeClaimTemplates:
  - metadata:
      name: sampling-config
    spec:
      accessModes: ["ReadOnlyMany"]
      resources:
        requests:
          storage: 1Mi
```

#### æ–¹æ¡ˆäºŒï¼šé‡‡æ ·ç­–ç•¥é…ç½®

```json
{
  "service_strategies": [
    {
      "service": "frontend",
      "type": "probabilistic",
      "param": 0.8,
      "operation_strategies": [
        {
          "operation": "health-check",
          "type": "probabilistic",
          "param": 0.0
        },
        {
          "operation": "/api/login",
          "type": "probabilistic",
          "param": 1.0
        }
      ]
    },
    {
      "service": "backend",
      "type": "ratelimiting",
      "param": 10.0
    }
  ],
  "default_strategy": {
    "type": "probabilistic",
    "param": 0.1,
    "operation_strategies": [
      {
        "operation": "health",
        "type": "probabilistic",
        "param": 0.0
      }
    ]
  }
}
```

## âš ï¸ æ‰§è¡Œé£é™©è¯„ä¼°

| æ“ä½œ | é£é™©ç­‰çº§ | å½±å“è¯„ä¼° | å›æ»šæ–¹æ¡ˆ |
|------|---------|---------|---------|
| Prometheus é…ç½®è°ƒæ•´ | â­â­ ä¸­ | å¯èƒ½å½±å“ç›‘æ§æ•°æ®é‡‡é›† | æ¢å¤åŸé…ç½®æ–‡ä»¶ |
| Grafana æ•°æ®æºå˜æ›´ | â­â­ ä¸­ | å¯èƒ½å½±å“ä»ªè¡¨æ¿æ˜¾ç¤º | æ¢å¤åŸæ•°æ®æºé…ç½® |
| Loki å­˜å‚¨ç­–ç•¥è°ƒæ•´ | â­â­â­ é«˜ | å¯èƒ½å½±å“æ—¥å¿—æ•°æ®å®Œæ•´æ€§ | è°¨æ…æµ‹è¯•ååº”ç”¨ |
| Jaeger é‡‡æ ·ç­–ç•¥ä¿®æ”¹ | â­â­ ä¸­ | å¯èƒ½å½±å“è¿½è¸ªæ•°æ®è¦†ç›–ç‡ | é€æ­¥è°ƒæ•´é‡‡æ ·ç‡ |

## ğŸ“Š å¯è§‚æµ‹æ€§éªŒè¯ä¸ç›‘æ§

### å¯è§‚æµ‹æ€§éªŒè¯è„šæœ¬

```bash
#!/bin/bash
# å¯è§‚æµ‹æ€§éªŒè¯è„šæœ¬

echo "=== å¯è§‚æµ‹æ€§éªŒè¯ ==="

# 1. Prometheus éªŒè¯
echo "1. Prometheus éªŒè¯:"
if kubectl get crd prometheuses.monitoring.coreos.com &>/dev/null; then
  PROMETHEUS_HEALTH=$(kubectl get pods -n monitoring -l app=prometheus -o jsonpath='{.items[*].status.containerStatuses[*].ready}' | tr ' ' '\n' | grep -c true)
  TOTAL_PROMETHEUS=$(kubectl get pods -n monitoring -l app=prometheus --no-headers | wc -l)
  echo "Prometheus å¥åº·çŠ¶æ€: $PROMETHEUS_HEALTH/$TOTAL_PROMETHEUS"
  
  if [ $PROMETHEUS_HEALTH -ne $TOTAL_PROMETHEUS ]; then
    echo "ä¸å¥åº·çš„ Prometheus å®ä¾‹:"
    kubectl get pods -n monitoring -l app=prometheus | grep -v "Running"
  fi
else
  echo "Prometheus æœªéƒ¨ç½²"
fi

# 2. Grafana éªŒè¯
echo "2. Grafana éªŒè¯:"
if kubectl get deploy grafana -n monitoring &>/dev/null; then
  GRAFANA_READY=$(kubectl get deploy grafana -n monitoring -o jsonpath='{.status.readyReplicas}')
  GRAFANA_TOTAL=$(kubectl get deploy grafana -n monitoring -o jsonpath='{.status.replicas}')
  echo "Grafana å°±ç»ªçŠ¶æ€: $GRAFANA_READY/$GRAFANA_TOTAL"
else
  echo "Grafana æœªéƒ¨ç½²"
fi

# 3. Loki éªŒè¯
echo "3. Loki éªŒè¯:"
if kubectl get statefulset loki -n logging &>/dev/null; then
  LOKI_READY=$(kubectl get statefulset loki -n logging -o jsonpath='{.status.readyReplicas}')
  LOKI_TOTAL=$(kubectl get statefulset loki -n logging -o jsonpath='{.status.replicas}')
  echo "Loki å°±ç»ªçŠ¶æ€: $LOKI_READY/$LOKI_TOTAL"
  
  # æµ‹è¯•æ—¥å¿—æ‘„å…¥
  TEST_LOG="{\"timestamp\":\"$(date -Iseconds)\",\"level\":\"info\",\"message\":\"observability test\"}"
  LOKI_URL=$(kubectl get svc loki -n logging -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}')
  curl -s -X POST "http://$LOKI_URL/loki/api/v1/push" \
    -H "Content-Type: application/json" \
    -d "{\"streams\":[{\"stream\":{\"job\":\"test\"},\"values\":[[\"$(date +%s)000000000\",\"$TEST_LOG\"]]}]}" >/dev/null 2>&1 && echo "âœ“ Loki æ—¥å¿—æ‘„å…¥æµ‹è¯•é€šè¿‡" || echo "âœ— Loki æ—¥å¿—æ‘„å…¥æµ‹è¯•å¤±è´¥"
else
  echo "Loki æœªéƒ¨ç½²"
fi

# 4. Jaeger éªŒè¯
echo "4. Jaeger éªŒè¯:"
if kubectl get jaeger jaeger-prod -n tracing &>/dev/null; then
  JAEGER_READY=$(kubectl get pods -n tracing -l app=jaeger -o jsonpath='{.items[*].status.containerStatuses[*].ready}' | tr ' ' '\n' | grep -c true)
  JAEGER_TOTAL=$(kubectl get pods -n tracing -l app=jaeger --no-headers | wc -l)
  echo "Jaeger å°±ç»ªçŠ¶æ€: $JAEGER_READY/$JAEGER_TOTAL"
  
  # æµ‹è¯•è¿½è¸ªæ•°æ®
  JAEGER_QUERY_URL=$(kubectl get svc jaeger-query -n tracing -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}')
  curl -s "http://$JAEGER_QUERY_URL/api/services" | jq -r '.data | length' >/dev/null 2>&1 && echo "âœ“ Jaeger æœåŠ¡å‘ç°æ­£å¸¸" || echo "âœ— Jaeger æœåŠ¡å‘ç°é—®é¢˜"
else
  echo "Jaeger æœªéƒ¨ç½²"
fi

echo "å¯è§‚æµ‹æ€§éªŒè¯å®Œæˆï¼"
```

### å¯è§‚æµ‹æ€§ç›‘æ§å‘Šè­¦é…ç½®

```yaml
# Prometheus å¯è§‚æµ‹æ€§ç›‘æ§å‘Šè­¦
groups:
- name: observability
  rules:
  - alert: PrometheusDown
    expr: absent(up{job="prometheus-k8s"})
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Prometheus å®ä¾‹å®•æœº"
      description: "Prometheus ç›‘æ§å®ä¾‹ä¸å¯ç”¨"

  - alert: GrafanaDown
    expr: absent(up{job="grafana"})
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Grafana å®ä¾‹å®•æœº"
      description: "Grafana å¯è§†åŒ–å®ä¾‹ä¸å¯ç”¨"

  - alert: LokiDown
    expr: absent(up{job="loki"})
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Loki å®ä¾‹å®•æœº"
      description: "Loki æ—¥å¿—æ”¶é›†å®ä¾‹ä¸å¯ç”¨"

  - alert: JaegerCollectorDown
    expr: absent(up{job="jaeger-collector"})
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Jaeger Collector å®•æœº"
      description: "Jaeger è¿½è¸ªæ”¶é›†å™¨ä¸å¯ç”¨"

  - alert: PrometheusStorageLow
    expr: (node_filesystem_free_bytes{mountpoint="/prometheus"} / node_filesystem_size_bytes{mountpoint="/prometheus"}) * 100 < 15
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Prometheus å­˜å‚¨ç©ºé—´ä¸è¶³"
      description: "Prometheus å­˜å‚¨å‰©ä½™ç©ºé—´å°äº15%"

  - alert: LokiHighMemoryUsage
    expr: (container_memory_usage_bytes{container="loki"} / container_spec_memory_limit_bytes{container="loki"}) * 100 > 80
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Loki å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
      description: "Loki å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡80%"

  - alert: GrafanaHighCPUUsage
    expr: rate(container_cpu_usage_seconds_total{container="grafana"}[5m]) > 0.8
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Grafana CPU ä½¿ç”¨ç‡è¿‡é«˜"
      description: "Grafana CPU ä½¿ç”¨ç‡æŒç»­è¶…è¿‡80%"

  - alert: JaegerTraceLoss
    expr: increase(jaeger_collector_spans_dropped_total[5m]) > 100
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Jaeger è¿½è¸ªæ•°æ®ä¸¢å¤±"
      description: "Jaeger Collector ä¸¢å¼ƒçš„ spans æ•°é‡å¼‚å¸¸å¢åŠ "
```

## ğŸ“š å¯è§‚æµ‹æ€§æœ€ä½³å®è·µ

### å¯è§‚æµ‹æ€§æ¶æ„è®¾è®¡

```yaml
# å¯è§‚æµ‹æ€§æ¶æ„æœ€ä½³å®è·µ
observabilityArchitecture:
  monitoring:
    prometheus:
      deployment: "HA with Thanos"
      retention: "90d"
      storage: "Remote write to object storage"
      federation: "Hierarchical federation for multi-cluster"
    
    alerting:
      alertmanager:
        replicas: 3
        clustering: enabled
        receivers:
          - name: "pagerduty"
            pagerduty_configs:
            - service_key: "<pagerduty-key>"
          - name: "slack"
            slack_configs:
            - channel: "#alerts"
              send_resolved: true
    
    visualization:
      grafana:
        replicas: 2
        persistence: enabled
        authentication: "OAuth with OIDC"
        datasources:
          - name: "Prometheus"
            type: "prometheus"
            url: "http://thanos-query:9090"
          - name: "Loki"
            type: "loki"
            url: "http://loki-gateway:80"
          - name: "Jaeger"
            type: "jaeger"
            url: "http://jaeger-query:16686"
  
  logging:
    collection:
      promtail:
        deployment: "DaemonSet"
        scrapeConfigs:
          - job_name: "kubernetes-pods"
            kubernetes_sd_configs:
            - role: pod
            relabel_configs:
            - source_labels: ['__meta_kubernetes_pod_annotation_promtail_io_scrape']
              action: keep
              regex: true
    
    storage:
      loki:
        deployment: "Single binary mode"
        retention: "30d"
        compression: "snappy"
        indexCache: "in-memory"
    
    processing:
      logql:
        optimization:
          - query_splitting: "enabled"
          - parallelization: "enabled"
          - caching: "enabled"
  
  tracing:
    collection:
      jaeger:
        agent: "DaemonSet"
        collector: "Deployment with HPA"
        sampling:
          strategies: "adaptive"
          default_ratio: 0.1
    
    storage:
      backend: "Elasticsearch"
      retention: "7d"
      indices:
        rollover: "daily"
        lifecycle: "ILM policy"
    
    analysis:
      hotrod: "demo application for tracing"
      traceAnalytics: "enabled in Kibana"
```

### å¯è§‚æµ‹æ€§æ•°æ®è´¨é‡ç®¡ç†

```bash
#!/bin/bash
# å¯è§‚æµ‹æ€§æ•°æ®è´¨é‡ç®¡ç†è„šæœ¬

QUALITY_REPORT="/var/log/kubernetes/observability-quality-$(date +%Y%m%d).log"

{
  echo "=== å¯è§‚æµ‹æ€§æ•°æ®è´¨é‡æŠ¥å‘Š $(date) ==="
  
  # 1. ç›‘æ§æ•°æ®è´¨é‡æ£€æŸ¥
  echo "1. ç›‘æ§æ•°æ®è´¨é‡æ£€æŸ¥:"
  
  # æ£€æŸ¥æŒ‡æ ‡å®Œæ•´æ€§
  METRIC_COMPLETENESS=$(kubectl exec -n monitoring prometheus-k8s-0 -- wget -qO- http://localhost:9090/api/v1/query?query=count(up) | jq -r '.data.result[0].value[1]')
  TOTAL_TARGETS=$(kubectl exec -n monitoring prometheus-k8s-0 -- wget -qO- http://localhost:9090/api/v1/targets | jq -r '.data.activeTargets | length')
  COMPLETENESS_RATE=$((METRIC_COMPLETENESS * 100 / TOTAL_TARGETS))
  echo "ç›‘æ§æŒ‡æ ‡å®Œæ•´æ€§: ${COMPLETENESS_RATE}%"
  
  # 2. æ—¥å¿—æ•°æ®è´¨é‡æ£€æŸ¥
  echo "2. æ—¥å¿—æ•°æ®è´¨é‡æ£€æŸ¥:"
  
  # æ£€æŸ¥æ—¥å¿—æ‘„å…¥é€Ÿç‡
  LOG_INGESTION_RATE=$(kubectl exec -n logging loki-0 -- wget -qO- http://localhost:3100/metrics | grep "loki_ingester_lines_received_total" | awk '{print $2}')
  echo "æ—¥å¿—æ‘„å…¥æ€»é‡: $LOG_INGESTION_RATE è¡Œ"
  
  # æ£€æŸ¥é‡å¤æ—¥å¿—
  DUPLICATE_LOGS=$(kubectl exec -n logging loki-0 -- wget -qO- http://localhost:3100/metrics | grep "loki_ingester_duplicate_lines_total" | awk '{print $2}')
  echo "é‡å¤æ—¥å¿—æ•°é‡: $DUPLICATE_LOGS"
  
  # 3. è¿½è¸ªæ•°æ®è´¨é‡æ£€æŸ¥
  echo "3. è¿½è¸ªæ•°æ®è´¨é‡æ£€æŸ¥:"
  
  # æ£€æŸ¥è¿½è¸ªè·¨åº¦
  TRACE_SPANS=$(kubectl exec -n tracing jaeger-collector-0 -- wget -qO- http://localhost:14269/metrics | grep "jaeger_collector_spans_received_total" | awk '{print $2}')
  echo "æ¥æ”¶çš„è¿½è¸ªè·¨åº¦: $TRACE_SPANS"
  
  # æ£€æŸ¥é‡‡æ ·ç‡
  SAMPLED_TRACES=$(kubectl exec -n tracing jaeger-collector-0 -- wget -qO- http://localhost:14269/metrics | grep "jaeger_collector_traces_saved_total" | awk '{print $2}')
  if [ "$TRACE_SPANS" != "0" ]; then
    SAMPLING_RATE=$((SAMPLED_TRACES * 100 / TRACE_SPANS))
    echo "è¿½è¸ªé‡‡æ ·ç‡: ${SAMPLING_RATE}%"
  fi
  
  # 4. å­˜å‚¨ä½¿ç”¨æ•ˆç‡æ£€æŸ¥
  echo "4. å­˜å‚¨ä½¿ç”¨æ•ˆç‡æ£€æŸ¥:"
  
  # Prometheus å­˜å‚¨æ•ˆç‡
  PROM_STORAGE=$(kubectl exec -n monitoring prometheus-k8s-0 -- df /prometheus | tail -1 | awk '{print $5}' | sed 's/%//')
  echo "Prometheus å­˜å‚¨ä½¿ç”¨ç‡: ${PROM_STORAGE}%"
  
  # Loki å­˜å‚¨æ•ˆç‡
  LOKI_STORAGE=$(kubectl exec -n logging loki-0 -- df /var/loki | tail -1 | awk '{print $5}' | sed 's/%//')
  echo "Loki å­˜å‚¨ä½¿ç”¨ç‡: ${LOKI_STORAGE}%"
  
} >> "$QUALITY_REPORT"

echo "å¯è§‚æµ‹æ€§æ•°æ®è´¨é‡æŠ¥å‘Šå·²ç”Ÿæˆ: $QUALITY_REPORT"
```

## ğŸ”„ å…¸å‹å¯è§‚æµ‹æ€§æ•…éšœæ¡ˆä¾‹

### æ¡ˆä¾‹ä¸€ï¼šPrometheus æ•°æ®å­˜å‚¨çˆ†æ»¡

**é—®é¢˜æè¿°**ï¼šPrometheus å®ä¾‹ç£ç›˜ç©ºé—´è€—å°½ï¼Œå¯¼è‡´æ•°æ®æ— æ³•å†™å…¥ï¼Œç›‘æ§å‘Šè­¦å¤±æ•ˆã€‚

**æ ¹æœ¬åŸå› **ï¼šæ•°æ®ä¿ç•™æ—¶é—´è®¾ç½®è¿‡é•¿ï¼ŒåŠ ä¸Šé«˜åŸºæ•°æŒ‡æ ‡å¯¼è‡´å­˜å‚¨å¿«é€Ÿå¢é•¿ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. è°ƒæ•´æ•°æ®ä¿ç•™ç­–ç•¥ï¼Œç¼©çŸ­ä¿ç•™æ—¶é—´
2. ä¼˜åŒ–æŒ‡æ ‡æŠ“å–é…ç½®ï¼Œå‡å°‘é«˜åŸºæ•°æŒ‡æ ‡
3. å¯ç”¨è¿œç¨‹å†™å…¥ï¼Œå°†å†å²æ•°æ®å½’æ¡£åˆ°é•¿æœŸå­˜å‚¨
4. å®æ–½å­˜å‚¨å®¹é‡ç›‘æ§å’Œé¢„è­¦æœºåˆ¶

### æ¡ˆä¾‹äºŒï¼šGrafana æŸ¥è¯¢æ€§èƒ½ä¸‹é™

**é—®é¢˜æè¿°**ï¼šGrafana ä»ªè¡¨æ¿åŠ è½½ç¼“æ…¢ï¼Œå¤æ‚æŸ¥è¯¢ç»å¸¸è¶…æ—¶ã€‚

**æ ¹æœ¬åŸå› **ï¼šæ•°æ®æºè¿æ¥é…ç½®ä¸å½“ï¼Œç¼ºä¹æŸ¥è¯¢ç¼“å­˜ï¼Œä»ªè¡¨æ¿è®¾è®¡ä¸åˆç†ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ä¼˜åŒ–æ•°æ®æºè¿æ¥æ± é…ç½®
2. å¯ç”¨æŸ¥è¯¢ç»“æœç¼“å­˜
3. é‡æ„å¤æ‚ä»ªè¡¨æ¿ï¼Œåˆ†è§£æŸ¥è¯¢
4. å®æ–½æŸ¥è¯¢æ€§èƒ½ç›‘æ§

## ğŸ“ å¯è§‚æµ‹æ€§æ”¯æŒèµ„æº

**å®˜æ–¹æ–‡æ¡£**ï¼š
- Prometheus: https://prometheus.io/docs/
- Grafana: https://grafana.com/docs/
- Loki: https://grafana.com/docs/loki/latest/
- Jaeger: https://www.jaegertracing.io/docs/

**ç¤¾åŒºæ”¯æŒ**ï¼š
- CNCF Observability TAG: https://github.com/cncf/tag-observability
- Prometheus ç¤¾åŒº: https://prometheus.io/community/
- Grafana ç¤¾åŒº: https://community.grafana.com/