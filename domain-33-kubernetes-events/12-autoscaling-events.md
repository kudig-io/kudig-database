# 12 - è‡ªåŠ¨æ‰©ç¼©å®¹äº‹ä»¶ (HPA / VPA / Cluster Autoscaler)

> **é€‚ç”¨ç‰ˆæœ¬**: Kubernetes v1.25 - v1.32 | **æœ€åæ›´æ–°**: 2026-02 | **ä½œè€…**: Allen Galler

> **æœ¬æ–‡æ¡£è¯¦ç»†è®°å½• HPAã€VPA å’Œ Cluster Autoscaler äº§ç”Ÿçš„æ‰€æœ‰è‡ªåŠ¨æ‰©ç¼©å®¹ç›¸å…³äº‹ä»¶ã€‚**

---

## ğŸ“‹ ç›®å½•

- [äº‹ä»¶æ€»è§ˆ](#äº‹ä»¶æ€»è§ˆ)
- [HPA äº‹ä»¶è¯¦è§£](#hpa-äº‹ä»¶è¯¦è§£)
- [VPA äº‹ä»¶è¯¦è§£](#vpa-äº‹ä»¶è¯¦è§£)
- [Cluster Autoscaler äº‹ä»¶è¯¦è§£](#cluster-autoscaler-äº‹ä»¶è¯¦è§£)
- [HPA å†³ç­–ç®—æ³•](#hpa-å†³ç­–ç®—æ³•)
- [VPA å·¥ä½œæ¨¡å¼](#vpa-å·¥ä½œæ¨¡å¼)
- [CA æ‰©ç¼©å®¹å†³ç­–é€»è¾‘](#ca-æ‰©ç¼©å®¹å†³ç­–é€»è¾‘)
- [Behavior è¡Œä¸ºé…ç½®](#behavior-è¡Œä¸ºé…ç½®)
- [æ•…éšœæ’æŸ¥åœºæ™¯](#æ•…éšœæ’æŸ¥åœºæ™¯)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## äº‹ä»¶æ€»è§ˆ

### äº‹ä»¶ç»Ÿè®¡è¡¨

| ç»„ä»¶ | äº‹ä»¶ç±»å‹ | äº‹ä»¶æ•°é‡ | ä¸»è¦ç”¨é€” |
|------|---------|---------|---------|
| **HPA** | Normal | 5 | æ‰©ç¼©å®¹æˆåŠŸã€è®¡ç®—å®Œæˆ |
| | Warning | 11 | æŒ‡æ ‡è·å–å¤±è´¥ã€è®¡ç®—é”™è¯¯ |
| **VPA** | Normal | 3 | é©±é€ Podã€æä¾›å»ºè®®ã€æ›´æ–°æ£€æŸ¥ç‚¹ |
| | Warning | 1 | æ›´æ–°å¤±è´¥ |
| **Cluster Autoscaler** | Normal | 5 | èŠ‚ç‚¹æ‰©ç¼©å®¹æˆåŠŸ |
| | Warning | 3 | æ‰©ç¼©å®¹å¤±è´¥ |
| **æ€»è®¡** | - | **28** | è‡ªåŠ¨æ‰©ç¼©å®¹å…¨ç”Ÿå‘½å‘¨æœŸ |

### äº‹ä»¶é¢‘ç‡åˆ†çº§

| é¢‘ç‡çº§åˆ« | äº‹ä»¶æ•°é‡ | ä»£è¡¨äº‹ä»¶ |
|---------|---------|---------|
| **é«˜é¢‘** (æ¯æ¬¡æ‰©ç¼©å®¹) | 3 | SuccessfulRescale, DesiredReplicasComputed, AbleToScale |
| **ä¸­é¢‘** (å®šæœŸè§¦å‘) | 7 | FailedGetResourceMetric, ReadyForNewScale, TriggeredScaleUp |
| **ä½é¢‘** (å¼‚å¸¸/ç‰¹æ®Š) | 13 | FailedRescale, EvictedByVPA, ScaleDownFailed |
| **ç½•è§** (é…ç½®é”™è¯¯) | 5 | InvalidMetricSourceType, InvalidSelector |

---

## HPA äº‹ä»¶è¯¦è§£

### 1. SuccessfulRescale

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: SuccessfulRescale
ç±»å‹: Normal
å¼•å…¥ç‰ˆæœ¬: v1.1+
ç»„ä»¶: horizontal-pod-autoscaler
é¢‘ç‡: é«˜é¢‘ (æ¯æ¬¡æ‰©ç¼©å®¹æˆåŠŸ)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Normal
Reason: SuccessfulRescale
Message: New size: 5; reason: cpu resource utilization (percentage of request) above target
Age: 30s
From: horizontal-pod-autoscaler
```

**è§¦å‘æ¡ä»¶**
- HPA æˆåŠŸæ›´æ”¹ Deployment/ReplicaSet çš„å‰¯æœ¬æ•°
- æŒ‡æ ‡æ»¡è¶³æ‰©ç¼©å®¹æ¡ä»¶
- Scale æ“ä½œæ‰§è¡ŒæˆåŠŸ

**ç¤ºä¾‹åœºæ™¯**

**åœºæ™¯ 1: CPU ä½¿ç”¨ç‡è¶…è¿‡ç›®æ ‡è§¦å‘æ‰©å®¹**
```bash
# æŸ¥çœ‹ HPA äº‹ä»¶
kubectl describe hpa web-app

Events:
  Type    Reason             Age   Message
  ----    ------             ----  -------
  Normal  SuccessfulRescale  45s   New size: 5; reason: cpu resource utilization (percentage of request) above target
```

**åœºæ™¯ 2: è‡ªå®šä¹‰æŒ‡æ ‡è§¦å‘æ‰©å®¹**
```bash
Events:
  Normal  SuccessfulRescale  1m    New size: 8; reason: http_requests_per_second above target
```

**æ’æŸ¥å»ºè®®**
âœ… **æ­£å¸¸äº‹ä»¶** - ç¡®è®¤æ‰©ç¼©å®¹ç¬¦åˆé¢„æœŸ
- æ£€æŸ¥æ–°å‰¯æœ¬æ•°æ˜¯å¦åˆç†
- éªŒè¯æŒ‡æ ‡è¶‹åŠ¿æ˜¯å¦ç¨³å®š
- ç›‘æ§èµ„æºä½¿ç”¨æƒ…å†µ

**ç›¸å…³é…ç½®**
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-app
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

---

### 2. FailedRescale

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: FailedRescale
ç±»å‹: Warning
å¼•å…¥ç‰ˆæœ¬: v1.1+
ç»„ä»¶: horizontal-pod-autoscaler
é¢‘ç‡: ä½é¢‘ (æ‰©ç¼©å®¹å¤±è´¥)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Warning
Reason: FailedRescale
Message: New size: 8; reason: failed to update deployment.apps/web-app scale: Operation cannot be fulfilled
Age: 15s
From: horizontal-pod-autoscaler
```

**è§¦å‘æ¡ä»¶**
- HPA è®¡ç®—å‡ºæ–°å‰¯æœ¬æ•°ï¼Œä½† Scale æ“ä½œå¤±è´¥
- API Server è¿”å›é”™è¯¯
- èµ„æºå†²çªæˆ–é™åˆ¶

**å¸¸è§åŸå› **

**åŸå›  1: èµ„æºé…é¢é™åˆ¶**
```bash
# æ£€æŸ¥ ResourceQuota
kubectl get resourcequota -n production

NAME            CREATED AT
compute-quota   2026-02-01T10:00:00Z

kubectl describe resourcequota compute-quota

Status:
  Hard:
    requests.cpu: 100
    requests.memory: 200Gi
    pods: 50  # è¾¾åˆ°ä¸Šé™
  Used:
    pods: 50
```

**åŸå›  2: PodDisruptionBudget é˜»æ­¢ç¼©å®¹**
```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: web-app-pdb
spec:
  minAvailable: 5
  selector:
    matchLabels:
      app: web-app
# å¦‚æœå½“å‰æœ‰ 5 ä¸ª Podï¼ŒHPA æ— æ³•ç¼©å®¹åˆ° 3
```

**åŸå›  3: Deployment å¹¶å‘æ›´æ–°å†²çª**
```bash
Events:
  Warning  FailedRescale  10s  the object has been modified; please apply your changes to the latest version
```

**æ’æŸ¥æ­¥éª¤**
```bash
# 1. æ£€æŸ¥ HPA çŠ¶æ€
kubectl get hpa web-app -o yaml | grep -A 10 conditions

# 2. æ£€æŸ¥ç›®æ ‡èµ„æºçŠ¶æ€
kubectl get deployment web-app -o yaml | grep -A 5 status

# 3. æŸ¥çœ‹ API Server æ—¥å¿—
kubectl logs -n kube-system kube-apiserver-master-1 | grep "web-app"

# 4. æ£€æŸ¥ ResourceQuota
kubectl describe resourcequota -n production
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# æ–¹æ¡ˆ 1: è°ƒæ•´ ResourceQuota
kubectl edit resourcequota compute-quota
# å¢åŠ  pods é™åˆ¶

# æ–¹æ¡ˆ 2: è°ƒæ•´ PDB
kubectl edit pdb web-app-pdb
# é™ä½ minAvailable

# æ–¹æ¡ˆ 3: ç­‰å¾…å¹¶å‘å†²çªè§£å†³
# HPA ä¼šè‡ªåŠ¨é‡è¯•
```

---

### 3. DesiredReplicasComputed

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: DesiredReplicasComputed
ç±»å‹: Normal
å¼•å…¥ç‰ˆæœ¬: v1.1+
ç»„ä»¶: horizontal-pod-autoscaler
é¢‘ç‡: é«˜é¢‘ (æ¯ä¸ªè¯„ä¼°å‘¨æœŸ)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Normal
Reason: DesiredReplicasComputed
Message: Computed desired replicas: 8 (from current 5, based on cpu utilization: 85%)
Age: 1m
From: horizontal-pod-autoscaler
```

**è§¦å‘æ¡ä»¶**
- HPA å®Œæˆä¸€æ¬¡æŒ‡æ ‡è¯„ä¼°
- è®¡ç®—å‡ºæœŸæœ›å‰¯æœ¬æ•°
- æ— è®ºæ˜¯å¦æ‰§è¡Œæ‰©ç¼©å®¹

**ç®—æ³•è¯´æ˜**
```
desiredReplicas = ceil[currentReplicas * (currentMetricValue / targetMetricValue)]

ç¤ºä¾‹:
currentReplicas = 5
currentMetricValue = 85% (CPU ä½¿ç”¨ç‡)
targetMetricValue = 70%

desiredReplicas = ceil[5 * (85 / 70)] = ceil[6.07] = 7
```

**ç¤ºä¾‹åœºæ™¯**

**åœºæ™¯ 1: è®¡ç®—åæ— éœ€æ‰©ç¼©å®¹**
```bash
Events:
  Normal  DesiredReplicasComputed  30s  Computed desired replicas: 5 (current 5, cpu: 68%)
  # 68% < 70%ï¼Œæ— éœ€æ‰©å®¹
```

**åœºæ™¯ 2: è®¡ç®—åéœ€è¦æ‰©å®¹**
```bash
Events:
  Normal  DesiredReplicasComputed  45s  Computed desired replicas: 8 (current 5, cpu: 95%)
  Normal  AbleToScale              44s  Recommended replicas: 8
  Normal  SuccessfulRescale        43s  New size: 8
```

**è°ƒè¯•ä¿¡æ¯**
```bash
# æŸ¥çœ‹è¯¦ç»†è®¡ç®—è¿‡ç¨‹
kubectl get hpa web-app -o yaml

status:
  currentMetrics:
  - type: Resource
    resource:
      name: cpu
      current:
        averageUtilization: 85
        averageValue: 850m
  desiredReplicas: 8
  currentReplicas: 5
```

---

### 4. FailedGetResourceMetric

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: FailedGetResourceMetric
ç±»å‹: Warning
å¼•å…¥ç‰ˆæœ¬: v1.6+
ç»„ä»¶: horizontal-pod-autoscaler
é¢‘ç‡: ä¸­é¢‘ (æŒ‡æ ‡è·å–å¤±è´¥)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Warning
Reason: FailedGetResourceMetric
Message: failed to get cpu utilization: unable to get metrics for resource cpu: no metrics returned from resource metrics API
Age: 30s
From: horizontal-pod-autoscaler
```

**è§¦å‘æ¡ä»¶**
- æ— æ³•ä» Metrics Server è·å–èµ„æºæŒ‡æ ‡
- Metrics Server ä¸å¯ç”¨
- Pod æœªå®šä¹‰ resource requests

**å¸¸è§åŸå› **

**åŸå›  1: Metrics Server æœªå®‰è£…æˆ–ä¸å¯ç”¨**
```bash
# æ£€æŸ¥ Metrics Server
kubectl get deployment metrics-server -n kube-system

Error: deployments.apps "metrics-server" not found

# å®‰è£… Metrics Server
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

**åŸå›  2: Pod æœªå®šä¹‰ resources.requests**
```yaml
# é”™è¯¯é…ç½® - ç¼ºå°‘ resources.requests
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  template:
    spec:
      containers:
      - name: app
        image: nginx:1.21
        # ç¼ºå°‘ resources å®šä¹‰ï¼

---
# æ­£ç¡®é…ç½®
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  template:
    spec:
      containers:
      - name: app
        image: nginx:1.21
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
```

**åŸå›  3: Metrics Server API å¼‚å¸¸**
```bash
# æ£€æŸ¥ Metrics Server æ—¥å¿—
kubectl logs -n kube-system deployment/metrics-server

E0210 10:15:30.123456       1 manager.go:111] unable to fully collect metrics: [unable to fully scrape metrics from source kubelet_summary:node1: unable to fetch metrics from Kubelet node1 (node1): Get "https://node1:10250/stats/summary?only_cpu_and_memory=true": x509: certificate signed by unknown authority]
```

**æ’æŸ¥æ­¥éª¤**
```bash
# 1. æ£€æŸ¥ Metrics Server çŠ¶æ€
kubectl get apiservice v1beta1.metrics.k8s.io
NAME                     SERVICE                      AVAILABLE   AGE
v1beta1.metrics.k8s.io   kube-system/metrics-server   True        30d

# 2. æµ‹è¯•æŒ‡æ ‡è·å–
kubectl top nodes
kubectl top pods -n production

# 3. æ£€æŸ¥ Pod resources å®šä¹‰
kubectl get deployment web-app -o yaml | grep -A 10 resources

# 4. æŸ¥çœ‹ HPA çŠ¶æ€
kubectl get hpa web-app -o yaml | grep -A 20 conditions
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# æ–¹æ¡ˆ 1: ä¿®å¤ Metrics Server
kubectl edit deployment metrics-server -n kube-system
# æ·»åŠ  --kubelet-insecure-tls å‚æ•°

# æ–¹æ¡ˆ 2: æ·»åŠ  resources.requests
kubectl set resources deployment web-app --requests=cpu=100m,memory=128Mi

# æ–¹æ¡ˆ 3: é‡å¯ Metrics Server
kubectl rollout restart deployment metrics-server -n kube-system
```

---

### 5. FailedComputeMetricsReplicas

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: FailedComputeMetricsReplicas
ç±»å‹: Warning
å¼•å…¥ç‰ˆæœ¬: v1.6+
ç»„ä»¶: horizontal-pod-autoscaler
é¢‘ç‡: ä½é¢‘ (è®¡ç®—é”™è¯¯)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Warning
Reason: FailedComputeMetricsReplicas
Message: failed to compute desired number of replicas based on listed metrics for Deployment/web-app: invalid metrics (1 invalid out of 2); first error is: failed to get cpu utilization: missing request for cpu
Age: 1m
From: horizontal-pod-autoscaler
```

**è§¦å‘æ¡ä»¶**
- å¤šä¸ªæŒ‡æ ‡ä¸­éƒ¨åˆ†å¤±è´¥
- æŒ‡æ ‡æ•°æ®ä¸å®Œæ•´æˆ–æ— æ•ˆ
- è®¡ç®—è¿‡ç¨‹å‡ºç°é”™è¯¯

**å¸¸è§åœºæ™¯**
```yaml
# åœºæ™¯: å¤šæŒ‡æ ‡ HPAï¼Œéƒ¨åˆ†æŒ‡æ ‡å¤±è´¥
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-app
spec:
  metrics:
  - type: Resource
    resource:
      name: cpu  # æˆåŠŸ
      target:
        type: Utilization
        averageUtilization: 70
  - type: Pods
    pods:
      metric:
        name: http_requests  # å¤±è´¥ - æŒ‡æ ‡ä¸å­˜åœ¨
      target:
        type: AverageValue
        averageValue: "1000"
```

**æ’æŸ¥å»ºè®®**
```bash
# æ£€æŸ¥æ¯ä¸ªæŒ‡æ ‡æº
kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespaces/production/pods
kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1/namespaces/production/pods/*/http_requests
```

---

### 6-9. æŒ‡æ ‡è·å–å¤±è´¥äº‹ä»¶

**FailedGetExternalMetric (v1.10+)**
```
Type: Warning
Reason: FailedGetExternalMetric
Message: failed to get external metric cloudwatch-sqs-queue-depth: unable to fetch metrics from external metrics API
```

**FailedGetObjectMetric (v1.6+)**
```
Type: Warning
Reason: FailedGetObjectMetric
Message: failed to get object metric: unable to get metric ingress_requests_per_second for Ingress/web-ingress
```

**FailedGetPodsMetric (v1.6+)**
```
Type: Warning
Reason: FailedGetPodsMetric
Message: failed to get pods metric: unable to get metric http_requests for selector app=web
```

**æ’æŸ¥é‡ç‚¹**
- æ£€æŸ¥ Custom Metrics API / External Metrics API æ˜¯å¦éƒ¨ç½²
- éªŒè¯ Prometheus Adapter / Datadog Cluster Agent ç­‰é€‚é…å™¨é…ç½®
- ç¡®è®¤æŒ‡æ ‡åç§°å’Œé€‰æ‹©å™¨æ­£ç¡®

---

### 10-13. é…ç½®é”™è¯¯äº‹ä»¶

**InvalidMetricSourceType (v1.6+)**
```
Type: Warning
Reason: InvalidMetricSourceType
Message: invalid metric source type: Object
```

**InvalidSelector (v1.6+)**
```
Type: Warning
Reason: InvalidSelector
Message: invalid selector: unable to parse selector
```

**FailedUpdateStatus (v1.1+)**
```
Type: Warning
Reason: FailedUpdateStatus
Message: failed to update status: the server could not find the requested resource
```

**FailedGetScale (v1.1+)**
```
Type: Warning
Reason: FailedGetScale
Message: failed to get scale subresource: deployments.apps "web-app" not found
```

---

### 14. AbleToScale

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: AbleToScale
ç±»å‹: Normal
å¼•å…¥ç‰ˆæœ¬: v1.23+
ç»„ä»¶: horizontal-pod-autoscaler
é¢‘ç‡: é«˜é¢‘ (æ¯æ¬¡å‡†å¤‡æ‰©ç¼©å®¹)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Normal
Reason: AbleToScale
Message: the HPA controller was able to get the target's current scale
Age: 30s
From: horizontal-pod-autoscaler
```

**è§¦å‘æ¡ä»¶**
- HPA æˆåŠŸè·å–ç›®æ ‡èµ„æºçš„ scale å­èµ„æº
- å‡†å¤‡æ‰§è¡Œæ‰©ç¼©å®¹è¯„ä¼°

**ç¤ºä¾‹**
```bash
Events:
  Normal  AbleToScale              1m   the HPA controller was able to get the target's current scale
  Normal  DesiredReplicasComputed  1m   Computed desired replicas: 8
  Normal  SuccessfulRescale        59s  New size: 8
```

---

### 15. ReadyForNewScale

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: ReadyForNewScale
ç±»å‹: Normal
å¼•å…¥ç‰ˆæœ¬: v1.23+
ç»„ä»¶: horizontal-pod-autoscaler
é¢‘ç‡: ä¸­é¢‘ (å†·å´æœŸå)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Normal
Reason: ReadyForNewScale
Message: recommended size matches current size
Age: 2m
From: horizontal-pod-autoscaler
```

**è§¦å‘æ¡ä»¶**
- ä¸Šæ¬¡æ‰©ç¼©å®¹çš„å†·å´æœŸå·²è¿‡
- HPA å¯ä»¥æ‰§è¡Œæ–°çš„æ‰©ç¼©å®¹æ“ä½œ

**å†·å´æœŸè¯´æ˜**
```yaml
# v1.23+ behavior é…ç½®
spec:
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # ç¼©å®¹å†·å´æœŸ 5 åˆ†é’Ÿ
    scaleUp:
      stabilizationWindowSeconds: 0    # æ‰©å®¹æ— å†·å´æœŸ
```

---

### 16. ScaleDownStabilized

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: ScaleDownStabilized
ç±»å‹: Normal
å¼•å…¥ç‰ˆæœ¬: v1.17+
ç»„ä»¶: horizontal-pod-autoscaler
é¢‘ç‡: ä¸­é¢‘ (ç¼©å®¹ç¨³å®šæœŸ)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Normal
Reason: ScaleDownStabilized
Message: recent recommendations were higher than current one, skipping the scale down
Age: 1m
From: horizontal-pod-autoscaler
```

**è§¦å‘æ¡ä»¶**
- è®¡ç®—å‡ºçš„å‰¯æœ¬æ•°å°äºå½“å‰å€¼ï¼ˆéœ€è¦ç¼©å®¹ï¼‰
- ä½†åœ¨ç¨³å®šçª—å£æœŸå†…æœ‰æ›´é«˜çš„å»ºè®®å€¼
- ä¸ºé¿å…é¢‘ç¹æ³¢åŠ¨ï¼Œè·³è¿‡æœ¬æ¬¡ç¼©å®¹

**ç¨³å®šçª—å£æœºåˆ¶**
```yaml
spec:
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # 5 åˆ†é’Ÿçª—å£
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
```

**ç¤ºä¾‹åœºæ™¯**
```
æ—¶é—´çº¿:
10:00 - è®¡ç®—: éœ€è¦ 10 å‰¯æœ¬
10:01 - è®¡ç®—: éœ€è¦ 8 å‰¯æœ¬
10:02 - è®¡ç®—: éœ€è¦ 6 å‰¯æœ¬ (ä½† 5 åˆ†é’Ÿå†…æœ€é«˜æ˜¯ 10ï¼Œè·³è¿‡ç¼©å®¹)
10:03 - è®¡ç®—: éœ€è¦ 7 å‰¯æœ¬
10:05 - è®¡ç®—: éœ€è¦ 6 å‰¯æœ¬ (ç¨³å®šçª—å£å†…æœ€é«˜æ˜¯ 8ï¼Œè·³è¿‡ç¼©å®¹)
10:06 - è®¡ç®—: éœ€è¦ 5 å‰¯æœ¬ (ç¨³å®šçª—å£å†…æœ€é«˜æ˜¯ 7ï¼Œæ‰§è¡Œç¼©å®¹åˆ° 7)
```

---

## VPA äº‹ä»¶è¯¦è§£

### 17. EvictedByVPA

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: EvictedByVPA
ç±»å‹: Normal
å¼•å…¥ç‰ˆæœ¬: VPA addon
ç»„ä»¶: vpa-updater
é¢‘ç‡: ä½é¢‘ (VPA é©±é€ Pod)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Normal
Reason: EvictedByVPA
Message: Pod evicted by VPA Updater to apply resource recommendation
Age: 30s
From: vpa-updater
```

**è§¦å‘æ¡ä»¶**
- VPA æ¨¡å¼ä¸º `Auto` æˆ– `Recreate`
- Pod å®é™…èµ„æºä¸æ¨èå€¼å·®å¼‚è¶…è¿‡é˜ˆå€¼
- VPA è§¦å‘é©±é€ä»¥åº”ç”¨æ–°çš„èµ„æºè¯·æ±‚

**VPA é…ç½®ç¤ºä¾‹**
```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: web-app-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  updatePolicy:
    updateMode: Auto  # æˆ– Recreate
  resourcePolicy:
    containerPolicies:
    - containerName: '*'
      minAllowed:
        cpu: 100m
        memory: 128Mi
      maxAllowed:
        cpu: 2
        memory: 2Gi
```

**æ’æŸ¥å»ºè®®**
```bash
# æŸ¥çœ‹ VPA æ¨èå€¼
kubectl describe vpa web-app-vpa

Recommendation:
  Container Recommendations:
    Container Name:  app
    Lower Bound:
      Cpu:     150m
      Memory:  262144k
    Target:
      Cpu:     200m  # æ¨èå€¼
      Memory:  300Mi
    Upper Bound:
      Cpu:     500m
      Memory:  500Mi
```

---

### 18. RecommendationProvided

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: RecommendationProvided
ç±»å‹: Normal
å¼•å…¥ç‰ˆæœ¬: VPA addon
ç»„ä»¶: vpa-recommender
é¢‘ç‡: ä¸­é¢‘ (å®šæœŸæ›´æ–°)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Normal
Reason: RecommendationProvided
Message: VPA recommender provided new resource recommendation: cpu=200m, memory=300Mi
Age: 5m
From: vpa-recommender
```

**è§¦å‘æ¡ä»¶**
- VPA Recommender å®Œæˆåˆ†æ
- ç”Ÿæˆæ–°çš„èµ„æºæ¨èå€¼
- æ‰€æœ‰ updateMode éƒ½ä¼šäº§ç”Ÿæ­¤äº‹ä»¶

---

### 19. UpdateFailed

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: UpdateFailed
ç±»å‹: Warning
å¼•å…¥ç‰ˆæœ¬: VPA addon
ç»„ä»¶: vpa-updater
é¢‘ç‡: ä½é¢‘ (æ›´æ–°å¤±è´¥)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Warning
Reason: UpdateFailed
Message: failed to evict pod: PodDisruptionBudget violation
Age: 2m
From: vpa-updater
```

**å¸¸è§åŸå› **
- PodDisruptionBudget é™åˆ¶é©±é€
- Pod æ ‡è®°ä¸ºä¸å¯é©±é€ (`cluster-autoscaler.kubernetes.io/safe-to-evict: "false"`)
- èµ„æºé…é¢ä¸è¶³

---

### 20. CheckpointUpdated

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: CheckpointUpdated
ç±»å‹: Normal
å¼•å…¥ç‰ˆæœ¬: VPA addon
ç»„ä»¶: vpa-recommender
é¢‘ç‡: ä½é¢‘ (å®šæœŸæ£€æŸ¥ç‚¹)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Normal
Reason: CheckpointUpdated
Message: VPA checkpoint updated with new resource usage data
Age: 10m
From: vpa-recommender
```

**è¯´æ˜**
- VPA Recommender å®šæœŸä¿å­˜å†å²æ•°æ®åˆ° checkpoint
- ç”¨äºé‡å¯åæ¢å¤æ¨èçŠ¶æ€

---

## Cluster Autoscaler äº‹ä»¶è¯¦è§£

### 21. ScaledUpGroup

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: ScaledUpGroup
ç±»å‹: Normal
å¼•å…¥ç‰ˆæœ¬: CA addon
ç»„ä»¶: cluster-autoscaler
é¢‘ç‡: ä¸­é¢‘ (èŠ‚ç‚¹æ‰©å®¹)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Normal
Reason: ScaledUpGroup
Message: Scale-up: group node-group-1 size increased from 3 to 5
Age: 2m
From: cluster-autoscaler
```

**è§¦å‘æ¡ä»¶**
- æœ‰ Pod å› èµ„æºä¸è¶³å¤„äº Pending çŠ¶æ€
- CA è¯„ä¼°å¯ä»¥é€šè¿‡å¢åŠ èŠ‚ç‚¹è°ƒåº¦è¿™äº› Pod
- æˆåŠŸå‘äº‘ä¾›åº”å•†è¯·æ±‚å¢åŠ èŠ‚ç‚¹

**ç¤ºä¾‹åœºæ™¯**
```bash
# 1. Pod Pending
kubectl get pods

NAME                READY   STATUS    RESTARTS   AGE
web-app-1           1/1     Running   0          10m
web-app-2           0/1     Pending   0          1m  # èµ„æºä¸è¶³

# 2. æŸ¥çœ‹ Pending åŸå› 
kubectl describe pod web-app-2

Events:
  Warning  FailedScheduling  1m  0/3 nodes are available: 3 Insufficient cpu.

# 3. CA è§¦å‘æ‰©å®¹
kubectl get events --field-selector involvedObject.kind=Node

Type    Reason          Message
Normal  ScaledUpGroup   Scale-up: group node-group-1 size increased from 3 to 5

# 4. æ–°èŠ‚ç‚¹åŠ å…¥
kubectl get nodes

NAME      STATUS   ROLES    AGE
node-1    Ready    worker   10d
node-2    Ready    worker   10d
node-3    Ready    worker   10d
node-4    Ready    worker   2m   # æ–°èŠ‚ç‚¹
node-5    Ready    worker   2m   # æ–°èŠ‚ç‚¹
```

**é…ç½®å‚æ•°**
```yaml
# CA Deployment é…ç½®
spec:
  containers:
  - command:
    - ./cluster-autoscaler
    - --cloud-provider=aws
    - --nodes=1:10:node-group-1  # min:max:name
    - --scale-down-enabled=true
    - --scale-down-delay-after-add=10m
    - --scale-down-unneeded-time=10m
```

---

### 22. ScaleDown

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: ScaleDown
ç±»å‹: Normal
å¼•å…¥ç‰ˆæœ¬: CA addon
ç»„ä»¶: cluster-autoscaler
é¢‘ç‡: ä¸­é¢‘ (èŠ‚ç‚¹ç¼©å®¹)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Normal
Reason: ScaleDown
Message: Scale-down: node node-4 removed from group node-group-1
Age: 5m
From: cluster-autoscaler
```

**è§¦å‘æ¡ä»¶**
- èŠ‚ç‚¹ä¸Š Pod æ€»èµ„æºè¯·æ±‚ä½äºé˜ˆå€¼ï¼ˆé»˜è®¤ 50%ï¼‰
- èŠ‚ç‚¹ä¸Šçš„ Pod å¯ä»¥è°ƒåº¦åˆ°å…¶ä»–èŠ‚ç‚¹
- æ»¡è¶³ç¼©å®¹ç­‰å¾…æ—¶é—´ï¼ˆé»˜è®¤ 10 åˆ†é’Ÿï¼‰

**ç¼©å®¹å†³ç­–æ¡ä»¶**
```
èŠ‚ç‚¹å¯ä»¥ç¼©å®¹çš„æ¡ä»¶ï¼ˆæ‰€æœ‰æ¡ä»¶å¿…é¡»æ»¡è¶³ï¼‰:

1. èŠ‚ç‚¹åˆ©ç”¨ç‡ä½äºé˜ˆå€¼ (--scale-down-utilization-threshold=0.5)
2. èŠ‚ç‚¹ç©ºé—²æ—¶é—´è¶…è¿‡é˜ˆå€¼ (--scale-down-unneeded-time=10m)
3. èŠ‚ç‚¹ä¸Šæ‰€æœ‰ Pod æ»¡è¶³ä»¥ä¸‹ä¹‹ä¸€:
   - å¯ä»¥è¢«é©±é€ (æ—  PDB é™åˆ¶)
   - å¯ä»¥è°ƒåº¦åˆ°å…¶ä»–èŠ‚ç‚¹
   - æ˜¯ DaemonSet Pod
   - æœ‰ local storage ä½†å¯ä»¥å®¹å¿æ•°æ®ä¸¢å¤±
4. èŠ‚ç‚¹æ²¡æœ‰ç¼©å®¹ä¿æŠ¤æ³¨è§£:
   - cluster-autoscaler.kubernetes.io/scale-down-disabled: "true"
5. èŠ‚ç‚¹ä¸Šæ²¡æœ‰ç³»ç»Ÿ Pod (é™¤ DaemonSet å’Œ kube-system)
```

---

### 23. ScaleDownEmpty

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: ScaleDownEmpty
ç±»å‹: Normal
å¼•å…¥ç‰ˆæœ¬: CA addon
ç»„ä»¶: cluster-autoscaler
é¢‘ç‡: ä¸­é¢‘ (ç©ºèŠ‚ç‚¹ç¼©å®¹)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Normal
Reason: ScaleDownEmpty
Message: Scale-down: empty node node-5 removed
Age: 1m
From: cluster-autoscaler
```

**è§¦å‘æ¡ä»¶**
- èŠ‚ç‚¹ä¸Šæ²¡æœ‰ä»»ä½• Podï¼ˆé™¤ DaemonSetï¼‰
- æ»¡è¶³ç©ºèŠ‚ç‚¹ç¼©å®¹ç­‰å¾…æ—¶é—´ï¼ˆé»˜è®¤ 10 åˆ†é’Ÿï¼‰

**é…ç½®å‚æ•°**
```bash
--scale-down-unneeded-time=10m          # æ™®é€šèŠ‚ç‚¹ç¼©å®¹ç­‰å¾…æ—¶é—´
--scale-down-unready-time=20m           # æœªå°±ç»ªèŠ‚ç‚¹ç¼©å®¹ç­‰å¾…æ—¶é—´
--scale-down-delay-after-add=10m        # æ‰©å®¹åå»¶è¿Ÿç¼©å®¹æ—¶é—´
--scale-down-delay-after-delete=0s      # åˆ é™¤èŠ‚ç‚¹åå»¶è¿Ÿæ—¶é—´
--scale-down-delay-after-failure=3m     # ç¼©å®¹å¤±è´¥åå»¶è¿Ÿæ—¶é—´
```

---

### 24. ScaleDownFailed

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: ScaleDownFailed
ç±»å‹: Warning
å¼•å…¥ç‰ˆæœ¬: CA addon
ç»„ä»¶: cluster-autoscaler
é¢‘ç‡: ä½é¢‘ (ç¼©å®¹å¤±è´¥)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Warning
Reason: ScaleDownFailed
Message: Scale-down: failed to delete node node-4: failed to terminate instance i-abc123
Age: 2m
From: cluster-autoscaler
```

**å¸¸è§åŸå› **

**åŸå›  1: äº‘ä¾›åº”å•† API å¤±è´¥**
```
Message: failed to delete node: RequestLimitExceeded: Request limit exceeded
```

**åŸå›  2: Pod é©±é€å¤±è´¥**
```
Message: failed to evict pod web-app-1: PodDisruptionBudget violation
```

**åŸå›  3: èŠ‚ç‚¹æœ‰ä¿æŠ¤æ³¨è§£**
```yaml
apiVersion: v1
kind: Node
metadata:
  annotations:
    cluster-autoscaler.kubernetes.io/scale-down-disabled: "true"
```

---

### 25. NotTriggerScaleUp

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: NotTriggerScaleUp
ç±»å‹: Warning
å¼•å…¥ç‰ˆæœ¬: CA addon
ç»„ä»¶: cluster-autoscaler
é¢‘ç‡: ä½é¢‘ (æ‰©å®¹æ¡ä»¶ä¸æ»¡è¶³)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Warning
Reason: NotTriggerScaleUp
Message: pod didn't trigger scale-up: 2 max node group size reached
Age: 30s
From: cluster-autoscaler
```

**å¸¸è§åŸå› **

**åŸå›  1: èŠ‚ç‚¹ç»„è¾¾åˆ°æœ€å¤§å€¼**
```bash
--nodes=1:10:node-group-1  # å½“å‰å·²æœ‰ 10 ä¸ªèŠ‚ç‚¹
```

**åŸå›  2: Pod èµ„æºè¯·æ±‚è¶…è¿‡èŠ‚ç‚¹è§„æ ¼**
```yaml
# Pod è¯·æ±‚
resources:
  requests:
    cpu: 32    # è¶…è¿‡èŠ‚ç‚¹è§„æ ¼
    memory: 128Gi

# èŠ‚ç‚¹è§„æ ¼: 16 CPU, 64Gi å†…å­˜
```

**åŸå›  3: èŠ‚ç‚¹é€‰æ‹©å™¨/äº²å’Œæ€§æ— æ³•æ»¡è¶³**
```yaml
nodeSelector:
  gpu: "true"  # ä½†èŠ‚ç‚¹ç»„æ²¡æœ‰ GPU æ ‡ç­¾
```

---

### 26. TriggeredScaleUp

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: TriggeredScaleUp
ç±»å‹: Normal
å¼•å…¥ç‰ˆæœ¬: CA addon
ç»„ä»¶: cluster-autoscaler
é¢‘ç‡: ä¸­é¢‘ (è§¦å‘æ‰©å®¹)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Normal
Reason: TriggeredScaleUp
Message: pod triggered scale-up: [{node-group-1 3->5 (max: 10)}]
Age: 1m
From: cluster-autoscaler
```

**è§¦å‘æ¡ä»¶**
- Pod å¤„äº Pending çŠ¶æ€
- è°ƒåº¦å™¨æ— æ³•åœ¨ç°æœ‰èŠ‚ç‚¹ä¸Šè°ƒåº¦
- CA è¯„ä¼°å¢åŠ èŠ‚ç‚¹å¯ä»¥è°ƒåº¦è¯¥ Pod

**ç¤ºä¾‹**
```bash
# Pod äº‹ä»¶
kubectl describe pod web-app-pending

Events:
  Type     Reason            Age   Message
  ----     ------            ----  -------
  Warning  FailedScheduling  2m    0/3 nodes available: 3 Insufficient cpu
  Normal   TriggeredScaleUp  1m    pod triggered scale-up

# èŠ‚ç‚¹äº‹ä»¶
kubectl get events --field-selector reason=ScaledUpGroup

Type    Reason         Message
Normal  ScaledUpGroup  Scale-up: group node-group-1 size increased from 3 to 5
```

---

### 27. ScaleDownDisabledAnnotation

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: ScaleDownDisabledAnnotation
ç±»å‹: Normal
å¼•å…¥ç‰ˆæœ¬: CA addon
ç»„ä»¶: cluster-autoscaler
é¢‘ç‡: ä½é¢‘ (æ³¨è§£ä¿æŠ¤)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Normal
Reason: ScaleDownDisabledAnnotation
Message: scale-down disabled by annotation on node node-4
Age: 5m
From: cluster-autoscaler
```

**è§¦å‘æ¡ä»¶**
- èŠ‚ç‚¹æœ‰ç¼©å®¹ä¿æŠ¤æ³¨è§£
- CA è·³è¿‡è¯¥èŠ‚ç‚¹çš„ç¼©å®¹è¯„ä¼°

**ä¿æŠ¤æ³¨è§£**
```yaml
# èŠ‚ç‚¹çº§åˆ«ä¿æŠ¤
apiVersion: v1
kind: Node
metadata:
  annotations:
    cluster-autoscaler.kubernetes.io/scale-down-disabled: "true"

# Pod çº§åˆ«ä¿æŠ¤ï¼ˆé˜²æ­¢èŠ‚ç‚¹è¢«ç¼©å®¹ï¼‰
apiVersion: v1
kind: Pod
metadata:
  annotations:
    cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
```

---

### 28. FailedToScaleUpGroup

**åŸºæœ¬ä¿¡æ¯**
```yaml
äº‹ä»¶åç§°: FailedToScaleUpGroup
ç±»å‹: Warning
å¼•å…¥ç‰ˆæœ¬: CA addon
ç»„ä»¶: cluster-autoscaler
é¢‘ç‡: ä½é¢‘ (æ‰©å®¹å¤±è´¥)
```

**äº‹ä»¶æ ¼å¼**
```
Type: Warning
Reason: FailedToScaleUpGroup
Message: failed to increase node group size: rate limit exceeded
Age: 1m
From: cluster-autoscaler
```

**å¸¸è§åŸå› **
- äº‘ä¾›åº”å•† API é™æµ
- èµ„æºé…é¢ä¸è¶³ï¼ˆvCPUã€IP åœ°å€ç­‰ï¼‰
- èŠ‚ç‚¹ç»„é…ç½®é”™è¯¯
- ç½‘ç»œã€å®‰å…¨ç»„é—®é¢˜

**æ’æŸ¥æ­¥éª¤**
```bash
# 1. æŸ¥çœ‹ CA æ—¥å¿—
kubectl logs -n kube-system deployment/cluster-autoscaler

# 2. æ£€æŸ¥äº‘ä¾›åº”å•†é…é¢
aws ec2 describe-account-attributes --attribute-names max-instances

# 3. éªŒè¯èŠ‚ç‚¹ç»„é…ç½®
aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names node-group-1
```

---

## HPA å†³ç­–ç®—æ³•

### åŸºæœ¬è®¡ç®—å…¬å¼

```
desiredReplicas = ceil[currentReplicas * (currentMetricValue / targetMetricValue)]

å…¶ä¸­:
- currentReplicas: å½“å‰å‰¯æœ¬æ•°
- currentMetricValue: å½“å‰æŒ‡æ ‡å€¼ï¼ˆæ‰€æœ‰ Pod å¹³å‡å€¼ï¼‰
- targetMetricValue: ç›®æ ‡æŒ‡æ ‡å€¼
- ceil: å‘ä¸Šå–æ•´
```

### è¯¦ç»†è®¡ç®—æµç¨‹

**æ­¥éª¤ 1: è·å– Pod æŒ‡æ ‡**
```go
// è·å–æ‰€æœ‰ Ready çŠ¶æ€çš„ Pod æŒ‡æ ‡
readyPods := getReadyPods(deployment)
currentMetricValue := sum(metrics) / len(readyPods)
```

**æ­¥éª¤ 2: è®¡ç®—æœŸæœ›å‰¯æœ¬æ•°**
```go
if currentMetricValue > targetMetricValue {
    // æ‰©å®¹
    desiredReplicas = ceil(currentReplicas * (currentMetricValue / targetMetricValue))
} else if currentMetricValue < targetMetricValue {
    // ç¼©å®¹
    desiredReplicas = floor(currentReplicas * (currentMetricValue / targetMetricValue))
}
```

**æ­¥éª¤ 3: åº”ç”¨è¾¹ç•Œé™åˆ¶**
```go
if desiredReplicas < minReplicas {
    desiredReplicas = minReplicas
}
if desiredReplicas > maxReplicas {
    desiredReplicas = maxReplicas
}
```

**æ­¥éª¤ 4: åº”ç”¨å®¹å¿åº¦ï¼ˆToleranceï¼‰**
```go
tolerance := 0.1  // é»˜è®¤ 10%
if abs((currentMetricValue - targetMetricValue) / targetMetricValue) < tolerance {
    // åœ¨å®¹å¿èŒƒå›´å†…ï¼Œä¸æ‰§è¡Œæ‰©ç¼©å®¹
    desiredReplicas = currentReplicas
}
```

### å®é™…ç¤ºä¾‹

**ç¤ºä¾‹ 1: CPU ä½¿ç”¨ç‡æ‰©å®¹**
```
å½“å‰çŠ¶æ€:
- currentReplicas: 5
- CPU requests: 100m per pod
- CPU usage: å¹³å‡ 85m per pod
- targetUtilization: 70%

è®¡ç®—è¿‡ç¨‹:
currentMetricValue = (85m / 100m) * 100% = 85%
targetMetricValue = 70%

desiredReplicas = ceil[5 * (85 / 70)]
                = ceil[5 * 1.214]
                = ceil[6.07]
                = 7

ç»“æœ: æ‰©å®¹åˆ° 7 ä¸ªå‰¯æœ¬
```

**ç¤ºä¾‹ 2: è‡ªå®šä¹‰æŒ‡æ ‡æ‰©å®¹**
```
å½“å‰çŠ¶æ€:
- currentReplicas: 3
- æŒ‡æ ‡: http_requests_per_second
- å½“å‰å€¼: 1500 (æ¯ä¸ª Pod 500 è¯·æ±‚/ç§’)
- ç›®æ ‡å€¼: 300 è¯·æ±‚/ç§’ per pod

è®¡ç®—è¿‡ç¨‹:
currentMetricValue = 1500 / 3 = 500
targetMetricValue = 300

desiredReplicas = ceil[3 * (500 / 300)]
                = ceil[3 * 1.667]
                = ceil[5]
                = 5

ç»“æœ: æ‰©å®¹åˆ° 5 ä¸ªå‰¯æœ¬
```

### å¤šæŒ‡æ ‡å†³ç­–

**å¹¶è¡Œè®¡ç®—æ‰€æœ‰æŒ‡æ ‡ï¼Œå–æœ€å¤§å€¼**
```yaml
metrics:
- type: Resource
  resource:
    name: cpu
    target:
      type: Utilization
      averageUtilization: 70
- type: Resource
  resource:
    name: memory
    target:
      type: Utilization
      averageUtilization: 80
```

**è®¡ç®—é€»è¾‘**
```go
// è®¡ç®—æ¯ä¸ªæŒ‡æ ‡çš„æœŸæœ›å‰¯æœ¬æ•°
cpuDesiredReplicas := calculateReplicas(cpuMetric)      // ä¾‹å¦‚: 7
memoryDesiredReplicas := calculateReplicas(memoryMetric) // ä¾‹å¦‚: 5

// å–æœ€å¤§å€¼ï¼ˆä¿å®ˆç­–ç•¥ï¼Œç¡®ä¿æ»¡è¶³æ‰€æœ‰æŒ‡æ ‡ï¼‰
finalDesiredReplicas := max(cpuDesiredReplicas, memoryDesiredReplicas)
// ç»“æœ: 7
```

### ç‰¹æ®Šåœºæ™¯å¤„ç†

**åœºæ™¯ 1: Pod å¯åŠ¨ä¸­ï¼ˆæœªå°±ç»ªï¼‰**
```go
// å¿½ç•¥æœªå°±ç»ªçš„ Pod
readyPods := filterReady(allPods)
currentMetricValue := sum(metricsOfReadyPods) / len(readyPods)
```

**åœºæ™¯ 2: ç¼ºå¤±æŒ‡æ ‡çš„ Pod**
```go
// å¦‚æœ Pod æŒ‡æ ‡ç¼ºå¤±ï¼ˆå¦‚åˆšå¯åŠ¨ï¼‰
if missingMetrics > 0 {
    // å‡è®¾ç¼ºå¤±æŒ‡æ ‡çš„ Pod ä½¿ç”¨ç›®æ ‡å€¼
    estimatedValue := (sumExistingMetrics + missingMetrics * targetValue) / totalPods
}
```

**åœºæ™¯ 3: å®¹å¿åº¦é˜ˆå€¼**
```yaml
# é»˜è®¤å®¹å¿åº¦ 10%
# å¦‚æœ currentValue åœ¨ [targetValue * 0.9, targetValue * 1.1] èŒƒå›´å†…
# ä¸è§¦å‘æ‰©ç¼©å®¹

ç¤ºä¾‹:
targetValue = 70%
å®¹å¿èŒƒå›´ = [63%, 77%]
å¦‚æœ currentValue = 72%ï¼Œä¸æ‰©ç¼©å®¹
```

---

## VPA å·¥ä½œæ¨¡å¼

### å››ç§æ¨¡å¼å¯¹æ¯”

| æ¨¡å¼ | è¡Œä¸º | é€‚ç”¨åœºæ™¯ | é£é™© |
|------|------|---------|------|
| **Off** | ä»…æä¾›å»ºè®®ï¼Œä¸æ›´æ–° Pod | è§‚å¯Ÿæµ‹è¯•é˜¶æ®µ | æ—  |
| **Initial** | ä»…åœ¨ Pod åˆ›å»ºæ—¶åº”ç”¨å»ºè®® | æ–°éƒ¨ç½²çš„åº”ç”¨ | ä½ |
| **Auto** | è‡ªåŠ¨é©±é€å¹¶é‡å»º Pod | æ— çŠ¶æ€åº”ç”¨ | ä¸­ |
| **Recreate** | æ‰‹åŠ¨é‡å¯æ—¶åº”ç”¨å»ºè®® | æœ‰çŠ¶æ€åº”ç”¨ã€éœ€è¦æ§åˆ¶é‡å¯æ—¶é—´ | ä½ |

### æ¨¡å¼è¯¦è§£

**1. Off æ¨¡å¼ - ä»…è§‚å¯Ÿ**
```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: web-app-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  updatePolicy:
    updateMode: "Off"  # ä»…æä¾›å»ºè®®
```

**è¡Œä¸º**
- VPA Recommender æŒç»­åˆ†æèµ„æºä½¿ç”¨æƒ…å†µ
- ç”Ÿæˆæ¨èå€¼å¹¶è®°å½•åˆ° VPA status
- **ä¸ä¼š**ä¿®æ”¹ä»»ä½• Pod çš„ resources
- **ä¸ä¼š**é©±é€æˆ–é‡å¯ Pod

**æŸ¥çœ‹å»ºè®®**
```bash
kubectl describe vpa web-app-vpa

Status:
  Recommendation:
    Container Recommendations:
      Container Name:  app
      Lower Bound:
        Cpu:     100m
        Memory:  128Mi
      Target:      # æ¨èåº”ç”¨çš„å€¼
        Cpu:     200m
        Memory:  256Mi
      Upper Bound:
        Cpu:     500m
        Memory:  512Mi
```

**é€‚ç”¨åœºæ™¯**
- åˆæ¬¡éƒ¨ç½² VPAï¼Œè¯„ä¼°æ¨èå€¼æ˜¯å¦åˆç†
- ç”Ÿäº§ç¯å¢ƒè§‚å¯ŸæœŸ
- ä¸æƒ³è‡ªåŠ¨æ›´æ”¹èµ„æºçš„åº”ç”¨

---

**2. Initial æ¨¡å¼ - åˆ›å»ºæ—¶åº”ç”¨**
```yaml
updatePolicy:
  updateMode: "Initial"
```

**è¡Œä¸º**
- å¯¹**æ–°åˆ›å»º**çš„ Podï¼Œåº”ç”¨ VPA æ¨èçš„ resources
- å¯¹**å·²å­˜åœ¨**çš„ Podï¼Œä¸åšä»»ä½•æ›´æ”¹
- ä¸ä¼šé©±é€ç°æœ‰ Pod

**ç¤ºä¾‹**
```bash
# åˆå§‹ Deployment
apiVersion: apps/v1
kind: Deployment
spec:
  template:
    spec:
      containers:
      - name: app
        resources:
          requests:
            cpu: 100m      # åˆå§‹é…ç½®
            memory: 128Mi

# åˆ›å»º VPAï¼ˆInitial æ¨¡å¼ï¼‰å
# ç°æœ‰ Pod: ä¿æŒ 100m CPU, 128Mi å†…å­˜
# æ–°å»º Pod: ä½¿ç”¨ VPA æ¨èå€¼ï¼ˆå¦‚ 200m CPU, 256Mi å†…å­˜ï¼‰

# æ‰©å®¹åçš„æ–° Pod
kubectl get pod web-app-new -o yaml | grep -A 5 resources

resources:
  requests:
    cpu: 200m      # VPA æ¨èå€¼
    memory: 256Mi
```

**é€‚ç”¨åœºæ™¯**
- æ–°éƒ¨ç½²çš„åº”ç”¨ï¼Œæƒ³é€æ­¥åº”ç”¨ VPA æ¨è
- é¿å…ç°æœ‰ Pod è¢«é©±é€ï¼Œä½†å¸Œæœ›æ–° Pod ä½¿ç”¨ä¼˜åŒ–é…ç½®
- æ»šåŠ¨æ›´æ–°æ—¶è‡ªåŠ¨åº”ç”¨æ–°é…ç½®

---

**3. Auto æ¨¡å¼ - è‡ªåŠ¨æ›´æ–°**
```yaml
updatePolicy:
  updateMode: "Auto"
```

**è¡Œä¸º**
- VPA Updater ä¸»åŠ¨é©±é€ Podï¼ˆè°ƒç”¨ Eviction APIï¼‰
- Deployment/ReplicaSet é‡å»º Pod
- æ–° Pod ä½¿ç”¨ VPA æ¨èçš„ resources

**é©±é€æ¡ä»¶**
```go
// VPA å†³å®šé©±é€çš„æ¡ä»¶ï¼ˆä»»ä¸€æ»¡è¶³ï¼‰:
1. Pod å½“å‰ CPU request ä¸æ¨èå€¼ç›¸å·® > 10%
2. Pod å½“å‰ memory request ä¸æ¨èå€¼ç›¸å·® > 10%
3. Pod èµ„æºä½¿ç”¨è¶…å‡º limitsï¼ˆé£é™©ä¼˜åŒ–ï¼‰
```

**äº‹ä»¶æµ**
```bash
# 1. VPA ç”Ÿæˆæ–°æ¨èå€¼
Events:
  Normal  RecommendationProvided  5m  new recommendation: cpu=400m, memory=512Mi

# 2. VPA Updater é©±é€ Pod
Events:
  Normal  EvictedByVPA  4m  Pod evicted to apply resource recommendation

# 3. Deployment é‡å»º Pod
Events:
  Normal  SuccessfulCreate  3m  Created pod: web-app-new

# 4. æ–° Pod ä½¿ç”¨æ¨èå€¼
kubectl get pod web-app-new -o yaml | grep -A 5 resources

resources:
  requests:
    cpu: 400m      # VPA æ›´æ–°åçš„å€¼
    memory: 512Mi
```

**é™åˆ¶å’Œä¿æŠ¤**
```yaml
# 1. PodDisruptionBudget ä¿æŠ¤
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: web-app-pdb
spec:
  minAvailable: 2  # VPA ä¼šéµå®ˆ PDBï¼Œç¡®ä¿æœ€å°‘ 2 ä¸ª Pod å¯ç”¨

# 2. resourcePolicy é™åˆ¶
spec:
  resourcePolicy:
    containerPolicies:
    - containerName: app
      minAllowed:
        cpu: 100m
        memory: 128Mi
      maxAllowed:
        cpu: 2          # VPA ä¸ä¼šæ¨èè¶…è¿‡ 2 CPU
        memory: 4Gi
      controlledResources:
      - cpu
      - memory
```

**é€‚ç”¨åœºæ™¯**
- æ— çŠ¶æ€åº”ç”¨ï¼ˆå¦‚ Web æœåŠ¡ï¼‰
- å¯ä»¥å®¹å¿ Pod é‡å¯
- å¸Œæœ›è‡ªåŠ¨ä¼˜åŒ–èµ„æºä½¿ç”¨

**é£é™©**
- Pod é‡å¯å¯¼è‡´æœåŠ¡ä¸­æ–­ï¼ˆéœ€é…åˆ PDBï¼‰
- é¢‘ç¹é©±é€å¯èƒ½å½±å“ç¨³å®šæ€§

---

**4. Recreate æ¨¡å¼ - æ‰‹åŠ¨æ§åˆ¶æ›´æ–°**
```yaml
updatePolicy:
  updateMode: "Recreate"
```

**è¡Œä¸º**
- VPA æ›´æ–° Deployment/StatefulSet çš„ resources å®šä¹‰
- **ä¸ä¼š**è‡ªåŠ¨é©±é€ Pod
- éœ€è¦æ‰‹åŠ¨è§¦å‘ Pod é‡å»ºï¼ˆå¦‚æ»šåŠ¨æ›´æ–°ï¼‰

**å·¥ä½œæµç¨‹**
```bash
# 1. VPA æ›´æ–° Deployment spec
kubectl get deployment web-app -o yaml | grep -A 5 resources

spec:
  template:
    spec:
      containers:
      - name: app
        resources:
          requests:
            cpu: 300m      # VPA æ›´æ–°çš„å€¼
            memory: 384Mi

# 2. ä½† Pod ä¸ä¼šè‡ªåŠ¨é‡å»º
kubectl get pods

NAME         STATUS    RESTARTS   AGE
web-app-1    Running   0          10d  # ä»ä½¿ç”¨æ—§é…ç½®

# 3. æ‰‹åŠ¨è§¦å‘æ»šåŠ¨æ›´æ–°
kubectl rollout restart deployment web-app

# 4. æ–° Pod ä½¿ç”¨ VPA æ¨èå€¼
kubectl get pods

NAME         STATUS    RESTARTS   AGE
web-app-new  Running   0          1m   # ä½¿ç”¨æ–°é…ç½®
```

**é€‚ç”¨åœºæ™¯**
- æœ‰çŠ¶æ€åº”ç”¨ï¼ˆStatefulSetï¼‰
- éœ€è¦æ§åˆ¶é‡å¯æ—¶é—´çª—å£
- ç”Ÿäº§ç¯å¢ƒéœ€è¦å®¡æ‰¹æµç¨‹
- å…³é”®æœåŠ¡ä¸èƒ½éšæ„é‡å¯

**ä¼˜åŠ¿**
- å®Œå…¨æ§åˆ¶ä½•æ—¶åº”ç”¨èµ„æºæ›´æ”¹
- é¿å…æ„å¤–é‡å¯
- å¯ä»¥é…åˆç»´æŠ¤çª—å£

---

### VPA ä¸ HPA å…±å­˜

**æ¨èé…ç½®**
```yaml
# VPA: ä»…ç®¡ç† memory
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: web-app-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: app
      controlledResources:
      - memory  # ä»…ç®¡ç†å†…å­˜

---
# HPA: ä»…ç®¡ç† cpu
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  metrics:
  - type: Resource
    resource:
      name: cpu  # ä»…åŸºäº CPU æ‰©ç¼©å®¹
      target:
        type: Utilization
        averageUtilization: 70
```

**é¿å…å†²çªçš„åŸåˆ™**
1. VPA ç®¡ç† memoryï¼ŒHPA åŸºäº CPU æ‰©ç¼©å®¹
2. ä¸è¦è®© VPA å’Œ HPA åŒæ—¶ç®¡ç†ç›¸åŒçš„èµ„æºæŒ‡æ ‡
3. ä¼˜å…ˆä½¿ç”¨ HPAï¼ˆæ¨ªå‘æ‰©å±•ï¼‰ï¼ŒVPA ä½œä¸ºè¡¥å……ï¼ˆçºµå‘ä¼˜åŒ–ï¼‰

---

## CA æ‰©ç¼©å®¹å†³ç­–é€»è¾‘

### æ‰©å®¹å†³ç­–æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. æ£€æµ‹ Pending Pods                     â”‚
â”‚    kubectl get pods --field-selector=   â”‚
â”‚    status.phase=Pending                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. åˆ†æ Pending åŸå›                      â”‚
â”‚    - Insufficient cpu/memory/gpu         â”‚
â”‚    - Node affinity/selector ä¸åŒ¹é…       â”‚
â”‚    - Taints/Tolerations ä¸åŒ¹é…           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. æ¨¡æ‹Ÿè°ƒåº¦åˆ°æ–°èŠ‚ç‚¹                      â”‚
â”‚    - ä¸ºæ¯ä¸ªèŠ‚ç‚¹ç»„æ¨¡æ‹Ÿæ·»åŠ èŠ‚ç‚¹            â”‚
â”‚    - è¿è¡Œè°ƒåº¦å™¨ç®—æ³•æ£€æŸ¥ Pod æ˜¯å¦å¯è°ƒåº¦   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. é€‰æ‹©æœ€ä½³èŠ‚ç‚¹ç»„                        â”‚
â”‚    - ä¼˜å…ˆçº§: èµ„æºåŒ¹é…åº¦                  â”‚
â”‚    - æˆæœ¬ï¼ˆå¦‚é…ç½®äº† Expanderï¼‰            â”‚
â”‚    - èŠ‚ç‚¹ç»„å½“å‰å¤§å°                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. æ£€æŸ¥çº¦æŸæ¡ä»¶                          â”‚
â”‚    - èŠ‚ç‚¹ç»„æœªè¾¾åˆ° max é™åˆ¶               â”‚
â”‚    - äº‘èµ„æºé…é¢å……è¶³                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. è§¦å‘æ‰©å®¹                              â”‚
â”‚    - è°ƒç”¨äº‘ä¾›åº”å•† API å¢åŠ èŠ‚ç‚¹           â”‚
â”‚    - ç”Ÿæˆ TriggeredScaleUp äº‹ä»¶          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç¼©å®¹å†³ç­–æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. è¯„ä¼°æ‰€æœ‰èŠ‚ç‚¹åˆ©ç”¨ç‡                    â”‚
â”‚    utilization = (requests / capacity)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. è¯†åˆ«ä½åˆ©ç”¨ç‡èŠ‚ç‚¹                      â”‚
â”‚    - utilization < threshold (é»˜è®¤ 50%)  â”‚
â”‚    - æŒç»­æ—¶é—´ > unneeded-time (é»˜è®¤ 10m) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. æ£€æŸ¥èŠ‚ç‚¹ä¸Šçš„ Pods                     â”‚
â”‚    å¯¹äºæ¯ä¸ª Podï¼Œæ£€æŸ¥:                   â”‚
â”‚    - æ˜¯å¦å¯ä»¥è¢«é©±é€ (PDB)                â”‚
â”‚    - æ˜¯å¦å¯ä»¥è°ƒåº¦åˆ°å…¶ä»–èŠ‚ç‚¹              â”‚
â”‚    - æ˜¯å¦æœ‰ local storage                â”‚
â”‚    - æ˜¯å¦æœ‰ scale-down-disabled æ³¨è§£     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. æ¨¡æ‹Ÿé©±é€å’Œé‡æ–°è°ƒåº¦                    â”‚
â”‚    - å°†èŠ‚ç‚¹ä¸Šçš„ Pod æ¨¡æ‹Ÿè°ƒåº¦åˆ°å…¶ä»–èŠ‚ç‚¹   â”‚
â”‚    - æ£€æŸ¥èµ„æºæ˜¯å¦å……è¶³                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. æ£€æŸ¥ç¼©å®¹ä¿æŠ¤                          â”‚
â”‚    - èŠ‚ç‚¹æ˜¯å¦æœ‰ä¿æŠ¤æ³¨è§£                  â”‚
â”‚    - æ˜¯å¦åœ¨å»¶è¿Ÿä¿æŠ¤æœŸå†…                  â”‚
â”‚    - èŠ‚ç‚¹ç»„æ˜¯å¦è¾¾åˆ° min é™åˆ¶             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. æ‰§è¡Œç¼©å®¹                              â”‚
â”‚    - é©±é€èŠ‚ç‚¹ä¸Šçš„ Pods                   â”‚
â”‚    - è°ƒç”¨äº‘ä¾›åº”å•† API åˆ é™¤èŠ‚ç‚¹           â”‚
â”‚    - ç”Ÿæˆ ScaleDown äº‹ä»¶                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®å‚æ•°è¯¦è§£

**æ‰©å®¹å‚æ•°**
```bash
# èŠ‚ç‚¹ç»„é…ç½®
--nodes=<min>:<max>:<node-group-name>
# ç¤ºä¾‹: --nodes=1:10:node-group-1
#       æœ€å°‘ 1 ä¸ªèŠ‚ç‚¹ï¼Œæœ€å¤š 10 ä¸ªèŠ‚ç‚¹

# æ‰©å®¹å»¶è¿Ÿ
--scale-up-from-zero=true          # å…è®¸ä» 0 æ‰©å®¹
--max-nodes-total=100              # é›†ç¾¤èŠ‚ç‚¹æ€»æ•°ä¸Šé™
--max-cores-total=320              # é›†ç¾¤æ€» CPU æ ¸æ•°ä¸Šé™
--max-memory-total=1280            # é›†ç¾¤æ€»å†…å­˜ä¸Šé™ (GiB)

# æ‰©å®¹åå»¶è¿Ÿç¼©å®¹ï¼ˆé¿å…æŠ–åŠ¨ï¼‰
--scale-down-delay-after-add=10m
```

**ç¼©å®¹å‚æ•°**
```bash
# ç¼©å®¹å¼€å…³
--scale-down-enabled=true

# ç¼©å®¹é˜ˆå€¼
--scale-down-utilization-threshold=0.5  # èŠ‚ç‚¹åˆ©ç”¨ç‡ä½äº 50% æ‰è€ƒè™‘ç¼©å®¹

# ç¼©å®¹ç­‰å¾…æ—¶é—´
--scale-down-unneeded-time=10m          # èŠ‚ç‚¹ä½åˆ©ç”¨ç‡æŒç»­ 10 åˆ†é’Ÿ
--scale-down-unready-time=20m           # æœªå°±ç»ªèŠ‚ç‚¹æŒç»­ 20 åˆ†é’Ÿ

# ç¼©å®¹å»¶è¿Ÿï¼ˆé¿å…é¢‘ç¹æ“ä½œï¼‰
--scale-down-delay-after-add=10m        # æ‰©å®¹å 10 åˆ†é’Ÿå†…ä¸ç¼©å®¹
--scale-down-delay-after-delete=0s      # åˆ é™¤èŠ‚ç‚¹åç«‹å³è¯„ä¼°å…¶ä»–èŠ‚ç‚¹
--scale-down-delay-after-failure=3m     # ç¼©å®¹å¤±è´¥å 3 åˆ†é’Ÿå†…ä¸é‡è¯•
```

### Expander ç­–ç•¥

**é€‰æ‹©èŠ‚ç‚¹ç»„çš„ç­–ç•¥ï¼ˆå½“å¤šä¸ªèŠ‚ç‚¹ç»„éƒ½æ»¡è¶³æ¡ä»¶æ—¶ï¼‰**

**1. random (é»˜è®¤)**
```bash
--expander=random
# éšæœºé€‰æ‹©ä¸€ä¸ªèŠ‚ç‚¹ç»„
```

**2. most-pods**
```bash
--expander=most-pods
# é€‰æ‹©èƒ½è°ƒåº¦æœ€å¤š Pending Pods çš„èŠ‚ç‚¹ç»„
```

**3. least-waste**
```bash
--expander=least-waste
# é€‰æ‹©æ·»åŠ èŠ‚ç‚¹åèµ„æºæµªè´¹æœ€å°‘çš„èŠ‚ç‚¹ç»„
# è®¡ç®—å…¬å¼: waste = (node_capacity - pod_requests) / node_capacity
```

**4. price**
```bash
--expander=price
# é€‰æ‹©æˆæœ¬æœ€ä½çš„èŠ‚ç‚¹ç»„ï¼ˆéœ€è¦äº‘ä¾›åº”å•†æ”¯æŒï¼‰
```

**5. priority**
```bash
--expander=priority
# æ ¹æ®é…ç½®çš„ä¼˜å…ˆçº§ ConfigMap é€‰æ‹©èŠ‚ç‚¹ç»„

# ConfigMap ç¤ºä¾‹
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-autoscaler-priority-expander
  namespace: kube-system
data:
  priorities: |-
    10:
      - .*-spot-.*   # ä¼˜å…ˆé€‰æ‹© Spot å®ä¾‹èŠ‚ç‚¹ç»„
    50:
      - .*-gpu-.*    # å…¶æ¬¡é€‰æ‹© GPU èŠ‚ç‚¹ç»„
    100:
      - .*           # æœ€åé€‰æ‹©å…¶ä»–èŠ‚ç‚¹ç»„
```

---

## Behavior è¡Œä¸ºé…ç½®

### v1.18+ Behavior å­—æ®µ

**å¼•å…¥ç‰ˆæœ¬**: Kubernetes v1.18+  
**ç¨³å®šç‰ˆæœ¬**: v1.23+

**ä½œç”¨**: ç²¾ç»†æ§åˆ¶ HPA çš„æ‰©ç¼©å®¹è¡Œä¸ºï¼Œé¿å…é¢‘ç¹æ³¢åŠ¨ã€‚

### å®Œæ•´é…ç½®ç¤ºä¾‹

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-app-advanced
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  minReplicas: 2
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0  # æ‰©å®¹æ— ç¨³å®šçª—å£
      policies:
      - type: Percent
        value: 100       # æ¯æ¬¡æœ€å¤šå¢åŠ  100% (ç¿»å€)
        periodSeconds: 15
      - type: Pods
        value: 4         # æ¯æ¬¡æœ€å¤šå¢åŠ  4 ä¸ª Pod
        periodSeconds: 15
      selectPolicy: Max  # å–ä¸¤ä¸ªç­–ç•¥çš„æœ€å¤§å€¼
    scaleDown:
      stabilizationWindowSeconds: 300  # ç¼©å®¹ç¨³å®šçª—å£ 5 åˆ†é’Ÿ
      policies:
      - type: Percent
        value: 50        # æ¯åˆ†é’Ÿæœ€å¤šå‡å°‘ 50%
        periodSeconds: 60
      - type: Pods
        value: 2         # æ¯åˆ†é’Ÿæœ€å¤šå‡å°‘ 2 ä¸ª Pod
        periodSeconds: 60
      selectPolicy: Min  # å–ä¸¤ä¸ªç­–ç•¥çš„æœ€å°å€¼ï¼ˆä¿å®ˆç¼©å®¹ï¼‰
```

### å­—æ®µè¯¦è§£

**1. stabilizationWindowSeconds**

**ä½œç”¨**: ç¨³å®šçª—å£æœŸï¼Œé¿å…æŒ‡æ ‡æŠ–åŠ¨å¯¼è‡´é¢‘ç¹æ‰©ç¼©å®¹ã€‚

**æ‰©å®¹çª—å£**
```yaml
scaleUp:
  stabilizationWindowSeconds: 0  # é»˜è®¤ 0ï¼Œç«‹å³æ‰©å®¹
```
- è®¾ä¸º 0: ä¸€æ—¦æŒ‡æ ‡è¶…è¿‡é˜ˆå€¼ï¼Œç«‹å³æ‰©å®¹
- è®¾ä¸º N: åœ¨è¿‡å» N ç§’å†…ï¼Œå–æ¨èå‰¯æœ¬æ•°çš„æœ€å¤§å€¼

**ç¼©å®¹çª—å£**
```yaml
scaleDown:
  stabilizationWindowSeconds: 300  # é»˜è®¤ 300 ç§’ï¼ˆ5 åˆ†é’Ÿï¼‰
```
- åœ¨è¿‡å» 300 ç§’å†…ï¼Œå–æ¨èå‰¯æœ¬æ•°çš„æœ€å°å€¼
- é¿å…æµé‡çŸ­æš‚ä¸‹é™å°±ç«‹å³ç¼©å®¹

**ç¤ºä¾‹**
```
æ—¶é—´çº¿ (ç¼©å®¹åœºæ™¯):
10:00 - æ¨èå‰¯æœ¬æ•°: 10
10:01 - æ¨èå‰¯æœ¬æ•°: 8
10:02 - æ¨èå‰¯æœ¬æ•°: 6  # æµé‡çŸ­æš‚ä¸‹é™
10:03 - æ¨èå‰¯æœ¬æ•°: 9  # æµé‡æ¢å¤
10:04 - æ¨èå‰¯æœ¬æ•°: 8
10:05 - æ¨èå‰¯æœ¬æ•°: 8

å®é™…ç¼©å®¹å†³ç­–ï¼ˆstabilizationWindowSeconds=300ï¼‰:
10:05 - å–è¿‡å» 5 åˆ†é’Ÿæœ€å°å€¼ = 6
      - ä½†ç”±äºçª—å£å†…æœ‰æ›´é«˜å€¼ï¼ˆ10ï¼‰ï¼Œä¸ä¼šç«‹å³ç¼©å®¹åˆ° 6
      - ä¿å®ˆç¼©å®¹ï¼Œé¿å…é¢‘ç¹æ³¢åŠ¨
```

---

**2. policies**

**ç±»å‹**: Percent æˆ– Pods

**Percent ç±»å‹**
```yaml
policies:
- type: Percent
  value: 50
  periodSeconds: 60
```
- å«ä¹‰: æ¯ 60 ç§’ï¼Œæœ€å¤šå¢åŠ /å‡å°‘ 50% çš„å‰¯æœ¬æ•°
- è®¡ç®—: maxChange = ceil(currentReplicas * 0.5)

**ç¤ºä¾‹**
```
å½“å‰å‰¯æœ¬æ•°: 10
Percent=50, periodSeconds=60

æœ€å¤§å˜åŒ–é‡ = ceil(10 * 0.5) = 5
å› æ­¤ï¼Œæ¯åˆ†é’Ÿæœ€å¤šå¢åŠ /å‡å°‘ 5 ä¸ªå‰¯æœ¬
```

**Pods ç±»å‹**
```yaml
policies:
- type: Pods
  value: 4
  periodSeconds: 60
```
- å«ä¹‰: æ¯ 60 ç§’ï¼Œæœ€å¤šå¢åŠ /å‡å°‘ 4 ä¸ª Pod

---

**3. selectPolicy**

**å¯é€‰å€¼**: Max, Min, Disabled

**Max** (æ‰©å®¹å¸¸ç”¨)
```yaml
scaleUp:
  policies:
  - type: Percent
    value: 100       # ç­–ç•¥ 1: æœ€å¤šç¿»å€
    periodSeconds: 15
  - type: Pods
    value: 4         # ç­–ç•¥ 2: æœ€å¤šå¢åŠ  4 ä¸ª
    periodSeconds: 15
  selectPolicy: Max  # å–æœ€å¤§å€¼
```

**ç¤ºä¾‹**
```
å½“å‰å‰¯æœ¬æ•°: 10

ç­–ç•¥ 1: 10 * 100% = 10 (å¯å¢åŠ  10 ä¸ªï¼Œå˜ä¸º 20)
ç­–ç•¥ 2: 4 (å¯å¢åŠ  4 ä¸ªï¼Œå˜ä¸º 14)

selectPolicy=Max: å– max(10, 4) = 10
ç»“æœ: æ‰©å®¹åˆ° 20 ä¸ªå‰¯æœ¬
```

**Min** (ç¼©å®¹å¸¸ç”¨)
```yaml
scaleDown:
  policies:
  - type: Percent
    value: 50        # ç­–ç•¥ 1: æœ€å¤šå‡å°‘ 50%
    periodSeconds: 60
  - type: Pods
    value: 2         # ç­–ç•¥ 2: æœ€å¤šå‡å°‘ 2 ä¸ª
    periodSeconds: 60
  selectPolicy: Min  # å–æœ€å°å€¼ï¼ˆä¿å®ˆç¼©å®¹ï¼‰
```

**ç¤ºä¾‹**
```
å½“å‰å‰¯æœ¬æ•°: 10

ç­–ç•¥ 1: 10 * 50% = 5 (å¯å‡å°‘ 5 ä¸ªï¼Œå˜ä¸º 5)
ç­–ç•¥ 2: 2 (å¯å‡å°‘ 2 ä¸ªï¼Œå˜ä¸º 8)

selectPolicy=Min: å– min(5, 2) = 2
ç»“æœ: ç¼©å®¹åˆ° 8 ä¸ªå‰¯æœ¬ï¼ˆæ›´ä¿å®ˆï¼‰
```

---

### å¸¸è§é…ç½®åœºæ™¯

**åœºæ™¯ 1: å¿«é€Ÿæ‰©å®¹ï¼Œæ…¢é€Ÿç¼©å®¹**
```yaml
behavior:
  scaleUp:
    stabilizationWindowSeconds: 0
    policies:
    - type: Percent
      value: 100
      periodSeconds: 15  # æ¯ 15 ç§’å¯ç¿»å€
    selectPolicy: Max
  scaleDown:
    stabilizationWindowSeconds: 300
    policies:
    - type: Pods
      value: 1           # æ¯åˆ†é’Ÿä»…å‡å°‘ 1 ä¸ª
      periodSeconds: 60
    selectPolicy: Min
```

**åœºæ™¯ 2: ç¦æ­¢ç¼©å®¹ï¼ˆä»…æ‰©å®¹ï¼‰**
```yaml
behavior:
  scaleDown:
    selectPolicy: Disabled  # å®Œå…¨ç¦æ­¢ç¼©å®¹
```

**åœºæ™¯ 3: å¹³æ»‘æ‰©ç¼©å®¹**
```yaml
behavior:
  scaleUp:
    stabilizationWindowSeconds: 60  # æ‰©å®¹ä¹Ÿæœ‰ç¨³å®šæœŸ
    policies:
    - type: Pods
      value: 2
      periodSeconds: 60
  scaleDown:
    stabilizationWindowSeconds: 300
    policies:
    - type: Pods
      value: 1
      periodSeconds: 60
```

---

## æ•…éšœæ’æŸ¥åœºæ™¯

### åœºæ™¯ 1: HPA æ— æ³•è·å–æŒ‡æ ‡

**ç—‡çŠ¶**
```bash
kubectl get hpa

NAME      REFERENCE          TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
web-app   Deployment/web-app <unknown>/70%   2         10        2          5m
```

**äº‹ä»¶**
```
Type: Warning
Reason: FailedGetResourceMetric
Message: failed to get cpu utilization: unable to get metrics for resource cpu
```

**æ’æŸ¥æ­¥éª¤**
```bash
# 1. æ£€æŸ¥ Metrics Server
kubectl get apiservice v1beta1.metrics.k8s.io
NAME                     SERVICE                      AVAILABLE
v1beta1.metrics.k8s.io   kube-system/metrics-server   False  # ä¸å¯ç”¨!

kubectl logs -n kube-system deployment/metrics-server

# 2. æ£€æŸ¥ Pod æ˜¯å¦å®šä¹‰ resources.requests
kubectl get deployment web-app -o yaml | grep -A 5 resources

# 3. æµ‹è¯•æŒ‡æ ‡è·å–
kubectl top pods -n production
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# å®‰è£…/ä¿®å¤ Metrics Server
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# æ·»åŠ  resources.requests
kubectl set resources deployment web-app --requests=cpu=100m,memory=128Mi
```

---

### åœºæ™¯ 2: HPA é¢‘ç¹æ‰©ç¼©å®¹

**ç—‡çŠ¶**
```bash
# æ¯åˆ†é’Ÿéƒ½åœ¨æ‰©ç¼©å®¹
Events:
  Normal  SuccessfulRescale  5m   New size: 8
  Normal  SuccessfulRescale  4m   New size: 6
  Normal  SuccessfulRescale  3m   New size: 9
  Normal  SuccessfulRescale  2m   New size: 7
```

**åŸå› åˆ†æ**
- æŒ‡æ ‡æ³¢åŠ¨å¤§
- ç›®æ ‡å€¼è®¾ç½®ä¸åˆç†
- ç¼ºå°‘ç¨³å®šçª—å£å’Œè¡Œä¸ºé…ç½®

**è§£å†³æ–¹æ¡ˆ**
```yaml
# æ·»åŠ  behavior é…ç½®
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
spec:
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # 5 åˆ†é’Ÿç¨³å®šçª—å£
      policies:
      - type: Pods
        value: 1
        periodSeconds: 60  # æ¯åˆ†é’Ÿæœ€å¤šå‡å°‘ 1 ä¸ª
    scaleUp:
      stabilizationWindowSeconds: 60   # æ‰©å®¹ä¹Ÿæ·»åŠ ç¨³å®šæœŸ
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
```

---

### åœºæ™¯ 3: Cluster Autoscaler ä¸æ‰©å®¹

**ç—‡çŠ¶**
```bash
kubectl get pods

NAME         STATUS    RESTARTS   AGE
web-app-1    Pending   0          10m  # ä¸€ç›´ Pending
```

**äº‹ä»¶**
```
Type: Warning
Reason: NotTriggerScaleUp
Message: pod didn't trigger scale-up: 2 max node group size reached
```

**æ’æŸ¥æ­¥éª¤**
```bash
# 1. æ£€æŸ¥èŠ‚ç‚¹ç»„é…ç½®
kubectl logs -n kube-system deployment/cluster-autoscaler | grep "max node group size"

# 2. æ£€æŸ¥ Pod èµ„æºè¯·æ±‚
kubectl describe pod web-app-1 | grep -A 5 "Requests"

# 3. æ£€æŸ¥èŠ‚ç‚¹ç»„çŠ¶æ€
aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names node-group-1
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# å¢åŠ èŠ‚ç‚¹ç»„æœ€å¤§å€¼
kubectl edit deployment cluster-autoscaler -n kube-system
# ä¿®æ”¹ --nodes=1:10:node-group-1 ä¸º --nodes=1:20:node-group-1
```

---

### åœºæ™¯ 4: VPA é©±é€ Pod å¤±è´¥

**ç—‡çŠ¶**
```
Type: Warning
Reason: UpdateFailed
Message: failed to evict pod: PodDisruptionBudget violation
```

**åŸå› **
- PodDisruptionBudget é™åˆ¶
- æ²¡æœ‰è¶³å¤Ÿçš„å¯ç”¨å‰¯æœ¬

**æ’æŸ¥æ­¥éª¤**
```bash
# æ£€æŸ¥ PDB
kubectl get pdb

NAME          MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
web-app-pdb   5               N/A               0                     10d
```

**è§£å†³æ–¹æ¡ˆ**
```yaml
# è°ƒæ•´ PDB
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: web-app-pdb
spec:
  minAvailable: 3  # é™ä½æœ€å°å¯ç”¨æ•°
  selector:
    matchLabels:
      app: web-app
```

---

## æœ€ä½³å®è·µ

### HPA æœ€ä½³å®è·µ

**1. åˆç†è®¾ç½®ç›®æ ‡å€¼**
```yaml
# âŒ ä¸æ¨è: ç›®æ ‡å€¼è¿‡é«˜
metrics:
- type: Resource
  resource:
    name: cpu
    target:
      averageUtilization: 90  # å®¹æ˜“ OOMã€å»¶è¿Ÿå¢åŠ 

# âœ… æ¨è: ç•™æœ‰ä½™é‡
metrics:
- type: Resource
  resource:
    name: cpu
    target:
      averageUtilization: 70  # 30% ç¼“å†²ç©ºé—´
```

**2. é…ç½® behavior é¿å…æŠ–åŠ¨**
```yaml
behavior:
  scaleUp:
    stabilizationWindowSeconds: 0
    policies:
    - type: Percent
      value: 100
      periodSeconds: 15
  scaleDown:
    stabilizationWindowSeconds: 300
    policies:
    - type: Pods
      value: 1
      periodSeconds: 60
```

**3. å¤šæŒ‡æ ‡ç»„åˆ**
```yaml
metrics:
- type: Resource
  resource:
    name: cpu
    target:
      averageUtilization: 70
- type: Resource
  resource:
    name: memory
    target:
      averageUtilization: 80
- type: Pods
  pods:
    metric:
      name: http_requests_per_second
    target:
      type: AverageValue
      averageValue: "1000"
```

---

### VPA æœ€ä½³å®è·µ

**1. åˆ†é˜¶æ®µéƒ¨ç½²**
```
Phase 1: Off æ¨¡å¼ - è§‚å¯Ÿæ¨èå€¼ (1-2 å‘¨)
Phase 2: Initial æ¨¡å¼ - æ–° Pod åº”ç”¨æ¨è (1 å‘¨)
Phase 3: Auto æ¨¡å¼ - è‡ªåŠ¨æ›´æ–° (ç”Ÿäº§ç¯å¢ƒ)
```

**2. è®¾ç½®åˆç†è¾¹ç•Œ**
```yaml
resourcePolicy:
  containerPolicies:
  - containerName: app
    minAllowed:
      cpu: 100m      # é˜²æ­¢è¿‡ä½
      memory: 128Mi
    maxAllowed:
      cpu: 4         # é˜²æ­¢è¿‡é«˜
      memory: 8Gi
```

**3. é…åˆ PDB ä½¿ç”¨**
```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: app-pdb
spec:
  minAvailable: 50%  # ç¡®ä¿ VPA é©±é€æ—¶æœåŠ¡å¯ç”¨
```

---

### Cluster Autoscaler æœ€ä½³å®è·µ

**1. åˆç†é…ç½®èŠ‚ç‚¹ç»„**
```bash
# å¤šä¸ªèŠ‚ç‚¹ç»„æ»¡è¶³ä¸åŒå·¥ä½œè´Ÿè½½
--nodes=1:10:general-purpose-nodes  # é€šç”¨å·¥ä½œè´Ÿè½½
--nodes=0:5:gpu-nodes               # GPU å·¥ä½œè´Ÿè½½
--nodes=0:20:spot-nodes             # Spot å®ä¾‹ï¼ˆæˆæœ¬ä¼˜åŒ–ï¼‰
```

**2. è®¾ç½®èŠ‚ç‚¹ä¿æŠ¤**
```yaml
# å…³é”®èŠ‚ç‚¹ä¿æŠ¤
apiVersion: v1
kind: Node
metadata:
  annotations:
    cluster-autoscaler.kubernetes.io/scale-down-disabled: "true"

# Pod çº§åˆ«ä¿æŠ¤
apiVersion: v1
kind: Pod
metadata:
  annotations:
    cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
```

**3. ä¼˜åŒ–ç¼©å®¹å‚æ•°**
```bash
--scale-down-delay-after-add=10m        # æ‰©å®¹å 10 åˆ†é’Ÿä¸ç¼©å®¹
--scale-down-unneeded-time=10m          # èŠ‚ç‚¹ç©ºé—² 10 åˆ†é’Ÿæ‰ç¼©å®¹
--scale-down-utilization-threshold=0.5  # åˆ©ç”¨ç‡ä½äº 50% æ‰è€ƒè™‘ç¼©å®¹
```

---

## äº¤å‰å¼•ç”¨

### ç›¸å…³æ–‡æ¡£

| æ–‡æ¡£ | æè¿° |
|------|------|
| **domain-33-kubernetes-events/01-pod-lifecycle-events.md** | Pod ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ï¼ŒåŒ…æ‹¬ Pending çŠ¶æ€ |
| **domain-33-kubernetes-events/02-scheduling-events.md** | è°ƒåº¦äº‹ä»¶ï¼ŒCA æ‰©å®¹åçš„è°ƒåº¦è¿‡ç¨‹ |
| **domain-33-kubernetes-events/05-resource-events.md** | èµ„æºé…é¢äº‹ä»¶ï¼ŒHPA/CA å—é™åœºæ™¯ |
| **domain-33-kubernetes-events/11-metrics-monitoring-events.md** | Metrics Server äº‹ä»¶ï¼ŒHPA æŒ‡æ ‡æº |
| **domain-5-networking/30-service-mesh-deep-dive.md** | Service Mesh ç¯å¢ƒä¸‹çš„è‡ªåŠ¨æ‰©ç¼©å®¹ |
| **topic-structural-trouble-shooting/05-workloads/02-deployment-troubleshooting.md** | Deployment æ•…éšœæ’æŸ¥ |

### ç›¸å…³å‘½ä»¤

```bash
# HPA
kubectl get hpa
kubectl describe hpa <name>
kubectl top pods

# VPA
kubectl get vpa
kubectl describe vpa <name>

# Cluster Autoscaler
kubectl logs -n kube-system deployment/cluster-autoscaler
kubectl get nodes
kubectl describe node <name>

# äº‹ä»¶æŸ¥è¯¢
kubectl get events --sort-by='.lastTimestamp' | grep -E 'HorizontalPodAutoscaler|VPA|cluster-autoscaler'
```

---

> **KUDIG-DATABASE** | Domain-33: Kubernetes Events å…¨åŸŸäº‹ä»¶å¤§å…¨ | æ–‡æ¡£ 12/15
