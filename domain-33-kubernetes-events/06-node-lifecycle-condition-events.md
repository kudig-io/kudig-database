# 06 - èŠ‚ç‚¹ç”Ÿå‘½å‘¨æœŸä¸çŠ¶æ€äº‹ä»¶

> **é€‚ç”¨ç‰ˆæœ¬**: Kubernetes v1.25 - v1.32 | **æœ€åæ›´æ–°**: 2026-02 | **ä½œè€…**: Allen Galler

---

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [èŠ‚ç‚¹ç”Ÿå‘½å‘¨æœŸçŠ¶æ€æœº](#èŠ‚ç‚¹ç”Ÿå‘½å‘¨æœŸçŠ¶æ€æœº)
- [èŠ‚ç‚¹çŠ¶æ€ç±»å‹è¯¦è§£](#èŠ‚ç‚¹çŠ¶æ€ç±»å‹è¯¦è§£)
- [Kubelet èŠ‚ç‚¹çŠ¶æ€äº‹ä»¶](#kubelet-èŠ‚ç‚¹çŠ¶æ€äº‹ä»¶)
- [Node Controller äº‹ä»¶](#node-controller-äº‹ä»¶)
- [èŠ‚ç‚¹é©±é€æœºåˆ¶](#èŠ‚ç‚¹é©±é€æœºåˆ¶)
- [ç”Ÿäº§ç¯å¢ƒç›‘æ§å»ºè®®](#ç”Ÿäº§ç¯å¢ƒç›‘æ§å»ºè®®)

---

## æ¦‚è¿°

èŠ‚ç‚¹ï¼ˆNodeï¼‰æ˜¯ Kubernetes é›†ç¾¤ä¸­çš„å·¥ä½œæœºå™¨ï¼Œå¯ä»¥æ˜¯ç‰©ç†æœºæˆ–è™šæ‹Ÿæœºã€‚èŠ‚ç‚¹çš„å¥åº·çŠ¶æ€ç›´æ¥å½±å“é›†ç¾¤çš„å¯ç”¨æ€§å’Œç¨³å®šæ€§ã€‚æœ¬æ–‡æ¡£è¯¦ç»†è®°å½•äº†èŠ‚ç‚¹ç”Ÿå‘½å‘¨æœŸä¸­çš„æ‰€æœ‰å…³é”®äº‹ä»¶ï¼ŒåŒ…æ‹¬ï¼š

- **kubelet èŠ‚ç‚¹çŠ¶æ€äº‹ä»¶**ï¼šç”±èŠ‚ç‚¹ä¸Šçš„ kubelet ç»„ä»¶äº§ç”Ÿï¼Œåæ˜ èŠ‚ç‚¹çš„å®æ—¶å¥åº·çŠ¶å†µ
- **Node Controller äº‹ä»¶**ï¼šç”±æ§åˆ¶å¹³é¢çš„ node-controller äº§ç”Ÿï¼Œè´Ÿè´£èŠ‚ç‚¹çš„æ³¨å†Œã€ç›‘æ§å’Œé©±é€é€»è¾‘
- **èµ„æºå‹åŠ›äº‹ä»¶**ï¼šå†…å­˜ã€ç£ç›˜ã€PID ç­‰èµ„æºä¸è¶³æ—¶è§¦å‘çš„äº‹ä»¶
- **é©±é€äº‹ä»¶**ï¼šèŠ‚ç‚¹èµ„æºå‹åŠ›å¯¼è‡´çš„ Pod é©±é€äº‹ä»¶

---

## èŠ‚ç‚¹ç”Ÿå‘½å‘¨æœŸçŠ¶æ€æœº

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Node Lifecycle State Machine                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    [New Node]
        â”‚
        â”œâ”€> kubelet starts
        â”‚   Event: Starting
        â”‚
        â”œâ”€> Node registers with API Server
        â”‚   Event: RegisteredNode (node-controller)
        â”‚
        â”œâ”€> Initial status: NodeNotReady
        â”‚   Event: NodeNotReady
        â”‚
        â”œâ”€> kubelet initializes (network, runtime, etc.)
        â”‚
        â”œâ”€> Node becomes ready
        â”‚   Event: NodeReady
        â”‚   Condition: Ready=True
        â”‚
        â”œâ”€> Normal Operation
        â”‚   â”œâ”€> Periodic heartbeat (node status updates)
        â”‚   â”œâ”€> Resource monitoring
        â”‚   â””â”€> Condition updates
        â”‚
        â”œâ”€> Resource Pressure Detected
        â”‚   â”œâ”€> MemoryPressure: NodeHasInsufficientMemory
        â”‚   â”œâ”€> DiskPressure: NodeHasDiskPressure
        â”‚   â””â”€> PIDPressure: NodeHasInsufficientPID
        â”‚
        â”œâ”€> Eviction Threshold Met
        â”‚   Event: EvictionThresholdMet
        â”‚   â””â”€> Start evicting pods
        â”‚
        â”œâ”€> Node Becomes Unhealthy
        â”‚   Event: NodeNotReady
        â”‚   â””â”€> node-controller starts monitoring
        â”‚
        â”œâ”€> Grace Period Expired (default: 5min)
        â”‚   Event: DeletingAllPods
        â”‚   â””â”€> Force terminate pods
        â”‚
        â””â”€> Node Removal
            Event: RemovingNode / DeletingNode

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Schedulability States                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    NodeSchedulable â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ NodeNotSchedulable
    (spec.unschedulable=false)      (spec.unschedulable=true)
                                    (kubectl cordon)
```

---

## èŠ‚ç‚¹çŠ¶æ€ç±»å‹è¯¦è§£

Kubernetes èŠ‚ç‚¹æœ‰ä»¥ä¸‹äº”ç§æ ¸å¿ƒ Condition ç±»å‹ï¼š

| Condition Type | å«ä¹‰ | True çŠ¶æ€ | False çŠ¶æ€ | Unknown çŠ¶æ€ |
|:---|:---|:---|:---|:---|
| **Ready** | èŠ‚ç‚¹æ˜¯å¦å¥åº·å¹¶å‡†å¤‡æ¥å— Pod | èŠ‚ç‚¹å¥åº·ï¼Œå¯è°ƒåº¦ | èŠ‚ç‚¹ä¸å¥åº· | node-controller æ— æ³•è¿æ¥ |
| **MemoryPressure** | èŠ‚ç‚¹å†…å­˜æ˜¯å¦ç´§å¼  | å†…å­˜ä¸è¶³ | å†…å­˜å……è¶³ | æ— æ³•æ£€æµ‹ |
| **DiskPressure** | èŠ‚ç‚¹ç£ç›˜æ˜¯å¦ç´§å¼  | ç£ç›˜ä¸è¶³ | ç£ç›˜å……è¶³ | æ— æ³•æ£€æµ‹ |
| **PIDPressure** | èŠ‚ç‚¹è¿›ç¨‹ ID æ˜¯å¦ç´§å¼  | PID ä¸è¶³ | PID å……è¶³ | æ— æ³•æ£€æµ‹ |
| **NetworkUnavailable** | èŠ‚ç‚¹ç½‘ç»œæ˜¯å¦ä¸å¯ç”¨ | ç½‘ç»œé…ç½®é”™è¯¯ | ç½‘ç»œæ­£å¸¸ | æ— æ³•æ£€æµ‹ |

---

## Kubelet èŠ‚ç‚¹çŠ¶æ€äº‹ä»¶

### `Starting` - kubelet å¯åŠ¨

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Normal |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (ä»…åœ¨ kubelet å¯åŠ¨æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤ºèŠ‚ç‚¹ä¸Šçš„ kubelet ç»„ä»¶æ­£åœ¨å¯åŠ¨ã€‚kubelet æ˜¯æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„æ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£ç®¡ç† Pod å’Œå®¹å™¨çš„ç”Ÿå‘½å‘¨æœŸï¼Œä¸ API Server é€šä¿¡ï¼Œå¹¶æŠ¥å‘ŠèŠ‚ç‚¹çŠ¶æ€ã€‚

åœ¨ kubelet å¯åŠ¨æ—¶ï¼Œå®ƒä¼šè¿›è¡Œä¸€ç³»åˆ—åˆå§‹åŒ–æ“ä½œï¼ŒåŒ…æ‹¬åŠ è½½é…ç½®ã€åˆå§‹åŒ–å®¹å™¨è¿è¡Œæ—¶å®¢æˆ·ç«¯ã€è®¾ç½®ç½‘ç»œã€æ³¨å†ŒèŠ‚ç‚¹åˆ° API Server ç­‰ã€‚æ­¤äº‹ä»¶æ˜¯èŠ‚ç‚¹ç”Ÿå‘½å‘¨æœŸçš„èµ·ç‚¹ã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Normal
Reason:  Starting
Message: Starting kubelet.
Source:  kubelet, node1.example.com
```

#### å½±å“é¢è¯´æ˜

- **é›†ç¾¤å½±å“**ï¼šå•ä¸ªèŠ‚ç‚¹çš„ kubelet å¯åŠ¨ä¸å½±å“å…¶ä»–èŠ‚ç‚¹
- **è°ƒåº¦å½±å“**ï¼šåœ¨èŠ‚ç‚¹å˜ä¸º Ready ä¹‹å‰ï¼Œscheduler ä¸ä¼šå°† Pod è°ƒåº¦åˆ°æ­¤èŠ‚ç‚¹
- **ç°æœ‰ Pod**ï¼šå¦‚æœæ˜¯é‡å¯ï¼ŒèŠ‚ç‚¹ä¸Šçš„ Pod éœ€è¦é‡æ–°åŒæ­¥å’Œå¯åŠ¨

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹ kubelet å¯åŠ¨äº‹ä»¶
kubectl get events --field-selector involvedObject.kind=Node,reason=Starting

# æ£€æŸ¥ kubelet æœåŠ¡çŠ¶æ€
systemctl status kubelet

# æŸ¥çœ‹ kubelet å¯åŠ¨æ—¥å¿—
journalctl -u kubelet -n 100 --no-pager

# æ£€æŸ¥ kubelet é…ç½®
kubelet --version
ps aux | grep kubelet
```

#### è§£å†³å»ºè®®

| åœºæ™¯ | å»ºè®® |
|:---|:---|
| æ­£å¸¸å¯åŠ¨ | æ— éœ€å¤„ç†ï¼Œç­‰å¾…èŠ‚ç‚¹å˜ä¸º Ready |
| åå¤é‡å¯ | æ£€æŸ¥ kubelet æ—¥å¿—ï¼Œå¯èƒ½æ˜¯é…ç½®é”™è¯¯æˆ–ä¾èµ–æœåŠ¡æœªå¯åŠ¨ |
| å¯åŠ¨å¤±è´¥ | æ£€æŸ¥å®¹å™¨è¿è¡Œæ—¶(containerd/docker)æ˜¯å¦æ­£å¸¸è¿è¡Œ |
| å¯åŠ¨ç¼“æ…¢ | æ£€æŸ¥ç½‘ç»œè¿é€šæ€§å’Œ API Server å¯è¾¾æ€§ |

---

### `NodeReady` - èŠ‚ç‚¹å°±ç»ª

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Normal |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (çŠ¶æ€å˜åŒ–æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤ºèŠ‚ç‚¹å·²æˆåŠŸé€šè¿‡æ‰€æœ‰å¥åº·æ£€æŸ¥ï¼Œå˜ä¸º Ready çŠ¶æ€ï¼Œå¯ä»¥æ¥å— Pod è°ƒåº¦ã€‚kubelet ä¼šå®šæœŸæ£€æŸ¥èŠ‚ç‚¹çš„å„é¡¹èµ„æºå’Œç»„ä»¶çŠ¶æ€ï¼ŒåŒ…æ‹¬å®¹å™¨è¿è¡Œæ—¶ã€ç½‘ç»œæ’ä»¶ã€å­˜å‚¨æ’ä»¶ç­‰ã€‚

å½“èŠ‚ç‚¹çš„ Ready Condition ä» False/Unknown å˜ä¸º True æ—¶ï¼Œä¼šäº§ç”Ÿæ­¤äº‹ä»¶ã€‚è¿™æ˜¯èŠ‚ç‚¹ç”Ÿå‘½å‘¨æœŸä¸­çš„é‡è¦é‡Œç¨‹ç¢‘ï¼Œæ ‡å¿—ç€èŠ‚ç‚¹å¯ä»¥å¼€å§‹æ‰¿è½½å·¥ä½œè´Ÿè½½ã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Normal
Reason:  NodeReady
Message: Node node1.example.com status is now: NodeReady
Source:  kubelet, node1.example.com
```

```bash
# kubectl describe node è¾“å‡º
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  Ready            True    Mon, 10 Feb 2026 10:30:00 +0800  Mon, 10 Feb 2026 10:25:00 +0800  KubeletReady                 kubelet is posting ready status
```

#### å½±å“é¢è¯´æ˜

- **é›†ç¾¤å½±å“**ï¼šå¢åŠ é›†ç¾¤çš„å¯ç”¨å®¹é‡
- **è°ƒåº¦å½±å“**ï¼šscheduler å¼€å§‹å¯ä»¥å°† Pod è°ƒåº¦åˆ°æ­¤èŠ‚ç‚¹
- **ç°æœ‰ Pod**ï¼šå¦‚æœæ˜¯ä» NotReady æ¢å¤ï¼ŒèŠ‚ç‚¹ä¸Šçš„ Pod ä¼šé‡æ–°å¯åŠ¨

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€
kubectl get nodes

# æŸ¥çœ‹èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
kubectl describe node <node-name>

# æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€å†å²
kubectl get events --field-selector involvedObject.kind=Node,involvedObject.name=<node-name> --sort-by='.lastTimestamp'

# æ£€æŸ¥èŠ‚ç‚¹èµ„æºå®¹é‡
kubectl get node <node-name> -o jsonpath='{.status.capacity}' | jq

# æ£€æŸ¥èŠ‚ç‚¹å¯åˆ†é…èµ„æº
kubectl get node <node-name> -o jsonpath='{.status.allocatable}' | jq
```

#### è§£å†³å»ºè®®

| åœºæ™¯ | å»ºè®® |
|:---|:---|
| æ–°èŠ‚ç‚¹å˜ä¸º Ready | æ­£å¸¸æƒ…å†µï¼Œå¯ä»¥å¼€å§‹è°ƒåº¦ Pod |
| èŠ‚ç‚¹ä» NotReady æ¢å¤ | æ£€æŸ¥ä¹‹å‰å¤±è´¥çš„åŸå› ï¼Œç¡®ä¿æ ¹æœ¬é—®é¢˜å·²è§£å†³ |
| Ready çŠ¶æ€ä¸ç¨³å®š | æ£€æŸ¥ç½‘ç»œã€å­˜å‚¨ç­‰åº•å±‚åŸºç¡€è®¾æ–½ç¨³å®šæ€§ |
| åå¤ Ready/NotReady | å¯èƒ½æ˜¯ kubelet å¿ƒè·³è¶…æ—¶ï¼Œæ£€æŸ¥ API Server è¿æ¥å’Œæ€§èƒ½ |

---

### `NodeNotReady` - èŠ‚ç‚¹æœªå°±ç»ª

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Warning |
| **æ¥æºç»„ä»¶** | kubelet / node-controller |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (æ•…éšœæ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤ºèŠ‚ç‚¹çš„å¥åº·æ£€æŸ¥å¤±è´¥ï¼ŒèŠ‚ç‚¹å˜ä¸º NotReady çŠ¶æ€ã€‚è¿™å¯èƒ½æ˜¯ç”±äº kubelet æœ¬èº«çš„é—®é¢˜ã€å®¹å™¨è¿è¡Œæ—¶æ•…éšœã€ç½‘ç»œé—®é¢˜æˆ–å…¶ä»–å…³é”®ç»„ä»¶æ•…éšœå¯¼è‡´çš„ã€‚

å½“èŠ‚ç‚¹å˜ä¸º NotReady çŠ¶æ€æ—¶ï¼Œscheduler å°†ä¸å†è°ƒåº¦æ–°çš„ Pod åˆ°æ­¤èŠ‚ç‚¹ã€‚å¦‚æœèŠ‚ç‚¹æŒç»­ NotReady è¶…è¿‡ä¸€å®šæ—¶é—´ï¼ˆé»˜è®¤ 5 åˆ†é’Ÿï¼‰ï¼Œnode-controller ä¼šå¼€å§‹é©±é€èŠ‚ç‚¹ä¸Šçš„ Podã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Warning
Reason:  NodeNotReady
Message: Node node1.example.com status is now: NodeNotReady
Source:  kubelet, node1.example.com
```

```bash
# kubectl describe node è¾“å‡º
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  Ready            False   Mon, 10 Feb 2026 10:30:00 +0800  Mon, 10 Feb 2026 10:35:00 +0800  KubeletNotReady              container runtime not responding
```

æˆ–è€…ç”± node-controller æ£€æµ‹åˆ°å¿ƒè·³è¶…æ—¶ï¼š

```yaml
Type:    Warning
Reason:  NodeNotReady
Message: Node node1.example.com status is now: NodeNotReady (node-controller detected)
Source:  node-controller
```

#### å½±å“é¢è¯´æ˜

- **é›†ç¾¤å½±å“**ï¼šå‡å°‘é›†ç¾¤å¯ç”¨å®¹é‡ï¼Œå¯èƒ½è§¦å‘å‘Šè­¦
- **è°ƒåº¦å½±å“**ï¼šæ–° Pod ä¸ä¼šè¢«è°ƒåº¦åˆ°æ­¤èŠ‚ç‚¹
- **ç°æœ‰ Pod**ï¼š
  - ç«‹å³å½±å“ï¼šPod çŠ¶æ€å˜ä¸º Unknown
  - 5 åˆ†é’Ÿåï¼ˆé»˜è®¤ pod-eviction-timeoutï¼‰ï¼šPod è¢«é©±é€ï¼Œåœ¨å…¶ä»–èŠ‚ç‚¹é‡å»º
- **æœåŠ¡å½±å“**ï¼šå¦‚æœèŠ‚ç‚¹ä¸Šæœ‰ Service çš„ endpointsï¼Œä¼šè¢«æ ‡è®°ä¸º NotReady

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€å’Œæ¡ä»¶
kubectl get nodes
kubectl describe node <node-name>

# æŸ¥çœ‹èŠ‚ç‚¹äº‹ä»¶
kubectl get events --field-selector involvedObject.kind=Node,involvedObject.name=<node-name> --sort-by='.lastTimestamp'

# æ£€æŸ¥ kubelet æœåŠ¡çŠ¶æ€ï¼ˆéœ€è¦ç™»å½•èŠ‚ç‚¹ï¼‰
systemctl status kubelet
journalctl -u kubelet -n 100 --no-pager

# æ£€æŸ¥å®¹å™¨è¿è¡Œæ—¶çŠ¶æ€
systemctl status containerd  # æˆ– docker
crictl info
crictl pods

# æ£€æŸ¥èŠ‚ç‚¹èµ„æº
top
free -h
df -h
iostat -x 1 5

# æ£€æŸ¥ç½‘ç»œè¿é€šæ€§
ping <api-server-ip>
curl -k https://<api-server-ip>:6443/healthz

# æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—
journalctl -n 200 --no-pager
dmesg | tail -100
```

#### è§£å†³å»ºè®®

| åŸå›  | è§£å†³æ–¹æ¡ˆ |
|:---|:---|
| kubelet è¿›ç¨‹åœæ­¢ | `systemctl restart kubelet` |
| å®¹å™¨è¿è¡Œæ—¶æ•…éšœ | é‡å¯å®¹å™¨è¿è¡Œæ—¶: `systemctl restart containerd` |
| ç½‘ç»œè¿æ¥ä¸­æ–­ | æ£€æŸ¥å¹¶ä¿®å¤ç½‘ç»œé…ç½®ï¼Œç¡®ä¿å¯ä»¥è®¿é—® API Server |
| èµ„æºè€—å°½ (å†…å­˜/ç£ç›˜) | æ¸…ç†èµ„æºï¼Œé‡Šæ”¾ç©ºé—´ï¼Œå¢åŠ èµ„æºé…é¢ |
| ç³»ç»Ÿè´Ÿè½½è¿‡é«˜ | å‡å°‘èŠ‚ç‚¹è´Ÿè½½ï¼Œè¿ç§»éƒ¨åˆ† Pod |
| è¯ä¹¦è¿‡æœŸ | æ›´æ–° kubelet è¯ä¹¦ï¼Œé‡å¯ kubelet |
| API Server ä¸å¯è¾¾ | æ£€æŸ¥é˜²ç«å¢™ã€ç½‘ç»œç­–ç•¥ï¼Œç¡®ä¿ API Server å¥åº· |
| CNI æ’ä»¶æ•…éšœ | æ£€æŸ¥å¹¶ä¿®å¤ CNI æ’ä»¶é…ç½® |

---

### `NodeSchedulable` - èŠ‚ç‚¹å¯è°ƒåº¦

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Normal |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (è°ƒåº¦çŠ¶æ€å˜åŒ–æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤ºèŠ‚ç‚¹çš„ `spec.unschedulable` å­—æ®µè¢«è®¾ç½®ä¸º `false`ï¼ŒèŠ‚ç‚¹æ¢å¤å¯è°ƒåº¦çŠ¶æ€ã€‚è¿™é€šå¸¸å‘ç”Ÿåœ¨æ‰§è¡Œ `kubectl uncordon` å‘½ä»¤ä¹‹åã€‚

èŠ‚ç‚¹å¯è°ƒåº¦æ„å‘³ç€ Kubernetes scheduler å¯ä»¥å°†æ–°çš„ Pod è°ƒåº¦åˆ°æ­¤èŠ‚ç‚¹ã€‚è¿™ä¸å½±å“å·²ç»è¿è¡Œåœ¨èŠ‚ç‚¹ä¸Šçš„ Podã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Normal
Reason:  NodeSchedulable
Message: Node node1.example.com status is now: NodeSchedulable
Source:  kubelet, node1.example.com
```

#### å½±å“é¢è¯´æ˜

- **é›†ç¾¤å½±å“**ï¼šå¢åŠ é›†ç¾¤çš„å¯è°ƒåº¦å®¹é‡
- **è°ƒåº¦å½±å“**ï¼šscheduler å¯ä»¥è°ƒåº¦æ–° Pod åˆ°æ­¤èŠ‚ç‚¹
- **ç°æœ‰ Pod**ï¼šä¸å—å½±å“ï¼Œç»§ç»­è¿è¡Œ

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹å¯è°ƒåº¦çŠ¶æ€
kubectl get nodes
kubectl get node <node-name> -o jsonpath='{.spec.unschedulable}'

# æŸ¥çœ‹èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
kubectl describe node <node-name>

# å–æ¶ˆèŠ‚ç‚¹ä¸å¯è°ƒåº¦æ ‡è®°
kubectl uncordon <node-name>
```

#### è§£å†³å»ºè®®

| åœºæ™¯ | å»ºè®® |
|:---|:---|
| ç»´æŠ¤åæ¢å¤ | æ­£å¸¸æ“ä½œï¼Œç¡®è®¤èŠ‚ç‚¹å¥åº·åå…è®¸è°ƒåº¦ |
| è‡ªåŠ¨æ¢å¤ | æ£€æŸ¥æ˜¯å¦æœ‰è‡ªåŠ¨åŒ–å·¥å…·è¯¯æ“ä½œ |
| æ„å¤–å˜åŒ– | å®¡è®¡ API Server æ—¥å¿—ï¼ŒæŸ¥æ‰¾æ“ä½œæ¥æº |

---

### `NodeNotSchedulable` - èŠ‚ç‚¹ä¸å¯è°ƒåº¦

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Normal |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (è°ƒåº¦çŠ¶æ€å˜åŒ–æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤ºèŠ‚ç‚¹çš„ `spec.unschedulable` å­—æ®µè¢«è®¾ç½®ä¸º `true`ï¼ŒèŠ‚ç‚¹è¢«æ ‡è®°ä¸ºä¸å¯è°ƒåº¦ã€‚è¿™é€šå¸¸ç”±ç®¡ç†å‘˜æ‰§è¡Œ `kubectl cordon` å‘½ä»¤è§¦å‘ï¼Œç”¨äºç»´æŠ¤å‰çš„å‡†å¤‡å·¥ä½œã€‚

èŠ‚ç‚¹ä¸å¯è°ƒåº¦æ„å‘³ç€ scheduler ä¸ä¼šå°†æ–°çš„ Pod è°ƒåº¦åˆ°æ­¤èŠ‚ç‚¹ï¼Œä½†å·²ç»è¿è¡Œçš„ Pod ä¸å—å½±å“ï¼Œç»§ç»­æ­£å¸¸è¿è¡Œã€‚è¿™æ˜¯å®‰å…¨æ’ç©ºèŠ‚ç‚¹ï¼ˆdrainï¼‰çš„ç¬¬ä¸€æ­¥ã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Normal
Reason:  NodeNotSchedulable
Message: Node node1.example.com status is now: NodeNotSchedulable
Source:  kubelet, node1.example.com
```

```bash
# kubectl get nodes è¾“å‡º
NAME                 STATUS                     ROLES    AGE   VERSION
node1.example.com    Ready,SchedulingDisabled   worker   10d   v1.28.0
```

#### å½±å“é¢è¯´æ˜

- **é›†ç¾¤å½±å“**ï¼šå‡å°‘é›†ç¾¤çš„å¯è°ƒåº¦å®¹é‡
- **è°ƒåº¦å½±å“**ï¼šæ–° Pod ä¸ä¼šè¢«è°ƒåº¦åˆ°æ­¤èŠ‚ç‚¹
- **ç°æœ‰ Pod**ï¼šä¸å—å½±å“ï¼Œç»§ç»­è¿è¡Œ
- **DaemonSet**ï¼šå³ä½¿èŠ‚ç‚¹ä¸å¯è°ƒåº¦ï¼ŒDaemonSet Pod ä»ä¼šè¢«è°ƒåº¦

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹ä¸å¯è°ƒåº¦çš„èŠ‚ç‚¹
kubectl get nodes | grep SchedulingDisabled

# æŸ¥çœ‹èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
kubectl describe node <node-name>

# æŸ¥çœ‹èŠ‚ç‚¹ unschedulable å­—æ®µ
kubectl get node <node-name> -o jsonpath='{.spec.unschedulable}'

# æŸ¥çœ‹ç›¸å…³äº‹ä»¶
kubectl get events --field-selector involvedObject.kind=Node,involvedObject.name=<node-name>

# æ ‡è®°èŠ‚ç‚¹ä¸ºä¸å¯è°ƒåº¦
kubectl cordon <node-name>

# æ¢å¤èŠ‚ç‚¹å¯è°ƒåº¦
kubectl uncordon <node-name>
```

#### è§£å†³å»ºè®®

| åœºæ™¯ | å»ºè®® |
|:---|:---|
| è®¡åˆ’ç»´æŠ¤ | æ­£å¸¸æ“ä½œæµç¨‹ï¼šcordon â†’ drain â†’ ç»´æŠ¤ â†’ uncordon |
| æ’æŸ¥é—®é¢˜ | æš‚æ—¶éš”ç¦»èŠ‚ç‚¹ï¼Œé˜²æ­¢æ–° Pod è°ƒåº¦åˆ°æœ‰é—®é¢˜çš„èŠ‚ç‚¹ |
| æ„å¤–æ ‡è®° | æ‰§è¡Œ `kubectl uncordon` æ¢å¤è°ƒåº¦ |
| é•¿æœŸä¸å¯è°ƒåº¦ | è€ƒè™‘æ˜¯å¦åº”è¯¥åˆ é™¤èŠ‚ç‚¹æˆ–è§£å†³æ ¹æœ¬é—®é¢˜ |

---

### `NodeHasSufficientMemory` - èŠ‚ç‚¹å†…å­˜å……è¶³

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Normal |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.4+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (MemoryPressure çŠ¶æ€å˜åŒ–æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤ºèŠ‚ç‚¹çš„å¯ç”¨å†…å­˜æ¢å¤åˆ°æ­£å¸¸æ°´å¹³ï¼ŒMemoryPressure condition ä» True å˜ä¸º Falseã€‚kubelet ä¼šå®šæœŸæ£€æŸ¥èŠ‚ç‚¹çš„å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œå½“å¯ç”¨å†…å­˜è¶…è¿‡é©±é€é˜ˆå€¼æ—¶ï¼Œä¼šäº§ç”Ÿæ­¤äº‹ä»¶ã€‚

è¿™æ„å‘³ç€èŠ‚ç‚¹ä»å†…å­˜å‹åŠ›çŠ¶æ€ä¸­æ¢å¤ï¼Œå¯ä»¥ç»§ç»­æ¥å—æ–°çš„ Pod è°ƒåº¦ï¼ˆå¦‚æœä¹‹å‰å› å†…å­˜å‹åŠ›è¢«æ ‡è®°ä¸ºä¸å¯è°ƒåº¦ï¼‰ã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Normal
Reason:  NodeHasSufficientMemory
Message: Node node1.example.com status is now: NodeHasSufficientMemory
Source:  kubelet, node1.example.com
```

```bash
# kubectl describe node è¾“å‡º
Conditions:
  Type             Status  Reason                  Message
  ----             ------  ------                  -------
  MemoryPressure   False   KubeletHasSufficientMemory   kubelet has sufficient memory available
```

#### å½±å“é¢è¯´æ˜

- **é›†ç¾¤å½±å“**ï¼šèŠ‚ç‚¹æ¢å¤æ­£å¸¸æœåŠ¡èƒ½åŠ›
- **è°ƒåº¦å½±å“**ï¼šå¦‚æœä¹‹å‰å›  MemoryPressure è¢« scheduler é¿å…ï¼Œç°åœ¨å¯ä»¥æ­£å¸¸è°ƒåº¦
- **é©±é€å½±å“**ï¼šåœæ­¢åŸºäºå†…å­˜å‹åŠ›çš„ Pod é©±é€

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹ MemoryPressure çŠ¶æ€
kubectl get node <node-name> -o jsonpath='{.status.conditions[?(@.type=="MemoryPressure")]}'

# æŸ¥çœ‹èŠ‚ç‚¹å†…å­˜ä½¿ç”¨æƒ…å†µ
kubectl describe node <node-name> | grep -A 5 "Allocated resources"

# ç™»å½•èŠ‚ç‚¹æŸ¥çœ‹å†…å­˜
free -h
vmstat 1 5

# æŸ¥çœ‹èŠ‚ç‚¹ä¸Š Pod çš„å†…å­˜ä½¿ç”¨
kubectl top pods --all-namespaces --field-selector spec.nodeName=<node-name> --sort-by=memory
```

#### è§£å†³å»ºè®®

| åœºæ™¯ | å»ºè®® |
|:---|:---|
| æ­£å¸¸æ¢å¤ | æ— éœ€å¤„ç†ï¼Œç›‘æ§å†…å­˜ä½¿ç”¨è¶‹åŠ¿ |
| é¢‘ç¹æ³¢åŠ¨ | æ£€æŸ¥æ˜¯å¦æœ‰å†…å­˜æ³„æ¼çš„åº”ç”¨ï¼Œè°ƒæ•´ Pod èµ„æºé™åˆ¶ |
| é©±é€åæ¢å¤ | åˆ†æä¹‹å‰å†…å­˜å‹åŠ›çš„åŸå› ï¼Œä¼˜åŒ–èµ„æºé…ç½® |

---

### `NodeHasNoDiskPressure` - èŠ‚ç‚¹æ— ç£ç›˜å‹åŠ›

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Normal |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.4+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (DiskPressure çŠ¶æ€å˜åŒ–æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤ºèŠ‚ç‚¹çš„ç£ç›˜ç©ºé—´æ¢å¤åˆ°æ­£å¸¸æ°´å¹³ï¼ŒDiskPressure condition ä» True å˜ä¸º Falseã€‚kubelet ç›‘æ§èŠ‚ç‚¹çš„ç£ç›˜ä½¿ç”¨æƒ…å†µï¼ŒåŒ…æ‹¬æ ¹æ–‡ä»¶ç³»ç»Ÿï¼ˆnodefsï¼‰å’Œå®¹å™¨é•œåƒæ–‡ä»¶ç³»ç»Ÿï¼ˆimagefsï¼‰ã€‚

å½“ç£ç›˜å¯ç”¨ç©ºé—´è¶…è¿‡é©±é€é˜ˆå€¼æ—¶ï¼ŒèŠ‚ç‚¹ä»ç£ç›˜å‹åŠ›çŠ¶æ€ä¸­æ¢å¤ã€‚è¿™æ„å‘³ç€èŠ‚ç‚¹å¯ä»¥ç»§ç»­æ‹‰å–é•œåƒå’Œåˆ›å»ºå®¹å™¨ã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Normal
Reason:  NodeHasNoDiskPressure
Message: Node node1.example.com status is now: NodeHasNoDiskPressure
Source:  kubelet, node1.example.com
```

```bash
# kubectl describe node è¾“å‡º
Conditions:
  Type             Status  Reason                  Message
  ----             ------  ------                  -------
  DiskPressure     False   KubeletHasNoDiskPressure   kubelet has no disk pressure
```

#### å½±å“é¢è¯´æ˜

- **é›†ç¾¤å½±å“**ï¼šèŠ‚ç‚¹æ¢å¤æ­£å¸¸æœåŠ¡èƒ½åŠ›
- **è°ƒåº¦å½±å“**ï¼šscheduler æ¢å¤æ­£å¸¸è°ƒåº¦åˆ°æ­¤èŠ‚ç‚¹
- **å®¹å™¨å½±å“**ï¼šå¯ä»¥æ­£å¸¸æ‹‰å–é•œåƒå’Œåˆ›å»ºå®¹å™¨

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹ DiskPressure çŠ¶æ€
kubectl get node <node-name> -o jsonpath='{.status.conditions[?(@.type=="DiskPressure")]}'

# æŸ¥çœ‹èŠ‚ç‚¹ç£ç›˜ä½¿ç”¨æƒ…å†µ
kubectl describe node <node-name> | grep -A 10 "Capacity\|Allocatable"

# ç™»å½•èŠ‚ç‚¹æŸ¥çœ‹ç£ç›˜
df -h
df -i  # æ£€æŸ¥ inode ä½¿ç”¨ç‡

# æŸ¥çœ‹ kubelet æ—¥å¿—ä¸­çš„ç£ç›˜ç›¸å…³ä¿¡æ¯
journalctl -u kubelet | grep -i "disk\|eviction"

# æŸ¥çœ‹å®¹å™¨é•œåƒå ç”¨
crictl images
du -sh /var/lib/containerd  # æˆ– /var/lib/docker
```

#### è§£å†³å»ºè®®

| åœºæ™¯ | å»ºè®® |
|:---|:---|
| æ­£å¸¸æ¢å¤ | ç›‘æ§ç£ç›˜ä½¿ç”¨è¶‹åŠ¿ï¼Œç¡®ä¿ä¸å†å‡ºç°å‹åŠ› |
| GC åæ¢å¤ | æ­£å¸¸æƒ…å†µï¼Œkubelet è‡ªåŠ¨æ¸…ç†äº†æœªä½¿ç”¨çš„é•œåƒå’Œå®¹å™¨ |
| æ‰‹åŠ¨æ¸…ç†åæ¢å¤ | å»ºç«‹å®šæœŸæ¸…ç†æœºåˆ¶ï¼Œæˆ–è°ƒæ•´ kubelet GC é…ç½® |

---

### `NodeHasSufficientPID` - èŠ‚ç‚¹ PID å……è¶³

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Normal |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.14+ |
| **ç”Ÿäº§é¢‘ç‡** | ç½•è§ (PIDPressure çŠ¶æ€å˜åŒ–æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤ºèŠ‚ç‚¹çš„å¯ç”¨è¿›ç¨‹ ID æ¢å¤åˆ°æ­£å¸¸æ°´å¹³ï¼ŒPIDPressure condition ä» True å˜ä¸º Falseã€‚Linux ç³»ç»Ÿå¯¹è¿›ç¨‹æ•°é‡æœ‰é™åˆ¶ï¼ˆkernel.pid_maxï¼‰ï¼Œå½“èŠ‚ç‚¹ä¸Šçš„è¿›ç¨‹æ•°æ¥è¿‘æ­¤é™åˆ¶æ—¶ä¼šè§¦å‘ PID å‹åŠ›ã€‚

PID å‹åŠ›çš„æ¢å¤æ„å‘³ç€èŠ‚ç‚¹ä¸Šçš„è¿›ç¨‹æ•°é™ä½åˆ°å®‰å…¨æ°´å¹³ï¼Œå¯ä»¥ç»§ç»­åˆ›å»ºæ–°è¿›ç¨‹å’Œå®¹å™¨ã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Normal
Reason:  NodeHasSufficientPID
Message: Node node1.example.com status is now: NodeHasSufficientPID
Source:  kubelet, node1.example.com
```

```bash
# kubectl describe node è¾“å‡º
Conditions:
  Type             Status  Reason                  Message
  ----             ------  ------                  -------
  PIDPressure      False   KubeletHasSufficientPID   kubelet has sufficient PID available
```

#### å½±å“é¢è¯´æ˜

- **é›†ç¾¤å½±å“**ï¼šèŠ‚ç‚¹æ¢å¤æ­£å¸¸æœåŠ¡èƒ½åŠ›
- **è°ƒåº¦å½±å“**ï¼šscheduler æ¢å¤æ­£å¸¸è°ƒåº¦åˆ°æ­¤èŠ‚ç‚¹
- **å®¹å™¨å½±å“**ï¼šå¯ä»¥æ­£å¸¸åˆ›å»ºæ–°å®¹å™¨å’Œè¿›ç¨‹

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹ PIDPressure çŠ¶æ€
kubectl get node <node-name> -o jsonpath='{.status.conditions[?(@.type=="PIDPressure")]}'

# ç™»å½•èŠ‚ç‚¹æŸ¥çœ‹è¿›ç¨‹æ•°
ps aux | wc -l
cat /proc/sys/kernel/pid_max
cat /proc/sys/kernel/threads-max

# æŸ¥çœ‹èŠ‚ç‚¹ä¸Šçš„ Pod æ•°é‡
kubectl get pods --all-namespaces --field-selector spec.nodeName=<node-name> --no-headers | wc -l

# æŸ¥çœ‹ cgroup PID ä½¿ç”¨æƒ…å†µ
cat /sys/fs/cgroup/pids/kubepods/pids.current
cat /sys/fs/cgroup/pids/kubepods/pids.max
```

#### è§£å†³å»ºè®®

| åœºæ™¯ | å»ºè®® |
|:---|:---|
| æ­£å¸¸æ¢å¤ | ç›‘æ§è¿›ç¨‹æ•°è¶‹åŠ¿ï¼Œç¡®ä¿ä¸å†å‡ºç°å‹åŠ› |
| Pod é©±é€åæ¢å¤ | åˆ†æä¹‹å‰ PID å‹åŠ›çš„åŸå› ï¼Œå¯èƒ½éœ€è¦é™åˆ¶å•ä¸ª Pod çš„è¿›ç¨‹æ•° |
| é¢‘ç¹æ³¢åŠ¨ | æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸åº”ç”¨åˆ›å»ºå¤§é‡è¿›ç¨‹ï¼Œè°ƒæ•´ Pod çš„ PID é™åˆ¶ |

---

### `NodeHasInsufficientMemory` - èŠ‚ç‚¹å†…å­˜ä¸è¶³

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Warning |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.4+ |
| **ç”Ÿäº§é¢‘ç‡** | ä¸­é¢‘ (èµ„æºå‹åŠ›åœºæ™¯) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤ºèŠ‚ç‚¹çš„å¯ç”¨å†…å­˜ä½äº kubelet é…ç½®çš„é©±é€é˜ˆå€¼ï¼ŒMemoryPressure condition è¢«è®¾ç½®ä¸º Trueã€‚è¿™æ˜¯èŠ‚ç‚¹è¿›å…¥èµ„æºå‹åŠ›çŠ¶æ€çš„å…³é”®ä¿¡å·ã€‚

å½“å†…å­˜ä¸è¶³æ—¶ï¼Œkubelet ä¼šé‡‡å–ä»¥ä¸‹æªæ–½ï¼š
1. è§¦å‘ MemoryPressure conditionï¼Œé€šçŸ¥ scheduler é¿å…è°ƒåº¦æ›´å¤š Pod
2. å¦‚æœè¾¾åˆ°ç¡¬é©±é€é˜ˆå€¼ï¼ˆhard evictionï¼‰ï¼Œç«‹å³å¼€å§‹é©±é€ Pod
3. å¦‚æœè¾¾åˆ°è½¯é©±é€é˜ˆå€¼ï¼ˆsoft evictionï¼‰ï¼Œåœ¨å®½é™æœŸåå¼€å§‹é©±é€ Pod

kubelet ä¼šä¼˜å…ˆé©±é€ QoS ç­‰çº§è¾ƒä½çš„ Podï¼ˆBestEffort > Burstable > Guaranteedï¼‰ã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Warning
Reason:  NodeHasInsufficientMemory
Message: Node node1.example.com status is now: NodeHasInsufficientMemory
Source:  kubelet, node1.example.com
```

```bash
# kubectl describe node è¾“å‡º
Conditions:
  Type             Status  Reason                  Message
  ----             ------  ------                  -------
  MemoryPressure   True    KubeletHasInsufficientMemory   kubelet has insufficient memory available
```

#### å½±å“é¢è¯´æ˜

- **é›†ç¾¤å½±å“**ï¼šèŠ‚ç‚¹å¯ç”¨æ€§é™ä½ï¼Œå¯èƒ½è§¦å‘é›†ç¾¤çº§åˆ«å‘Šè­¦
- **è°ƒåº¦å½±å“**ï¼šscheduler ä¼šé¿å…è°ƒåº¦æ–° Pod åˆ°æ­¤èŠ‚ç‚¹
- **ç°æœ‰ Pod**ï¼š
  - QoS=BestEffort çš„ Pod æœ€å…ˆè¢«é©±é€
  - QoS=Burstable çš„ Pod å…¶æ¬¡è¢«é©±é€
  - QoS=Guaranteed çš„ Pod æœ€åè¢«é©±é€
- **æœåŠ¡å½±å“**ï¼šè¢«é©±é€çš„ Pod ä¼šåœ¨å…¶ä»–èŠ‚ç‚¹é‡å»ºï¼Œå¯èƒ½å¯¼è‡´çŸ­æš‚çš„æœåŠ¡ä¸­æ–­

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹å†…å­˜çŠ¶æ€
kubectl describe node <node-name> | grep -A 5 "Conditions\|Allocated resources"

# æŸ¥çœ‹èŠ‚ç‚¹å†…å­˜è¯¦ç»†ä¿¡æ¯
kubectl get node <node-name> -o json | jq '.status.conditions[] | select(.type=="MemoryPressure")'

# æŸ¥çœ‹èŠ‚ç‚¹ä¸Š Pod çš„å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆæŒ‰å†…å­˜æ’åºï¼‰
kubectl top pods --all-namespaces --field-selector spec.nodeName=<node-name> --sort-by=memory

# æŸ¥çœ‹èŠ‚ç‚¹ä¸Š Pod çš„ QoS ç­‰çº§
kubectl get pods --all-namespaces --field-selector spec.nodeName=<node-name> -o custom-columns=NAME:.metadata.name,QOS:.status.qosClass,MEMORY:.spec.containers[*].resources.requests.memory

# ç™»å½•èŠ‚ç‚¹æŸ¥çœ‹ç³»ç»Ÿå†…å­˜
free -h
vmstat 1 5
cat /proc/meminfo

# æŸ¥çœ‹å†…å­˜æœ€å¤šçš„è¿›ç¨‹
ps aux --sort=-%mem | head -20

# æŸ¥çœ‹ kubelet é©±é€é˜ˆå€¼é…ç½®
kubectl get --raw /api/v1/nodes/<node-name>/proxy/configz | jq '.kubeletconfig.evictionHard, .kubeletconfig.evictionSoft'

# æŸ¥çœ‹é©±é€ç›¸å…³äº‹ä»¶
kubectl get events --all-namespaces --field-selector reason=Evicted,involvedObject.kind=Pod
```

#### è§£å†³å»ºè®®

| åŸå›  | è§£å†³æ–¹æ¡ˆ |
|:---|:---|
| Pod å†…å­˜ä½¿ç”¨è¶…å‡ºé¢„æœŸ | ä¼˜åŒ–åº”ç”¨å†…å­˜ä½¿ç”¨ï¼Œä¿®å¤å†…å­˜æ³„æ¼ |
| Pod requests é…ç½®ä¸åˆç† | è°ƒæ•´ Pod çš„ memory requests å’Œ limits |
| èŠ‚ç‚¹å†…å­˜é…ç½®ä¸è¶³ | å¢åŠ èŠ‚ç‚¹ç‰©ç†å†…å­˜ï¼Œæˆ–è¿ç§»éƒ¨åˆ† Pod åˆ°å…¶ä»–èŠ‚ç‚¹ |
| ç³»ç»Ÿè¿›ç¨‹å ç”¨è¿‡å¤š | ä¼˜åŒ–ç³»ç»Ÿé…ç½®ï¼Œé™åˆ¶éå¿…è¦ç³»ç»Ÿè¿›ç¨‹ |
| å†…å­˜ç¢ç‰‡åŒ– | é‡å¯èŠ‚ç‚¹è¿›è¡Œå†…å­˜æ•´ç†ï¼ˆéœ€è¦å…ˆ drainï¼‰ |
| è°ƒæ•´é©±é€é˜ˆå€¼ | æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ kubelet çš„ evictionHard/evictionSoft é…ç½® |
| å¢åŠ èŠ‚ç‚¹ | æ¨ªå‘æ‰©å±•é›†ç¾¤ï¼Œå¢åŠ æ›´å¤šå·¥ä½œèŠ‚ç‚¹ |

---

### `NodeHasDiskPressure` - èŠ‚ç‚¹ç£ç›˜å‹åŠ›

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Warning |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.4+ |
| **ç”Ÿäº§é¢‘ç‡** | ä¸­é¢‘ (èµ„æºå‹åŠ›åœºæ™¯) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤ºèŠ‚ç‚¹çš„ç£ç›˜ç©ºé—´æˆ– inode ä½äº kubelet é…ç½®çš„é©±é€é˜ˆå€¼ï¼ŒDiskPressure condition è¢«è®¾ç½®ä¸º Trueã€‚kubelet ç›‘æ§ä¸¤ä¸ªæ–‡ä»¶ç³»ç»Ÿï¼š

1. **nodefs**ï¼šèŠ‚ç‚¹æ ¹æ–‡ä»¶ç³»ç»Ÿï¼Œå­˜å‚¨ Pod æ—¥å¿—ã€EmptyDir å·ã€writable layers ç­‰
2. **imagefs**ï¼šå®¹å™¨é•œåƒæ–‡ä»¶ç³»ç»Ÿï¼ˆå¦‚æœå•ç‹¬åˆ†åŒºï¼‰ï¼Œå­˜å‚¨å®¹å™¨é•œåƒå’Œå®¹å™¨å¯å†™å±‚

å½“ç£ç›˜å‹åŠ›å‘ç”Ÿæ—¶ï¼Œkubelet ä¼šï¼š
1. è§¦å‘ DiskPressure conditionï¼Œé€šçŸ¥ scheduler é¿å…è°ƒåº¦
2. æ‰§è¡Œé•œåƒåƒåœ¾å›æ”¶ï¼ˆImage GCï¼‰ï¼Œåˆ é™¤æœªä½¿ç”¨çš„é•œåƒ
3. æ‰§è¡Œå®¹å™¨åƒåœ¾å›æ”¶ï¼ˆContainer GCï¼‰ï¼Œåˆ é™¤å·²åœæ­¢çš„å®¹å™¨
4. å¦‚æœä»ç„¶ä¸è¶³ï¼Œå¼€å§‹é©±é€ Podï¼ˆä¼˜å…ˆé©±é€å ç”¨ç£ç›˜æœ€å¤šçš„ Podï¼‰

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Warning
Reason:  NodeHasDiskPressure
Message: Node node1.example.com status is now: NodeHasDiskPressure
Source:  kubelet, node1.example.com
```

```bash
# kubectl describe node è¾“å‡º
Conditions:
  Type             Status  Reason                  Message
  ----             ------  ------                  -------
  DiskPressure     True    KubeletHasDiskPressure   kubelet has disk pressure
```

#### å½±å“é¢è¯´æ˜

- **é›†ç¾¤å½±å“**ï¼šèŠ‚ç‚¹å¯ç”¨æ€§é™ä½ï¼Œå¯èƒ½è§¦å‘é›†ç¾¤çº§åˆ«å‘Šè­¦
- **è°ƒåº¦å½±å“**ï¼šscheduler ä¼šé¿å…è°ƒåº¦æ–° Pod åˆ°æ­¤èŠ‚ç‚¹
- **é•œåƒæ‹‰å–**ï¼šå¯èƒ½æ— æ³•æ‹‰å–æ–°é•œåƒ
- **å®¹å™¨åˆ›å»º**ï¼šå¯èƒ½æ— æ³•åˆ›å»ºæ–°å®¹å™¨
- **ç°æœ‰ Pod**ï¼šå ç”¨ç£ç›˜æœ€å¤šçš„ Pod ä¼šè¢«ä¼˜å…ˆé©±é€
- **æ—¥å¿—æ”¶é›†**ï¼šPod æ—¥å¿—å¯èƒ½æ— æ³•æ­£å¸¸å†™å…¥

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹ç£ç›˜çŠ¶æ€
kubectl describe node <node-name> | grep -A 5 "Conditions\|Capacity\|Allocatable"

# æŸ¥çœ‹ DiskPressure è¯¦ç»†ä¿¡æ¯
kubectl get node <node-name> -o json | jq '.status.conditions[] | select(.type=="DiskPressure")'

# ç™»å½•èŠ‚ç‚¹æŸ¥çœ‹ç£ç›˜ä½¿ç”¨æƒ…å†µ
df -h
df -i  # æŸ¥çœ‹ inode ä½¿ç”¨æƒ…å†µ
du -sh /* | sort -rh | head -20

# æŸ¥çœ‹ kubelet/containerd æ•°æ®ç›®å½•å ç”¨
du -sh /var/lib/kubelet
du -sh /var/lib/containerd
du -sh /var/log/pods

# æŸ¥çœ‹å®¹å™¨é•œåƒå ç”¨
crictl images
crictl images -v | awk '{sum+=$5} END {print sum/1024/1024/1024 " GB"}'

# æŸ¥çœ‹æœªä½¿ç”¨çš„å®¹å™¨
crictl ps -a | grep Exited

# æŸ¥çœ‹ Pod ç£ç›˜ä½¿ç”¨ï¼ˆéœ€è¦ metrics-serverï¼‰
kubectl top pods --all-namespaces --field-selector spec.nodeName=<node-name>

# æŸ¥çœ‹ kubelet GC é…ç½®
kubectl get --raw /api/v1/nodes/<node-name>/proxy/configz | jq '.kubeletconfig.imageGCHighThresholdPercent, .kubeletconfig.imageGCLowThresholdPercent'

# æŸ¥çœ‹é©±é€é˜ˆå€¼
kubectl get --raw /api/v1/nodes/<node-name>/proxy/configz | jq '.kubeletconfig.evictionHard, .kubeletconfig.evictionSoft'
```

#### è§£å†³å»ºè®®

| åŸå›  | è§£å†³æ–¹æ¡ˆ |
|:---|:---|
| å®¹å™¨é•œåƒè¿‡å¤š | æ‰‹åŠ¨æ¸…ç†æœªä½¿ç”¨é•œåƒ: `crictl rmi --prune` |
| å®¹å™¨æ—¥å¿—è¿‡å¤§ | é…ç½®æ—¥å¿—è½®è½¬ï¼Œé™åˆ¶å®¹å™¨æ—¥å¿—å¤§å°ï¼ˆ--log-max-size, --log-max-filesï¼‰ |
| å·²åœæ­¢å®¹å™¨æœªæ¸…ç† | æ¸…ç†åœæ­¢çš„å®¹å™¨: `crictl rm $(crictl ps -a -q --state Exited)` |
| EmptyDir å·å ç”¨è¿‡å¤§ | æ£€æŸ¥ Pod çš„ EmptyDir ä½¿ç”¨ï¼Œæ¸…ç†æˆ–é™åˆ¶å¤§å° |
| ç³»ç»Ÿæ—¥å¿—è¿‡å¤§ | æ¸…ç†ç³»ç»Ÿæ—¥å¿—: `journalctl --vacuum-time=7d` |
| ç£ç›˜é…ç½®ä¸è¶³ | æ‰©å®¹ç£ç›˜ï¼Œæˆ–ä¸º imagefs å•ç‹¬åˆ†é…ç£ç›˜ |
| è°ƒæ•´ GC é˜ˆå€¼ | é™ä½ imageGCHighThresholdPercentï¼Œæ›´ç§¯æåœ°å›æ”¶é•œåƒ |
| è°ƒæ•´é©±é€é˜ˆå€¼ | æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ evictionHard/evictionSoft é…ç½® |
| Pod æ•°æ®æŒä¹…åŒ–é—®é¢˜ | ä½¿ç”¨ PV è€Œä¸æ˜¯ EmptyDir å­˜å‚¨å¤§é‡æ•°æ® |

---

### `NodeHasInsufficientPID` - èŠ‚ç‚¹ PID ä¸è¶³

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Warning |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.14+ |
| **ç”Ÿäº§é¢‘ç‡** | ç½•è§ (ç‰¹æ®Šåœºæ™¯) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤ºèŠ‚ç‚¹çš„å¯ç”¨è¿›ç¨‹ ID ä½äº kubelet é…ç½®çš„é©±é€é˜ˆå€¼ï¼ŒPIDPressure condition è¢«è®¾ç½®ä¸º Trueã€‚è¿™æ˜¯ä¸€ç§ç›¸å¯¹ç½•è§ä½†ä¸¥é‡çš„èµ„æºå‹åŠ›çŠ¶æ€ã€‚

Linux ç³»ç»Ÿå¯¹è¿›ç¨‹æ•°é‡æœ‰é™åˆ¶ï¼ˆç”± `kernel.pid_max` æ§åˆ¶ï¼Œé€šå¸¸ä¸º 32768 æˆ–æ›´é«˜ï¼‰ã€‚å½“èŠ‚ç‚¹ä¸Šè¿è¡Œå¤§é‡å®¹å™¨ï¼Œä¸”æ¯ä¸ªå®¹å™¨å¯åŠ¨å¤šä¸ªè¿›ç¨‹æ—¶ï¼Œå¯èƒ½ä¼šè€—å°½ PIDã€‚

å½“ PID ä¸è¶³æ—¶ï¼Œkubelet ä¼šï¼š
1. è§¦å‘ PIDPressure conditionï¼Œé€šçŸ¥ scheduler é¿å…è°ƒåº¦
2. æ— æ³•åˆ›å»ºæ–°è¿›ç¨‹å’Œå®¹å™¨
3. å¦‚æœè¾¾åˆ°é©±é€é˜ˆå€¼ï¼Œå¼€å§‹é©±é€ Pod

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Warning
Reason:  NodeHasInsufficientPID
Message: Node node1.example.com status is now: NodeHasInsufficientPID
Source:  kubelet, node1.example.com
```

```bash
# kubectl describe node è¾“å‡º
Conditions:
  Type             Status  Reason                  Message
  ----             ------  ------                  -------
  PIDPressure      True    KubeletHasInsufficientPID   kubelet has insufficient PID available
```

#### å½±å“é¢è¯´æ˜

- **é›†ç¾¤å½±å“**ï¼šèŠ‚ç‚¹æ— æ³•åˆ›å»ºæ–°è¿›ç¨‹ï¼Œä¸¥é‡å½±å“å¯ç”¨æ€§
- **è°ƒåº¦å½±å“**ï¼šscheduler ä¼šé¿å…è°ƒåº¦æ–° Pod åˆ°æ­¤èŠ‚ç‚¹
- **å®¹å™¨å½±å“**ï¼šæ— æ³•åˆ›å»ºæ–°å®¹å™¨ï¼Œç°æœ‰å®¹å™¨ä¹Ÿå¯èƒ½æ— æ³• fork æ–°è¿›ç¨‹
- **ç°æœ‰ Pod**ï¼šéƒ¨åˆ† Pod ä¼šè¢«é©±é€ä»¥é‡Šæ”¾ PID
- **ç³»ç»Ÿå½±å“**ï¼šç³»ç»Ÿå‘½ä»¤å¯èƒ½æ— æ³•æ‰§è¡Œï¼ŒSSH ç™»å½•å¯èƒ½å—é˜»

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹ PID å‹åŠ›çŠ¶æ€
kubectl describe node <node-name> | grep -A 2 PIDPressure

# æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
kubectl get node <node-name> -o json | jq '.status.conditions[] | select(.type=="PIDPressure")'

# ç™»å½•èŠ‚ç‚¹æŸ¥çœ‹è¿›ç¨‹æ•°
ps aux | wc -l
ps -eLf | wc -l  # åŒ…å«çº¿ç¨‹

# æŸ¥çœ‹ç³»ç»Ÿ PID é™åˆ¶
cat /proc/sys/kernel/pid_max
cat /proc/sys/kernel/threads-max

# æŸ¥çœ‹å½“å‰ PID ä½¿ç”¨æƒ…å†µ
cat /proc/sys/kernel/pid_max
cat /sys/fs/cgroup/pids/kubepods/pids.current
cat /sys/fs/cgroup/pids/kubepods/pids.max

# æŸ¥æ‰¾è¿›ç¨‹æ•°æœ€å¤šçš„å®¹å™¨
for pod in $(crictl pods -q); do
  echo "Pod: $pod"
  crictl ps | grep $pod | wc -l
done

# æŸ¥çœ‹èŠ‚ç‚¹ä¸Šçš„ Pod æ•°é‡
kubectl get pods --all-namespaces --field-selector spec.nodeName=<node-name> --no-headers | wc -l

# æŸ¥çœ‹ kubelet PID é©±é€é…ç½®
kubectl get --raw /api/v1/nodes/<node-name>/proxy/configz | jq '.kubeletconfig.evictionHard, .kubeletconfig.evictionSoft'

# æŸ¥æ‰¾åˆ›å»ºè¿›ç¨‹æœ€å¤šçš„ Pod
kubectl top pods --all-namespaces --field-selector spec.nodeName=<node-name>
```

#### è§£å†³å»ºè®®

| åŸå›  | è§£å†³æ–¹æ¡ˆ |
|:---|:---|
| å•ä¸ªå®¹å™¨è¿›ç¨‹æ•°è¿‡å¤š | é™åˆ¶å®¹å™¨çš„ PID æ•°é‡ï¼Œè®¾ç½® `--pids-limit` |
| Pod æ•°é‡è¿‡å¤š | å‡å°‘èŠ‚ç‚¹ä¸Šçš„ Pod æ•°é‡ï¼Œè¿ç§»éƒ¨åˆ† Pod |
| åº”ç”¨å¼‚å¸¸åˆ›å»ºè¿›ç¨‹ | ä¿®å¤åº”ç”¨ bugï¼Œé¿å…è¿›ç¨‹æ³„æ¼ |
| ç³»ç»Ÿ PID é™åˆ¶è¿‡ä½ | æé«˜ `kernel.pid_max`: `sysctl -w kernel.pid_max=65535` |
| Kubernetes é…ç½®ä¸å½“ | è°ƒæ•´ kubelet çš„ `podPidsLimit` å’Œ `evictionHard` é…ç½® |
| åƒµå°¸è¿›ç¨‹è¿‡å¤š | æŸ¥æ‰¾å¹¶æ¸…ç†åƒµå°¸è¿›ç¨‹ï¼Œä¿®å¤çˆ¶è¿›ç¨‹çš„ä¿¡å·å¤„ç† |
| é©±é€ Pod | æ‰‹åŠ¨é©±é€éƒ¨åˆ† Pod ä»¥é‡Šæ”¾ PID: `kubectl delete pod <pod-name>` |

---

### `Rebooted` - èŠ‚ç‚¹é‡å¯

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Warning |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (èŠ‚ç‚¹é‡å¯å) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤º kubelet æ£€æµ‹åˆ°èŠ‚ç‚¹å·²é‡å¯ï¼ˆé€šè¿‡ boot ID å˜åŒ–æ£€æµ‹ï¼‰ã€‚èŠ‚ç‚¹é‡å¯å¯èƒ½æ˜¯è®¡åˆ’å†…çš„ç»´æŠ¤æ“ä½œï¼Œä¹Ÿå¯èƒ½æ˜¯æ„å¤–çš„ç³»ç»Ÿå´©æºƒã€æ–­ç”µæˆ–å†…æ ¸ panicã€‚

å½“ kubelet æ£€æµ‹åˆ°èŠ‚ç‚¹é‡å¯åï¼Œä¼šæ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š
1. äº§ç”Ÿ Rebooted äº‹ä»¶
2. æ£€æŸ¥æŒ‚è½½çš„å·ï¼Œç¡®ä¿å·çŠ¶æ€æ­£ç¡®
3. é‡æ–°åŒæ­¥æ‰€æœ‰ Podï¼Œé‡æ–°åˆ›å»ºå®¹å™¨
4. é‡æ–°é…ç½®ç½‘ç»œå’Œå­˜å‚¨

èŠ‚ç‚¹é‡å¯ä¼šå¯¼è‡´æ‰€æœ‰éæŒä¹…åŒ–æ•°æ®ä¸¢å¤±ï¼ŒåŒ…æ‹¬ EmptyDir å·ã€å®¹å™¨ç¼“å­˜ç­‰ã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Warning
Reason:  Rebooted
Message: Node node1.example.com has been rebooted, boot id: 12345678-1234-1234-1234-123456789abc
Source:  kubelet, node1.example.com
```

æˆ–è€…ï¼š

```yaml
Type:    Warning
Reason:  Rebooted
Message: Node rebooted, boot id changed
Source:  kubelet, node1.example.com
```

#### å½±å“é¢è¯´æ˜

- **é›†ç¾¤å½±å“**ï¼šèŠ‚ç‚¹åœ¨é‡å¯æœŸé—´ä¸å¯ç”¨ï¼Œé™ä½é›†ç¾¤å®¹é‡
- **Pod å½±å“**ï¼š
  - æ‰€æœ‰ Pod éœ€è¦é‡æ–°å¯åŠ¨
  - EmptyDir å·çš„æ•°æ®ä¸¢å¤±
  - å®¹å™¨çš„ writable layer ä¸¢å¤±
  - å¯åŠ¨é¡ºåºå¯èƒ½ä¸ä¹‹å‰ä¸åŒ
- **å­˜å‚¨å½±å“**ï¼š
  - PV æŒ‚è½½éœ€è¦é‡æ–°æŒ‚è½½
  - æœ¬åœ°å­˜å‚¨ï¼ˆhostPath, local PVï¼‰éœ€è¦é‡æ–°æ£€æŸ¥
- **ç½‘ç»œå½±å“**ï¼š
  - Pod IP å¯èƒ½å˜åŒ–
  - CNI éœ€è¦é‡æ–°åˆå§‹åŒ–
  - iptables è§„åˆ™éœ€è¦é‡å»º
- **æœåŠ¡å½±å“**ï¼šèŠ‚ç‚¹é‡å¯å¯¼è‡´çš„æœåŠ¡ä¸­æ–­æ—¶é—´å–å†³äºé‡å¯é€Ÿåº¦å’Œ Pod å¯åŠ¨æ—¶é—´

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹é‡å¯äº‹ä»¶
kubectl get events --field-selector involvedObject.kind=Node,reason=Rebooted --all-namespaces

# æŸ¥çœ‹èŠ‚ç‚¹å¯åŠ¨æ—¶é—´
kubectl get node <node-name> -o json | jq '.status.nodeInfo.bootID'

# ç™»å½•èŠ‚ç‚¹æŸ¥çœ‹ç³»ç»Ÿå¯åŠ¨æ—¶é—´
uptime
who -b
last reboot | head

# æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—ï¼Œæ‰¾å‡ºé‡å¯åŸå› 
journalctl --since "2 hours ago" | grep -i "reboot\|shutdown\|panic"
dmesg | grep -i "reboot\|panic"

# æŸ¥çœ‹å†…æ ¸æ—¥å¿—
journalctl -k --since "2 hours ago"

# æŸ¥çœ‹ç³»ç»Ÿå´©æºƒæŠ¥å‘Šï¼ˆå¦‚æœæœ‰ï¼‰
ls -lh /var/crash/

# æŸ¥çœ‹èŠ‚ç‚¹ä¸Šçš„ Pod çŠ¶æ€
kubectl get pods --all-namespaces --field-selector spec.nodeName=<node-name>

# æŸ¥çœ‹ Pod é‡å¯æƒ…å†µ
kubectl get pods --all-namespaces --field-selector spec.nodeName=<node-name> -o custom-columns=NAME:.metadata.name,RESTARTS:.status.containerStatuses[*].restartCount

# æ£€æŸ¥å·æŒ‚è½½çŠ¶æ€
mount | grep kubelet
kubectl get volumeattachments | grep <node-name>
```

#### è§£å†³å»ºè®®

| é‡å¯åŸå›  | è§£å†³æ–¹æ¡ˆ |
|:---|:---|
| è®¡åˆ’å†…ç»´æŠ¤ | æ­£å¸¸æƒ…å†µï¼Œç¡®è®¤æ‰€æœ‰ Pod å·²æ¢å¤ï¼Œæ£€æŸ¥æœåŠ¡å¥åº· |
| ç³»ç»Ÿæ›´æ–°/è¡¥ä¸ | éªŒè¯æ›´æ–°æˆåŠŸï¼Œç›‘æ§èŠ‚ç‚¹ç¨³å®šæ€§ |
| å†…æ ¸ panic | åˆ†æ panic æ—¥å¿—ï¼Œå¯èƒ½æ˜¯å†…æ ¸ bug æˆ–ç¡¬ä»¶é—®é¢˜ |
| OOM killer | è°ƒæ•´ç³»ç»Ÿå†…å­˜é…ç½®ï¼Œä¼˜åŒ–åº”ç”¨å†…å­˜ä½¿ç”¨ |
| æ–­ç”µ/ç¡¬ä»¶æ•…éšœ | æ£€æŸ¥ç¡¬ä»¶çŠ¶æ€ï¼Œä¿®å¤æˆ–æ›´æ¢æ•…éšœç¡¬ä»¶ |
| äººä¸ºè¯¯æ“ä½œ | å®¡è®¡æ“ä½œè®°å½•ï¼ŒåŠ å¼ºæƒé™ç®¡ç†å’Œæ“ä½œè§„èŒƒ |
| è‡ªåŠ¨é‡å¯ï¼ˆçœ‹é—¨ç‹—ï¼‰ | æ£€æŸ¥è§¦å‘è‡ªåŠ¨é‡å¯çš„æ¡ä»¶ï¼Œè§£å†³æ ¹æœ¬é—®é¢˜ |
| å·æŒ‚è½½å¤±è´¥ | æ£€æŸ¥å­˜å‚¨ç³»ç»Ÿï¼Œä¿®å¤å·æŒ‚è½½é—®é¢˜ |
| Pod æ— æ³•å¯åŠ¨ | æŸ¥çœ‹ Pod äº‹ä»¶å’Œæ—¥å¿—ï¼Œè§£å†³å¯åŠ¨é—®é¢˜ |

---

### `NodeAllocatableEnforced` - èŠ‚ç‚¹å¯åˆ†é…èµ„æºé™åˆ¶å·²æ›´æ–°

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Normal |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.6+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (kubelet å¯åŠ¨æˆ–é…ç½®æ›´æ”¹æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤º kubelet å·²åº”ç”¨æˆ–æ›´æ–°èŠ‚ç‚¹çš„ Allocatable èµ„æºé™åˆ¶ã€‚Allocatable æ˜¯èŠ‚ç‚¹ä¸Šå¯ä¾› Pod ä½¿ç”¨çš„èµ„æºé‡ï¼Œè®¡ç®—å…¬å¼ä¸ºï¼š

```
Allocatable = Capacity - Reserved(System) - Reserved(Kubernetes) - Eviction Threshold
```

å…¶ä¸­ï¼š
- **Capacity**ï¼šèŠ‚ç‚¹çš„æ€»èµ„æºå®¹é‡ï¼ˆCPUã€å†…å­˜ã€ç£ç›˜ç­‰ï¼‰
- **System Reserved**ï¼šä¸ºç³»ç»Ÿè¿›ç¨‹ï¼ˆsshd, systemd ç­‰ï¼‰ä¿ç•™çš„èµ„æº
- **Kubernetes Reserved**ï¼šä¸º Kubernetes ç»„ä»¶ï¼ˆkubelet, container runtime ç­‰ï¼‰ä¿ç•™çš„èµ„æº
- **Eviction Threshold**ï¼šé©±é€é˜ˆå€¼ï¼Œè§¦å‘ Pod é©±é€å‰ä¿ç•™çš„èµ„æº

kubelet ä½¿ç”¨ cgroup å¼ºåˆ¶æ‰§è¡Œè¿™äº›é™åˆ¶ï¼Œç¡®ä¿ç³»ç»Ÿå’Œ Kubernetes ç»„ä»¶ä¸ä¼šè¢« Pod è€—å°½èµ„æºã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Normal
Reason:  NodeAllocatableEnforced
Message: Updated Node Allocatable limit across pods
Source:  kubelet, node1.example.com
```

æˆ–è€…æ›´è¯¦ç»†çš„æ¶ˆæ¯ï¼š

```yaml
Type:    Normal
Reason:  NodeAllocatableEnforced
Message: Updated limits for pod cgroup: memory=16Gi, cpu=8
Source:  kubelet, node1.example.com
```

#### å½±å“é¢è¯´æ˜

- **èµ„æºç®¡ç†**ï¼šç¡®ä¿ç³»ç»Ÿå’Œ Kubernetes ç»„ä»¶æœ‰è¶³å¤Ÿèµ„æºè¿è¡Œ
- **è°ƒåº¦å½±å“**ï¼šscheduler ä½¿ç”¨ Allocatable å€¼è¿›è¡Œè°ƒåº¦å†³ç­–
- **Pod é™åˆ¶**ï¼šæ‰€æœ‰ Pod çš„èµ„æºä½¿ç”¨æ€»å’Œä¸èƒ½è¶…è¿‡ Allocatable
- **é˜²æ­¢èŠ‚ç‚¹ä¸ç¨³å®š**ï¼šé€šè¿‡ä¿ç•™èµ„æºé˜²æ­¢ OOM å’Œç³»ç»Ÿè¿›ç¨‹è¢«æ€

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹çš„ Capacity å’Œ Allocatable
kubectl describe node <node-name> | grep -A 10 "Capacity\|Allocatable"

# æŸ¥çœ‹è¯¦ç»†çš„èµ„æºä¿¡æ¯
kubectl get node <node-name> -o json | jq '.status.capacity, .status.allocatable'

# æŸ¥çœ‹èµ„æºé¢„ç•™é…ç½®
kubectl get node <node-name> -o json | jq '.metadata.annotations'

# æŸ¥çœ‹ kubelet é…ç½®
kubectl get --raw /api/v1/nodes/<node-name>/proxy/configz | jq '.kubeletconfig | {systemReserved, kubeReserved, evictionHard}'

# ç™»å½•èŠ‚ç‚¹æŸ¥çœ‹ cgroup é™åˆ¶
cat /sys/fs/cgroup/memory/kubepods/memory.limit_in_bytes
cat /sys/fs/cgroup/cpu/kubepods/cpu.cfs_quota_us

# æŸ¥çœ‹èŠ‚ç‚¹èµ„æºä½¿ç”¨æƒ…å†µ
kubectl top node <node-name>

# æŸ¥çœ‹èŠ‚ç‚¹ä¸Šæ‰€æœ‰ Pod çš„èµ„æº requests æ€»å’Œ
kubectl describe node <node-name> | grep -A 15 "Allocated resources"
```

#### è§£å†³å»ºè®®

| åœºæ™¯ | å»ºè®® |
|:---|:---|
| é¦–æ¬¡å¯åŠ¨ | æ­£å¸¸æƒ…å†µï¼ŒéªŒè¯ Allocatable é…ç½®æ˜¯å¦ç¬¦åˆé¢„æœŸ |
| é…ç½®æ›´æ–° | ç¡®è®¤é…ç½®æ›´æ”¹æ˜¯å¦ç¬¦åˆè§„åˆ’ï¼Œç›‘æ§èŠ‚ç‚¹å’Œ Pod çš„è¡Œä¸º |
| Allocatable è¿‡å° | è°ƒæ•´ kubelet çš„ systemReserved å’Œ kubeReserved é…ç½® |
| Allocatable è¿‡å¤§ | å¢åŠ èµ„æºé¢„ç•™ï¼Œé˜²æ­¢ç³»ç»Ÿè¿›ç¨‹è¢«é¥¿æ­» |
| cgroup é™åˆ¶å¤±æ•ˆ | æ£€æŸ¥ cgroup é…ç½®å’Œ kubelet æ—¥å¿— |
| èµ„æºè¶…é¢åˆ†é… | è°ƒæ•´ Pod çš„ requests å’Œ limits |

**æ¨èé…ç½®ç¤ºä¾‹**ï¼š

```yaml
# kubelet é…ç½®æ–‡ä»¶
systemReserved:
  cpu: "500m"
  memory: "1Gi"
  ephemeral-storage: "10Gi"
kubeReserved:
  cpu: "500m"
  memory: "1Gi"
  ephemeral-storage: "10Gi"
evictionHard:
  memory.available: "500Mi"
  nodefs.available: "10%"
  imagefs.available: "15%"
enforceNodeAllocatable:
  - pods
  - kube-reserved
  - system-reserved
```

---

### `InvalidDiskCapacity` - ç£ç›˜å®¹é‡æ— æ•ˆ

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Warning |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ç½•è§ (é…ç½®é”™è¯¯æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤º kubelet æ£€æµ‹åˆ°æ–‡ä»¶ç³»ç»Ÿçš„å®¹é‡ä¸º 0 æˆ–æ— æ•ˆã€‚è¿™é€šå¸¸æ˜¯ç”±äºæ–‡ä»¶ç³»ç»ŸæŒ‚è½½å¤±è´¥ã€ç£ç›˜æ•…éšœæˆ– cadvisor è·å–ç£ç›˜ä¿¡æ¯å¤±è´¥å¯¼è‡´çš„ã€‚

å½“ç£ç›˜å®¹é‡æ— æ•ˆæ—¶ï¼Œkubelet æ— æ³•å‡†ç¡®ç›‘æ§ç£ç›˜ä½¿ç”¨æƒ…å†µï¼Œå¯èƒ½å¯¼è‡´ï¼š
1. æ— æ³•æ­£ç¡®æ‰§è¡Œç£ç›˜å‹åŠ›æ£€æµ‹
2. é•œåƒåƒåœ¾å›æ”¶ï¼ˆImage GCï¼‰æ— æ³•æ­£å¸¸å·¥ä½œ
3. å®¹å™¨åƒåœ¾å›æ”¶ï¼ˆContainer GCï¼‰æ— æ³•æ­£å¸¸å·¥ä½œ
4. é©±é€æœºåˆ¶å¯èƒ½å¤±æ•ˆ

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Warning
Reason:  InvalidDiskCapacity
Message: invalid capacity 0 on image filesystem
Source:  kubelet, node1.example.com
```

æˆ–è€…ï¼š

```yaml
Type:    Warning
Reason:  InvalidDiskCapacity
Message: failed to get fs info for "imagefs": unable to find data in memory cache
Source:  kubelet, node1.example.com
```

#### å½±å“é¢è¯´æ˜

- **ç›‘æ§å½±å“**ï¼šæ— æ³•å‡†ç¡®ç›‘æ§ç£ç›˜ä½¿ç”¨æƒ…å†µ
- **GC å½±å“**ï¼šåƒåœ¾å›æ”¶æœºåˆ¶å¯èƒ½å¤±æ•ˆ
- **é©±é€å½±å“**ï¼šåŸºäºç£ç›˜å‹åŠ›çš„é©±é€å¯èƒ½ä¸å·¥ä½œ
- **è°ƒåº¦å½±å“**ï¼šå¯èƒ½å¯¼è‡´ DiskPressure condition ä¸å‡†ç¡®

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹ç£ç›˜ç›¸å…³äº‹ä»¶
kubectl get events --field-selector involvedObject.kind=Node,reason=InvalidDiskCapacity

# æŸ¥çœ‹èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
kubectl describe node <node-name>

# ç™»å½•èŠ‚ç‚¹æŸ¥çœ‹æ–‡ä»¶ç³»ç»ŸæŒ‚è½½
df -h
mount | grep kubelet
mount | grep containerd

# æ£€æŸ¥ kubelet ä½¿ç”¨çš„è·¯å¾„
ls -la /var/lib/kubelet
ls -la /var/lib/containerd

# æŸ¥çœ‹ kubelet æ—¥å¿—
journalctl -u kubelet -n 200 --no-pager | grep -i "disk\|filesystem\|capacity"

# æ£€æŸ¥ cadvisor æ˜¯å¦æ­£å¸¸å·¥ä½œ
curl http://localhost:4194/api/v1.3/machine

# æŸ¥çœ‹æ–‡ä»¶ç³»ç»ŸçŠ¶æ€
stat -f /var/lib/kubelet
stat -f /var/lib/containerd

# æ£€æŸ¥ç£ç›˜é”™è¯¯
dmesg | grep -i "disk\|error\|fail"
smartctl -a /dev/sda  # éœ€è¦å®‰è£… smartmontools
```

#### è§£å†³å»ºè®®

| åŸå›  | è§£å†³æ–¹æ¡ˆ |
|:---|:---|
| æ–‡ä»¶ç³»ç»ŸæœªæŒ‚è½½ | æŒ‚è½½æ–‡ä»¶ç³»ç»Ÿï¼Œç¡®ä¿ kubelet æ•°æ®ç›®å½•æ­£å¸¸ |
| ç£ç›˜æ•…éšœ | ä¿®å¤æˆ–æ›´æ¢æ•…éšœç£ç›˜ |
| cadvisor æ•…éšœ | é‡å¯ kubelet ä»¥é‡å¯ cadvisor |
| æƒé™é—®é¢˜ | æ£€æŸ¥ kubelet å¯¹æ–‡ä»¶ç³»ç»Ÿçš„è®¿é—®æƒé™ |
| å®¹å™¨è¿è¡Œæ—¶é—®é¢˜ | æ£€æŸ¥å¹¶ä¿®å¤å®¹å™¨è¿è¡Œæ—¶é…ç½® |
| tmpfs é…ç½®é”™è¯¯ | æ£€æŸ¥ tmpfs æŒ‚è½½é…ç½®ï¼Œç¡®ä¿å¤§å°æ­£ç¡® |
| é‡å¯ kubelet | `systemctl restart kubelet` |

---

### `FreeDiskSpaceFailed` - ç£ç›˜ç©ºé—´æ¸…ç†å¤±è´¥

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Warning |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ä¸­é¢‘ (ç£ç›˜å‹åŠ›æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤º kubelet å°è¯•é€šè¿‡åƒåœ¾å›æ”¶ï¼ˆGCï¼‰é‡Šæ”¾ç£ç›˜ç©ºé—´ï¼Œä½†æœªèƒ½é‡Šæ”¾è¶³å¤Ÿçš„ç©ºé—´ä»¥æ»¡è¶³è¦æ±‚ã€‚è¿™é€šå¸¸å‘ç”Ÿåœ¨èŠ‚ç‚¹ç£ç›˜ä½¿ç”¨ç‡å¾ˆé«˜ï¼Œä¸”é•œåƒ GC å’Œå®¹å™¨ GC éƒ½æ— æ³•é‡Šæ”¾è¶³å¤Ÿç©ºé—´çš„æƒ…å†µä¸‹ã€‚

å½“ç£ç›˜ç©ºé—´æ¸…ç†å¤±è´¥æ—¶ï¼Œkubelet ä¼šï¼š
1. äº§ç”Ÿ FreeDiskSpaceFailed äº‹ä»¶
2. ç»§ç»­å¤„äº DiskPressure çŠ¶æ€
3. å¯èƒ½å¼€å§‹é©±é€ Pod ä»¥é‡Šæ”¾ç£ç›˜ç©ºé—´

è¿™æ˜¯ç£ç›˜å‹åŠ›å‡çº§çš„ä¿¡å·ï¼Œè¡¨æ˜å¸¸è§„çš„åƒåœ¾å›æ”¶æœºåˆ¶å·²ç»ä¸å¤Ÿç”¨äº†ã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Warning
Reason:  FreeDiskSpaceFailed
Message: failed to garbage collect required amount of images. Wanted to free 5242880000 bytes, but freed 524288000 bytes
Source:  kubelet, node1.example.com
```

æˆ–è€…ï¼š

```yaml
Type:    Warning
Reason:  FreeDiskSpaceFailed
Message: failed to free disk space: failed to garbage collect required amount of images
Source:  kubelet, node1.example.com
```

#### å½±å“é¢è¯´æ˜

- **ç£ç›˜çŠ¶æ€**ï¼šèŠ‚ç‚¹ç»§ç»­å¤„äº DiskPressure çŠ¶æ€
- **é•œåƒæ‹‰å–**ï¼šå¯èƒ½æ— æ³•æ‹‰å–æ–°é•œåƒ
- **å®¹å™¨åˆ›å»º**ï¼šå¯èƒ½æ— æ³•åˆ›å»ºæ–°å®¹å™¨
- **Pod é©±é€**ï¼škubelet å¯èƒ½å¼€å§‹é©±é€ Pod
- **æœåŠ¡å½±å“**ï¼šå¯èƒ½å¯¼è‡´æœåŠ¡ä¸­æ–­å’Œ Pod è¿ç§»

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹ç£ç›˜ç©ºé—´æ¸…ç†å¤±è´¥äº‹ä»¶
kubectl get events --field-selector reason=FreeDiskSpaceFailed --all-namespaces

# æŸ¥çœ‹èŠ‚ç‚¹ç£ç›˜çŠ¶æ€
kubectl describe node <node-name> | grep -A 5 DiskPressure

# ç™»å½•èŠ‚ç‚¹æŸ¥çœ‹ç£ç›˜ä½¿ç”¨æƒ…å†µ
df -h
df -i

# æŸ¥çœ‹å“ªäº›ç›®å½•å ç”¨æœ€å¤š
du -sh /* | sort -rh | head -20
du -sh /var/lib/kubelet/* | sort -rh | head -20
du -sh /var/lib/containerd/* | sort -rh | head -20

# æŸ¥çœ‹å®¹å™¨é•œåƒå ç”¨
crictl images
crictl images -v | awk '{print $3}' | awk '{sum+=$1} END {print "Total:", sum/1024/1024/1024 "GB"}'

# æŸ¥çœ‹å·²åœæ­¢çš„å®¹å™¨
crictl ps -a | grep Exited | wc -l

# æŸ¥çœ‹ Pod æ—¥å¿—å ç”¨
du -sh /var/log/pods/* | sort -rh | head -20

# æŸ¥çœ‹ kubelet GC æ—¥å¿—
journalctl -u kubelet | grep -i "garbage collect\|image gc\|container gc"

# æŸ¥çœ‹ GC é…ç½®
kubectl get --raw /api/v1/nodes/<node-name>/proxy/configz | jq '.kubeletconfig | {imageGCHighThresholdPercent, imageGCLowThresholdPercent, imageMinimumGCAge}'
```

#### è§£å†³å»ºè®®

| åŸå›  | è§£å†³æ–¹æ¡ˆ |
|:---|:---|
| æ‰€æœ‰é•œåƒéƒ½åœ¨ä½¿ç”¨ | æ‰‹åŠ¨åˆ é™¤æœªä½¿ç”¨çš„é•œåƒï¼Œæˆ–å¢åŠ ç£ç›˜ç©ºé—´ |
| å®¹å™¨æ—¥å¿—è¿‡å¤§ | é…ç½®æ—¥å¿—è½®è½¬ï¼Œæ¸…ç†æ—§æ—¥å¿— |
| å¤§æ–‡ä»¶å ç”¨ | æŸ¥æ‰¾å¹¶åˆ é™¤ä¸å¿…è¦çš„å¤§æ–‡ä»¶ |
| GC é˜ˆå€¼è¿‡é«˜ | é™ä½ imageGCHighThresholdPercentï¼Œæ›´ç§¯æåœ°å›æ”¶ |
| ç£ç›˜çœŸçš„æ»¡äº† | æ‰©å®¹ç£ç›˜ï¼Œæˆ–è¿ç§»éƒ¨åˆ† Pod åˆ°å…¶ä»–èŠ‚ç‚¹ |
| åƒµå°¸å®¹å™¨è¿‡å¤š | æ‰‹åŠ¨æ¸…ç†: `crictl rm $(crictl ps -a -q --state Exited)` |
| æ‰‹åŠ¨æ¸…ç†é•œåƒ | `crictl rmi --prune` æˆ– `crictl rmi <image-id>` |
| æ¸…ç† Pod æ—¥å¿— | åˆ é™¤æ—§çš„ Pod æ—¥å¿—ç›®å½• |
| é©±é€ Pod | æ‰‹åŠ¨é©±é€å ç”¨ç£ç›˜å¤šçš„ Pod |

**æ‰‹åŠ¨æ¸…ç†æ­¥éª¤**ï¼š

```bash
# 1. æ¸…ç†æœªä½¿ç”¨çš„é•œåƒï¼ˆè°¨æ…æ“ä½œï¼‰
crictl rmi --prune

# 2. æ¸…ç†å·²åœæ­¢çš„å®¹å™¨
crictl rm $(crictl ps -a -q --state Exited)

# 3. æ¸…ç†æ—§çš„ Pod æ—¥å¿—ï¼ˆè°¨æ…æ“ä½œï¼Œå¯èƒ½å½±å“é—®é¢˜æ’æŸ¥ï¼‰
find /var/log/pods -type d -mtime +7 -exec rm -rf {} \;

# 4. æ¸…ç† systemd journal æ—¥å¿—
journalctl --vacuum-time=7d

# 5. æ¸…ç† apt/yum ç¼“å­˜
apt-get clean  # Debian/Ubuntu
yum clean all  # RHEL/CentOS
```

---

### `EvictionThresholdMet` - é©±é€é˜ˆå€¼å·²è¾¾åˆ°

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Warning |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.4+ |
| **ç”Ÿäº§é¢‘ç‡** | ä¸­é¢‘ (èµ„æºå‹åŠ›æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤ºèŠ‚ç‚¹çš„èµ„æºä½¿ç”¨å·²ç»è¾¾åˆ° kubelet é…ç½®çš„é©±é€é˜ˆå€¼ï¼ˆeviction thresholdï¼‰ï¼Œkubelet å°†å¼€å§‹é©±é€ Pod ä»¥å›æ”¶èµ„æºã€‚é©±é€é˜ˆå€¼åˆ†ä¸ºä¸¤ç±»ï¼š

1. **ç¡¬é©±é€é˜ˆå€¼ï¼ˆHard Evictionï¼‰**ï¼šç«‹å³é©±é€ï¼Œæ²¡æœ‰å®½é™æœŸ
   - ä¾‹å¦‚ï¼š`memory.available<100Mi`, `nodefs.available<10%`
   - è¾¾åˆ°é˜ˆå€¼åï¼Œkubelet ç«‹å³é€‰æ‹© Pod è¿›è¡Œé©±é€

2. **è½¯é©±é€é˜ˆå€¼ï¼ˆSoft Evictionï¼‰**ï¼šæœ‰å®½é™æœŸï¼Œè¶…æ—¶åæ‰é©±é€
   - ä¾‹å¦‚ï¼š`memory.available<1Gi,eviction-soft-grace-period.memory.available=1m30s`
   - è¾¾åˆ°é˜ˆå€¼åç­‰å¾…å®½é™æœŸï¼ŒæœŸé—´å¦‚æœèµ„æºæ¢å¤åˆ™ä¸é©±é€

kubelet é©±é€ Pod çš„ä¼˜å…ˆçº§é¡ºåºï¼š
1. **BestEffort** Podsï¼ˆæ²¡æœ‰ requests å’Œ limitsï¼‰
2. **Burstable** Podsï¼ˆä½¿ç”¨é‡è¶…è¿‡ requests çš„ï¼‰
3. **Burstable** Podsï¼ˆä½¿ç”¨é‡æœªè¶…è¿‡ requests çš„ï¼‰
4. **Guaranteed** Podsï¼ˆrequests == limitsï¼‰

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Warning
Reason:  EvictionThresholdMet
Message: Attempting to reclaim memory
Source:  kubelet, node1.example.com
```

```yaml
Type:    Warning
Reason:  EvictionThresholdMet
Message: Attempting to reclaim nodefs
Source:  kubelet, node1.example.com
```

```yaml
Type:    Warning
Reason:  EvictionThresholdMet
Message: Attempting to reclaim ephemeral-storage
Source:  kubelet, node1.example.com
```

#### å½±å“é¢è¯´æ˜

- **Pod é©±é€**ï¼šç¬¦åˆæ¡ä»¶çš„ Pod ä¼šè¢«ç»ˆæ­¢
- **æœåŠ¡ä¸­æ–­**ï¼šè¢«é©±é€çš„ Pod éœ€è¦åœ¨å…¶ä»–èŠ‚ç‚¹é‡å»ºï¼Œå¯èƒ½çŸ­æš‚ä¸­æ–­æœåŠ¡
- **è°ƒåº¦å½±å“**ï¼šèŠ‚ç‚¹è¢«æ ‡è®°ä¸ºå‹åŠ›çŠ¶æ€ï¼Œæ–° Pod ä¸ä¼šè°ƒåº¦åˆ°æ­¤èŠ‚ç‚¹
- **çº§è”æ•ˆåº”**ï¼šé©±é€çš„ Pod è¿ç§»åˆ°å…¶ä»–èŠ‚ç‚¹ï¼Œå¯èƒ½å¯¼è‡´å…¶ä»–èŠ‚ç‚¹ä¹Ÿäº§ç”Ÿå‹åŠ›

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹é©±é€é˜ˆå€¼äº‹ä»¶
kubectl get events --field-selector reason=EvictionThresholdMet --all-namespaces --sort-by='.lastTimestamp'

# æŸ¥çœ‹èŠ‚ç‚¹æ¡ä»¶
kubectl describe node <node-name> | grep -A 10 Conditions

# æŸ¥çœ‹è¢«é©±é€çš„ Pod
kubectl get events --field-selector reason=Evicted --all-namespaces

# æŸ¥çœ‹èŠ‚ç‚¹èµ„æºä½¿ç”¨æƒ…å†µ
kubectl top node <node-name>
kubectl top pods --all-namespaces --field-selector spec.nodeName=<node-name> --sort-by=memory

# æŸ¥çœ‹é©±é€é˜ˆå€¼é…ç½®
kubectl get --raw /api/v1/nodes/<node-name>/proxy/configz | jq '.kubeletconfig | {evictionHard, evictionSoft, evictionSoftGracePeriod, evictionMaxPodGracePeriod}'

# ç™»å½•èŠ‚ç‚¹æŸ¥çœ‹èµ„æº
free -h
df -h
cat /proc/meminfo | grep -i available

# æŸ¥çœ‹ kubelet é©±é€æ—¥å¿—
journalctl -u kubelet | grep -i "evict\|threshold"

# æŸ¥çœ‹å“ªäº› Pod è¢«é©±é€äº†
kubectl get pods --all-namespaces -o json | jq '.items[] | select(.status.reason=="Evicted") | {name: .metadata.name, namespace: .metadata.namespace, reason: .status.reason, message: .status.message}'
```

#### è§£å†³å»ºè®®

| åœºæ™¯ | è§£å†³æ–¹æ¡ˆ |
|:---|:---|
| å†…å­˜é©±é€ | ä¼˜åŒ–åº”ç”¨å†…å­˜ä½¿ç”¨ï¼Œè°ƒæ•´ Pod memory requests/limits |
| ç£ç›˜é©±é€ | æ¸…ç†ç£ç›˜ç©ºé—´ï¼Œæ‰©å®¹ç£ç›˜ï¼Œé™åˆ¶å®¹å™¨æ—¥å¿—å¤§å° |
| PID é©±é€ | é™åˆ¶å®¹å™¨è¿›ç¨‹æ•°ï¼Œä¿®å¤è¿›ç¨‹æ³„æ¼é—®é¢˜ |
| é¢‘ç¹é©±é€ | å¢åŠ èŠ‚ç‚¹èµ„æºï¼Œæˆ–è°ƒæ•´é©±é€é˜ˆå€¼ |
| é˜ˆå€¼é…ç½®ä¸å½“ | æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ evictionHard/evictionSoft é…ç½® |
| åº”ç”¨èµ„æºé…ç½®ä¸å½“ | ä¸º Pod è®¾ç½®åˆç†çš„ requests å’Œ limits |
| é›†ç¾¤å®¹é‡ä¸è¶³ | å¢åŠ æ›´å¤šå·¥ä½œèŠ‚ç‚¹ |
| é˜²æ­¢ç‰¹å®š Pod è¢«é©±é€ | ä½¿ç”¨ Guaranteed QoSï¼Œè®¾ç½® PriorityClass |

**æ¨èé©±é€é˜ˆå€¼é…ç½®**ï¼š

```yaml
# kubelet é…ç½®
evictionHard:
  memory.available: "500Mi"
  nodefs.available: "10%"
  imagefs.available: "15%"
  nodefs.inodesFree: "5%"
  pid.available: "5%"

evictionSoft:
  memory.available: "1Gi"
  nodefs.available: "15%"
  imagefs.available: "20%"

evictionSoftGracePeriod:
  memory.available: "1m30s"
  nodefs.available: "2m"
  imagefs.available: "2m"

evictionMaxPodGracePeriod: 60
```

---

### `ContainerGCFailed` - å®¹å™¨åƒåœ¾å›æ”¶å¤±è´¥

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Warning |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (GC å¤±è´¥æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤º kubelet å°è¯•æ¸…ç†å·²åœæ­¢çš„å®¹å™¨ï¼ˆContainer Garbage Collectionï¼‰æ—¶å¤±è´¥ã€‚Container GC è´Ÿè´£åˆ é™¤å·²ç»é€€å‡ºçš„å®¹å™¨ï¼Œé‡Šæ”¾ç£ç›˜ç©ºé—´ã€‚

kubelet çš„ Container GC ç­–ç•¥ï¼š
- **MinAge**ï¼šå®¹å™¨è‡³å°‘å­˜åœ¨å¤šä¹…åæ‰èƒ½è¢«å›æ”¶ï¼ˆé»˜è®¤ 0ï¼Œç«‹å³å›æ”¶ï¼‰
- **MaxPerPodContainer**ï¼šæ¯ä¸ª Pod ä¿ç•™çš„æ­»äº¡å®¹å™¨æ•°ï¼ˆé»˜è®¤ 1ï¼‰
- **MaxContainers**ï¼šèŠ‚ç‚¹ä¸Šä¿ç•™çš„æ­»äº¡å®¹å™¨æ€»æ•°ï¼ˆé»˜è®¤ -1ï¼Œæ— é™åˆ¶ï¼‰

GC å¤±è´¥å¯èƒ½ç”±ä»¥ä¸‹åŸå› å¯¼è‡´ï¼š
1. å®¹å™¨è¿è¡Œæ—¶ï¼ˆcontainerd/dockerï¼‰API è°ƒç”¨å¤±è´¥
2. å®¹å™¨å·æ— æ³•å¸è½½
3. å®¹å™¨æ–‡ä»¶ç³»ç»Ÿæ— æ³•åˆ é™¤
4. æƒé™é—®é¢˜

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Warning
Reason:  ContainerGCFailed
Message: rpc error: code = Unknown desc = failed to remove container "abc123": device or resource busy
Source:  kubelet, node1.example.com
```

```yaml
Type:    Warning
Reason:  ContainerGCFailed
Message: failed to garbage collect containers: rpc error accessing container runtime
Source:  kubelet, node1.example.com
```

#### å½±å“é¢è¯´æ˜

- **ç£ç›˜ç©ºé—´**ï¼šæ— æ³•é€šè¿‡ Container GC é‡Šæ”¾ç£ç›˜ç©ºé—´
- **å®¹å™¨æ•°é‡**ï¼šæ­»äº¡å®¹å™¨å †ç§¯ï¼Œå ç”¨èµ„æº
- **æ€§èƒ½å½±å“**ï¼šè¿‡å¤šå®¹å™¨å¯èƒ½å½±å“å®¹å™¨è¿è¡Œæ—¶æ€§èƒ½
- **ç£ç›˜å‹åŠ›**ï¼šå¯èƒ½åŠ å‰§ DiskPressure çŠ¶æ€

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹ Container GC å¤±è´¥äº‹ä»¶
kubectl get events --field-selector reason=ContainerGCFailed --all-namespaces

# æŸ¥çœ‹èŠ‚ç‚¹äº‹ä»¶è¯¦æƒ…
kubectl describe node <node-name>

# ç™»å½•èŠ‚ç‚¹æŸ¥çœ‹å·²åœæ­¢çš„å®¹å™¨
crictl ps -a | grep Exited | wc -l
crictl ps -a | grep Exited | head -20

# æŸ¥çœ‹å®¹å™¨è¿è¡Œæ—¶çŠ¶æ€
systemctl status containerd
crictl info

# å°è¯•æ‰‹åŠ¨åˆ é™¤å®¹å™¨
crictl rm <container-id>

# æŸ¥çœ‹å®¹å™¨æ–‡ä»¶ç³»ç»Ÿ
ls -la /run/containerd/io.containerd.runtime.v2.task/k8s.io/
ls -la /var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/

# æŸ¥çœ‹æŒ‚è½½ç‚¹
mount | grep kubelet
mount | grep overlay

# æŸ¥çœ‹ kubelet æ—¥å¿—
journalctl -u kubelet | grep -i "container gc\|garbage collect"

# æŸ¥çœ‹å®¹å™¨è¿è¡Œæ—¶æ—¥å¿—
journalctl -u containerd | grep -i "remove\|delete\|error"

# æ£€æŸ¥ç£ç›˜ I/O
iostat -x 1 5
```

#### è§£å†³å»ºè®®

| åŸå›  | è§£å†³æ–¹æ¡ˆ |
|:---|:---|
| å®¹å™¨è¿è¡Œæ—¶æ•…éšœ | é‡å¯å®¹å™¨è¿è¡Œæ—¶: `systemctl restart containerd` |
| å·å¸è½½å¤±è´¥ | æ‰‹åŠ¨å¸è½½: `umount <mount-point>` |
| æ–‡ä»¶ç³»ç»Ÿç¹å¿™ | æŸ¥æ‰¾å ç”¨è¿›ç¨‹: `lsof <file>`, `fuser -m <mount-point>` |
| æƒé™é—®é¢˜ | æ£€æŸ¥ kubelet å’Œå®¹å™¨è¿è¡Œæ—¶çš„æƒé™ |
| overlayfs é—®é¢˜ | æ‰‹åŠ¨æ¸…ç† overlay å±‚ |
| æ‰‹åŠ¨æ¸…ç†å®¹å™¨ | `crictl rm $(crictl ps -a -q --state Exited)` |
| é‡å¯ kubelet | `systemctl restart kubelet` |
| æ–‡ä»¶ç³»ç»ŸæŸå | è¿è¡Œ `fsck` ä¿®å¤æ–‡ä»¶ç³»ç»Ÿï¼ˆéœ€è¦å…ˆ drain èŠ‚ç‚¹ï¼‰ |

---

### `ImageGCFailed` - é•œåƒåƒåœ¾å›æ”¶å¤±è´¥

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Warning |
| **æ¥æºç»„ä»¶** | kubelet |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (GC å¤±è´¥æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤º kubelet å°è¯•æ¸…ç†æœªä½¿ç”¨çš„å®¹å™¨é•œåƒï¼ˆImage Garbage Collectionï¼‰æ—¶å¤±è´¥ã€‚Image GC è´Ÿè´£åˆ é™¤ä¸å†ä½¿ç”¨çš„é•œåƒï¼Œé‡Šæ”¾ç£ç›˜ç©ºé—´ã€‚

kubelet çš„ Image GC ç­–ç•¥ï¼š
- **HighThresholdPercent**ï¼šç£ç›˜ä½¿ç”¨ç‡è¾¾åˆ°æ­¤å€¼æ—¶è§¦å‘ GCï¼ˆé»˜è®¤ 85%ï¼‰
- **LowThresholdPercent**ï¼šGC ä¼šåˆ é™¤é•œåƒç›´åˆ°ç£ç›˜ä½¿ç”¨ç‡é™åˆ°æ­¤å€¼ï¼ˆé»˜è®¤ 80%ï¼‰
- **MinAge**ï¼šé•œåƒè‡³å°‘å­˜åœ¨å¤šä¹…åæ‰èƒ½è¢«å›æ”¶ï¼ˆé»˜è®¤ 2 åˆ†é’Ÿï¼‰

Image GC ä¼šæ ¹æ®é•œåƒçš„æœ€åä½¿ç”¨æ—¶é—´ï¼ˆLRUï¼‰æ¥å†³å®šåˆ é™¤é¡ºåºï¼Œæ­£åœ¨ä½¿ç”¨çš„é•œåƒä¸ä¼šè¢«åˆ é™¤ã€‚

GC å¤±è´¥å¯èƒ½ç”±ä»¥ä¸‹åŸå› å¯¼è‡´ï¼š
1. å®¹å™¨è¿è¡Œæ—¶ API è°ƒç”¨å¤±è´¥
2. æ‰€æœ‰é•œåƒéƒ½åœ¨ä½¿ç”¨ä¸­
3. é•œåƒæ–‡ä»¶ç³»ç»ŸæŸå
4. æƒé™é—®é¢˜

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Warning
Reason:  ImageGCFailed
Message: failed to garbage collect required amount of images. Attempted to free 10737418240 bytes, but only freed 1073741824 bytes
Source:  kubelet, node1.example.com
```

```yaml
Type:    Warning
Reason:  ImageGCFailed
Message: failed to get ImageFs info: unable to find data for container /
Source:  kubelet, node1.example.com
```

```yaml
Type:    Warning
Reason:  ImageGCFailed
Message: rpc error: code = Unknown desc = failed to remove image: image is being used by containers
Source:  kubelet, node1.example.com
```

#### å½±å“é¢è¯´æ˜

- **ç£ç›˜ç©ºé—´**ï¼šæ— æ³•é€šè¿‡ Image GC é‡Šæ”¾ç£ç›˜ç©ºé—´
- **é•œåƒå †ç§¯**ï¼šæœªä½¿ç”¨çš„é•œåƒå †ç§¯ï¼Œå ç”¨ç£ç›˜
- **ç£ç›˜å‹åŠ›**ï¼šå¯èƒ½å¯¼è‡´æˆ–åŠ å‰§ DiskPressure çŠ¶æ€
- **é•œåƒæ‹‰å–**ï¼šå¯èƒ½æ— æ³•æ‹‰å–æ–°é•œåƒ

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹ Image GC å¤±è´¥äº‹ä»¶
kubectl get events --field-selector reason=ImageGCFailed --all-namespaces

# æŸ¥çœ‹èŠ‚ç‚¹äº‹ä»¶è¯¦æƒ…
kubectl describe node <node-name>

# ç™»å½•èŠ‚ç‚¹æŸ¥çœ‹é•œåƒå ç”¨
crictl images
crictl images -v

# æŸ¥çœ‹é•œåƒå ç”¨ç©ºé—´æ€»å’Œ
crictl images -v | awk 'NR>1 {sum+=$5} END {print "Total:", sum/1024/1024/1024 "GB"}'

# æŸ¥çœ‹å“ªäº›é•œåƒå ç”¨æœ€å¤š
crictl images -v | sort -k5 -rh | head -20

# æŸ¥çœ‹é•œåƒä½¿ç”¨æƒ…å†µ
for img in $(crictl images -q); do
  echo "Image: $img"
  crictl ps -a | grep $img | wc -l
done

# æŸ¥çœ‹ç£ç›˜ä½¿ç”¨æƒ…å†µ
df -h
du -sh /var/lib/containerd/io.containerd.content.v1.content

# æŸ¥çœ‹ kubelet GC é…ç½®
kubectl get --raw /api/v1/nodes/<node-name>/proxy/configz | jq '.kubeletconfig | {imageGCHighThresholdPercent, imageGCLowThresholdPercent, imageMinimumGCAge}'

# æŸ¥çœ‹ kubelet æ—¥å¿—
journalctl -u kubelet | grep -i "image gc\|garbage collect"

# æŸ¥çœ‹å®¹å™¨è¿è¡Œæ—¶æ—¥å¿—
journalctl -u containerd | grep -i "image\|remove\|delete"

# å°è¯•æ‰‹åŠ¨åˆ é™¤æœªä½¿ç”¨çš„é•œåƒ
crictl rmi --prune
```

#### è§£å†³å»ºè®®

| åŸå›  | è§£å†³æ–¹æ¡ˆ |
|:---|:---|
| æ‰€æœ‰é•œåƒéƒ½åœ¨ä½¿ç”¨ | åˆ é™¤ä¸éœ€è¦çš„ Podï¼Œé‡Šæ”¾é•œåƒå¼•ç”¨ |
| å®¹å™¨è¿è¡Œæ—¶æ•…éšœ | é‡å¯å®¹å™¨è¿è¡Œæ—¶: `systemctl restart containerd` |
| GC é˜ˆå€¼è¿‡é«˜ | é™ä½ imageGCHighThresholdPercentï¼Œæ›´æ—©è§¦å‘ GC |
| é•œåƒçœŸçš„å¤ªå¤š | æ‰‹åŠ¨åˆ é™¤æœªä½¿ç”¨çš„é•œåƒ: `crictl rmi <image-id>` |
| ç£ç›˜çœŸçš„æ»¡äº† | æ‰©å®¹ç£ç›˜ï¼Œæˆ–ä¸º imagefs å•ç‹¬åˆ†é…ç£ç›˜ |
| é•œåƒæ‹‰å–ç­–ç•¥é—®é¢˜ | è°ƒæ•´ Pod çš„ imagePullPolicyï¼Œé¿å…å †ç§¯å¤šä¸ªç‰ˆæœ¬ |
| æ‰‹åŠ¨æ¸…ç† | `crictl rmi --prune` åˆ é™¤æ‰€æœ‰æœªä½¿ç”¨çš„é•œåƒ |
| é‡å¯ kubelet | `systemctl restart kubelet` |

**æ‰‹åŠ¨æ¸…ç†æ­¥éª¤**ï¼š

```bash
# 1. æŸ¥çœ‹é•œåƒåˆ—è¡¨
crictl images

# 2. åˆ é™¤æœªä½¿ç”¨çš„é•œåƒï¼ˆè°¨æ…æ“ä½œï¼‰
crictl rmi --prune

# 3. æ‰‹åŠ¨åˆ é™¤ç‰¹å®šé•œåƒ
crictl rmi <image-id>

# 4. æŸ¥çœ‹æ¸…ç†æ•ˆæœ
df -h
crictl images
```

---

## Node Controller äº‹ä»¶

### `RegisteredNode` - èŠ‚ç‚¹å·²æ³¨å†Œ

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Normal |
| **æ¥æºç»„ä»¶** | node-controller |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (æ–°èŠ‚ç‚¹åŠ å…¥æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤ºæ–°èŠ‚ç‚¹å·²æˆåŠŸæ³¨å†Œåˆ° Kubernetes é›†ç¾¤çš„æ§åˆ¶å¹³é¢ã€‚å½“ kubelet é¦–æ¬¡å¯åŠ¨æ—¶ï¼Œå®ƒä¼šå‘ API Server æ³¨å†ŒèŠ‚ç‚¹å¯¹è±¡ï¼Œnode-controller æ£€æµ‹åˆ°æ–°èŠ‚ç‚¹åä¼šäº§ç”Ÿæ­¤äº‹ä»¶ã€‚

èŠ‚ç‚¹æ³¨å†Œæ˜¯èŠ‚ç‚¹åŠ å…¥é›†ç¾¤çš„ç¬¬ä¸€æ­¥ï¼Œä¹‹å node-controller ä¼šæŒç»­ç›‘æ§èŠ‚ç‚¹çš„å¥åº·çŠ¶æ€ã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Normal
Reason:  RegisteredNode
Message: Node node1.example.com event: Registered Node node1.example.com in Controller
Source:  node-controller
```

æˆ–è€…ï¼š

```yaml
Type:    Normal
Reason:  RegisteredNode
Message: Registered node node1.example.com
Source:  controllermanager
```

#### å½±å“é¢è¯´æ˜

- **é›†ç¾¤å½±å“**ï¼šé›†ç¾¤å¢åŠ ä¸€ä¸ªæ–°çš„å·¥ä½œèŠ‚ç‚¹
- **å®¹é‡å½±å“**ï¼šé›†ç¾¤æ€»å®¹é‡å¢åŠ 
- **ç›‘æ§å½±å“**ï¼šnode-controller å¼€å§‹ç›‘æ§æ­¤èŠ‚ç‚¹

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹æ³¨å†Œäº‹ä»¶
kubectl get events --field-selector reason=RegisteredNode --all-namespaces

# æŸ¥çœ‹èŠ‚ç‚¹ä¿¡æ¯
kubectl get nodes
kubectl describe node <node-name>

# æŸ¥çœ‹èŠ‚ç‚¹æ³¨å†Œæ—¶é—´
kubectl get node <node-name> -o jsonpath='{.metadata.creationTimestamp}'

# æŸ¥çœ‹èŠ‚ç‚¹æ ‡ç­¾å’Œæ³¨è§£
kubectl get node <node-name> -o json | jq '.metadata.labels, .metadata.annotations'

# æŸ¥çœ‹ node-controller æ—¥å¿—ï¼ˆéœ€è¦è®¿é—®æ§åˆ¶å¹³é¢ï¼‰
kubectl logs -n kube-system <controller-manager-pod> | grep -i "register\|node"
```

#### è§£å†³å»ºè®®

| åœºæ™¯ | å»ºè®® |
|:---|:---|
| æ–°èŠ‚ç‚¹åŠ å…¥ | æ­£å¸¸æƒ…å†µï¼ŒéªŒè¯èŠ‚ç‚¹é…ç½®å’Œèµ„æº |
| æ„å¤–æ³¨å†Œ | æ£€æŸ¥æ˜¯å¦æœ‰æœªæˆæƒçš„èŠ‚ç‚¹åŠ å…¥é›†ç¾¤ |
| é‡å¤æ³¨å†Œ | æ£€æŸ¥ kubelet é…ç½®ï¼Œå¯èƒ½æ˜¯èŠ‚ç‚¹åç§°å†²çª |

---

### `RemovingNode` - ä»æ§åˆ¶å™¨ç§»é™¤èŠ‚ç‚¹

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Normal |
| **æ¥æºç»„ä»¶** | node-controller |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (èŠ‚ç‚¹åˆ é™¤æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤º node-controller æ­£åœ¨å°†èŠ‚ç‚¹ä»å…¶ç®¡ç†åˆ—è¡¨ä¸­ç§»é™¤ã€‚è¿™é€šå¸¸å‘ç”Ÿåœ¨æ‰§è¡Œ `kubectl delete node` å‘½ä»¤åï¼Œæˆ–è€…èŠ‚ç‚¹å¯¹è±¡è¢« API Server åˆ é™¤æ—¶ã€‚

ç§»é™¤èŠ‚ç‚¹åï¼Œnode-controller å°†ä¸å†ç›‘æ§æ­¤èŠ‚ç‚¹çš„å¥åº·çŠ¶æ€ã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Normal
Reason:  RemovingNode
Message: Removing Node node1.example.com from Controller
Source:  node-controller
```

#### å½±å“é¢è¯´æ˜

- **é›†ç¾¤å½±å“**ï¼šé›†ç¾¤å®¹é‡å‡å°‘
- **ç›‘æ§å½±å“**ï¼šnode-controller åœæ­¢ç›‘æ§æ­¤èŠ‚ç‚¹
- **Pod å½±å“**ï¼šèŠ‚ç‚¹ä¸Šçš„ Pod å·²ç»æˆ–å°†è¦è¢«åˆ é™¤

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹åˆ é™¤äº‹ä»¶
kubectl get events --field-selector reason=RemovingNode --all-namespaces

# æŸ¥çœ‹èŠ‚ç‚¹åˆ—è¡¨
kubectl get nodes

# æŸ¥çœ‹ node-controller æ—¥å¿—
kubectl logs -n kube-system <controller-manager-pod> | grep -i "remove\|delete"
```

#### è§£å†³å»ºè®®

| åœºæ™¯ | å»ºè®® |
|:---|:---|
| è®¡åˆ’å†…ä¸‹çº¿ | æ­£å¸¸æ“ä½œï¼Œç¡®è®¤èŠ‚ç‚¹å·² drain |
| æ„å¤–åˆ é™¤ | æ£€æŸ¥æ“ä½œå®¡è®¡æ—¥å¿—ï¼Œæ‰¾å‡ºåˆ é™¤æ¥æº |
| èŠ‚ç‚¹æ•…éšœåæ¸…ç† | æ­£å¸¸æƒ…å†µï¼Œæ¸…ç†å¤±è´¥èŠ‚ç‚¹ |

---

### `DeletingNode` - åˆ é™¤èŠ‚ç‚¹

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Normal |
| **æ¥æºç»„ä»¶** | node-controller |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (èŠ‚ç‚¹åˆ é™¤æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤º node-controller æ­£åœ¨åˆ é™¤èŠ‚ç‚¹å¯¹è±¡ã€‚è¿™æ˜¯èŠ‚ç‚¹ç”Ÿå‘½å‘¨æœŸçš„ç»ˆç‚¹ã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Normal
Reason:  DeletingNode
Message: Deleting Node node1.example.com
Source:  node-controller
```

#### å½±å“é¢è¯´æ˜

- **èŠ‚ç‚¹å¯¹è±¡**ï¼šèŠ‚ç‚¹å¯¹è±¡å°†ä» API Server åˆ é™¤
- **Pod å½±å“**ï¼šèŠ‚ç‚¹ä¸Šçš„ Pod åº”è¯¥å·²ç»è¢«åˆ é™¤
- **èµ„æºå½±å“**ï¼šèŠ‚ç‚¹çš„èµ„æºä¸å†è®¡å…¥é›†ç¾¤å®¹é‡

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹èŠ‚ç‚¹åˆ é™¤äº‹ä»¶
kubectl get events --field-selector reason=DeletingNode --all-namespaces

# æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦è¿˜å­˜åœ¨
kubectl get nodes | grep <node-name>

# æŸ¥çœ‹æ‰€æœ‰èŠ‚ç‚¹
kubectl get nodes
```

#### è§£å†³å»ºè®®

| åœºæ™¯ | å»ºè®® |
|:---|:---|
| æ­£å¸¸ä¸‹çº¿ | æ— éœ€å¤„ç†ï¼ŒèŠ‚ç‚¹å·²æˆåŠŸç§»é™¤ |
| ç¡®è®¤ Pod è¿ç§» | æ£€æŸ¥åº”ç”¨æ˜¯å¦å·²åœ¨å…¶ä»–èŠ‚ç‚¹è¿è¡Œ |
| æ›´æ–°ç›‘æ§å’Œå‘Šè­¦ | ç§»é™¤å¯¹æ­¤èŠ‚ç‚¹çš„ç›‘æ§é…ç½® |

---

### `DeletingAllPods` - åˆ é™¤èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰ Pod

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Normal |
| **æ¥æºç»„ä»¶** | node-controller |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ä½é¢‘ (èŠ‚ç‚¹å¤±è´¥æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤º node-controller æ£€æµ‹åˆ°èŠ‚ç‚¹æŒç»­ NotReady è¶…è¿‡ pod-eviction-timeoutï¼ˆé»˜è®¤ 5 åˆ†é’Ÿï¼‰ï¼Œå¼€å§‹å¼ºåˆ¶åˆ é™¤èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰ Podã€‚è¿™æ˜¯èŠ‚ç‚¹å¤±è´¥åçš„è‡ªåŠ¨æ¢å¤æœºåˆ¶ã€‚

å½“èŠ‚ç‚¹é•¿æ—¶é—´ NotReady æ—¶ï¼Œnode-controller ä¼šï¼š
1. äº§ç”Ÿ DeletingAllPods äº‹ä»¶
2. åˆ é™¤èŠ‚ç‚¹ä¸Šæ‰€æœ‰ Pod çš„ API å¯¹è±¡
3. è§¦å‘ Pod åœ¨å…¶ä»–èŠ‚ç‚¹é‡å»ºï¼ˆå¦‚æœæ˜¯ Deployment, StatefulSet ç­‰ç®¡ç†çš„ï¼‰

æ³¨æ„ï¼šè¿™åªæ˜¯åˆ é™¤ API å¯¹è±¡ï¼Œå®é™…çš„å®¹å™¨è¿›ç¨‹å¯èƒ½ä»åœ¨æ•…éšœèŠ‚ç‚¹ä¸Šè¿è¡Œï¼ˆå¦‚æœèŠ‚ç‚¹åªæ˜¯ç½‘ç»œéš”ç¦»è€ŒéçœŸæ­£å®•æœºï¼‰ã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Normal
Reason:  DeletingAllPods
Message: Deleting all Pods from Node node1.example.com
Source:  node-controller
```

```yaml
Type:    Normal
Reason:  DeletingAllPods
Message: Node node1.example.com event: Deleting all Pods because of NodeNotReady condition
Source:  node-controller
```

#### å½±å“é¢è¯´æ˜

- **Pod ç”Ÿå‘½å‘¨æœŸ**ï¼šèŠ‚ç‚¹ä¸Šæ‰€æœ‰ Pod çš„ API å¯¹è±¡è¢«åˆ é™¤
- **æœåŠ¡å½±å“**ï¼š
  - Deployment/ReplicaSetï¼šPod ä¼šåœ¨å…¶ä»–èŠ‚ç‚¹é‡å»º
  - StatefulSetï¼šPod ä¼šæŒ‰é¡ºåºåœ¨å…¶ä»–èŠ‚ç‚¹é‡å»º
  - DaemonSetï¼šPod ä¸ä¼šé‡å»ºï¼ˆå› ä¸ºæ˜¯æŒ‰èŠ‚ç‚¹è°ƒåº¦çš„ï¼‰
  - è£¸ Podï¼ˆæ— æ§åˆ¶å™¨ï¼‰ï¼šPod ä¸¢å¤±ï¼Œä¸ä¼šé‡å»º
- **æ•°æ®å½±å“**ï¼š
  - EmptyDir å·çš„æ•°æ®ä¸¢å¤±
  - hostPath å·çš„æ•°æ®ä¿ç•™åœ¨æ•…éšœèŠ‚ç‚¹
  - PV å·éœ€è¦é‡æ–°æŒ‚è½½ï¼ˆå¯èƒ½å— VolumeAttachment é™åˆ¶ï¼‰
- **æ¢å¤æ—¶é—´**ï¼šå–å†³äº Pod é‡æ–°è°ƒåº¦å’Œå¯åŠ¨çš„æ—¶é—´

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹ DeletingAllPods äº‹ä»¶
kubectl get events --field-selector reason=DeletingAllPods --all-namespaces

# æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€
kubectl get nodes
kubectl describe node <node-name>

# æŸ¥çœ‹èŠ‚ç‚¹ä¸Šçš„ Podï¼ˆå¯èƒ½å·²ç»ä¸å­˜åœ¨ï¼‰
kubectl get pods --all-namespaces --field-selector spec.nodeName=<node-name>

# æŸ¥çœ‹ Pod åˆ é™¤å’Œé‡å»ºäº‹ä»¶
kubectl get events --all-namespaces --sort-by='.lastTimestamp' | grep <node-name>

# æŸ¥çœ‹ Pod åœ¨æ–°èŠ‚ç‚¹ä¸Šçš„çŠ¶æ€
kubectl get pods --all-namespaces -o wide | grep -v <node-name>

# æŸ¥çœ‹ node-controller é…ç½®
kubectl describe cm kube-controller-manager -n kube-system | grep pod-eviction-timeout

# æŸ¥çœ‹ node-controller æ—¥å¿—
kubectl logs -n kube-system <controller-manager-pod> | grep -i "deleting.*pod\|evict"

# æ£€æŸ¥å­˜å‚¨å·çš„æŒ‚è½½çŠ¶æ€
kubectl get volumeattachments | grep <node-name>

# æŸ¥çœ‹å—å½±å“çš„æœåŠ¡
kubectl get svc --all-namespaces
kubectl get endpoints --all-namespaces
```

#### è§£å†³å»ºè®®

| åœºæ™¯ | è§£å†³æ–¹æ¡ˆ |
|:---|:---|
| èŠ‚ç‚¹çœŸçš„å®•æœº | ç¡®è®¤ Pod å·²åœ¨å…¶ä»–èŠ‚ç‚¹é‡å»ºï¼Œä¿®å¤æˆ–æ›´æ¢æ•…éšœèŠ‚ç‚¹ |
| ç½‘ç»œéš”ç¦» | ä¿®å¤ç½‘ç»œé—®é¢˜ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æ¸…ç†æ•…éšœèŠ‚ç‚¹ä¸Šçš„å®¹å™¨ |
| èŠ‚ç‚¹ç»´æŠ¤ | å¦‚æœæ˜¯è®¡åˆ’å†…ç»´æŠ¤ï¼Œåº”è¯¥å…ˆ drain è€Œä¸æ˜¯ç­‰å¾…è‡ªåŠ¨é©±é€ |
| Pod æœªé‡å»º | æ£€æŸ¥æ§åˆ¶å™¨çŠ¶æ€ï¼ˆDeployment, StatefulSet ç­‰ï¼‰ |
| å­˜å‚¨å·æ— æ³•æŒ‚è½½ | æ‰‹åŠ¨é‡Šæ”¾ VolumeAttachment: `kubectl delete volumeattachment <name>` |
| è£¸ Pod ä¸¢å¤± | ä½¿ç”¨æ§åˆ¶å™¨ç®¡ç† Podï¼Œé¿å…ä½¿ç”¨è£¸ Pod |
| æ•°æ®ä¸¢å¤± | ä½¿ç”¨ PV æŒä¹…åŒ–æ•°æ®ï¼Œä¸è¦ä¾èµ– EmptyDir |
| æœåŠ¡ä¸­æ–­æ—¶é—´è¿‡é•¿ | è°ƒæ•´ pod-eviction-timeoutï¼ˆéœ€æƒè¡¡åˆ©å¼Šï¼‰|
| é˜²æ­¢æ•°æ®æŸå | å¯¹äºæœ‰çŠ¶æ€åº”ç”¨ï¼Œè€ƒè™‘ä½¿ç”¨ fencing æœºåˆ¶ |

**pod-eviction-timeout é…ç½®å»ºè®®**ï¼š

```yaml
# kube-controller-manager é…ç½®
# é»˜è®¤å€¼ï¼š5mï¼ˆ5åˆ†é’Ÿï¼‰
# è¾ƒçŸ­çš„è¶…æ—¶ï¼šå¿«é€Ÿæ¢å¤ï¼Œä½†å¯èƒ½è¯¯åˆ¤
# è¾ƒé•¿çš„è¶…æ—¶ï¼šå‡å°‘è¯¯åˆ¤ï¼Œä½†æ¢å¤æ…¢
--pod-eviction-timeout=5m

# å¯¹äºç½‘ç»œä¸ç¨³å®šçš„ç¯å¢ƒï¼Œå¯ä»¥é€‚å½“å»¶é•¿ï¼š
--pod-eviction-timeout=10m
```

---

### `TerminatingEvictedPod` - ç»ˆæ­¢è¢«é©±é€çš„ Pod

| å±æ€§ | è¯´æ˜ |
|:---|:---|
| **äº‹ä»¶ç±»å‹** | Normal |
| **æ¥æºç»„ä»¶** | node-controller |
| **å…³è”èµ„æº** | Node |
| **é€‚ç”¨ç‰ˆæœ¬** | v1.0+ |
| **ç”Ÿäº§é¢‘ç‡** | ä¸­é¢‘ (èŠ‚ç‚¹å¤±è´¥æ—¶) |

#### äº‹ä»¶å«ä¹‰

æ­¤äº‹ä»¶è¡¨ç¤º node-controller æ­£åœ¨æ ‡è®°ç‰¹å®šçš„ Pod ä¸ºåˆ é™¤çŠ¶æ€ã€‚è¿™é€šå¸¸å‘ç”Ÿåœ¨èŠ‚ç‚¹æŒç»­ NotReadyï¼Œnode-controller å¼€å§‹é©±é€èŠ‚ç‚¹ä¸Šçš„ Pod æ—¶ã€‚

æ¯ä¸ªè¢«é©±é€çš„ Pod éƒ½ä¼šäº§ç”Ÿä¸€ä¸ª TerminatingEvictedPod äº‹ä»¶ã€‚

#### å…¸å‹äº‹ä»¶æ¶ˆæ¯

```yaml
Type:    Normal
Reason:  TerminatingEvictedPod
Message: Pod my-app-xxx from Namespace default has been marked for deletion. Pod will be deleted if it is not being updated or node will not be ready before Sun, 10 Feb 2026 11:00:00 +0800
Source:  node-controller
```

æˆ–è€…ï¼š

```yaml
Type:    Normal
Reason:  TerminatingEvictedPod
Message: Marking for deletion Pod my-app-xxx
Source:  node-controller
```

#### å½±å“é¢è¯´æ˜

- **Pod ç”Ÿå‘½å‘¨æœŸ**ï¼šPod è¢«æ ‡è®°ä¸º Terminating çŠ¶æ€
- **æœåŠ¡å½±å“**ï¼šPod å¯¹åº”çš„ Endpoint è¢«ç§»é™¤ï¼Œæµé‡ä¸å†è·¯ç”±åˆ°æ­¤ Pod
- **é‡å»º**ï¼šå¦‚æœ Pod æœ‰æ§åˆ¶å™¨ï¼ˆDeployment ç­‰ï¼‰ï¼Œä¼šåœ¨å…¶ä»–èŠ‚ç‚¹é‡å»º

#### æ’æŸ¥å»ºè®®

```bash
# æŸ¥çœ‹ TerminatingEvictedPod äº‹ä»¶
kubectl get events --field-selector reason=TerminatingEvictedPod --all-namespaces

# æŸ¥çœ‹å¤„äº Terminating çŠ¶æ€çš„ Pod
kubectl get pods --all-namespaces | grep Terminating

# æŸ¥çœ‹ç‰¹å®š Pod çš„äº‹ä»¶
kubectl describe pod <pod-name> -n <namespace>

# æŸ¥çœ‹ Pod çš„çŠ¶æ€å’ŒåŸå› 
kubectl get pod <pod-name> -n <namespace> -o json | jq '.status.reason, .status.message'

# æŸ¥çœ‹ Pod æ‰€åœ¨èŠ‚ç‚¹
kubectl get pod <pod-name> -n <namespace> -o jsonpath='{.spec.nodeName}'

# æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€
kubectl describe node <node-name>
```

#### è§£å†³å»ºè®®

| åœºæ™¯ | è§£å†³æ–¹æ¡ˆ |
|:---|:---|
| èŠ‚ç‚¹ NotReady | ä¿®å¤èŠ‚ç‚¹ï¼Œæˆ–ç¡®è®¤ Pod å·²åœ¨å…¶ä»–èŠ‚ç‚¹é‡å»º |
| Pod é•¿æ—¶é—´ Terminating | æ£€æŸ¥èŠ‚ç‚¹è¿é€šæ€§ï¼Œå¯èƒ½éœ€è¦å¼ºåˆ¶åˆ é™¤: `kubectl delete pod <pod> --grace-period=0 --force` |
| é¢‘ç¹é©±é€ | è°ƒæŸ¥èŠ‚ç‚¹ä¸ç¨³å®šçš„æ ¹æœ¬åŸå› ï¼Œä¿®å¤åŸºç¡€è®¾æ–½é—®é¢˜ |
| æœåŠ¡å½±å“ | ç¡®ä¿æœ‰è¶³å¤Ÿçš„å‰¯æœ¬æ•°ï¼Œé¿å…å•ç‚¹æ•…éšœ |

---

## èŠ‚ç‚¹é©±é€æœºåˆ¶

### kubelet é©±é€ï¼ˆNode-pressure Evictionï¼‰

kubelet ä¼šä¸»åŠ¨ç›‘æ§èŠ‚ç‚¹èµ„æºï¼Œå½“èµ„æºä¸è¶³æ—¶é©±é€ Podã€‚

#### é©±é€ä¿¡å·ï¼ˆEviction Signalsï¼‰

| ä¿¡å· | å«ä¹‰ | æè¿° |
|:---|:---|:---|
| `memory.available` | å¯ç”¨å†…å­˜ | `memory.available := node.status.capacity[memory] - workingSet` |
| `nodefs.available` | èŠ‚ç‚¹æ ¹æ–‡ä»¶ç³»ç»Ÿå¯ç”¨ç©ºé—´ | `nodefs.available := node.stats.fs.available` |
| `nodefs.inodesFree` | èŠ‚ç‚¹æ ¹æ–‡ä»¶ç³»ç»Ÿå¯ç”¨ inode | `nodefs.inodesFree := node.stats.fs.inodesFree` |
| `imagefs.available` | é•œåƒæ–‡ä»¶ç³»ç»Ÿå¯ç”¨ç©ºé—´ | `imagefs.available := node.stats.runtime.imagefs.available` |
| `imagefs.inodesFree` | é•œåƒæ–‡ä»¶ç³»ç»Ÿå¯ç”¨ inode | `imagefs.inodesFree := node.stats.runtime.imagefs.inodesFree` |
| `pid.available` | å¯ç”¨è¿›ç¨‹ ID | `pid.available := node.stats.rlimit.maxpid - node.stats.rlimit.curproc` |

#### é©±é€é˜ˆå€¼ç±»å‹

**ç¡¬é©±é€é˜ˆå€¼ï¼ˆHard Eviction Thresholdsï¼‰**ï¼š
- è¾¾åˆ°é˜ˆå€¼ç«‹å³é©±é€ï¼Œæ²¡æœ‰å®½é™æœŸ
- ä¸éµå®ˆ Pod çš„ terminationGracePeriodSeconds
- é»˜è®¤é…ç½®ï¼š
  ```yaml
  evictionHard:
    memory.available: "100Mi"
    nodefs.available: "10%"
    nodefs.inodesFree: "5%"
    imagefs.available: "15%"
  ```

**è½¯é©±é€é˜ˆå€¼ï¼ˆSoft Eviction Thresholdsï¼‰**ï¼š
- è¾¾åˆ°é˜ˆå€¼åç­‰å¾…å®½é™æœŸï¼ŒæœŸé—´èµ„æºæ¢å¤åˆ™ä¸é©±é€
- éµå®ˆ Pod çš„ terminationGracePeriodSecondsï¼ˆä½†ä¸è¶…è¿‡ evictionMaxPodGracePeriodï¼‰
- é»˜è®¤é…ç½®ï¼š
  ```yaml
  evictionSoft:
    memory.available: "1.5Gi"
    nodefs.available: "15%"
  evictionSoftGracePeriod:
    memory.available: "1m30s"
    nodefs.available: "2m"
  evictionMaxPodGracePeriod: 90
  ```

#### é©±é€ç­–ç•¥

**1. é©±é€é¡ºåºï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰**ï¼š

1. **BestEffort or Burstable** Pods ä¸”ä½¿ç”¨é‡è¶…è¿‡ requests
2. **Burstable** Pods ä¸”ä½¿ç”¨é‡ä½äº requests
3. **Guaranteed** Pods å’Œ **Burstable** Pods ä¸”ä½¿ç”¨é‡ç­‰äº requests

åœ¨åŒä¸€ä¼˜å…ˆçº§å†…ï¼ŒæŒ‰ä»¥ä¸‹é¡ºåºé©±é€ï¼š
1. Pod Priority è¾ƒä½çš„ï¼ˆPriorityClassï¼‰
2. èµ„æºä½¿ç”¨é‡è¶…è¿‡ requests æ›´å¤šçš„
3. Pod Priority å’Œèµ„æºä½¿ç”¨ç›¸åŒæ—¶ï¼Œéšæœºé€‰æ‹©

**2. é©±é€è¡Œä¸º**ï¼š

- **å†…å­˜å‹åŠ›**ï¼škubelet ä¸ç­‰å¾…å®½é™æœŸï¼Œç«‹å³æ€æ‰ Podï¼ˆç±»ä¼¼ OOM killerï¼‰
- **ç£ç›˜å‹åŠ›**ï¼škubelet å…ˆæ‰§è¡Œ Image GC å’Œ Container GCï¼Œå¤±è´¥åæ‰é©±é€ Pod
- **PID å‹åŠ›**ï¼škubelet é©±é€ Pod ä»¥é‡Šæ”¾ PID

**3. æœ€å°å›æ”¶é‡ï¼ˆMinimum Eviction Reclaimï¼‰**ï¼š

kubelet å¯ä»¥é…ç½®æœ€å°å›æ”¶é‡ï¼Œç¡®ä¿é©±é€åèµ„æºå……è¶³ï¼š

```yaml
evictionMinimumReclaim:
  memory.available: "500Mi"
  nodefs.available: "1Gi"
  imagefs.available: "2Gi"
```

### node-controller é©±é€ï¼ˆTaint-based Evictionï¼‰

node-controller é€šè¿‡ taint æœºåˆ¶é©±é€ Podã€‚

#### Taint ç±»å‹

å½“èŠ‚ç‚¹å‡ºç°é—®é¢˜æ—¶ï¼Œnode-controller ä¼šè‡ªåŠ¨æ·»åŠ  taintï¼š

| Taint Key | Effect | æ¡ä»¶ | å«ä¹‰ |
|:---|:---|:---|:---|
| `node.kubernetes.io/not-ready` | NoExecute | Ready=False | èŠ‚ç‚¹æœªå°±ç»ª |
| `node.kubernetes.io/unreachable` | NoExecute | Ready=Unknown | èŠ‚ç‚¹ä¸å¯è¾¾ |
| `node.kubernetes.io/memory-pressure` | NoSchedule | MemoryPressure=True | å†…å­˜å‹åŠ› |
| `node.kubernetes.io/disk-pressure` | NoSchedule | DiskPressure=True | ç£ç›˜å‹åŠ› |
| `node.kubernetes.io/pid-pressure` | NoSchedule | PIDPressure=True | PID å‹åŠ› |
| `node.kubernetes.io/network-unavailable` | NoSchedule | NetworkUnavailable=True | ç½‘ç»œä¸å¯ç”¨ |
| `node.kubernetes.io/unschedulable` | NoSchedule | spec.unschedulable=true | èŠ‚ç‚¹ä¸å¯è°ƒåº¦ |

#### å®¹å¿æ—¶é—´ï¼ˆToleration Secondsï¼‰

Pod å¯ä»¥é€šè¿‡ toleration è®¾ç½®å¯¹ taint çš„å®¹å¿æ—¶é—´ï¼š

```yaml
tolerations:
- key: "node.kubernetes.io/not-ready"
  operator: "Exists"
  effect: "NoExecute"
  tolerationSeconds: 300  # 5åˆ†é’Ÿ
- key: "node.kubernetes.io/unreachable"
  operator: "Exists"
  effect: "NoExecute"
  tolerationSeconds: 300  # 5åˆ†é’Ÿ
```

é»˜è®¤æƒ…å†µä¸‹ï¼ŒKubernetes ä¼šè‡ªåŠ¨ä¸ºæ‰€æœ‰ Pod æ·»åŠ ä»¥ä¸‹ tolerationï¼š
- `node.kubernetes.io/not-ready:NoExecute` for 300s
- `node.kubernetes.io/unreachable:NoExecute` for 300s

DaemonSet çš„ Pod ä¼šæœ‰ç‰¹æ®Šçš„ tolerationï¼Œä¸ä¼šå› ä¸ºèŠ‚ç‚¹é—®é¢˜è¢«é©±é€ã€‚

---

## ç”Ÿäº§ç¯å¢ƒç›‘æ§å»ºè®®

### ç›‘æ§æŒ‡æ ‡

**èŠ‚ç‚¹çº§åˆ«æŒ‡æ ‡**ï¼š

| æŒ‡æ ‡ | å«ä¹‰ | å‘Šè­¦é˜ˆå€¼å»ºè®® |
|:---|:---|:---|
| `kube_node_status_condition{condition="Ready",status="true"}` | èŠ‚ç‚¹ Ready çŠ¶æ€ | == 0 æŒç»­ 1 åˆ†é’Ÿ |
| `kube_node_status_condition{condition="MemoryPressure",status="true"}` | èŠ‚ç‚¹å†…å­˜å‹åŠ› | == 1 |
| `kube_node_status_condition{condition="DiskPressure",status="true"}` | èŠ‚ç‚¹ç£ç›˜å‹åŠ› | == 1 |
| `kube_node_status_condition{condition="PIDPressure",status="true"}` | èŠ‚ç‚¹ PID å‹åŠ› | == 1 |
| `kube_node_spec_unschedulable` | èŠ‚ç‚¹ä¸å¯è°ƒåº¦ | == 1 æŒç»­ 10 åˆ†é’Ÿ |
| `node_memory_MemAvailable_bytes` | èŠ‚ç‚¹å¯ç”¨å†…å­˜ | < 500Mi |
| `node_filesystem_avail_bytes{mountpoint="/"}` | èŠ‚ç‚¹ç£ç›˜å¯ç”¨ç©ºé—´ | < 10% |
| `node_filesystem_files_free{mountpoint="/"}` | èŠ‚ç‚¹å¯ç”¨ inode | < 10% |

**äº‹ä»¶çº§åˆ«ç›‘æ§**ï¼š

```promql
# èŠ‚ç‚¹ NotReady äº‹ä»¶
kube_event_count{reason="NodeNotReady"} > 0

# é©±é€é˜ˆå€¼äº‹ä»¶
kube_event_count{reason="EvictionThresholdMet"} > 0

# Pod é©±é€äº‹ä»¶
kube_event_count{reason="Evicted"} > 0

# èŠ‚ç‚¹é‡å¯äº‹ä»¶
kube_event_count{reason="Rebooted"} > 0

# GC å¤±è´¥äº‹ä»¶
kube_event_count{reason=~"ImageGCFailed|ContainerGCFailed"} > 0
```

### å‘Šè­¦è§„åˆ™

**Prometheus AlertManager è§„åˆ™ç¤ºä¾‹**ï¼š

```yaml
groups:
- name: node-health
  interval: 30s
  rules:
  # èŠ‚ç‚¹ NotReady
  - alert: NodeNotReady
    expr: kube_node_status_condition{condition="Ready",status="true"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Node {{ $labels.node }} is not ready"
      description: "Node {{ $labels.node }} has been NotReady for more than 1 minute."

  # èŠ‚ç‚¹å†…å­˜å‹åŠ›
  - alert: NodeMemoryPressure
    expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Node {{ $labels.node }} has memory pressure"
      description: "Node {{ $labels.node }} has been under memory pressure for more than 5 minutes."

  # èŠ‚ç‚¹ç£ç›˜å‹åŠ›
  - alert: NodeDiskPressure
    expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Node {{ $labels.node }} has disk pressure"
      description: "Node {{ $labels.node }} has been under disk pressure for more than 5 minutes."

  # èŠ‚ç‚¹ PID å‹åŠ›
  - alert: NodePIDPressure
    expr: kube_node_status_condition{condition="PIDPressure",status="true"} == 1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Node {{ $labels.node }} has PID pressure"
      description: "Node {{ $labels.node }} has been under PID pressure for more than 2 minutes."

  # èŠ‚ç‚¹å¯ç”¨å†…å­˜ä½
  - alert: NodeLowMemory
    expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Node {{ $labels.node }} has low available memory"
      description: "Node {{ $labels.node }} has less than 10% memory available for more than 5 minutes."

  # èŠ‚ç‚¹ç£ç›˜ç©ºé—´ä½
  - alert: NodeLowDiskSpace
    expr: node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"} * 100 < 15
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Node {{ $labels.node }} has low disk space"
      description: "Node {{ $labels.node }} has less than 15% disk space available for more than 10 minutes."

  # èŠ‚ç‚¹é©±é€ Pod
  - alert: NodeEvictingPods
    expr: rate(kube_event_count{reason="Evicted"}[5m]) > 0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Node is evicting pods due to resource pressure"
      description: "Eviction events detected in the cluster."

  # èŠ‚ç‚¹ GC å¤±è´¥
  - alert: NodeGCFailed
    expr: rate(kube_event_count{reason=~"ImageGCFailed|ContainerGCFailed"}[10m]) > 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Node {{ $labels.node }} GC failed"
      description: "Node {{ $labels.node }} has failed to garbage collect resources."
```

### ä»ªè¡¨æ¿ï¼ˆDashboardï¼‰

**Grafana ä»ªè¡¨æ¿å…³é”®é¢æ¿**ï¼š

1. **é›†ç¾¤èŠ‚ç‚¹æ¦‚è§ˆ**
   - æ€»èŠ‚ç‚¹æ•°
   - Ready èŠ‚ç‚¹æ•°
   - NotReady èŠ‚ç‚¹æ•°
   - ä¸å¯è°ƒåº¦èŠ‚ç‚¹æ•°

2. **èŠ‚ç‚¹çŠ¶æ€æ—¶é—´çº¿**
   - èŠ‚ç‚¹ Ready çŠ¶æ€å†å²
   - èŠ‚ç‚¹ Condition å˜åŒ–å†å²

3. **èŠ‚ç‚¹èµ„æºå‹åŠ›**
   - MemoryPressure èŠ‚ç‚¹åˆ—è¡¨
   - DiskPressure èŠ‚ç‚¹åˆ—è¡¨
   - PIDPressure èŠ‚ç‚¹åˆ—è¡¨

4. **èŠ‚ç‚¹èµ„æºä½¿ç”¨**
   - CPU ä½¿ç”¨ç‡ï¼ˆæŒ‰èŠ‚ç‚¹ï¼‰
   - å†…å­˜ä½¿ç”¨ç‡ï¼ˆæŒ‰èŠ‚ç‚¹ï¼‰
   - ç£ç›˜ä½¿ç”¨ç‡ï¼ˆæŒ‰èŠ‚ç‚¹ï¼‰
   - ç½‘ç»œæµé‡ï¼ˆæŒ‰èŠ‚ç‚¹ï¼‰

5. **èŠ‚ç‚¹äº‹ä»¶ç»Ÿè®¡**
   - æœ€è¿‘ 1 å°æ—¶äº‹ä»¶ç»Ÿè®¡ï¼ˆæŒ‰ Reasonï¼‰
   - NotReady äº‹ä»¶æ—¶é—´çº¿
   - é©±é€äº‹ä»¶æ—¶é—´çº¿
   - GC å¤±è´¥äº‹ä»¶æ—¶é—´çº¿

6. **èŠ‚ç‚¹å®¹é‡å’Œåˆ†é…**
   - èŠ‚ç‚¹ Capacity vs Allocatable
   - èŠ‚ç‚¹èµ„æºè¯·æ±‚ vs ä½¿ç”¨
   - èŠ‚ç‚¹ Pod æ•°é‡

### æœ€ä½³å®è·µ

1. **èµ„æºé¢„ç•™é…ç½®**
   ```yaml
   # ä¸ºç³»ç»Ÿè¿›ç¨‹é¢„ç•™èµ„æº
   systemReserved:
     cpu: "500m"
     memory: "1Gi"
     ephemeral-storage: "10Gi"
   
   # ä¸º Kubernetes ç»„ä»¶é¢„ç•™èµ„æº
   kubeReserved:
     cpu: "500m"
     memory: "1Gi"
     ephemeral-storage: "10Gi"
   ```

2. **é©±é€é˜ˆå€¼é…ç½®**
   ```yaml
   # ç¡¬é©±é€é˜ˆå€¼ï¼ˆç«‹å³é©±é€ï¼‰
   evictionHard:
     memory.available: "500Mi"
     nodefs.available: "10%"
     nodefs.inodesFree: "5%"
     imagefs.available: "15%"
     pid.available: "5%"
   
   # è½¯é©±é€é˜ˆå€¼ï¼ˆæœ‰å®½é™æœŸï¼‰
   evictionSoft:
     memory.available: "1Gi"
     nodefs.available: "15%"
     imagefs.available: "20%"
   
   evictionSoftGracePeriod:
     memory.available: "1m30s"
     nodefs.available: "2m"
     imagefs.available: "2m"
   ```

3. **é•œåƒåƒåœ¾å›æ”¶é…ç½®**
   ```yaml
   # ç£ç›˜ä½¿ç”¨ç‡è¾¾åˆ° 85% æ—¶è§¦å‘ Image GC
   imageGCHighThresholdPercent: 85
   
   # Image GC ä¼šåˆ é™¤é•œåƒç›´åˆ°ç£ç›˜ä½¿ç”¨ç‡é™åˆ° 80%
   imageGCLowThresholdPercent: 80
   
   # é•œåƒè‡³å°‘å­˜åœ¨ 2 åˆ†é’Ÿåæ‰èƒ½è¢«å›æ”¶
   imageMinimumGCAge: 2m
   ```

4. **å®¹å™¨æ—¥å¿—è½®è½¬**
   ```yaml
   # å•ä¸ªå®¹å™¨æ—¥å¿—æ–‡ä»¶æœ€å¤§å¤§å°
   containerLogMaxSize: 10Mi
   
   # æ¯ä¸ªå®¹å™¨ä¿ç•™çš„æ—¥å¿—æ–‡ä»¶æ•°é‡
   containerLogMaxFiles: 5
   ```

5. **Pod èµ„æºé…ç½®æœ€ä½³å®è·µ**
   - ä¸ºæ‰€æœ‰ Pod è®¾ç½® requests å’Œ limits
   - ä½¿ç”¨ QoS Guaranteed ä¿æŠ¤å…³é”®åº”ç”¨
   - ä¸ºä¸é‡è¦çš„åº”ç”¨ä½¿ç”¨ QoS BestEffort
   - è®¾ç½®åˆç†çš„ PriorityClass

6. **èŠ‚ç‚¹ç»´æŠ¤æµç¨‹**
   ```bash
   # 1. æ ‡è®°èŠ‚ç‚¹ä¸å¯è°ƒåº¦
   kubectl cordon <node-name>
   
   # 2. é©±é€èŠ‚ç‚¹ä¸Šçš„ Pod
   kubectl drain <node-name> --ignore-daemonsets --delete-emptydir-data
   
   # 3. æ‰§è¡Œç»´æŠ¤æ“ä½œ
   
   # 4. æ¢å¤èŠ‚ç‚¹å¯è°ƒåº¦
   kubectl uncordon <node-name>
   ```

7. **è‡ªåŠ¨åŒ–å“åº”**
   - è®¾ç½®è‡ªåŠ¨å‘Šè­¦é€šçŸ¥ï¼ˆPagerDuty, Slack, Emailï¼‰
   - å¯¹äºéå…³é”®èŠ‚ç‚¹ï¼Œé…ç½®è‡ªåŠ¨ä¿®å¤ï¼ˆè‡ªåŠ¨é‡å¯ã€è‡ªåŠ¨æ›¿æ¢ï¼‰
   - é…ç½® Cluster Autoscaler è‡ªåŠ¨æ‰©ç¼©å®¹

8. **æ—¥å¿—æ”¶é›†å’Œåˆ†æ**
   - æ”¶é›† kubelet æ—¥å¿—åˆ°ä¸­å¿ƒåŒ–æ—¥å¿—ç³»ç»Ÿ
   - æ”¶é›†èŠ‚ç‚¹ç³»ç»Ÿæ—¥å¿—ï¼ˆjournalctl, dmesgï¼‰
   - æ”¶é›†èŠ‚ç‚¹äº‹ä»¶åˆ°æ—¥å¿—ç³»ç»Ÿ
   - å®šæœŸåˆ†ææ—¥å¿—ï¼Œå‘ç°æ½œåœ¨é—®é¢˜

---

> **KUDIG-DATABASE** | Domain-33: Kubernetes Events å…¨åŸŸäº‹ä»¶å¤§å…¨ | æ–‡æ¡£ 06/15
