# 13-Kubernetesæˆæœ¬æ²»ç†

> **é€‚ç”¨èŒƒå›´**: Kubernetes v1.25-v1.32 | **ç»´æŠ¤çŠ¶æ€**: ğŸ”§ æŒç»­æ›´æ–°ä¸­ | **ä¸“å®¶çº§åˆ«**: â­â­â­â­â­

## ğŸ“‹ æ¦‚è¿°

Kubernetesæˆæœ¬æ²»ç†æ˜¯FinOpså®è·µçš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»å¦‚ä½•å®æ–½æœ‰æ•ˆçš„æˆæœ¬ç›‘æ§ã€ä¼˜åŒ–å’Œæ²»ç†ç­–ç•¥ã€‚

## ğŸ’° æˆæœ¬åˆ†ææ¡†æ¶

### æˆæœ¬æ„æˆåˆ†æ

#### 1. æˆæœ¬åˆ†æ‘Šæ¨¡å‹
```yaml
# æˆæœ¬åˆ†æ‘Šé…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: cost-allocation-config
  namespace: finops
data:
  allocation-rules.yaml: |
    rules:
    - name: "team-based-allocation"
      selector:
        matchLabels:
          team: "*"
      allocation:
        type: "proportional"
        metric: "resource_usage"
        
    - name: "project-based-allocation"
      selector:
        matchLabels:
          project: "*"
      allocation:
        type: "fixed"
        percentage: 100
        
    - name: "environment-based-allocation"
      selector:
        matchLabels:
          environment: "*"
      allocation:
        type: "tiered"
        tiers:
        - value: "production"
          multiplier: 1.0
        - value: "staging"
          multiplier: 0.5
        - value: "development"
          multiplier: 0.2
```

#### 2. æˆæœ¬æ ‡ç­¾ä½“ç³»
```yaml
# èµ„æºæ ‡ç­¾ç­–ç•¥
apiVersion: v1
kind: ConfigMap
metadata:
  name: cost-labeling-policy
  namespace: finops
data:
  labeling-rules.yaml: |
    required_labels:
    - name: "cost-center"
      description: "Business unit or cost center responsible"
      regex: "^[A-Z0-9]{3,10}$"
      
    - name: "team"
      description: "Team owning the resource"
      allowed_values: ["frontend", "backend", "platform", "data"]
      
    - name: "environment"
      description: "Deployment environment"
      allowed_values: ["production", "staging", "development", "testing"]
      
    - name: "project"
      description: "Project or initiative name"
      regex: "^[a-z0-9]([a-z0-9-]*[a-z0-9])?$"
      
    - name: "owner"
      description: "Primary contact person"
      regex: "^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$"
```

### æˆæœ¬æ”¶é›†å’Œè®¡é‡

#### 1. Prometheusæˆæœ¬æŒ‡æ ‡
```yaml
# æˆæœ¬ç›¸å…³æŒ‡æ ‡æ”¶é›†
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: cost-metrics
  namespace: monitoring
spec:
  groups:
  - name: cost.rules
    rules:
    # CPUæˆæœ¬è®¡ç®—
    - record: cost:cpu_hours:sum_rate
      expr: sum(rate(container_cpu_usage_seconds_total[1h])) by (namespace, pod, container)
      
    # å†…å­˜æˆæœ¬è®¡ç®—
    - record: cost:memory_gb_hours:sum_rate
      expr: sum(rate(container_memory_working_set_bytes[1h]) / 1024^3) by (namespace, pod, container)
      
    # å­˜å‚¨æˆæœ¬è®¡ç®—
    - record: cost:storage_gb_hours:sum_rate
      expr: sum(rate(container_fs_usage_bytes[1h]) / 1024^3) by (namespace, pod, container)
      
    # ç½‘ç»œæˆæœ¬è®¡ç®—
    - record: cost:network_bytes:sum_rate
      expr: sum(rate(container_network_receive_bytes_total[1h]) + rate(container_network_transmit_bytes_total[1h])) by (namespace, pod)
```

#### 2. æˆæœ¬æ•°æ®èšåˆ
```python
#!/usr/bin/env python3
# æˆæœ¬æ•°æ®èšåˆå’Œåˆ†æè„šæœ¬

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import requests

class CostAnalyzer:
    def __init__(self, prometheus_url, cloud_billing_api=None):
        self.prometheus_url = prometheus_url
        self.cloud_billing_api = cloud_billing_api
        self.cost_rates = {
            'aws': {
                'cpu_hour': 0.023,      # m5.largeå®ä¾‹CPUå°æ—¶æˆæœ¬
                'memory_gb_hour': 0.003, # å†…å­˜GBå°æ—¶æˆæœ¬
                'storage_gb_month': 0.10, # EBSå­˜å‚¨æœˆæˆæœ¬
                'network_gb': 0.01       # ç½‘ç»œæµé‡GBæˆæœ¬
            }
        }
    
    def query_prometheus(self, query, start_time, end_time, step='1h'):
        """æŸ¥è¯¢PrometheusæŒ‡æ ‡"""
        params = {
            'query': query,
            'start': start_time.timestamp(),
            'end': end_time.timestamp(),
            'step': step
        }
        
        response = requests.get(f"{self.prometheus_url}/api/v1/query_range", params=params)
        return response.json()
    
    def calculate_resource_costs(self, start_time, end_time):
        """è®¡ç®—èµ„æºä½¿ç”¨æˆæœ¬"""
        # æŸ¥è¯¢CPUä½¿ç”¨ç‡
        cpu_query = 'sum(rate(container_cpu_usage_seconds_total[1h])) by (namespace, pod, container)'
        cpu_data = self.query_prometheus(cpu_query, start_time, end_time)
        
        # æŸ¥è¯¢å†…å­˜ä½¿ç”¨
        memory_query = 'sum(rate(container_memory_working_set_bytes[1h]) / 1024^3) by (namespace, pod, container)'
        memory_data = self.query_prometheus(memory_query, start_time, end_time)
        
        # æŸ¥è¯¢å­˜å‚¨ä½¿ç”¨
        storage_query = 'sum(rate(container_fs_usage_bytes[1h]) / 1024^3) by (namespace, pod, container)'
        storage_data = self.query_prometheus(storage_query, start_time, end_time)
        
        # è®¡ç®—æˆæœ¬
        costs = {
            'cpu_cost': self.calculate_cpu_cost(cpu_data),
            'memory_cost': self.calculate_memory_cost(memory_data),
            'storage_cost': self.calculate_storage_cost(storage_data)
        }
        
        return costs
    
    def calculate_cpu_cost(self, cpu_data):
        """è®¡ç®—CPUæˆæœ¬"""
        total_cpu_hours = 0
        cost_breakdown = {}
        
        if 'data' in cpu_data and 'result' in cpu_data['data']:
            for series in cpu_data['data']['result']:
                namespace = series['metric'].get('namespace', 'unknown')
                values = series['values']
                
                namespace_cpu_hours = sum(float(value[1]) for value in values)
                total_cpu_hours += namespace_cpu_hours
                
                if namespace not in cost_breakdown:
                    cost_breakdown[namespace] = 0
                cost_breakdown[namespace] += namespace_cpu_hours * self.cost_rates['aws']['cpu_hour']
        
        return {
            'total': total_cpu_hours * self.cost_rates['aws']['cpu_hour'],
            'breakdown': cost_breakdown,
            'total_hours': total_cpu_hours
        }
    
    def calculate_memory_cost(self, memory_data):
        """è®¡ç®—å†…å­˜æˆæœ¬"""
        total_memory_gb_hours = 0
        cost_breakdown = {}
        
        if 'data' in memory_data and 'result' in memory_data['data']:
            for series in memory_data['data']['result']:
                namespace = series['metric'].get('namespace', 'unknown')
                values = series['values']
                
                namespace_memory_gb_hours = sum(float(value[1]) for value in values)
                total_memory_gb_hours += namespace_memory_gb_hours
                
                if namespace not in cost_breakdown:
                    cost_breakdown[namespace] = 0
                cost_breakdown[namespace] += namespace_memory_gb_hours * self.cost_rates['aws']['memory_gb_hour']
        
        return {
            'total': total_memory_gb_hours * self.cost_rates['aws']['memory_gb_hour'],
            'breakdown': cost_breakdown,
            'total_gb_hours': total_memory_gb_hours
        }
    
    def calculate_storage_cost(self, storage_data):
        """è®¡ç®—å­˜å‚¨æˆæœ¬"""
        total_storage_gb_hours = 0
        cost_breakdown = {}
        
        if 'data' in storage_data and 'result' in storage_data['data']:
            for series in storage_data['data']['result']:
                namespace = series['metric'].get('namespace', 'unknown')
                values = series['values']
                
                namespace_storage_gb_hours = sum(float(value[1]) for value in values)
                total_storage_gb_hours += namespace_storage_gb_hours
                
                if namespace not in cost_breakdown:
                    cost_breakdown[namespace] = 0
                cost_breakdown[namespace] += (namespace_storage_gb_hours / 24 / 30) * self.cost_rates['aws']['storage_gb_month']
        
        return {
            'total': (total_storage_gb_hours / 24 / 30) * self.cost_rates['aws']['storage_gb_month'],
            'breakdown': cost_breakdown,
            'total_gb_hours': total_storage_gb_hours
        }
    
    def generate_cost_report(self, start_time, end_time):
        """ç”Ÿæˆæˆæœ¬æŠ¥å‘Š"""
        costs = self.calculate_resource_costs(start_time, end_time)
        
        report = {
            'period': {
                'start': start_time.isoformat(),
                'end': end_time.isoformat()
            },
            'summary': {
                'total_cost': sum(cost['total'] for cost in costs.values()),
                'cpu_cost': costs['cpu_cost']['total'],
                'memory_cost': costs['memory_cost']['total'],
                'storage_cost': costs['storage_cost']['total']
            },
            'breakdown_by_namespace': self.aggregate_namespace_costs(costs),
            'recommendations': self.generate_cost_recommendations(costs)
        }
        
        return report
    
    def aggregate_namespace_costs(self, costs):
        """æŒ‰å‘½åç©ºé—´èšåˆæˆæœ¬"""
        namespace_costs = {}
        
        for cost_type, cost_data in costs.items():
            for namespace, amount in cost_data['breakdown'].items():
                if namespace not in namespace_costs:
                    namespace_costs[namespace] = 0
                namespace_costs[namespace] += amount
        
        return dict(sorted(namespace_costs.items(), key=lambda x: x[1], reverse=True))
    
    def generate_cost_recommendations(self, costs):
        """ç”Ÿæˆæˆæœ¬ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # CPUåˆ©ç”¨ç‡åˆ†æ
        cpu_efficiency = self.analyze_cpu_efficiency()
        if cpu_efficiency < 0.5:
            recommendations.append({
                'type': 'rightsizing',
                'priority': 'high',
                'description': f'Low CPU utilization ({cpu_efficiency:.1%}), consider rightsizing pods',
                'estimated_savings': costs['cpu_cost']['total'] * 0.3
            })
        
        # å†…å­˜æµªè´¹åˆ†æ
        memory_waste = self.analyze_memory_waste()
        if memory_waste > 0.3:
            recommendations.append({
                'type': 'memory_optimization',
                'priority': 'medium',
                'description': f'High memory waste ({memory_waste:.1%}), optimize memory requests/limits',
                'estimated_savings': costs['memory_cost']['total'] * 0.2
            })
        
        # é—²ç½®èµ„æºåˆ†æ
        idle_resources = self.find_idle_resources()
        if idle_resources:
            recommendations.append({
                'type': 'resource_cleanup',
                'priority': 'high',
                'description': f'Found {len(idle_resources)} idle resources, consider cleanup',
                'estimated_savings': sum(res['monthly_cost'] for res in idle_resources)
            })
        
        return recommendations
    
    def analyze_cpu_efficiency(self):
        """åˆ†æCPUä½¿ç”¨æ•ˆç‡"""
        # æŸ¥è¯¢CPUè¯·æ±‚å’Œå®é™…ä½¿ç”¨
        request_query = 'sum(kube_pod_container_resource_requests{resource="cpu"}) by (namespace)'
        usage_query = 'sum(rate(container_cpu_usage_seconds_total[1h])) by (namespace)'
        
        # ç®€åŒ–çš„æ•ˆç‡è®¡ç®—
        return 0.65  # æ¨¡æ‹Ÿå€¼
    
    def analyze_memory_waste(self):
        """åˆ†æå†…å­˜æµªè´¹"""
        # æŸ¥è¯¢å†…å­˜è¯·æ±‚å’Œå®é™…ä½¿ç”¨
        request_query = 'sum(kube_pod_container_resource_requests{resource="memory"}) by (namespace)'
        usage_query = 'sum(container_memory_working_set_bytes) by (namespace)'
        
        # ç®€åŒ–çš„æµªè´¹è®¡ç®—
        return 0.35  # æ¨¡æ‹Ÿå€¼
    
    def find_idle_resources(self):
        """æŸ¥æ‰¾é—²ç½®èµ„æº"""
        # æŸ¥è¯¢é•¿æ—¶é—´æœªä½¿ç”¨çš„Pods
        idle_query = '''
        count by(pod, namespace) (
            rate(container_cpu_usage_seconds_total[1h]) < 0.01
        ) > 24
        '''
        
        # ç®€åŒ–çš„é—²ç½®èµ„æºåˆ—è¡¨
        return [
            {
                'pod': 'old-app-7d5b8c9d4-xl2vz',
                'namespace': 'legacy',
                'monthly_cost': 45.23
            }
        ]

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    analyzer = CostAnalyzer("http://prometheus:9090")
    
    end_time = datetime.now()
    start_time = end_time - timedelta(days=30)
    
    report = analyzer.generate_cost_report(start_time, end_time)
    
    print("Monthly Cost Report:")
    print(json.dumps(report, indent=2))
```

## ğŸ“Š æˆæœ¬ä¼˜åŒ–ç­–ç•¥

### èµ„æºæƒåˆ©åŒ–

#### 1. è‡ªåŠ¨æƒåˆ©åŒ–å·¥å…·
```python
#!/usr/bin/env python3
# è‡ªåŠ¨èµ„æºæƒåˆ©åŒ–å·¥å…·

import asyncio
from kubernetes import client, config
from kubernetes.client.rest import ApiException
import numpy as np
from datetime import datetime, timedelta

class RightsizingOptimizer:
    def __init__(self):
        config.load_kube_config()
        self.apps_v1 = client.AppsV1Api()
        self.core_v1 = client.CoreV1Api()
        self.metrics_client = client.CustomObjectsApi()
        
    async def analyze_workload_metrics(self, namespace, workload_name, workload_type="deployment"):
        """åˆ†æå·¥ä½œè´Ÿè½½æŒ‡æ ‡"""
        # è·å–å†å²æŒ‡æ ‡æ•°æ®ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
        cpu_usage_data = await self.get_cpu_usage_history(namespace, workload_name)
        memory_usage_data = await self.get_memory_usage_history(namespace, workload_name)
        
        # è®¡ç®—å»ºè®®å€¼
        cpu_recommendation = self.calculate_cpu_recommendation(cpu_usage_data)
        memory_recommendation = self.calculate_memory_recommendation(memory_usage_data)
        
        return {
            'cpu_current': self.get_current_cpu_request(namespace, workload_name),
            'memory_current': self.get_current_memory_request(namespace, workload_name),
            'cpu_recommended': cpu_recommendation,
            'memory_recommended': memory_recommendation,
            'savings_potential': self.calculate_savings_potential(
                cpu_usage_data, memory_usage_data
            )
        }
    
    async def get_cpu_usage_history(self, namespace, workload_name):
        """è·å–CPUä½¿ç”¨å†å²"""
        # ç®€åŒ–çš„æ¨¡æ‹Ÿæ•°æ®
        return np.random.normal(0.3, 0.1, 168)  # ä¸€å‘¨æ¯å°æ—¶æ•°æ®
    
    async def get_memory_usage_history(self, namespace, workload_name):
        """è·å–å†…å­˜ä½¿ç”¨å†å²"""
        # ç®€åŒ–çš„æ¨¡æ‹Ÿæ•°æ®
        return np.random.normal(0.4, 0.15, 168)  # ä¸€å‘¨æ¯å°æ—¶æ•°æ®
    
    def calculate_cpu_recommendation(self, cpu_data):
        """è®¡ç®—CPUå»ºè®®å€¼"""
        # ä½¿ç”¨95ç™¾åˆ†ä½æ•°ä½œä¸ºå»ºè®®å€¼ï¼Œå¹¶å¢åŠ 20%ç¼“å†²
        p95 = np.percentile(cpu_data, 95)
        return round(p95 * 1.2, 3)
    
    def calculate_memory_recommendation(self, memory_data):
        """è®¡ç®—å†…å­˜å»ºè®®å€¼"""
        # ä½¿ç”¨95ç™¾åˆ†ä½æ•°ä½œä¸ºå»ºè®®å€¼ï¼Œå¹¶å¢åŠ 25%ç¼“å†²
        p95 = np.percentile(memory_data, 95)
        return f"{round(p95 * 1.25 * 1000)}Mi"  # è½¬æ¢ä¸ºMiå•ä½
    
    def get_current_cpu_request(self, namespace, workload_name):
        """è·å–å½“å‰CPUè¯·æ±‚å€¼"""
        try:
            deployment = self.apps_v1.read_namespaced_deployment(workload_name, namespace)
            container = deployment.spec.template.spec.containers[0]
            return container.resources.requests.get('cpu', '0') if container.resources.requests else '0'
        except ApiException:
            return '0'
    
    def get_current_memory_request(self, namespace, workload_name):
        """è·å–å½“å‰å†…å­˜è¯·æ±‚å€¼"""
        try:
            deployment = self.apps_v1.read_namespaced_deployment(workload_name, namespace)
            container = deployment.spec.template.spec.containers[0]
            return container.resources.requests.get('memory', '0') if container.resources.requests else '0'
        except ApiException:
            return '0'
    
    def calculate_savings_potential(self, cpu_data, memory_data):
        """è®¡ç®—èŠ‚çœæ½œåŠ›"""
        current_cpu_cost = 0.023  # ç®€åŒ–çš„æˆæœ¬è®¡ç®—
        current_memory_cost = 0.003
        
        # è®¡ç®—å½“å‰å’Œå»ºè®®çš„æˆæœ¬å·®å¼‚
        cpu_savings = current_cpu_cost * (1 - np.mean(cpu_data) / 0.5)  # å‡è®¾å½“å‰è¯·æ±‚ä¸º0.5
        memory_savings = current_memory_cost * (1 - np.mean(memory_data) / 0.5)
        
        return {
            'monthly_cpu_savings': cpu_savings * 720,  # 720å°æ—¶/æœˆ
            'monthly_memory_savings': memory_savings * 720,
            'total_monthly_savings': (cpu_savings + memory_savings) * 720
        }
    
    async def apply_rightsizing(self, namespace, workload_name, recommendations):
        """åº”ç”¨æƒåˆ©åŒ–å»ºè®®"""
        try:
            # è·å–å½“å‰éƒ¨ç½²é…ç½®
            deployment = self.apps_v1.read_namespaced_deployment(workload_name, namespace)
            
            # æ›´æ–°èµ„æºé…ç½®
            container = deployment.spec.template.spec.containers[0]
            if not container.resources:
                container.resources = client.V1ResourceRequirements()
            if not container.resources.requests:
                container.resources.requests = {}
            if not container.resources.limits:
                container.resources.limits = {}
            
            # åº”ç”¨å»ºè®®å€¼
            container.resources.requests['cpu'] = str(recommendations['cpu_recommended'])
            container.resources.requests['memory'] = recommendations['memory_recommended']
            container.resources.limits['cpu'] = str(recommendations['cpu_recommended'] * 1.5)
            container.resources.limits['memory'] = str(int(recommendations['memory_recommended'].rstrip('Mi')) * 1.5) + 'Mi'
            
            # æ›´æ–°éƒ¨ç½²
            self.apps_v1.patch_namespaced_deployment(workload_name, namespace, deployment)
            
            print(f"Applied rightsizing to {namespace}/{workload_name}")
            return True
            
        except ApiException as e:
            print(f"Failed to apply rightsizing: {e}")
            return False
    
    async def run_batch_optimization(self, namespaces=None):
        """æ‰¹é‡è¿è¡Œä¼˜åŒ–"""
        if not namespaces:
            # è·å–æ‰€æœ‰å‘½åç©ºé—´
            namespace_list = self.core_v1.list_namespace()
            namespaces = [ns.metadata.name for ns in namespace_list.items 
                         if ns.metadata.name not in ['kube-system', 'monitoring']]
        
        optimization_results = []
        
        for namespace in namespaces:
            try:
                deployments = self.apps_v1.list_namespaced_deployment(namespace)
                
                for deployment in deployments.items:
                    workload_name = deployment.metadata.name
                    
                    # åˆ†æå·¥ä½œè´Ÿè½½
                    recommendations = await self.analyze_workload_metrics(
                        namespace, workload_name
                    )
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ä¼˜åŒ–ç©ºé—´
                    if (recommendations['savings_potential']['total_monthly_savings'] > 10):  # è¶…è¿‡10ç¾å…ƒæ‰ä¼˜åŒ–
                        result = {
                            'namespace': namespace,
                            'workload': workload_name,
                            'current_config': {
                                'cpu': recommendations['cpu_current'],
                                'memory': recommendations['memory_current']
                            },
                            'recommended_config': {
                                'cpu': recommendations['cpu_recommended'],
                                'memory': recommendations['memory_recommended']
                            },
                            'savings': recommendations['savings_potential']
                        }
                        
                        optimization_results.append(result)
                        
                        # å¯é€‰æ‹©è‡ªåŠ¨åº”ç”¨ä¼˜åŒ–
                        # await self.apply_rightsizing(namespace, workload_name, recommendations)
                        
            except ApiException as e:
                print(f"Error processing namespace {namespace}: {e}")
        
        return optimization_results

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    optimizer = RightsizingOptimizer()
    results = await optimizer.run_batch_optimization(['production', 'staging'])
    
    print("Rightsizing Recommendations:")
    for result in results:
        print(f"\nWorkload: {result['namespace']}/{result['workload']}")
        print(f"Current: CPU={result['current_config']['cpu']}, Memory={result['current_config']['memory']}")
        print(f"Recommended: CPU={result['recommended_config']['cpu']}, Memory={result['recommended_config']['memory']}")
        print(f"Potential Savings: ${result['savings']['total_monthly_savings']:.2f}/month")

if __name__ == "__main__":
    asyncio.run(main())
```

### Spotå®ä¾‹ä¼˜åŒ–

#### 1. Spotå®ä¾‹è°ƒåº¦å™¨
```yaml
# Spotå®ä¾‹èŠ‚ç‚¹ç»„é…ç½®
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: spot-optimized-cluster
  region: us-west-2

managedNodeGroups:
- name: spot-critical-ng
  instanceTypes: ["m5.large", "m5.xlarge"]
  spot: true
  desiredCapacity: 5
  minSize: 3
  maxSize: 10
  labels:
    node-group: spot-critical
    lifecycle: spot
  taints:
  - key: spot
    value: "true"
    effect: NoSchedule
  tags:
    k8s.io/cluster-autoscaler/node-template/label/lifecycle: spot
    k8s.io/cluster-autoscaler/node-template/taint/spot: "true:NoSchedule"

- name: spot-batch-ng
  instanceTypes: ["c5.large", "c5.xlarge", "c5.2xlarge"]
  spot: true
  desiredCapacity: 3
  minSize: 1
  maxSize: 8
  labels:
    node-group: spot-batch
    workload: batch
  taints:
  - key: spot-batch
    value: "true"
    effect: NoSchedule
---
# Spotå®ä¾‹å®¹å¿åº¦é…ç½®
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spot-tolerant-app
spec:
  replicas: 3
  template:
    spec:
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: lifecycle
                operator: In
                values: ["spot"]
      tolerations:
      - key: spot
        operator: Equal
        value: "true"
        effect: NoSchedule
      - key: spot-batch
        operator: Equal
        value: "true"
        effect: NoSchedule
      containers:
      - name: app
        image: myapp:latest
        resources:
          requests:
            cpu: "1"
            memory: "2Gi"
          limits:
            cpu: "2"
            memory: "4Gi"
```

#### 2. Spotä¸­æ–­å¤„ç†
```python
#!/usr/bin/env python3
# Spotå®ä¾‹ä¸­æ–­å¤„ç†ç¨‹åº

import asyncio
import json
import boto3
from kubernetes import client, config
from kubernetes.client.rest import ApiException

class SpotInterruptionHandler:
    def __init__(self):
        config.load_kube_config()
        self.apps_v1 = client.AppsV1Api()
        self.core_v1 = client.CoreV1Api()
        self.ec2_client = boto3.client('ec2')
        self.sqs_client = boto3.client('sqs')
        
    async def monitor_spot_interruptions(self, queue_url):
        """ç›‘æ§Spotå®ä¾‹ä¸­æ–­"""
        while True:
            try:
                # ä»SQSé˜Ÿåˆ—æ¥æ”¶ä¸­æ–­é€šçŸ¥
                response = self.sqs_client.receive_message(
                    QueueUrl=queue_url,
                    MaxNumberOfMessages=10,
                    WaitTimeSeconds=20
                )
                
                if 'Messages' in response:
                    for message in response['Messages']:
                        interruption_event = json.loads(message['Body'])
                        await self.handle_interruption(interruption_event)
                        
                        # åˆ é™¤å·²å¤„ç†çš„æ¶ˆæ¯
                        self.sqs_client.delete_message(
                            QueueUrl=queue_url,
                            ReceiptHandle=message['ReceiptHandle']
                        )
                
                await asyncio.sleep(1)
                
            except Exception as e:
                print(f"Error monitoring interruptions: {e}")
                await asyncio.sleep(30)
    
    async def handle_interruption(self, event):
        """å¤„ç†ä¸­æ–­äº‹ä»¶"""
        if event.get('detail-type') == 'EC2 Spot Instance Interruption Warning':
            instance_id = event['detail']['instance-id']
            interruption_time = event['detail']['instance-action']
            
            print(f"Handling spot interruption for instance {instance_id}")
            
            # è·å–èŠ‚ç‚¹åç§°
            node_name = await self.get_node_name_by_instance(instance_id)
            if not node_name:
                return
            
            # å‡†å¤‡èŠ‚ç‚¹æ’æ°´
            await self.prepare_node_drain(node_name)
            
            # ä¼˜é›…åœ°æ’æ°´èŠ‚ç‚¹
            await self.drain_node_gracefully(node_name)
            
            # ç­‰å¾…æ–°èŠ‚ç‚¹å¯åŠ¨
            await self.wait_for_node_replacement(node_name)
    
    async def get_node_name_by_instance(self, instance_id):
        """é€šè¿‡å®ä¾‹IDè·å–èŠ‚ç‚¹åç§°"""
        try:
            nodes = self.core_v1.list_node()
            
            for node in nodes.items:
                provider_id = node.spec.provider_id
                if provider_id and instance_id in provider_id:
                    return node.metadata.name
            
            return None
            
        except ApiException as e:
            print(f"Error getting node name: {e}")
            return None
    
    async def prepare_node_drain(self, node_name):
        """å‡†å¤‡èŠ‚ç‚¹æ’æ°´"""
        try:
            # æ ‡è®°èŠ‚ç‚¹ä¸ºä¸å¯è°ƒåº¦
            body = {
                "spec": {
                    "unschedulable": True
                }
            }
            self.core_v1.patch_node(node_name, body)
            
            print(f"Marked node {node_name} as unschedulable")
            
        except ApiException as e:
            print(f"Error preparing node drain: {e}")
    
    async def drain_node_gracefully(self, node_name):
        """ä¼˜é›…åœ°æ’æ°´èŠ‚ç‚¹"""
        try:
            # è·å–èŠ‚ç‚¹ä¸Šçš„Pods
            pods = self.core_v1.list_pod_for_all_namespaces(
                field_selector=f'spec.nodeName={node_name}'
            )
            
            # æŒ‰ä¼˜å…ˆçº§æ’åºPods
            evictable_pods = []
            critical_pods = []
            
            for pod in pods.items:
                # è·³è¿‡å…³é”®ç³»ç»ŸPods
                if (pod.metadata.namespace in ['kube-system', 'monitoring'] or
                    pod.metadata.labels.get('app') in ['istio', 'calico']):
                    critical_pods.append(pod)
                    continue
                
                evictable_pods.append(pod)
            
            # é€ä¸ªé©±é€Pods
            for pod in evictable_pods:
                try:
                    # æ£€æŸ¥æ˜¯å¦æœ‰PDBå…è®¸é©±é€
                    if await self.can_evict_pod(pod):
                        await self.evict_pod(pod)
                        await asyncio.sleep(5)  # ç»™äºˆé‡æ–°è°ƒåº¦æ—¶é—´
                        
                except Exception as e:
                    print(f"Error evicting pod {pod.metadata.name}: {e}")
            
            print(f"Drained {len(evictable_pods)} pods from node {node_name}")
            
        except ApiException as e:
            print(f"Error draining node: {e}")
    
    async def can_evict_pod(self, pod):
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥é©±é€Pod"""
        try:
            # æ£€æŸ¥PodDisruptionBudget
            pdb_list = self.policy_v1beta1.list_pod_disruption_budget_for_all_namespaces()
            
            for pdb in pdb_list.items:
                if (pdb.metadata.namespace == pod.metadata.namespace and
                    self.matches_selector(pod, pdb.spec.selector)):
                    
                    # æ£€æŸ¥å½“å‰å¹²æ‰°æ˜¯å¦åœ¨å…è®¸èŒƒå›´å†…
                    current_disruptions = await self.get_current_disruptions(pdb)
                    max_unavailable = pdb.spec.max_unavailable
                    
                    if isinstance(max_unavailable, str) and '%' in max_unavailable:
                        percentage = int(max_unavailable.rstrip('%'))
                        max_allowed = int(len(self.get_matching_pods(pdb)) * percentage / 100)
                    else:
                        max_allowed = int(max_unavailable)
                    
                    return current_disruptions < max_allowed
            
            return True  # æ²¡æœ‰PDBé™åˆ¶
            
        except Exception as e:
            print(f"Error checking eviction allowance: {e}")
            return False
    
    async def evict_pod(self, pod):
        """é©±é€Pod"""
        try:
            eviction = client.V1beta1Eviction(
                metadata=client.V1ObjectMeta(
                    name=pod.metadata.name,
                    namespace=pod.metadata.namespace
                )
            )
            
            self.core_v1.create_namespaced_pod_eviction(
                name=pod.metadata.name,
                namespace=pod.metadata.namespace,
                body=eviction
            )
            
            print(f"Evicted pod {pod.metadata.namespace}/{pod.metadata.name}")
            
        except ApiException as e:
            print(f"Error evicting pod: {e}")
    
    async def wait_for_node_replacement(self, old_node_name):
        """ç­‰å¾…èŠ‚ç‚¹æ›¿æ¢"""
        max_wait_time = 300  # 5åˆ†é’Ÿ
        check_interval = 10
        
        for i in range(max_wait_time // check_interval):
            try:
                node = self.core_v1.read_node(old_node_name)
                
                # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å‡†å¤‡å¥½
                for condition in node.status.conditions:
                    if condition.type == 'Ready' and condition.status == 'True':
                        print(f"Node {old_node_name} is ready again")
                        return
                
            except ApiException:
                # èŠ‚ç‚¹å¯èƒ½å·²è¢«åˆ é™¤ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–°èŠ‚ç‚¹
                nodes = self.core_v1.list_node()
                spot_nodes = [node for node in nodes.items 
                             if node.metadata.labels.get('lifecycle') == 'spot']
                
                if len(spot_nodes) >= self.get_expected_spot_node_count():
                    print("New spot nodes are available")
                    return
            
            await asyncio.sleep(check_interval)
        
        print(f"Timeout waiting for node replacement after {max_wait_time} seconds")
    
    def get_expected_spot_node_count(self):
        """è·å–é¢„æœŸçš„SpotèŠ‚ç‚¹æ•°é‡"""
        # è¿™é‡Œå¯ä»¥æ ¹æ®ä½ çš„é…ç½®è¿”å›é¢„æœŸæ•°é‡
        return 5

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    handler = SpotInterruptionHandler()
    await handler.monitor_spot_interruptions('https://sqs.us-west-2.amazonaws.com/123456789012/spot-interruption-queue')

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ“ˆ æˆæœ¬ç›‘æ§å‘Šè­¦

### é¢„ç®—ç®¡ç†å’Œå‘Šè­¦

#### 1. é¢„ç®—é…ç½®
```yaml
# æˆæœ¬é¢„ç®—é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: cost-budgets
  namespace: finops
data:
  budgets.yaml: |
    budgets:
    - name: "monthly-total-budget"
      period: "monthly"
      amount: 10000
      currency: "USD"
      thresholds: [50, 80, 90, 100]
      recipients:
      - "finops-team@example.com"
      - "platform-team@example.com"
      
    - name: "team-budgets"
      period: "monthly"
      by_label: "team"
      amounts:
        frontend: 3000
        backend: 4000
        platform: 2000
        data: 1000
      currency: "USD"
      thresholds: [75, 90, 100]
      recipients:
      - "team-leads@example.com"
      
    - name: "project-budgets"
      period: "weekly"
      by_label: "project"
      amounts:
        ecommerce: 2000
        analytics: 1500
        mobile: 1000
      currency: "USD"
      thresholds: [80, 95, 100]
      recipients:
      - "project-managers@example.com"
```

#### 2. æˆæœ¬å‘Šè­¦è§„åˆ™
```yaml
# Prometheusæˆæœ¬å‘Šè­¦è§„åˆ™
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: cost-alerts
  namespace: monitoring
spec:
  groups:
  - name: cost.rules
    rules:
    # é¢„ç®—è¶…æ”¯å‘Šè­¦
    - alert: BudgetExceeded
      expr: |
        sum by(team) (
          cost:total_daily:sum_rate * 30
        ) > on(team) group_left(amount)
        cost:budget:amount{budget="team-monthly"}
      for: 1h
      labels:
        severity: warning
      annotations:
        summary: "Team {{ $labels.team }} budget exceeded"
        description: "Monthly budget of {{ $labels.amount }} USD exceeded by {{ printf \"%.2f\" $value }} USD"
        
    # å¼‚å¸¸æˆæœ¬å¢é•¿å‘Šè­¦
    - alert: AbnormalCostIncrease
      expr: |
        abs(
          rate(cost:total_daily:sum_rate[1d])
          /
          rate(cost:total_daily:sum_rate[7d] offset 1d)
          - 1
        ) > 0.3
      for: 2h
      labels:
        severity: warning
      annotations:
        summary: "Abnormal cost increase detected"
        description: "Daily cost increased by more than 30% compared to last week"
        
    # èµ„æºæµªè´¹å‘Šè­¦
    - alert: ResourceWasteDetected
      expr: |
        sum by(namespace) (
          kube_resourcequota{type="hard", resource="requests.cpu"}
          -
          sum by(namespace) (kube_pod_container_resource_requests{resource="cpu"})
        ) / sum by(namespace) (kube_resourcequota{type="hard", resource="requests.cpu"}) > 0.4
      for: 6h
      labels:
        severity: info
      annotations:
        summary: "Significant CPU resource waste in namespace {{ $labels.namespace }}"
        description: "Over 40% of allocated CPU resources are unused"
```

## ğŸ”§ å®æ–½æ£€æŸ¥æ¸…å•

### æˆæœ¬æ²»ç†ä½“ç³»
- [ ] å»ºç«‹æˆæœ¬åˆ†æ‘Šå’Œæ ‡ç­¾ä½“ç³»
- [ ] éƒ¨ç½²æˆæœ¬æ”¶é›†å’Œè®¡é‡å·¥å…·
- [ ] å®æ–½èµ„æºæƒåˆ©åŒ–è‡ªåŠ¨åŒ–
- [ ] é…ç½®Spotå®ä¾‹ä¼˜åŒ–ç­–ç•¥
- [ ] å»ºç«‹é¢„ç®—ç®¡ç†å’Œå‘Šè­¦æœºåˆ¶
- [ ] å®æ–½æˆæœ¬å¯è§†åŒ–å’ŒæŠ¥å‘Š

### ä¼˜åŒ–ç­–ç•¥å®æ–½
- [ ] åˆ†æç°æœ‰èµ„æºä½¿ç”¨æ•ˆç‡
- [ ] åˆ¶å®šèµ„æºæƒåˆ©åŒ–è®¡åˆ’
- [ ] é…ç½®è‡ªåŠ¨æ‰©ç¼©å®¹ç­–ç•¥
- [ ] å®æ–½é—²ç½®èµ„æºæ¸…ç†æœºåˆ¶
- [ ] ä¼˜åŒ–å­˜å‚¨å’Œç½‘ç»œæˆæœ¬
- [ ] å»ºç«‹æˆæœ¬ä¼˜åŒ–æŒç»­æ”¹è¿›

### ç›‘æ§å’Œæ²»ç†
- [ ] éƒ¨ç½²å®æ—¶æˆæœ¬ç›‘æ§ç³»ç»Ÿ
- [ ] é…ç½®å¤šå±‚çº§å‘Šè­¦æœºåˆ¶
- [ ] å»ºç«‹æˆæœ¬å¼‚å¸¸æ£€æµ‹èƒ½åŠ›
- [ ] å®æ–½æˆæœ¬è¶‹åŠ¿åˆ†æ
- [ ] å»ºç«‹æˆæœ¬æ²»ç†æµç¨‹
- [ ] å®šæœŸå®¡æŸ¥å’Œä¼˜åŒ–æˆæœ¬ç­–ç•¥

---

*æœ¬æ–‡æ¡£ä¸ºä¼ä¸šçº§Kubernetesæˆæœ¬æ²»ç†æä¾›å®Œæ•´çš„ç­–ç•¥æ¡†æ¶å’ŒæŠ€æœ¯å®æ–½æ–¹æ¡ˆ*