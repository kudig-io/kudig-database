# 05-æ—¥å¿—æ”¶é›†åˆ†æå¹³å°

> **é€‚ç”¨èŒƒå›´**: Kubernetes v1.25-v1.32 | **ç»´æŠ¤çŠ¶æ€**: ğŸ”§ æŒç»­æ›´æ–°ä¸­ | **ä¸“å®¶çº§åˆ«**: â­â­â­â­â­

## ğŸ“‹ æ¦‚è¿°

å®Œæ•´çš„æ—¥å¿—æ”¶é›†åˆ†æå¹³å°æ˜¯å¯è§‚æµ‹æ€§ä½“ç³»çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»åŸºäºELK/EFKæŠ€æœ¯æ ˆçš„ä¼ä¸šçº§æ—¥å¿—è§£å†³æ–¹æ¡ˆã€‚

## ğŸ—ï¸ æ—¥å¿—æ¶æ„è®¾è®¡

### åˆ†å±‚æ—¥å¿—æ¶æ„

#### 1. æ—¥å¿—æ”¶é›†å±‚
```yaml
# Fluent Bit DaemonSeté…ç½®
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluent-bit
  namespace: logging
spec:
  selector:
    matchLabels:
      app: fluent-bit
  template:
    metadata:
      labels:
        app: fluent-bit
    spec:
      serviceAccountName: fluent-bit
      containers:
      - name: fluent-bit
        image: fluent/fluent-bit:2.0
        ports:
        - containerPort: 2020
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch.logging.svc"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: fluent-bit-config
          mountPath: /fluent-bit/etc/
        resources:
          limits:
            memory: 100Mi
          requests:
            cpu: 100m
            memory: 100Mi
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: fluent-bit-config
        configMap:
          name: fluent-bit-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: logging
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf
        HTTP_Server   On
        HTTP_Listen   0.0.0.0
        HTTP_Port     2020

    [INPUT]
        Name              tail
        Tag               kube.*
        Path              /var/log/containers/*.log
        Parser            docker
        DB                /var/log/flb_kube.db
        Mem_Buf_Limit     5MB
        Skip_Long_Lines   On
        Refresh_Interval  10

    [FILTER]
        Name                kubernetes
        Match               kube.*
        Kube_URL            https://kubernetes.default.svc:443
        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
        K8S-Logging.Parser  On
        K8S-Logging.Exclude Off

    [OUTPUT]
        Name            es
        Match           kube.*
        Host            ${FLUENT_ELASTICSEARCH_HOST}
        Port            ${FLUENT_ELASTICSEARCH_PORT}
        Logstash_Format On
        Replace_Dots    On
        Retry_Limit     False
```

#### 2. æ—¥å¿—ç¼“å†²å±‚
```yaml
# Kafkaä½œä¸ºæ—¥å¿—ç¼“å†²
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: logging
spec:
  serviceName: kafka-headless
  replicas: 3
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:7.3.0
        env:
        - name: KAFKA_BROKER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: "zookeeper:2181"
        - name: KAFKA_ADVERTISED_LISTENERS
          value: "PLAINTEXT://kafka-$(KAFKA_BROKER_ID).kafka-headless:9092"
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
          value: "3"
        ports:
        - containerPort: 9092
        volumeMounts:
        - name: data
          mountPath: /var/lib/kafka
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi
```

#### 3. æ—¥å¿—å­˜å‚¨å±‚
```yaml
# Elasticsearché›†ç¾¤é…ç½®
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: elasticsearch
  namespace: logging
spec:
  version: 8.5.3
  nodeSets:
  - name: default
    count: 3
    config:
      node.store.allow_mmap: false
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 100Gi
    podTemplate:
      spec:
        containers:
        - name: elasticsearch
          env:
          - name: ES_JAVA_OPTS
            value: -Xms2g -Xmx2g
          resources:
            requests:
              memory: 2Gi
              cpu: 1
            limits:
              memory: 4Gi
              cpu: 2
```

## ğŸ” æ—¥å¿—åˆ†æå¹³å°

### Kibanaé…ç½®

#### 1. Kibanaéƒ¨ç½²é…ç½®
```yaml
# Kibanaé…ç½®
apiVersion: kibana.k8s.elastic.co/v1
kind: Kibana
metadata:
  name: kibana
  namespace: logging
spec:
  version: 8.5.3
  count: 1
  elasticsearchRef:
    name: elasticsearch
  config:
    server.publicBaseUrl: "https://kibana.example.com"
    xpack.security.encryptionKey: "something_at_least_32_characters"
    xpack.security.session.idleTimeout: "1h"
    xpack.security.session.lifespan: "30d"
  http:
    tls:
      selfSignedCertificate:
        disabled: true
```

#### 2. æ—¥å¿—ç´¢å¼•æ¨¡æ¿
```json
{
  "index_patterns": ["kubernetes-*"],
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1,
      "refresh_interval": "30s",
      "blocks": {
        "read_only_allow_delete": "false"
      }
    },
    "mappings": {
      "properties": {
        "@timestamp": { "type": "date" },
        "log.level": { "type": "keyword" },
        "message": { "type": "text" },
        "kubernetes": {
          "properties": {
            "pod": { "type": "keyword" },
            "namespace": { "type": "keyword" },
            "container": { "type": "keyword" },
            "node": { "type": "keyword" }
          }
        },
        "host": {
          "properties": {
            "name": { "type": "keyword" }
          }
        }
      }
    }
  }
}
```

### æ—¥å¿—è§£æä¼˜åŒ–

#### 1. ç»“æ„åŒ–æ—¥å¿—å¤„ç†
```yaml
# æ—¥å¿—è§£æé…ç½®
parsers.conf: |
  [PARSER]
      Name   json
      Format json
      Time_Key time
      Time_Format %d/%b/%Y:%H:%M:%S %z

  [PARSER]
      Name   docker
      Format json
      Time_Key time
      Time_Format %Y-%m-%dT%H:%M:%S.%L
      Time_Keep   On

  [PARSER]
      Name   syslog
      Format regex
      Regex ^\<(?<pri>[0-9]+)\>(?<time>[^ ]* {1,2}[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>[a-zA-Z0-9_\/\.\-]*)(?:\[(?<pid>[0-9]+)\])?(?:[^\:]*\:)? *(?<message>.*)$
      Time_Key time
      Time_Format %b %d %H:%M:%S
```

#### 2. å¤šæ ¼å¼æ—¥å¿—é€‚é…
```yaml
# å¤šæ ¼å¼æ—¥å¿—è·¯ç”±
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-multi-format
  namespace: logging
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        
    [INPUT]
        Name              tail
        Path              /var/log/containers/app-*.log
        Parser            docker
        Tag               app.*

    [INPUT]
        Name              tail
        Path              /var/log/containers/nginx-*.log
        Parser            nginx
        Tag               nginx.*

    [FILTER]
        Name          rewrite_tag
        Match         app.*
        Rule          $kubernetes['container_name'] ^(app-.+)$ app.$1 false

    [OUTPUT]
        Name          es
        Match         app.*
        Index         kubernetes-app-%Y.%m.%d
```

## ğŸ“Š æ—¥å¿—åˆ†æå®è·µ

### å…³é”®æŒ‡æ ‡ç›‘æ§

#### 1. é”™è¯¯æ—¥å¿—ç›‘æ§
```yaml
# é”™è¯¯æ—¥å¿—å‘Šè­¦è§„åˆ™
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: log-error-alerts
  namespace: monitoring
spec:
  groups:
  - name: log.rules
    rules:
    - alert: HighErrorRate
      expr: rate(log_messages_total{level="error"}[5m]) > 10
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High error log rate detected"
        description: "{{ $labels.app }} is generating {{ printf \"%.2f\" $value }} errors per second"
```

#### 2. åº”ç”¨æ€§èƒ½æ—¥å¿—
```json
{
  "dashboard": {
    "title": "Application Logs Analysis",
    "panels": [
      {
        "title": "Error Rate by Service",
        "type": "graph",
        "targets": [
          {
            "query": "SELECT count(*) as error_count FROM \"kubernetes-*\" WHERE log.level = 'error' GROUP BY kubernetes.container"
          }
        ]
      },
      {
        "title": "Response Time Distribution",
        "type": "heatmap",
        "targets": [
          {
            "query": "SELECT percentile(response_time, 50) as p50, percentile(response_time, 95) as p95, percentile(response_time, 99) as p99 FROM \"kubernetes-*\" GROUP BY time(5m)"
          }
        ]
      }
    ]
  }
}
```

### æ—¥å¿—æœç´¢ä¼˜åŒ–

#### 1. Elasticsearchç´¢å¼•ç”Ÿå‘½å‘¨æœŸç®¡ç†
```yaml
# ILMç­–ç•¥é…ç½®
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: elasticsearch
spec:
  auth:
    fileRealm:
    - username: ilm_admin
      password: changeme
  http:
    tls:
      certificate:
        secretName: elasticsearch-cert
---
PUT _ilm/policy/log_retention_policy
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_age": "7d",
            "max_size": "50gb"
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "forcemerge": {
            "max_num_segments": 1
          }
        }
      },
      "cold": {
        "min_age": "30d",
        "actions": {
          "freeze": {}
        }
      },
      "delete": {
        "min_age": "90d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
```

#### 2. æ—¥å¿—é‡‡æ ·ç­–ç•¥
```yaml
# æ™ºèƒ½æ—¥å¿—é‡‡æ ·é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-sampling
  namespace: logging
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        
    [INPUT]
        Name              tail
        Path              /var/log/containers/debug-*.log
        Parser            docker
        Tag               debug.*
        
    [FILTER]
        Name          throttle
        Match         debug.*
        Rate          100
        Window        300
        Interval      1s
        
    [FILTER]
        Name          grep
        Match         *
        Exclude       log.level debug
        Exclude       kubernetes.container debug-container
```

## ğŸ”§ å¹³å°è¿ç»´ç®¡ç†

### å®‰å…¨è®¿é—®æ§åˆ¶

#### 1. è®¤è¯æˆæƒé…ç½®
```yaml
# Kibanaå®‰å…¨é…ç½®
apiVersion: kibana.k8s.elastic.co/v1
kind: Kibana
metadata:
  name: kibana
spec:
  secureSettings:
  - secretName: kibana-secure-settings
---
apiVersion: v1
kind: Secret
metadata:
  name: kibana-secure-settings
type: Opaque
data:
  xpack.security.authc.providers: |
    basic.basic1:
      order: 0
    saml.saml1:
      order: 1
      realm: saml1
  xpack.security.encryptionKey: |
    base64_encoded_encryption_key
```

#### 2. ç½‘ç»œç­–ç•¥é…ç½®
```yaml
# æ—¥å¿—ç»„ä»¶ç½‘ç»œéš”ç¦»
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: logging-isolation
  namespace: logging
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 9200
  - from:
    - podSelector:
        matchLabels:
          app: kibana
    ports:
    - protocol: TCP
      port: 9200
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
```

### æ€§èƒ½è°ƒä¼˜

#### 1. èµ„æºé…é¢ç®¡ç†
```yaml
# æ—¥å¿—ç»„ä»¶èµ„æºé™åˆ¶
apiVersion: v1
kind: ResourceQuota
metadata:
  name: logging-quota
  namespace: logging
spec:
  hard:
    requests.cpu: "4"
    requests.memory: 8Gi
    limits.cpu: "8"
    limits.memory: 16Gi
    persistentvolumeclaims: "10"
    requests.storage: 1Ti
---
apiVersion: v1
kind: LimitRange
metadata:
  name: logging-limits
  namespace: logging
spec:
  limits:
  - default:
      cpu: 1
      memory: 2Gi
    defaultRequest:
      cpu: 500m
      memory: 1Gi
    type: Container
```

#### 2. å­˜å‚¨ä¼˜åŒ–é…ç½®
```yaml
# Elasticsearchå­˜å‚¨ä¼˜åŒ–
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: elasticsearch
spec:
  nodeSets:
  - name: hot-nodes
    count: 3
    config:
      node.roles: ["data_hot", "ingest"]
      index.routing.allocation.require.data: "hot"
    podTemplate:
      spec:
        containers:
        - name: elasticsearch
          resources:
            requests:
              memory: 4Gi
              cpu: 2
            limits:
              memory: 8Gi
              cpu: 4
  - name: warm-nodes
    count: 2
    config:
      node.roles: ["data_warm"]
      index.routing.allocation.require.data: "warm"
    podTemplate:
      spec:
        containers:
        - name: elasticsearch
          resources:
            requests:
              memory: 8Gi
              cpu: 2
            limits:
              memory: 16Gi
              cpu: 4
```

## ğŸ“ˆ ç›‘æ§ä¸å‘Šè­¦

### æ—¥å¿—å¹³å°å¥åº·ç›‘æ§

#### 1. ç»„ä»¶å¥åº·æ£€æŸ¥
```yaml
# æ—¥å¿—ç»„ä»¶å¥åº·ç›‘æ§
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: logging-health
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: elasticsearch
  endpoints:
  - port: http
    path: /_cluster/health
    interval: 30s
    scrapeTimeout: 10s
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: logging-platform-alerts
  namespace: monitoring
spec:
  groups:
  - name: logging.rules
    rules:
    - alert: ElasticsearchClusterRed
      expr: elasticsearch_cluster_health_status{color="red"} == 1
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "Elasticsearch cluster is in RED state"
        
    - alert: FluentBitBufferFull
      expr: fluentbit_buffer_overrun_total > 0
      for: 1m
      labels:
        severity: warning
      annotations:
        summary: "Fluent Bit buffer is overrun"
```

#### 2. æ€§èƒ½æŒ‡æ ‡ç›‘æ§
```json
{
  "dashboard": {
    "title": "Logging Platform Performance",
    "panels": [
      {
        "title": "Log Processing Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(fluentbit_input_bytes_total[5m])",
            "legendFormat": "Bytes/sec"
          }
        ]
      },
      {
        "title": "Elasticsearch Indexing Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(elasticsearch_indices_indexing_index_total[5m])",
            "legendFormat": "Documents/sec"
          }
        ]
      }
    ]
  }
}
```

## ğŸ”§ å®æ–½æ£€æŸ¥æ¸…å•

### å¹³å°éƒ¨ç½²
- [ ] è®¾è®¡æ—¥å¿—æ”¶é›†æ¶æ„å’Œæ•°æ®æµå‘
- [ ] éƒ¨ç½²æ—¥å¿—æ”¶é›†ä»£ç†(Fluent Bit/Fluentd)
- [ ] é…ç½®æ—¥å¿—ç¼“å†²å±‚(Kafka/Redis)
- [ ] éƒ¨ç½²æ—¥å¿—å­˜å‚¨(Elasticsearché›†ç¾¤)
- [ ] é…ç½®æ—¥å¿—åˆ†æç•Œé¢(Kibana)
- [ ] å®ç°æ—¥å¿—è§£æå’Œç»“æ„åŒ–å¤„ç†

### å®‰å…¨ä¸æ€§èƒ½
- [ ] é…ç½®è®¿é—®è®¤è¯å’Œæˆæƒæœºåˆ¶
- [ ] å®æ–½ç½‘ç»œå®‰å…¨éš”ç¦»ç­–ç•¥
- [ ] ä¼˜åŒ–å­˜å‚¨å’ŒæŸ¥è¯¢æ€§èƒ½
- [ ] é…ç½®ç´¢å¼•ç”Ÿå‘½å‘¨æœŸç®¡ç†
- [ ] å®æ–½æ—¥å¿—é‡‡æ ·å’Œè¿‡æ»¤ç­–ç•¥
- [ ] å»ºç«‹ç›‘æ§å‘Šè­¦ä½“ç³»

### è¿è¥ç»´æŠ¤
- [ ] åˆ¶å®šæ—¥å¿—ä¿ç•™å’Œæ¸…ç†ç­–ç•¥
- [ ] å»ºç«‹æ—¥å¿—å¹³å°è¿ç»´æ‰‹å†Œ
- [ ] å®šæœŸè¿›è¡Œæ€§èƒ½è°ƒä¼˜
- [ ] ç»´æŠ¤æ—¥å¿—åˆ†ææ¨¡æ¿å’Œä»ªè¡¨æ¿
- [ ] å»ºç«‹æ•…éšœæ’æŸ¥å’Œæ¢å¤æµç¨‹
- [ ] æŒç»­æ”¹è¿›æ—¥å¿—æ”¶é›†è¦†ç›–ç‡

---

*æœ¬æ–‡æ¡£ä¸ºä¼ä¸šçº§æ—¥å¿—æ”¶é›†åˆ†æå¹³å°æä¾›å®Œæ•´çš„æŠ€æœ¯å®æ–½æ–¹æ¡ˆå’Œè¿ç»´æŒ‡å¯¼*