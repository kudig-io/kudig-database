# 23. äº‹ä»¶å“åº”å¤„ç† (Incident Response Handling)

> **é€‚ç”¨èŒƒå›´**: Kubernetes v1.25-v1.32 | **æ›´æ–°æ—¶é—´**: 2024å¹´ | **é¢„è®¡é˜…è¯»æ—¶é—´**: 45åˆ†é’Ÿ

## ğŸ“‹ ç« èŠ‚æ¦‚è§ˆ

æœ¬ç« èŠ‚è¯¦ç»†ä»‹ç»Kubernetesç”Ÿäº§ç¯å¢ƒä¸­äº‹ä»¶å“åº”å’Œå¤„ç†çš„æœ€ä½³å®è·µï¼Œæ¶µç›–SREç†å¿µã€æ•…éšœå¤„ç†æµç¨‹ã€æ ¹å› åˆ†æå’ŒæŒç»­æ”¹è¿›æœºåˆ¶ã€‚

---

## 1. SREç†å¿µä¸äº‹ä»¶ç®¡ç†

### 1.1 Site Reliability Engineeringæ ¸å¿ƒåŸåˆ™

#### Google SREä¸‰å¤§æ”¯æŸ±
```yaml
å¯é æ€§å·¥ç¨‹æ ¸å¿ƒç†å¿µ:
  æœåŠ¡çº§åˆ«ç›®æ ‡(SLO):
    - ç”¨æˆ·ä½“éªŒé‡åŒ–æ ‡å‡†
    - é”™è¯¯é¢„ç®—ç®¡ç†
    - å¯æ¥å—çš„é£é™©æ°´å¹³
  
  ç›‘æ§ä¸å‘Šè­¦:
    - é»„é‡‘ä¿¡å·ç›‘æ§
    - æ™ºèƒ½å‘Šè­¦ç­–ç•¥
    - å‘Šè­¦ç–²åŠ³é¢„é˜²
  
  è‡ªåŠ¨åŒ–ä¸å·¥å…·åŒ–:
    - æ•…éšœè‡ªæ„ˆèƒ½åŠ›
    - è¿ç»´æ•ˆç‡æå‡
    - äººæœºåä½œä¼˜åŒ–
```

#### SRE vs ä¼ ç»Ÿè¿ç»´å¯¹æ¯”
| ç»´åº¦ | ä¼ ç»Ÿè¿ç»´ | SRE |
|------|----------|-----|
| å…³æ³¨ç‚¹ | ç³»ç»Ÿç¨³å®šæ€§ | ç”¨æˆ·ä½“éªŒ |
| è¡¡é‡æ ‡å‡† | ç³»ç»Ÿæ­£å¸¸è¿è¡Œæ—¶é—´ | æœåŠ¡è´¨é‡æŒ‡æ ‡ |
| å¤„ç†æ–¹å¼ | è¢«åŠ¨å“åº” | ä¸»åŠ¨é¢„é˜² |
| è‡ªåŠ¨åŒ–ç¨‹åº¦ | æ‰‹å·¥æ“ä½œä¸ºä¸» | é«˜åº¦è‡ªåŠ¨åŒ– |

### 1.2 äº‹ä»¶åˆ†çº§ä¸å“åº”æ ‡å‡†

#### äº‹ä»¶ä¸¥é‡æ€§ç­‰çº§å®šä¹‰
```yaml
äº‹ä»¶åˆ†çº§æ ‡å‡†:
  P0 - ç´§æ€¥:
    å½±å“èŒƒå›´: å…¨å±€æœåŠ¡ä¸­æ–­
    å“åº”æ—¶é—´: 15åˆ†é’Ÿå†…å“åº”
    è§£å†³æ—¶é™: 2å°æ—¶å†…æ¢å¤
    
  P1 - é«˜ä¼˜å…ˆçº§:
    å½±å“èŒƒå›´: æ ¸å¿ƒåŠŸèƒ½å—æŸ
    å“åº”æ—¶é—´: 30åˆ†é’Ÿå†…å“åº”
    è§£å†³æ—¶é™: 4å°æ—¶å†…æ¢å¤
    
  P2 - ä¸­ç­‰ä¼˜å…ˆçº§:
    å½±å“èŒƒå›´: éƒ¨åˆ†åŠŸèƒ½å¼‚å¸¸
    å“åº”æ—¶é—´: 2å°æ—¶å†…å“åº”
    è§£å†³æ—¶é™: 24å°æ—¶å†…è§£å†³
    
  P3 - ä½ä¼˜å…ˆçº§:
    å½±å“èŒƒå›´: è½»å¾®å½±å“
    å“åº”æ—¶é—´: 8å°æ—¶å†…å“åº”
    è§£å†³æ—¶é™: 72å°æ—¶å†…è§£å†³
```

#### Kubernetesç‰¹å®šäº‹ä»¶åˆ†ç±»
```bash
# é›†ç¾¤å±‚é¢äº‹ä»¶
kubectl get events --all-namespaces --field-selector type!=Normal

# Podç›¸å…³äº‹ä»¶ç­›é€‰
kubectl get events --field-selector involvedObject.kind=Pod

# Nodeç›¸å…³äº‹ä»¶
kubectl get events --field-selector involvedObject.kind=Node
```

---

## 2. äº‹ä»¶å“åº”æµç¨‹

### 2.1 æ ‡å‡†äº‹ä»¶å“åº”æµç¨‹

#### ITILäº‹ä»¶ç®¡ç†æµç¨‹
```mermaid
graph TD
    A[äº‹ä»¶æ£€æµ‹] --> B[äº‹ä»¶åˆ†ç±»]
    B --> C[ä¼˜å…ˆçº§è¯„ä¼°]
    C --> D[é€šçŸ¥å“åº”å›¢é˜Ÿ]
    D --> E[åˆæ­¥è¯Šæ–­]
    E --> F[æ ¹æœ¬åŸå› åˆ†æ]
    F --> G[æ‰§è¡Œä¿®å¤]
    G --> H[éªŒè¯æ¢å¤]
    H --> I[äº‹åæ€»ç»“]
    I --> J[æŒç»­æ”¹è¿›]
```

#### è¯¦ç»†å“åº”æ­¥éª¤
```yaml
äº‹ä»¶å“åº”é˜¶æ®µ:
  ç¬¬ä¸€é˜¶æ®µ - æ£€æµ‹ä¸é€šçŸ¥:
    - ç›‘æ§ç³»ç»Ÿè§¦å‘å‘Šè­¦
    - è‡ªåŠ¨åˆ›å»ºäº‹ä»¶å·¥å•
    - é€šçŸ¥ç›¸å…³äººå‘˜
    
  ç¬¬äºŒé˜¶æ®µ - è¯„ä¼°ä¸åˆ†ç±»:
    - ç¡®è®¤äº‹ä»¶çœŸå®æ€§
    - è¯„ä¼°å½±å“èŒƒå›´
    - ç¡®å®šä¼˜å…ˆçº§ç­‰çº§
    
  ç¬¬ä¸‰é˜¶æ®µ - å“åº”ä¸æ²Ÿé€š:
    - ç»„å»ºåº”æ€¥å“åº”å›¢é˜Ÿ
    - å»ºç«‹æ²Ÿé€šæ¸ é“
    - å®šæœŸçŠ¶æ€æ›´æ–°
    
  ç¬¬å››é˜¶æ®µ - è¯Šæ–­ä¸ä¿®å¤:
    - æ”¶é›†è¯Šæ–­ä¿¡æ¯
    - åˆ¶å®šä¿®å¤æ–¹æ¡ˆ
    - æ‰§è¡Œä¿®å¤æ“ä½œ
    
  ç¬¬äº”é˜¶æ®µ - éªŒè¯ä¸å…³é—­:
    - éªŒè¯æœåŠ¡æ¢å¤æ­£å¸¸
    - æ›´æ–°äº‹ä»¶çŠ¶æ€
    - å…³é—­äº‹ä»¶å·¥å•
```

### 2.2 Kubernetesäº‹ä»¶å¤„ç†å®æˆ˜

#### äº‹ä»¶ä¿¡æ¯æ”¶é›†è„šæœ¬
```bash
#!/bin/bash
# incident-collector.sh - äº‹ä»¶ä¿¡æ¯è‡ªåŠ¨æ”¶é›†è„šæœ¬

CLUSTER_NAME=$(kubectl config current-context)
TIMESTAMP=$(date -u +"%Y%m%d_%H%M%S")

# åˆ›å»ºäº‹ä»¶æ”¶é›†ç›®å½•
INCIDENT_DIR="/tmp/incident_${TIMESTAMP}"
mkdir -p ${INCIDENT_DIR}

echo "å¼€å§‹æ”¶é›†äº‹ä»¶ä¿¡æ¯..."
echo "é›†ç¾¤: ${CLUSTER_NAME}"
echo "æ—¶é—´æˆ³: ${TIMESTAMP}"

# 1. é›†ç¾¤åŸºæœ¬ä¿¡æ¯
kubectl cluster-info > ${INCIDENT_DIR}/cluster-info.txt 2>&1
kubectl get nodes -o wide > ${INCIDENT_DIR}/nodes-status.txt 2>&1

# 2. äº‹ä»¶æ”¶é›†
kubectl get events --all-namespaces --sort-by='.lastTimestamp' > ${INCIDENT_DIR}/events-all.txt
kubectl get events --all-namespaces --field-selector type=Warning > ${INCIDENT_DIR}/events-warning.txt

# 3. PodçŠ¶æ€
kubectl get pods --all-namespaces --field-selector=status.phase!=Running > ${INCIDENT_DIR}/pods-non-running.txt
kubectl get pods --all-namespaces | grep -E "(CrashLoopBackOff|Error|Pending)" > ${INCIDENT_DIR}/pods-problematic.txt

# 4. ç³»ç»Ÿç»„ä»¶çŠ¶æ€
kubectl get componentstatuses > ${INCIDENT_DIR}/component-status.txt 2>&1
kubectl top nodes > ${INCIDENT_DIR}/node-resources.txt 2>&1
kubectl top pods --all-namespaces > ${INCIDENT_DIR}/pod-resources.txt 2>&1

# 5. æ—¥å¿—æ”¶é›†
echo "æ”¶é›†å…³é”®ç»„ä»¶æ—¥å¿—..."
kubectl logs -n kube-system -l component=kube-apiserver --tail=1000 > ${INCIDENT_DIR}/apiserver-logs.txt 2>&1
kubectl logs -n kube-system -l component=kube-controller-manager --tail=1000 > ${INCIDENT_DIR}/controller-logs.txt 2>&1
kubectl logs -n kube-system -l component=kube-scheduler --tail=1000 > ${INCIDENT_DIR}/scheduler-logs.txt 2>&1

# 6. ç½‘ç»œçŠ¶æ€
kubectl get svc --all-namespaces > ${INCIDENT_DIR}/services.txt
kubectl get endpoints --all-namespaces > ${INCIDENT_DIR}/endpoints.txt
kubectl get ingress --all-namespaces > ${INCIDENT_DIR}/ingresses.txt

# 7. å­˜å‚¨çŠ¶æ€
kubectl get pv > ${INCIDENT_DIR}/persistent-volumes.txt
kubectl get pvc --all-namespaces > ${INCIDENT_DIR}/persistent-volume-claims.txt

# æ‰“åŒ…æ”¶é›†ç»“æœ
tar -czf "/tmp/incident_${TIMESTAMP}.tar.gz" -C /tmp "incident_${TIMESTAMP}"
rm -rf ${INCIDENT_DIR}

echo "äº‹ä»¶ä¿¡æ¯æ”¶é›†å®Œæˆ: /tmp/incident_${TIMESTAMP}.tar.gz"
```

#### äº‹ä»¶å¿«é€Ÿè¯Šæ–­å‘½ä»¤é›†
```bash
# å¿«é€Ÿå¥åº·æ£€æŸ¥
alias khealth='kubectl get nodes && kubectl get pods --all-namespaces'

# äº‹ä»¶å®æ—¶ç›‘æ§
alias kevents='watch -n 5 "kubectl get events --all-namespaces --sort-by=.lastTimestamp | tail -20"'

# Podé—®é¢˜è¯Šæ–­
alias kpods-problem='kubectl get pods --all-namespaces --field-selector=status.phase!=Running'

# èµ„æºå‹åŠ›æ£€æŸ¥
alias kpressure='kubectl top nodes && kubectl top pods --all-namespaces'
```

---

## 3. æ ¹æœ¬åŸå› åˆ†æ(RCA)

### 3.1 RCAæ–¹æ³•è®º

#### 5 Whysåˆ†ææ³•
```markdown
é—®é¢˜: API Serverå“åº”ç¼“æ…¢

1. ä¸ºä»€ä¹ˆAPI Serveræ…¢ï¼Ÿå› ä¸ºetcdå“åº”æ—¶é—´å¢åŠ 
2. ä¸ºä»€ä¹ˆetcdå“åº”æ…¢ï¼Ÿå› ä¸ºç£ç›˜I/Oå»¶è¿Ÿé«˜
3. ä¸ºä»€ä¹ˆç£ç›˜I/Oå»¶è¿Ÿé«˜ï¼Ÿå› ä¸ºç£ç›˜ç©ºé—´ä¸è¶³
4. ä¸ºä»€ä¹ˆç£ç›˜ç©ºé—´ä¸è¶³ï¼Ÿå› ä¸ºæ—¥å¿—æ–‡ä»¶æœªæ¸…ç†
5. ä¸ºä»€ä¹ˆæ—¥å¿—æœªæ¸…ç†ï¼Ÿå› ä¸ºç¼ºå°‘è‡ªåŠ¨æ¸…ç†ç­–ç•¥

æ ¹æœ¬åŸå› : ç¼ºå°‘etcdæ—¥å¿—è‡ªåŠ¨æ¸…ç†æœºåˆ¶
è§£å†³æ–¹æ¡ˆ: é…ç½®etcdè‡ªåŠ¨å‹ç¼©å’Œæ—¥å¿—è½®è½¬
```

#### é±¼éª¨å›¾åˆ†ææ³•
```
API Serveræ€§èƒ½é—®é¢˜
â”œâ”€â”€ äººå‘˜å› ç´ 
â”‚   â”œâ”€â”€ é…ç½®é”™è¯¯
â”‚   â””â”€â”€ æ“ä½œå¤±è¯¯
â”œâ”€â”€ æµç¨‹å› ç´ 
â”‚   â”œâ”€â”€ ç¼ºå°‘ç›‘æ§
â”‚   â””â”€â”€ å‘Šè­¦ä¸åŠæ—¶
â”œâ”€â”€ æŠ€æœ¯å› ç´ 
â”‚   â”œâ”€â”€ èµ„æºä¸è¶³
â”‚   â”œâ”€â”€ ç‰ˆæœ¬bug
â”‚   â””â”€â”€ ç½‘ç»œé—®é¢˜
â””â”€â”€ ç¯å¢ƒå› ç´ 
    â”œâ”€â”€ ç¡¬ä»¶æ•…éšœ
    â””â”€â”€ äº‘æœåŠ¡å•†é—®é¢˜
```

### 3.2 Kuberneteså¸¸è§æ•…éšœæ¨¡å¼

#### æ§åˆ¶å¹³é¢æ•…éšœ
```yaml
æ•…éšœç±»å‹:
  API Serveræ•…éšœ:
    ç—‡çŠ¶: kubectlå‘½ä»¤å¤±è´¥ï¼Œé›†ç¾¤ä¸å¯è®¿é—®
    å¸¸è§åŸå› :
      - è¯ä¹¦è¿‡æœŸ
      - èµ„æºè€—å°½
      - é…ç½®é”™è¯¯
    è¯Šæ–­å‘½ä»¤:
      kubectl get componentstatuses
      systemctl status kube-apiserver
      
  etcdæ•…éšœ:
    ç—‡çŠ¶: æ•°æ®è¯»å†™å¤±è´¥ï¼Œé›†ç¾¤çŠ¶æ€ä¸ä¸€è‡´
    å¸¸è§åŸå› :
      - ç£ç›˜ç©ºé—´æ»¡
      - ç½‘ç»œåˆ†åŒº
      - æˆå‘˜èŠ‚ç‚¹æ•…éšœ
    è¯Šæ–­å‘½ä»¤:
      etcdctl endpoint health
      etcdctl member list
      
  Controller Manageræ•…éšœ:
    ç—‡çŠ¶: Deploymentä¸å·¥ä½œï¼ŒæœåŠ¡æ— æ³•è°ƒåº¦
    å¸¸è§åŸå› :
      - æƒé™é…ç½®é”™è¯¯
      - èµ„æºç«äº‰
      - ç‰ˆæœ¬å…¼å®¹é—®é¢˜
    è¯Šæ–­å‘½ä»¤:
      kubectl logs -n kube-system -l component=kube-controller-manager
```

#### å·¥ä½œèŠ‚ç‚¹æ•…éšœ
```yaml
æ•…éšœç±»å‹:
  Node NotReady:
    ç—‡çŠ¶: èŠ‚ç‚¹çŠ¶æ€æ˜¾ç¤ºNotReady
    å¸¸è§åŸå› :
      - kubeletæœåŠ¡åœæ­¢
      - ç½‘ç»œè¿æ¥é—®é¢˜
      - èµ„æºè€—å°½
    è¯Šæ–­å‘½ä»¤:
      systemctl status kubelet
      journalctl -u kubelet
      
  Podé©±é€:
    ç—‡çŠ¶: Podè¢«æ„å¤–ç»ˆæ­¢å¹¶é‡æ–°è°ƒåº¦
    å¸¸è§åŸå› :
      - å†…å­˜å‹åŠ›
      - ç£ç›˜å‹åŠ›
      - èŠ‚ç‚¹ç»´æŠ¤
    è¯Šæ–­å‘½ä»¤:
      kubectl describe node <node-name>
      kubectl get events --field-selector involvedObject.name=<node-name>
      
  CNIç½‘ç»œæ•…éšœ:
    ç—‡çŠ¶: Podé—´é€šä¿¡å¤±è´¥ï¼ŒDNSè§£æå¼‚å¸¸
    å¸¸è§åŸå› :
      - CNIæ’ä»¶é…ç½®é”™è¯¯
      - ç½‘ç»œç­–ç•¥å†²çª
      - IPåœ°å€è€—å°½
    è¯Šæ–­å‘½ä»¤:
      kubectl exec -it <pod> -- ping <other-pod-ip>
      ip route show
```

---

## 4. äº‹åæ€»ç»“ä¸æ”¹è¿›

### 4.1 äº‹ä»¶å¤ç›˜ä¼šè®®

#### å¤ç›˜ä¼šè®®æµç¨‹
```markdown
äº‹ä»¶å¤ç›˜æ ‡å‡†æµç¨‹:

1. äº‹å‰å‡†å¤‡ (ä¼šå‰1å¤©)
   - æ”¶é›†äº‹ä»¶ç›¸å…³èµ„æ–™
   - å‡†å¤‡æ—¶é—´çº¿æ¢³ç†
   - ç¡®å®šå‚ä¼šäººå‘˜

2. ä¼šè®®è¿›è¡Œ (90åˆ†é’Ÿ)
   - äº‹ä»¶å›é¡¾ (15åˆ†é’Ÿ)
   - æ—¶é—´çº¿æ¢³ç† (20åˆ†é’Ÿ)
   - æ ¹å› åˆ†æ (25åˆ†é’Ÿ)
   - æ”¹è¿›æªæ–½è®¨è®º (20åˆ†é’Ÿ)
   - è¡ŒåŠ¨è®¡åˆ’ç¡®è®¤ (10åˆ†é’Ÿ)

3. ä¼šåè·Ÿè¿›
   - ç¼–å†™å¤ç›˜æŠ¥å‘Š
   - è·Ÿè¸ªæ”¹è¿›æªæ–½æ‰§è¡Œ
   - æ›´æ–°åº”æ€¥é¢„æ¡ˆ
```

#### å¤ç›˜æŠ¥å‘Šæ¨¡æ¿
```markdown
# äº‹ä»¶å¤ç›˜æŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- äº‹ä»¶ç¼–å·: INC-2024-001
- å‘ç”Ÿæ—¶é—´: 2024-01-15 14:30 UTC
- æ¢å¤æ—¶é—´: 2024-01-15 16:45 UTC
- å½±å“æ—¶é•¿: 2å°æ—¶15åˆ†é’Ÿ
- å½±å“èŒƒå›´: ç”Ÿäº§ç¯å¢ƒ50%æœåŠ¡èƒ½åŠ›

## äº‹ä»¶æ—¶é—´çº¿
```

### 4.2 æŒç»­æ”¹è¿›æœºåˆ¶

#### æ”¹è¿›æªæ–½è·Ÿè¸ªç³»ç»Ÿ
```yaml
æ”¹è¿›æªæ–½ç®¡ç†:
  è®°å½•æ ¼å¼:
    - é—®é¢˜æè¿°
    - æ ¹æœ¬åŸå› 
    - è§£å†³æ–¹æ¡ˆ
    - è´£ä»»äºº
    - å®ŒæˆæœŸé™
    - éªŒè¯æ–¹æ³•
    
  è·Ÿè¸ªå‘¨æœŸ:
    - å‘¨æŠ¥: è¿›åº¦æ›´æ–°
    - æœˆæŠ¥: æ•ˆæœè¯„ä¼°
    - å­£åº¦: æ•´ä½“å›é¡¾
```

#### é¢„é˜²æªæ–½å®æ–½
```bash
# è‡ªåŠ¨åŒ–æ£€æŸ¥è„šæœ¬
#!/bin/bash
# preventive-checks.sh

echo "æ‰§è¡Œé¢„é˜²æ€§æ£€æŸ¥..."

# 1. è¯ä¹¦æœ‰æ•ˆæœŸæ£€æŸ¥
CERT_EXPIRY=$(openssl x509 -in /etc/kubernetes/pki/apiserver.crt -noout -enddate)
echo "API Serverè¯ä¹¦åˆ°æœŸæ—¶é—´: ${CERT_EXPIRY}"

# 2. ç£ç›˜ç©ºé—´æ£€æŸ¥
DISK_USAGE=$(df -h /var/lib/etcd | awk 'NR==2 {print $5}' | sed 's/%//')
if [ ${DISK_USAGE} -gt 80 ]; then
    echo "è­¦å‘Š: etcdç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜ (${DISK_USAGE}%)"
fi

# 3. Podé‡å¯æ¬¡æ•°æ£€æŸ¥
RESTARTING_PODS=$(kubectl get pods --all-namespaces -o jsonpath='{range .items[*]}{.metadata.name}{" "}{.status.containerStatuses[*].restartCount}{"\n"}{end}' | awk '$2 > 10 {print $1}')

if [ -n "${RESTARTING_PODS}" ]; then
    echo "å‘ç°é¢‘ç¹é‡å¯çš„Pod:"
    echo "${RESTARTING_PODS}"
fi

echo "é¢„é˜²æ€§æ£€æŸ¥å®Œæˆ"
```

---

## 5. äº‹ä»¶ç®¡ç†ç³»ç»Ÿé›†æˆ

### 5.1 å‘Šè­¦ä¸å·¥å•ç³»ç»Ÿ

#### Prometheuså‘Šè­¦è§„åˆ™ç¤ºä¾‹
```yaml
# alert-rules.yaml
groups:
- name: incident.rules
  rules:
  # é«˜ä¼˜å…ˆçº§å‘Šè­¦
  - alert: ClusterDown
    expr: up == 0
    for: 2m
    labels:
      severity: critical
      team: sre
    annotations:
      summary: "é›†ç¾¤ç»„ä»¶å®•æœº"
      description: "{{ $labels.instance }} ç»„ä»¶å·²å®•æœºè¶…è¿‡2åˆ†é’Ÿ"

  - alert: HighCPUUsage
    expr: rate(container_cpu_usage_seconds_total[5m]) > 0.9
    for: 5m
    labels:
      severity: warning
      team: sre
    annotations:
      summary: "CPUä½¿ç”¨ç‡è¿‡é«˜"
      description: "å®¹å™¨CPUä½¿ç”¨ç‡è¶…è¿‡90%"

  # è‡ªåŠ¨åˆ›å»ºäº‹ä»¶å·¥å•
  - alert: ServiceDegraded
    expr: probe_success == 0
    for: 3m
    labels:
      severity: major
      team: sre
      create_ticket: "true"
    annotations:
      summary: "æœåŠ¡é™çº§"
      description: "æœåŠ¡ {{ $labels.service }} ä¸å¯ç”¨"
```

#### ServiceNowé›†æˆç¤ºä¾‹
```python
# servicenow_integration.py
import requests
import json
from datetime import datetime

class IncidentManager:
    def __init__(self, instance_url, username, password):
        self.base_url = f"https://{instance_url}/api/now/table/incident"
        self.auth = (username, password)
        self.headers = {
            'Content-Type': 'application/json',
            'Accept': 'application/json'
        }
    
    def create_incident(self, alert_data):
        """æ ¹æ®å‘Šè­¦æ•°æ®åˆ›å»ºServiceNowäº‹ä»¶"""
        incident_data = {
            'short_description': alert_data['alertname'],
            'description': alert_data['description'],
            'urgency': self._map_severity(alert_data['severity']),
            'impact': '2',  # ä¸­ç­‰å½±å“
            'assignment_group': 'SRE Team',
            'caller_id': 'kubernetes_monitoring'
        }
        
        response = requests.post(
            self.base_url,
            auth=self.auth,
            headers=self.headers,
            data=json.dumps(incident_data)
        )
        
        if response.status_code == 201:
            return response.json()['result']['number']
        else:
            raise Exception(f"åˆ›å»ºäº‹ä»¶å¤±è´¥: {response.text}")
    
    def _map_severity(self, severity):
        """æ˜ å°„å‘Šè­¦çº§åˆ«åˆ°ServiceNowç´§æ€¥åº¦"""
        mapping = {
            'critical': '1',  # é«˜
            'warning': '2',   # ä¸­
            'info': '3'       # ä½
        }
        return mapping.get(severity, '3')

# ä½¿ç”¨ç¤ºä¾‹
manager = IncidentManager('your-instance.service-now.com', 'username', 'password')
incident_number = manager.create_incident({
    'alertname': 'HighMemoryUsage',
    'description': 'Node memory usage exceeded 90%',
    'severity': 'warning'
})
print(f"åˆ›å»ºäº‹ä»¶å·¥å•: {incident_number}")
```

### 5.2 è‡ªåŠ¨åŒ–å“åº”æœºåˆ¶

#### ChatOpsæœºå™¨äººé›†æˆ
```yaml
# chatbot-config.yaml
chatbot:
  name: "K8s-SRE-Bot"
  channels:
    - name: "production-alerts"
      type: "slack"
    - name: "incident-response"
      type: "teams"
  
  commands:
    - name: "incident_status"
      description: "æŸ¥è¯¢å½“å‰äº‹ä»¶çŠ¶æ€"
      trigger: "/status"
      script: |
        #!/bin/bash
        kubectl get events --sort-by=.lastTimestamp | tail -10
        
    - name: "incident_acknowledge"
      description: "ç¡®è®¤å¤„ç†äº‹ä»¶"
      trigger: "/ack"
      script: |
        #!/bin/bash
        INCIDENT_ID=$1
        echo "äº‹ä»¶ ${INCIDENT_ID} å·²è¢« ${USER} ç¡®è®¤å¤„ç†"
        
    - name: "incident_escalate"
      description: "å‡çº§äº‹ä»¶"
      trigger: "/escalate"
      script: |
        #!/bin/bash
        INCIDENT_ID=$1
        # è§¦å‘ç”µè¯å‘Šè­¦
        /usr/local/bin/phone-alert.sh ${INCIDENT_ID}
```

---

## 6. æœ€ä½³å®è·µæ€»ç»“

### 6.1 å…³é”®æˆåŠŸå› ç´ 

#### ç»„ç»‡å±‚é¢
âœ… **å»ºç«‹SREæ–‡åŒ–**: å°†å¯é æ€§ä½œä¸ºæ ¸å¿ƒä»·å€¼
âœ… **è·¨å›¢é˜Ÿåä½œ**: å¼€å‘ã€è¿ç»´ã€å®‰å…¨å›¢é˜Ÿç´§å¯†é…åˆ
âœ… **æŠ•èµ„è‡ªåŠ¨åŒ–**: å‡å°‘äººå·¥å¹²é¢„ï¼Œæé«˜å“åº”é€Ÿåº¦
âœ… **æŒç»­å­¦ä¹ **: å®šæœŸå¤ç›˜ï¼Œä¸æ–­ä¼˜åŒ–æµç¨‹

#### æŠ€æœ¯å±‚é¢
âœ… **å…¨é¢ç›‘æ§**: è¦†ç›–æ‰€æœ‰å…³é”®ç»„ä»¶å’ŒæœåŠ¡
âœ… **æ™ºèƒ½å‘Šè­¦**: å‡å°‘å™ªéŸ³ï¼Œæé«˜å‘Šè­¦å‡†ç¡®æ€§
âœ… **å¿«é€Ÿè¯Šæ–­**: æ ‡å‡†åŒ–çš„è¯Šæ–­å·¥å…·å’Œæµç¨‹
âœ… **è‡ªåŠ¨åŒ–ä¿®å¤**: å¯¹äºå·²çŸ¥é—®é¢˜å®ç°è‡ªåŠ¨æ¢å¤

### 6.2 å¸¸è§é™·é˜±é¿å…

#### âŒ é¿å…çš„åšæ³•
- ä¾èµ–ä¸ªäººç»éªŒè€Œéæ ‡å‡†åŒ–æµç¨‹
- å¿½è§†å‘Šè­¦ç–²åŠ³é—®é¢˜
- ç¼ºå°‘äº‹åæ€»ç»“å’Œæ”¹è¿›
- è¿‡åº¦ä¾èµ–æ‰‹å·¥æ“ä½œ

#### âœ… æ¨èåšæ³•
- å»ºç«‹å®Œå–„çš„äº‹ä»¶å“åº”æ‰‹å†Œ
- å®æ–½å‘Šè­¦åˆ†çº§å’Œè·¯ç”±æœºåˆ¶
- å®šæœŸè¿›è¡Œæ•…éšœæ¼”ç»ƒ
- æŒç»­ä¼˜åŒ–è‡ªåŠ¨åŒ–å·¥å…·é“¾

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [Google SRE Workbook](https://sre.google/workbook/)
- [Kubernetesæ•…éšœæ’æŸ¥æŒ‡å—](https://kubernetes.io/docs/tasks/debug/)
- [Prometheuså‘Šè­¦æœ€ä½³å®è·µ](https://prometheus.io/docs/practices/alerting/)

### å·¥å…·æ¨è
- **äº‹ä»¶ç®¡ç†**: PagerDuty, Opsgenie, ServiceNow
- **åä½œå·¥å…·**: Slack, Microsoft Teams, Discord
- **æ–‡æ¡£ç®¡ç†**: Confluence, Notion, Wikiç³»ç»Ÿ

### ç¤¾åŒºèµ„æº
- CNCF SREå·¥ä½œç»„
- Kubernetes SIG Instrumentation
- DevOps Instituteè®¤è¯è¯¾ç¨‹

---
*æœ¬æ–‡æ¡£ç”±Kubernetesç”Ÿäº§è¿ç»´ä¸“å®¶å›¢é˜Ÿç»´æŠ¤*