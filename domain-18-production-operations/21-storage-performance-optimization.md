# 21-å­˜å‚¨æ€§èƒ½ä¼˜åŒ–

> **é€‚ç”¨èŒƒå›´**: Kubernetes v1.25-v1.32 | **ç»´æŠ¤çŠ¶æ€**: ğŸ”§ æŒç»­æ›´æ–°ä¸­ | **ä¸“å®¶çº§åˆ«**: â­â­â­â­â­

## ğŸ“‹ æ¦‚è¿°

å­˜å‚¨æ€§èƒ½ä¼˜åŒ–å¯¹äºKubernetesé›†ç¾¤çš„æ•´ä½“æ€§èƒ½è‡³å…³é‡è¦ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»CSIé©±åŠ¨ä¼˜åŒ–ã€å­˜å‚¨ç±»é…ç½®å’Œæ€§èƒ½ç›‘æ§çš„æœ€ä½³å®è·µã€‚

## ğŸ’¾ CSIé©±åŠ¨æ€§èƒ½ä¼˜åŒ–

### æœ¬åœ°å­˜å‚¨ä¼˜åŒ–

#### 1. Local PVé…ç½®ä¼˜åŒ–
```yaml
# æœ¬åœ°å­˜å‚¨CSIé©±åŠ¨é…ç½®
apiVersion: storage.k8s.io/v1
kind: CSIDriver
metadata:
  name: local.csi.storage.example.com
spec:
  attachRequired: false
  podInfoOnMount: true
  volumeLifecycleModes:
  - Persistent
  - Ephemeral
---
# æœ¬åœ°å­˜å‚¨èŠ‚ç‚¹é…ç½®
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: local-storage-node
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: local-storage-node
  template:
    metadata:
      labels:
        app: local-storage-node
    spec:
      containers:
      - name: local-storage-driver
        image: custom/local-storage-driver:latest
        args:
        - --endpoint=$(CSI_ENDPOINT)
        - --nodeid=$(NODE_ID)
        - --v=5
        env:
        - name: CSI_ENDPOINT
          value: unix:///csi/csi.sock
        - name: NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: LOCAL_STORAGE_PATHS
          value: "/mnt/fast-ssd,/mnt/nvme-storage"
        volumeMounts:
        - name: plugin-dir
          mountPath: /csi
        - name: device-dir
          mountPath: /dev
        - name: storage-paths
          mountPath: /mnt
          mountPropagation: Bidirectional
        resources:
          requests:
            cpu: 50m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 512Mi
        securityContext:
          privileged: true
      volumes:
      - name: plugin-dir
        hostPath:
          path: /var/lib/kubelet/plugins/local.csi.storage.example.com
          type: DirectoryOrCreate
      - name: device-dir
        hostPath:
          path: /dev
          type: Directory
      - name: storage-paths
        hostPath:
          path: /mnt
          type: DirectoryOrCreate
---
# æœ¬åœ°å­˜å‚¨ç±»é…ç½®
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-fast-ssd
provisioner: local.csi.storage.example.com
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
parameters:
  storageType: "ssd"
  fsType: "ext4"
  mountOptions: "noatime,data=ordered,barrier=0"
reclaimPolicy: Delete
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-nvme
provisioner: local.csi.storage.example.com
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
parameters:
  storageType: "nvme"
  fsType: "xfs"
  mountOptions: "noatime,logbufs=8,logbsize=256k"
reclaimPolicy: Delete
```

#### 2. æœ¬åœ°å­˜å‚¨æ€§èƒ½è°ƒä¼˜è„šæœ¬
```bash
#!/bin/bash
# æœ¬åœ°å­˜å‚¨æ€§èƒ½ä¼˜åŒ–è„šæœ¬

# å­˜å‚¨è®¾å¤‡å‘ç°å’Œä¼˜åŒ–
optimize_local_storage() {
    echo "Optimizing local storage devices..."
    
    # å‘ç°SSDå’ŒNVMeè®¾å¤‡
    SSD_DEVICES=$(lsblk -d -o NAME,ROTA,TYPE | awk '$2==0 && $3=="disk" {print "/dev/"$1}')
    NVME_DEVICES=$(ls /dev/nvme* 2>/dev/null | grep -E 'nvme[0-9]+n[0-9]+' | head -10)
    
    # SSDä¼˜åŒ–
    for device in $SSD_DEVICES; do
        echo "Optimizing SSD: $device"
        
        # ç¦ç”¨ç”µæ¢¯ç®—æ³•
        echo noop > /sys/block/${device#/dev/}/queue/scheduler
        
        # è®¾ç½®è¯»å–æå‰é‡
        echo 4096 > /sys/block/${device#/dev/}/queue/read_ahead_kb
        
        # å¯ç”¨å†™å…¥ç¼“å­˜
        echo 1 > /sys/block/${device#/dev/}/queue/write_cache
        
        # è®¾ç½®I/Oæ·±åº¦
        echo 1024 > /sys/block/${device#/dev/}/queue/nr_requests
    done
    
    # NVMeä¼˜åŒ–
    for device in $NVME_DEVICES; do
        echo "Optimizing NVMe: $device"
        
        # NVMeç‰¹å®šä¼˜åŒ–
        echo 0 > /sys/block/${device#/dev/}/queue/iostats
        echo 1 > /sys/block/${device#/dev/}/queue/wbt_lat_usec
        echo 4096 > /sys/block/${device#/dev/}/queue/nr_requests
    done
}

# æ–‡ä»¶ç³»ç»Ÿä¼˜åŒ–
optimize_filesystems() {
    echo "Optimizing filesystems..."
    
    # æŸ¥æ‰¾æœ¬åœ°å­˜å‚¨æŒ‚è½½ç‚¹
    LOCAL_MOUNTS=$(mount | grep -E "(ssd|nvme|local)" | awk '{print $3}')
    
    for mount_point in $LOCAL_MOUNTS; do
        filesystem=$(mount | grep "$mount_point" | awk '{print $5}')
        
        case $filesystem in
            "ext4")
                tune2fs -o journal_data_writeback "$mount_point"
                tune2fs -m 1 "$mount_point"
                ;;
            "xfs")
                xfs_admin -c 1024 "$mount_point"
                ;;
        esac
    done
}

# æŒ‚è½½é€‰é¡¹ä¼˜åŒ–
optimize_mount_options() {
    echo "Optimizing mount options..."
    
    # å¤‡ä»½fstab
    cp /etc/fstab /etc/fstab.backup.$(date +%Y%m%d_%H%M%S)
    
    # ä¼˜åŒ–ç°æœ‰æŒ‚è½½
    sed -i 's/defaults/noatime,data=ordered,barrier=0/g' /etc/fstab
    
    # é‡æ–°æŒ‚è½½ä¼˜åŒ–çš„æ–‡ä»¶ç³»ç»Ÿ
    mount -o remount,noatime,data=ordered,barrier=0 /
    
    # ä¼˜åŒ–å…¶ä»–æœ¬åœ°å­˜å‚¨æŒ‚è½½ç‚¹
    for mount_point in $(mount | grep -E "(ssd|nvme)" | awk '{print $3}'); do
        if [ "$mount_point" != "/" ]; then
            mount -o remount,noatime "$mount_point"
        fi
    done
}

# å†…æ ¸å‚æ•°ä¼˜åŒ–
optimize_kernel_parameters() {
    echo "Optimizing kernel parameters..."
    
    cat > /etc/sysctl.d/99-storage-performance.conf << EOF
# å­˜å‚¨I/Oä¼˜åŒ–
vm.dirty_ratio = 15
vm.dirty_background_ratio = 5
vm.dirty_expire_centisecs = 2000
vm.dirty_writeback_centisecs = 100
vm.vfs_cache_pressure = 50

# å—è®¾å¤‡ä¼˜åŒ–
block-major-8-0.read_ahead_kb = 4096
block-major-8-16.read_ahead_kb = 4096

# æ–‡ä»¶ç³»ç»Ÿä¼˜åŒ–
fs.aio-max-nr = 1048576
fs.file-max = 2097152
EOF

    sysctl -p /etc/sysctl.d/99-storage-performance.conf
}

# æ‰§è¡Œä¼˜åŒ–
main() {
    echo "Starting local storage performance optimization..."
    
    optimize_local_storage
    optimize_filesystems
    optimize_mount_options
    optimize_kernel_parameters
    
    echo "Local storage optimization completed!"
    echo "Please reboot the system for all changes to take effect."
}

# åªåœ¨rootæƒé™ä¸‹æ‰§è¡Œ
if [ "$EUID" -ne 0 ]; then
    echo "Please run as root"
    exit 1
fi

main "$@"
```

### äº‘å­˜å‚¨CSIä¼˜åŒ–

#### 1. AWS EBS CSIä¼˜åŒ–
```yaml
# AWS EBS CSIé©±åŠ¨é…ç½®
apiVersion: storage.k8s.io/v1
kind: CSIDriver
metadata:
  name: ebs.csi.aws.com
spec:
  attachRequired: true
  podInfoOnMount: false
  volumeLifecycleModes:
  - Persistent
---
# EBS CSIæ§åˆ¶å™¨éƒ¨ç½²
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ebs-csi-controller
  namespace: kube-system
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ebs-csi-controller
  template:
    metadata:
      labels:
        app: ebs-csi-controller
    spec:
      containers:
      - name: ebs-plugin
        image: amazon/aws-ebs-csi-driver:v1.20.0
        args:
        - controller
        - --endpoint=$(CSI_ENDPOINT)
        - --logtostderr
        - --v=2
        env:
        - name: CSI_ENDPOINT
          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: aws-secret
              key: key_id
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: aws-secret
              key: access_key
        volumeMounts:
        - name: socket-dir
          mountPath: /var/lib/csi/sockets/pluginproxy/
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
      volumes:
      - name: socket-dir
        emptyDir: {}
---
# EBSå­˜å‚¨ç±»ä¼˜åŒ–é…ç½®
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: ebs-gp3
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: ebs.csi.aws.com
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
parameters:
  type: gp3
  csi.storage.k8s.io/fstype: ext4
  iops: "3000"
  throughput: "125"
  encrypted: "true"
  kmsKeyId: "arn:aws:kms:us-west-2:123456789012:key/abcd1234-a123-456a-a12b-a123b4cd56ef"
reclaimPolicy: Delete
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: ebs-io2
provisioner: ebs.csi.aws.com
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
parameters:
  type: io2
  csi.storage.k8s.io/fstype: xfs
  iopsPerGB: "100"
  encrypted: "true"
reclaimPolicy: Delete
```

#### 2. Google Cloud CSIä¼˜åŒ–
```yaml
# GCP PD CSIé©±åŠ¨é…ç½®
apiVersion: storage.k8s.io/v1
kind: CSIDriver
metadata:
  name: pd.csi.storage.gke.io
spec:
  attachRequired: true
  podInfoOnMount: false
  volumeLifecycleModes:
  - Persistent
---
# GCP PDå­˜å‚¨ç±»é…ç½®
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: premium-rwo
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: pd.csi.storage.gke.io
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
parameters:
  type: pd-ssd
  replication-type: none
  fstype: ext4
reclaimPolicy: Delete
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: standard-rwo
provisioner: pd.csi.storage.gke.io
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
parameters:
  type: pd-standard
  replication-type: none
  fstype: ext4
reclaimPolicy: Delete
```

## ğŸ¯ å­˜å‚¨æ€§èƒ½ç›‘æ§

### å­˜å‚¨æŒ‡æ ‡æ”¶é›†

#### 1. å­˜å‚¨æ€§èƒ½Prometheusè§„åˆ™
```yaml
# å­˜å‚¨æ€§èƒ½ç›‘æ§è§„åˆ™
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: storage-performance-rules
  namespace: monitoring
spec:
  groups:
  - name: storage.performance.rules
    rules:
    # å­˜å‚¨I/Oæ€§èƒ½æŒ‡æ ‡
    - record: storage:io_utilization:percentage
      expr: rate(node_disk_io_time_seconds_total[5m]) * 100
      
    - record: storage:read_latency:milliseconds
      expr: rate(node_disk_read_time_seconds_total[5m]) / rate(node_disk_reads_completed_total[5m]) * 1000
      
    - record: storage:write_latency:milliseconds
      expr: rate(node_disk_write_time_seconds_total[5m]) / rate(node_disk_writes_completed_total[5m]) * 1000
      
    - record: storage:iops:total
      expr: rate(node_disk_reads_completed_total[5m]) + rate(node_disk_writes_completed_total[5m])
      
    - record: storage:throughput:bytes_per_second
      expr: rate(node_disk_read_bytes_total[5m]) + rate(node_disk_written_bytes_total[5m])
      
    # PVCæ€§èƒ½æŒ‡æ ‡
    - record: pvc:usage:percentage
      expr: kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes * 100
      
    - record: pvc:iops:reads
      expr: rate(kubelet_volume_stats_reads_completed_total[5m])
      
    - record: pvc:iops:writes
      expr: rate(kubelet_volume_stats_writes_completed_total[5m])
      
    - record: pvc:latency:read_seconds
      expr: rate(kubelet_volume_stats_read_time_seconds[5m]) / rate(kubelet_volume_stats_reads_completed_total[5m])
      
    - record: pvc:latency:write_seconds
      expr: rate(kubelet_volume_stats_write_time_seconds[5m]) / rate(kubelet_volume_stats_writes_completed_total[5m])
      
    # å­˜å‚¨ç±»æ€§èƒ½
    - record: storageclass:average_latency:milliseconds
      expr: avg by(storageclass) (storage:read_latency:milliseconds + storage:write_latency:milliseconds) / 2
      
    - record: storageclass:utilization:percentage
      expr: avg by(storageclass) (storage:io_utilization:percentage)
```

#### 2. å­˜å‚¨æ€§èƒ½ä»ªè¡¨æ¿
```json
{
  "dashboard": {
    "title": "Storage Performance Dashboard",
    "panels": [
      {
        "title": "Storage I/O Utilization",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(node_disk_io_time_seconds_total[5m]) * 100",
            "legendFormat": "{{device}} Utilization %"
          }
        ]
      },
      {
        "title": "Storage Latency",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(node_disk_read_time_seconds_total[5m]) / rate(node_disk_reads_completed_total[5m]) * 1000",
            "legendFormat": "Read Latency (ms)"
          },
          {
            "expr": "rate(node_disk_write_time_seconds_total[5m]) / rate(node_disk_writes_completed_total[5m]) * 1000",
            "legendFormat": "Write Latency (ms)"
          }
        ]
      },
      {
        "title": "PVC Usage",
        "type": "gauge",
        "targets": [
          {
            "expr": "kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes * 100",
            "legendFormat": "{{persistentvolumeclaim}} Usage %"
          }
        ]
      },
      {
        "title": "Storage IOPS",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(node_disk_reads_completed_total[5m])",
            "legendFormat": "{{device}} Read IOPS"
          },
          {
            "expr": "rate(node_disk_writes_completed_total[5m])",
            "legendFormat": "{{device}} Write IOPS"
          }
        ]
      }
    ]
  }
}
```

### å­˜å‚¨æ€§èƒ½åˆ†æå·¥å…·

#### 1. å­˜å‚¨æ€§èƒ½åˆ†æè„šæœ¬
```python
#!/usr/bin/env python3
# å­˜å‚¨æ€§èƒ½åˆ†æå·¥å…·

import asyncio
import json
from datetime import datetime, timedelta
from kubernetes import client, config
import numpy as np

class StoragePerformanceAnalyzer:
    def __init__(self):
        config.load_kube_config()
        self.core_v1 = client.CoreV1Api()
        self.storage_v1 = client.StorageV1Api()
        
        self.performance_thresholds = {
            'io_utilization': 80,      # %
            'read_latency': 10,        # ms
            'write_latency': 15,       # ms
            'iops': 5000,              # ops/sec
            'throughput': 100 * 1024**2,  # 100 MB/s
            'pvc_usage': 85            # %
        }
    
    async def analyze_storage_performance(self):
        """åˆ†æå­˜å‚¨æ€§èƒ½"""
        analysis_report = {
            'timestamp': datetime.now().isoformat(),
            'cluster_info': await self.get_cluster_storage_info(),
            'storage_metrics': {},
            'performance_issues': [],
            'recommendations': []
        }
        
        # å¹¶è¡Œæ”¶é›†å­˜å‚¨æŒ‡æ ‡
        tasks = [
            self.analyze_node_storage(),
            self.analyze_pvc_performance(),
            self.analyze_storage_classes(),
            self.analyze_csi_drivers()
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†åˆ†æç»“æœ
        component_names = ['node_storage', 'pvc_performance', 'storage_classes', 'csi_drivers']
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                analysis_report['performance_issues'].append({
                    'component': component_names[i],
                    'error': str(result),
                    'severity': 'critical'
                })
            else:
                analysis_report['storage_metrics'][component_names[i]] = result
        
        # è¯†åˆ«æ€§èƒ½é—®é¢˜
        analysis_report['performance_issues'].extend(
            await self.identify_performance_issues(analysis_report['storage_metrics'])
        )
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        analysis_report['recommendations'] = await self.generate_recommendations(
            analysis_report['performance_issues']
        )
        
        return analysis_report
    
    async def get_cluster_storage_info(self):
        """è·å–é›†ç¾¤å­˜å‚¨ä¿¡æ¯"""
        try:
            # è·å–å­˜å‚¨ç±»
            storage_classes = self.storage_v1.list_storage_class()
            
            # è·å–æŒä¹…å·
            persistent_volumes = self.core_v1.list_persistent_volume()
            
            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            nodes = self.core_v1.list_node()
            
            return {
                'storage_classes_count': len(storage_classes.items),
                'persistent_volumes_count': len(persistent_volumes.items),
                'nodes_count': len(nodes.items),
                'total_storage_capacity': self.calculate_total_storage(persistent_volumes.items)
            }
        except Exception as e:
            return {'error': str(e)}
    
    def calculate_total_storage(self, pv_list):
        """è®¡ç®—æ€»å­˜å‚¨å®¹é‡"""
        total_capacity = 0
        for pv in pv_list:
            if pv.spec.capacity and 'storage' in pv.spec.capacity:
                capacity_str = pv.spec.capacity['storage']
                # ç®€åŒ–çš„å®¹é‡è§£æ
                if capacity_str.endswith('Gi'):
                    total_capacity += int(capacity_str[:-2]) * 1024**3
                elif capacity_str.endswith('Mi'):
                    total_capacity += int(capacity_str[:-2]) * 1024**2
        return total_capacity
    
    async def analyze_node_storage(self):
        """åˆ†æèŠ‚ç‚¹å­˜å‚¨æ€§èƒ½"""
        try:
            nodes = self.core_v1.list_node()
            node_storage_metrics = []
            
            for node in nodes.items:
                node_name = node.metadata.name
                metrics = await self.get_node_storage_metrics(node_name)
                node_storage_metrics.append(metrics)
            
            analysis = {
                'avg_io_utilization': np.mean([m['io_utilization'] for m in node_storage_metrics]),
                'avg_read_latency': np.mean([m['read_latency'] for m in node_storage_metrics]),
                'avg_write_latency': np.mean([m['write_latency'] for m in node_storage_metrics]),
                'high_utilization_devices': [
                    m for m in node_storage_metrics 
                    if m['io_utilization'] > self.performance_thresholds['io_utilization']
                ]
            }
            
            # è¯„ä¼°æ€§èƒ½
            issues = []
            if analysis['avg_io_utilization'] > self.performance_thresholds['io_utilization']:
                issues.append('High storage I/O utilization')
            
            if analysis['avg_read_latency'] > self.performance_thresholds['read_latency']:
                issues.append('High read latency')
                
            if analysis['avg_write_latency'] > self.performance_thresholds['write_latency']:
                issues.append('High write latency')
            
            analysis['status'] = 'degraded' if issues else 'healthy'
            analysis['issues'] = issues
            
            return analysis
            
        except Exception as e:
            return {'status': 'error', 'error': str(e)}
    
    async def analyze_pvc_performance(self):
        """åˆ†æPVCæ€§èƒ½"""
        try:
            # è·å–æ‰€æœ‰PVC
            pvcs = self.core_v1.list_persistent_volume_claim_for_all_namespaces()
            
            pvc_metrics = []
            for pvc in pvcs.items:
                metrics = await self.get_pvc_metrics(pvc)
                pvc_metrics.append(metrics)
            
            analysis = {
                'total_pvcs': len(pvcs.items),
                'avg_usage_percentage': np.mean([m['usage_percentage'] for m in pvc_metrics]),
                'high_usage_pvcs': [
                    m for m in pvc_metrics 
                    if m['usage_percentage'] > self.performance_thresholds['pvc_usage']
                ],
                'iops_statistics': {
                    'read_iops_avg': np.mean([m['read_iops'] for m in pvc_metrics]),
                    'write_iops_avg': np.mean([m['write_iops'] for m in pvc_metrics])
                }
            }
            
            # è¯„ä¼°æ€§èƒ½
            issues = []
            if analysis['avg_usage_percentage'] > self.performance_thresholds['pvc_usage']:
                issues.append('High PVC usage')
            
            high_usage_count = len(analysis['high_usage_pvcs'])
            if high_usage_count > len(pvcs.items) * 0.3:  # è¶…è¿‡30%çš„PVCä½¿ç”¨ç‡è¿‡é«˜
                issues.append(f'{high_usage_count} PVCs with high usage')
            
            analysis['status'] = 'degraded' if issues else 'healthy'
            analysis['issues'] = issues
            
            return analysis
            
        except Exception as e:
            return {'status': 'error', 'error': str(e)}
    
    async def analyze_storage_classes(self):
        """åˆ†æå­˜å‚¨ç±»æ€§èƒ½"""
        try:
            storage_classes = self.storage_v1.list_storage_class()
            
            sc_analysis = {
                'total_classes': len(storage_classes.items),
                'default_class': None,
                'class_performance': {}
            }
            
            # æ‰¾åˆ°é»˜è®¤å­˜å‚¨ç±»
            for sc in storage_classes.items:
                if sc.metadata.annotations and sc.metadata.annotations.get('storageclass.kubernetes.io/is-default-class') == 'true':
                    sc_analysis['default_class'] = sc.metadata.name
                
                # æ”¶é›†å­˜å‚¨ç±»é…ç½®ä¿¡æ¯
                sc_analysis['class_performance'][sc.metadata.name] = {
                    'provisioner': sc.provisioner,
                    'volume_binding_mode': sc.volume_binding_mode,
                    'allow_volume_expansion': sc.allow_volume_expansion,
                    'reclaim_policy': str(sc.reclaim_policy) if sc.reclaim_policy else 'Delete'
                }
            
            # è¯„ä¼°å­˜å‚¨ç±»é…ç½®
            issues = []
            if not sc_analysis['default_class']:
                issues.append('No default storage class configured')
            
            # æ£€æŸ¥æ€§èƒ½ç›¸å…³çš„å‚æ•°
            for sc_name, config in sc_analysis['class_performance'].items():
                if config['volume_binding_mode'] == 'Immediate':
                    issues.append(f'Storage class {sc_name} uses Immediate binding mode')
            
            sc_analysis['status'] = 'degraded' if issues else 'healthy'
            sc_analysis['issues'] = issues
            
            return sc_analysis
            
        except Exception as e:
            return {'status': 'error', 'error': str(e)}
    
    async def analyze_csi_drivers(self):
        """åˆ†æCSIé©±åŠ¨æ€§èƒ½"""
        try:
            # è·å–CSIé©±åŠ¨ä¿¡æ¯
            csi_drivers = self.storage_v1.list_csi_driver()
            
            driver_analysis = {
                'total_drivers': len(csi_drivers.items),
                'drivers': {}
            }
            
            for driver in csi_drivers.items:
                driver_analysis['drivers'][driver.metadata.name] = {
                    'attach_required': driver.spec.attach_required,
                    'pod_info_on_mount': driver.spec.pod_info_on_mount,
                    'volume_lifecycle_modes': driver.spec.volume_lifecycle_modes,
                    'fs_group_policy': getattr(driver.spec, 'fs_group_policy', 'ReadWriteOnceWithFSType')
                }
            
            # è¯„ä¼°CSIé…ç½®
            issues = []
            for driver_name, config in driver_analysis['drivers'].items():
                if not config['attach_required']:
                    issues.append(f'CSI driver {driver_name} does not require attachment')
            
            driver_analysis['status'] = 'degraded' if issues else 'healthy'
            driver_analysis['issues'] = issues
            
            return driver_analysis
            
        except Exception as e:
            return {'status': 'error', 'error': str(e)}
    
    async def identify_performance_issues(self, metrics):
        """è¯†åˆ«æ€§èƒ½é—®é¢˜"""
        issues = []
        
        # èŠ‚ç‚¹å­˜å‚¨é—®é¢˜
        node_metrics = metrics.get('node_storage', {})
        if node_metrics.get('status') == 'degraded':
            issues.append({
                'component': 'node_storage',
                'type': 'io_performance',
                'severity': 'high',
                'description': 'Node storage I/O performance degradation detected'
            })
        
        # PVCæ€§èƒ½é—®é¢˜
        pvc_metrics = metrics.get('pvc_performance', {})
        if pvc_metrics.get('status') == 'degraded':
            issues.append({
                'component': 'pvc',
                'type': 'capacity_utilization',
                'severity': 'medium',
                'description': 'High PVC capacity utilization detected'
            })
        
        # å­˜å‚¨ç±»é—®é¢˜
        sc_metrics = metrics.get('storage_classes', {})
        if sc_metrics.get('status') == 'degraded':
            issues.append({
                'component': 'storage_class',
                'type': 'configuration',
                'severity': 'medium',
                'description': 'Suboptimal storage class configuration detected'
            })
        
        return issues
    
    async def generate_recommendations(self, issues):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        for issue in issues:
            if issue['component'] == 'node_storage':
                recommendations.append({
                    'priority': 'high',
                    'category': 'storage_performance',
                    'description': 'Optimize node storage I/O performance',
                    'actions': [
                        'Upgrade to faster storage devices',
                        'Optimize filesystem mount options',
                        'Tune kernel I/O parameters',
                        'Implement storage tiering'
                    ]
                })
            
            elif issue['component'] == 'pvc':
                recommendations.append({
                    'priority': 'medium',
                    'category': 'capacity_management',
                    'description': 'Manage PVC capacity utilization',
                    'actions': [
                        'Implement PVC size monitoring',
                        'Set up automatic expansion policies',
                        'Review PVC sizing practices',
                        'Consider storage class optimization'
                    ]
                })
            
            elif issue['component'] == 'storage_class':
                recommendations.append({
                    'priority': 'medium',
                    'category': 'configuration_optimization',
                    'description': 'Optimize storage class configuration',
                    'actions': [
                        'Configure appropriate volume binding modes',
                        'Enable volume expansion where beneficial',
                        'Set optimal reclaim policies',
                        'Review provisioner-specific parameters'
                    ]
                })
        
        return recommendations
    
    # è¾…åŠ©æ–¹æ³•ï¼ˆç®€åŒ–å®ç°ï¼‰
    async def get_node_storage_metrics(self, node_name):
        """è·å–èŠ‚ç‚¹å­˜å‚¨æŒ‡æ ‡"""
        return {
            'node_name': node_name,
            'io_utilization': np.random.uniform(30, 90),
            'read_latency': np.random.uniform(2, 20),
            'write_latency': np.random.uniform(3, 25),
            'iops': np.random.uniform(1000, 8000)
        }
    
    async def get_pvc_metrics(self, pvc):
        """è·å–PVCæŒ‡æ ‡"""
        return {
            'namespace': pvc.metadata.namespace,
            'name': pvc.metadata.name,
            'usage_percentage': np.random.uniform(20, 95),
            'read_iops': np.random.uniform(50, 500),
            'write_iops': np.random.uniform(30, 300),
            'read_latency': np.random.uniform(1, 15),
            'write_latency': np.random.uniform(2, 20)
        }

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    analyzer = StoragePerformanceAnalyzer()
    report = await analyzer.analyze_storage_performance()
    
    print("Storage Performance Analysis Report:")
    print(json.dumps(report, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸš€ å­˜å‚¨ä¼˜åŒ–å®è·µ

### å­˜å‚¨åˆ†å±‚ç­–ç•¥

#### 1. å¤šå±‚å­˜å‚¨é…ç½®
```yaml
# å¤šå±‚å­˜å‚¨ç±»é…ç½®
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: tier-fast
  annotations:
    description: "High-performance tier for critical workloads"
provisioner: ebs.csi.aws.com
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
parameters:
  type: io2
  iopsPerGB: "500"
  encrypted: "true"
  fsType: "xfs"
reclaimPolicy: Delete
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: tier-standard
  annotations:
    description: "Standard performance tier for general workloads"
provisioner: ebs.csi.aws.com
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
parameters:
  type: gp3
  iops: "3000"
  throughput: "125"
  encrypted: "true"
  fsType: "ext4"
reclaimPolicy: Delete
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: tier-archive
  annotations:
    description: "Low-cost tier for archival data"
provisioner: ebs.csi.aws.com
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
parameters:
  type: st1
  encrypted: "true"
  fsType: "ext4"
reclaimPolicy: Delete
```

#### 2. æ™ºèƒ½å­˜å‚¨åˆ†é…
```python
#!/usr/bin/env python3
# æ™ºèƒ½å­˜å‚¨åˆ†é…æ§åˆ¶å™¨

import asyncio
from kubernetes import client, config
from datetime import datetime
import json

class IntelligentStorageAllocator:
    def __init__(self):
        config.load_kube_config()
        self.core_v1 = client.CoreV1Api()
        self.storage_v1 = client.StorageV1Api()
        
        self.storage_tiers = {
            'critical': {
                'storage_class': 'tier-fast',
                'min_iops': 10000,
                'max_latency': 5,  # ms
                'cost_multiplier': 3.0
            },
            'high': {
                'storage_class': 'tier-standard',
                'min_iops': 3000,
                'max_latency': 15,  # ms
                'cost_multiplier': 1.5
            },
            'standard': {
                'storage_class': 'tier-standard',
                'min_iops': 1000,
                'max_latency': 30,  # ms
                'cost_multiplier': 1.0
            },
            'archive': {
                'storage_class': 'tier-archive',
                'min_iops': 100,
                'max_latency': 100,  # ms
                'cost_multiplier': 0.3
            }
        }
    
    async def allocate_storage_intelligently(self, pvc_spec):
        """æ™ºèƒ½åˆ†é…å­˜å‚¨"""
        try:
            # åˆ†æå·¥ä½œè´Ÿè½½ç‰¹å¾
            workload_profile = await self.analyze_workload_characteristics(pvc_spec)
            
            # ç¡®å®šé€‚å½“çš„å­˜å‚¨å±‚çº§
            storage_tier = self.determine_storage_tier(workload_profile)
            
            # ç”Ÿæˆä¼˜åŒ–çš„PVCé…ç½®
            optimized_pvc = self.generate_optimized_pvc(pvc_spec, storage_tier)
            
            # åº”ç”¨å­˜å‚¨é…ç½®
            result = await self.apply_storage_configuration(optimized_pvc)
            
            return {
                'status': 'success',
                'allocated_tier': storage_tier,
                'workload_profile': workload_profile,
                'configuration': optimized_pvc,
                'cost_impact': self.calculate_cost_impact(storage_tier, pvc_spec)
            }
            
        except Exception as e:
            return {
                'status': 'failed',
                'error': str(e)
            }
    
    async def analyze_workload_characteristics(self, pvc_spec):
        """åˆ†æå·¥ä½œè´Ÿè½½ç‰¹å¾"""
        # ä»PVCæ³¨è§£å’Œæ ‡ç­¾ä¸­æå–ä¿¡æ¯
        annotations = pvc_spec.metadata.annotations or {}
        labels = pvc_spec.metadata.labels or {}
        
        # å·¥ä½œè´Ÿè½½ç±»å‹è¯†åˆ«
        workload_type = labels.get('workload-type', 'unknown')
        criticality = labels.get('criticality', 'standard')
        
        # æ€§èƒ½è¦æ±‚åˆ†æ
        performance_reqs = {
            'iops_requirement': int(annotations.get('storage.iops.requirement', '1000')),
            'latency_requirement': int(annotations.get('storage.latency.requirement', '50')),  # ms
            'throughput_requirement': int(annotations.get('storage.throughput.requirement', '100')),  # MB/s
            'availability_requirement': annotations.get('storage.availability.requirement', 'standard')
        }
        
        # æ•°æ®è®¿é—®æ¨¡å¼
        access_modes = [str(mode) for mode in pvc_spec.spec.access_modes]
        access_pattern = 'random' if 'ReadWriteMany' in access_modes else 'sequential'
        
        return {
            'workload_type': workload_type,
            'criticality': criticality,
            'performance_requirements': performance_reqs,
            'access_modes': access_modes,
            'access_pattern': access_pattern,
            'size_gb': self.parse_storage_size(pvc_spec.spec.resources.requests['storage'])
        }
    
    def determine_storage_tier(self, workload_profile):
        """ç¡®å®šå­˜å‚¨å±‚çº§"""
        perf_reqs = workload_profile['performance_requirements']
        criticality = workload_profile['criticality']
        
        # åŸºäºå…³é”®æ€§å’Œæ€§èƒ½è¦æ±‚é€‰æ‹©å±‚çº§
        if criticality == 'critical' or perf_reqs['iops_requirement'] > 5000:
            return 'critical'
        elif perf_reqs['iops_requirement'] > 2000 or perf_reqs['latency_requirement'] < 20:
            return 'high'
        elif perf_reqs['iops_requirement'] > 500:
            return 'standard'
        else:
            return 'archive'
    
    def generate_optimized_pvc(self, pvc_spec, storage_tier):
        """ç”Ÿæˆä¼˜åŒ–çš„PVCé…ç½®"""
        tier_config = self.storage_tiers[storage_tier]
        
        # åˆ›å»ºä¼˜åŒ–çš„PVCå¯¹è±¡
        optimized_pvc = client.V1PersistentVolumeClaim(
            metadata=client.V1ObjectMeta(
                name=pvc_spec.metadata.name,
                namespace=pvc_spec.metadata.namespace,
                annotations={
                    **(pvc_spec.metadata.annotations or {}),
                    'storage.optimized/tier': storage_tier,
                    'storage.optimized/class': tier_config['storage_class'],
                    'storage.optimized/timestamp': datetime.now().isoformat()
                }
            ),
            spec=client.V1PersistentVolumeClaimSpec(
                access_modes=pvc_spec.spec.access_modes,
                resources=client.V1ResourceRequirements(
                    requests={'storage': pvc_spec.spec.resources.requests['storage']}
                ),
                storage_class_name=tier_config['storage_class']
            )
        )
        
        return optimized_pvc
    
    async def apply_storage_configuration(self, pvc_config):
        """åº”ç”¨å­˜å‚¨é…ç½®"""
        try:
            # åˆ›å»ºæˆ–æ›´æ–°PVC
            namespace = pvc_config.metadata.namespace
            
            # æ£€æŸ¥PVCæ˜¯å¦å·²å­˜åœ¨
            try:
                existing_pvc = self.core_v1.read_namespaced_persistent_volume_claim(
                    pvc_config.metadata.name, namespace
                )
                # æ›´æ–°ç°æœ‰PVC
                result = self.core_v1.patch_namespaced_persistent_volume_claim(
                    pvc_config.metadata.name, namespace, pvc_config
                )
            except client.exceptions.ApiException as e:
                if e.status == 404:
                    # åˆ›å»ºæ–°çš„PVC
                    result = self.core_v1.create_namespaced_persistent_volume_claim(
                        namespace, pvc_config
                    )
                else:
                    raise e
            
            return {
                'action': 'created' if e.status == 404 else 'updated',
                'pvc_name': result.metadata.name,
                'namespace': result.metadata.namespace,
                'storage_class': result.spec.storage_class_name
            }
            
        except Exception as e:
            raise Exception(f"Failed to apply storage configuration: {e}")
    
    def calculate_cost_impact(self, storage_tier, original_pvc):
        """è®¡ç®—æˆæœ¬å½±å“"""
        tier_config = self.storage_tiers[storage_tier]
        original_size_gb = self.parse_storage_size(original_pvc.spec.resources.requests['storage'])
        
        # ç®€åŒ–çš„æˆæœ¬è®¡ç®—ï¼ˆå®é™…åº”è¯¥åŸºäºäº‘æä¾›å•†å®šä»·ï¼‰
        base_cost = original_size_gb * 0.10  # $0.10 per GB base rate
        tier_cost = base_cost * tier_config['cost_multiplier']
        
        return {
            'original_cost': base_cost,
            'optimized_cost': tier_cost,
            'savings': base_cost - tier_cost if tier_cost < base_cost else 0,
            'premium': tier_cost - base_cost if tier_cost > base_cost else 0
        }
    
    def parse_storage_size(self, size_str):
        """è§£æå­˜å‚¨å¤§å°"""
        if size_str.endswith('Gi'):
            return int(size_str[:-2])
        elif size_str.endswith('Mi'):
            return int(size_str[:-2]) / 1024
        elif size_str.endswith('Ti'):
            return int(size_str[:-2]) * 1024
        else:
            return int(size_str)

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    allocator = IntelligentStorageAllocator()
    
    # ç¤ºä¾‹PVCé…ç½®
    pvc_spec = client.V1PersistentVolumeClaim(
        metadata=client.V1ObjectMeta(
            name="example-pvc",
            namespace="default",
            labels={
                "workload-type": "database",
                "criticality": "high"
            },
            annotations={
                "storage.iops.requirement": "5000",
                "storage.latency.requirement": "10"
            }
        ),
        spec=client.V1PersistentVolumeClaimSpec(
            access_modes=["ReadWriteOnce"],
            resources=client.V1ResourceRequirements(
                requests={"storage": "100Gi"}
            )
        )
    )
    
    result = await allocator.allocate_storage_intelligently(pvc_spec)
    print("Intelligent Storage Allocation Result:")
    print(json.dumps(result, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ”§ å®æ–½æ£€æŸ¥æ¸…å•

### å­˜å‚¨åŸºç¡€è®¾æ–½ä¼˜åŒ–
- [ ] é€‰æ‹©å’Œé…ç½®é«˜æ€§èƒ½CSIé©±åŠ¨
- [ ] ä¼˜åŒ–æœ¬åœ°å­˜å‚¨è®¾å¤‡å’Œæ–‡ä»¶ç³»ç»Ÿ
- [ ] é…ç½®äº‘å­˜å‚¨æ€§èƒ½å‚æ•°
- [ ] å®æ–½å­˜å‚¨åˆ†å±‚ç­–ç•¥
- [ ] éƒ¨ç½²å­˜å‚¨æ€§èƒ½ç›‘æ§ç³»ç»Ÿ
- [ ] å»ºç«‹å­˜å‚¨å®¹é‡è§„åˆ’æœºåˆ¶

### æ€§èƒ½è°ƒä¼˜å®æ–½
- [ ] åˆ†æç°æœ‰å­˜å‚¨æ€§èƒ½ç“¶é¢ˆ
- [ ] ä¼˜åŒ–å­˜å‚¨I/Oå‚æ•°é…ç½®
- [ ] å®æ–½æ™ºèƒ½å­˜å‚¨åˆ†é…ç­–ç•¥
- [ ] é…ç½®å­˜å‚¨QoSç­–ç•¥
- [ ] ä¼˜åŒ–å­˜å‚¨ç½‘ç»œé…ç½®
- [ ] å®æ–½å­˜å‚¨ç¼“å­˜ç­–ç•¥

### ç›‘æ§å’Œç»´æŠ¤
- [ ] éƒ¨ç½²å­˜å‚¨æ€§èƒ½æŒ‡æ ‡æ”¶é›†
- [ ] å»ºç«‹å­˜å‚¨æ€§èƒ½åŸºçº¿
- [ ] å®æ–½è‡ªåŠ¨åŒ–å­˜å‚¨è¯Šæ–­
- [ ] å®šæœŸè¿›è¡Œå­˜å‚¨æ€§èƒ½è¯„ä¼°
- [ ] ç»´æŠ¤å­˜å‚¨ä¼˜åŒ–æ–‡æ¡£
- [ ] å»ºç«‹å­˜å‚¨æ€§èƒ½æ”¹è¿›æµç¨‹

---

*æœ¬æ–‡æ¡£ä¸ºä¼ä¸šçº§Kuberneteså­˜å‚¨æ€§èƒ½ä¼˜åŒ–æä¾›å®Œæ•´çš„è°ƒä¼˜æ–¹æ¡ˆå’Œå®æ–½æŒ‡å¯¼*