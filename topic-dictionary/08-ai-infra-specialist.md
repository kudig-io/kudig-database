# 08 - AI/MLåŸºç¡€è®¾æ–½ä¸“ä¸šè¯å…¸

> **é€‚ç”¨ç‰ˆæœ¬**: Kubernetes v1.25-v1.32 | **æœ€åæ›´æ–°**: 2026-02 | **ä½œè€…**: Allen Galler | **è´¨é‡ç­‰çº§**: â­â­â­â­â­ ä¸“å®¶çº§

---

## çŸ¥è¯†åœ°å›¾

| å±æ€§ | è¯´æ˜ |
|------|------|
| **æ–‡ä»¶è§’è‰²** | AI/ML åŸºç¡€è®¾æ–½ä¸“ä¸šè¯å…¸ â€” Kubernetes ä¸Šè¿è¡Œ AI å·¥ä½œè´Ÿè½½çš„å®Œæ•´çŸ¥è¯†ä½“ç³» |
| **é€‚åˆè¯»è€…** | MLå·¥ç¨‹å¸ˆå…¥é—¨K8s â†’ å¹³å°å·¥ç¨‹å¸ˆç®¡ç†AIå·¥ä½œè´Ÿè½½ â†’ SREä¼˜åŒ–AIåŸºç¡€è®¾æ–½ |
| **å‰ç½®çŸ¥è¯†** | 05(æ¦‚å¿µå‚è€ƒ)ä¸­çš„K8såŸºç¡€ + åŸºæœ¬MLæ¦‚å¿µ |
| **å…³è”æ–‡ä»¶** | 01(è¿ç»´å®è·µ)ã€03(æ€§èƒ½è°ƒä¼˜)ã€07(å·¥å…·ç”Ÿæ€ä¸­GPU/AIéƒ¨åˆ†) |

### å­¦ä¹ è·¯å¾„

| é˜¶æ®µ | ç« èŠ‚ | ç›®æ ‡ |
|------|------|------|
| **MLå·¥ç¨‹å¸ˆå…¥é—¨** | Â§1 å·¥ä½œè´Ÿè½½ä¼˜åŒ– + Â§5 æ¨¡å‹ç”Ÿå‘½å‘¨æœŸ | ç†è§£å¦‚ä½•åœ¨K8sä¸Šè®­ç»ƒå’Œéƒ¨ç½²æ¨¡å‹ |
| **å¹³å°å·¥ç¨‹å¸ˆ** | Â§2 å¹³å°è¿ç»´ + Â§6 æ¶æ„è®¾è®¡ | æ­å»ºå’Œç»´æŠ¤AIå¹³å°åŸºç¡€è®¾æ–½ |
| **æˆæœ¬ä¸åˆè§„** | Â§3 æˆæœ¬æ²»ç† + Â§4 å®‰å…¨åˆè§„ | ä¼˜åŒ–GPUæˆæœ¬ã€æ»¡è¶³åˆè§„è¦æ±‚ |

---

## ç›®å½•

- [1. AIå·¥ä½œè´Ÿè½½ä¼˜åŒ–](#1-aiå·¥ä½œè´Ÿè½½ä¼˜åŒ–)
- [2. AIå¹³å°è¿ç»´](#2-aiå¹³å°è¿ç»´)
- [3. AIæˆæœ¬æ²»ç†](#3-aiæˆæœ¬æ²»ç†)
- [4. AIå®‰å…¨åˆè§„](#4-aiå®‰å…¨åˆè§„)
- [5. AIæ¨¡å‹ç”Ÿå‘½å‘¨æœŸç®¡ç†](#5-aiæ¨¡å‹ç”Ÿå‘½å‘¨æœŸç®¡ç†)
- [6. AIåŸºç¡€è®¾æ–½æ¶æ„](#6-aiåŸºç¡€è®¾æ–½æ¶æ„)

---

## 1. AIå·¥ä½œè´Ÿè½½ä¼˜åŒ–

> **ğŸ”° åˆå­¦è€…å¯¼è¯»**: æœ¬èŠ‚è®²è§£å¦‚ä½•åœ¨Kubernetesä¸Šé«˜æ•ˆè¿è¡ŒAIè®­ç»ƒå’Œæ¨ç†ä»»åŠ¡,é‡ç‚¹æ˜¯GPUèµ„æºè°ƒåº¦å’Œåˆ†å¸ƒå¼è®¡ç®—çš„ä¼˜åŒ–ç­–ç•¥ã€‚

### 1.1 GPUèµ„æºè°ƒåº¦ä¸“ä¸šæœ¯è¯­

| æœ¯è¯­ | å®šä¹‰ | æŠ€æœ¯è¦ç‚¹ | åº”ç”¨åœºæ™¯ | ç›¸å…³å·¥å…· |
|------|------|----------|----------|----------|
| **GPUæ—¶é—´åˆ‡ç‰‡** | å°†å•ä¸ªGPUè™šæ‹ŸåŒ–ä¸ºå¤šä¸ªé€»è¾‘GPUå®ä¾‹çš„æŠ€æœ¯ | é€šè¿‡è®¾å¤‡æ’ä»¶å®ç°èµ„æºå…±äº«ï¼Œæ”¯æŒå¤šç§Ÿæˆ· | å¼€å‘ç¯å¢ƒã€å°æ¨¡å‹æ¨ç† | NVIDIA Time-Slicing, vGPU |
| **MIGå®ä¾‹** | å¤šå®ä¾‹GPUæŠ€æœ¯ï¼Œå°†ç‰©ç†GPUåˆ‡åˆ†ä¸ºå¤šä¸ªç‹¬ç«‹å®ä¾‹ | A100/H100æ”¯æŒï¼Œç¡¬ä»¶çº§éš”ç¦»ï¼Œæ˜¾å­˜/CUDAæ ¸å¿ƒç‹¬ç«‹ | å¤šç§Ÿæˆ·æ¨ç†ã€æ··åˆå·¥ä½œè´Ÿè½½ | NVIDIA MIG Manager |
| **GPUæ‹“æ‰‘æ„ŸçŸ¥è°ƒåº¦** | è€ƒè™‘GPUé—´NVLink/PCIeæ‹“æ‰‘å…³ç³»çš„è°ƒåº¦ç­–ç•¥ | NUMAäº²å’Œæ€§ã€å¸¦å®½ä¼˜åŒ–ã€å‡å°‘è·¨èŠ‚ç‚¹é€šä¿¡ | åˆ†å¸ƒå¼è®­ç»ƒã€å¤§æ¨¡å‹æ¨ç† | Volcano, Kueue |
| **Gangè°ƒåº¦** | å°†ä¸€ç»„Podä½œä¸ºä¸€ä¸ªæ•´ä½“è¿›è¡Œè°ƒåº¦çš„æœºåˆ¶ | å…¨éƒ¨æˆåŠŸæˆ–å…¨éƒ¨å¤±è´¥ï¼Œé¿å…èµ„æºç¢ç‰‡ | åˆ†å¸ƒå¼è®­ç»ƒã€MPIä½œä¸š | Volcano, Kube-Batch |
| **GPUå…±äº«æ± ** | å¤šä¸ªå·¥ä½œè´Ÿè½½å…±äº«åŒä¸€GPUèµ„æºæ± çš„ç®¡ç†æ–¹å¼ | å†…å­˜éš”ç¦»ã€ç®—åŠ›åˆ†é…ã€ä¼˜å…ˆçº§ç®¡ç† | æ¨ç†æœåŠ¡ã€æ‰¹é‡å¤„ç† | NVIDIA MPS, Run:ai |

> **ğŸ”° åˆå­¦è€…ç†è§£**: GPUè°ƒåº¦å†³å®šäº†AIä»»åŠ¡å¦‚ä½•ä½¿ç”¨æ˜‚è´µçš„GPUèµ„æºã€‚ç±»æ¯”ï¼šå°±åƒåœè½¦åœºç®¡ç†å‘˜åˆ†é…è½¦ä½,éœ€è¦æ ¹æ®è½¦è¾†å¤§å°(ä»»åŠ¡ç±»å‹)ã€åœæ”¾æ—¶é•¿(è®­ç»ƒ/æ¨ç†)ã€æ˜¯å¦æ‹¼è½¦(GPUå…±äº«)æ¥ä¼˜åŒ–åˆ©ç”¨ç‡ã€‚
>
> **ğŸ”§ å·¥ä½œåŸç†**: Kubernetesé»˜è®¤è°ƒåº¦å™¨åªèƒ½åˆ†é…æ•´å¡GPU,æ— æ³•å®ç°ç»†ç²’åº¦å…±äº«ã€‚é€šè¿‡æ‰©å±•è°ƒåº¦å™¨(å¦‚Volcano)å¯ä»¥å®ç°:
> 1. **æ‹“æ‰‘æ„ŸçŸ¥**: è¯†åˆ«GPUä¹‹é—´çš„NVLinkè¿æ¥,å°†åˆ†å¸ƒå¼è®­ç»ƒä»»åŠ¡è°ƒåº¦åˆ°é€šä¿¡æœ€å¿«çš„GPUç»„
> 2. **Gangè°ƒåº¦**: ç¡®ä¿å¤šèŠ‚ç‚¹è®­ç»ƒä»»åŠ¡çš„æ‰€æœ‰PodåŒæ—¶å¯åŠ¨,é¿å…éƒ¨åˆ†Podå ç”¨èµ„æºç­‰å¾…å…¶ä»–Pod
> 3. **èµ„æºå…±äº«**: é€šè¿‡MIGæˆ–æ—¶é—´åˆ‡ç‰‡æŠ€æœ¯å°†å•ä¸ªGPUè™šæ‹ŸåŒ–,ä¾›å¤šä¸ªå°ä»»åŠ¡å¹¶å‘ä½¿ç”¨
>
> **ğŸ“ æœ€å°ç¤ºä¾‹**:
> ```yaml
> apiVersion: v1
> kind: Pod
> metadata:
>   name: gpu-shared-pod
> spec:
>   schedulerName: volcano  # ä½¿ç”¨Volcanoè°ƒåº¦å™¨
>   containers:
>   - name: inference-worker
>     image: pytorch:latest
>     resources:
>       limits:
>         nvidia.com/gpu: 1  # è¯·æ±‚1ä¸ªGPU
>         # é€šè¿‡æ—¶é—´åˆ‡ç‰‡,å®é™…å¯èƒ½å…±äº«ä½¿ç”¨
>   annotations:
>     # æŒ‡å®šGPUæ‹“æ‰‘éœ€æ±‚
>     volcano.sh/gpu-topology: "nvlink"  # è¦æ±‚NVLinkè¿æ¥çš„GPU
> ```
>
> **âš ï¸ å¸¸è§è¯¯åŒº**:
> - âŒ è®¤ä¸ºGPUå¯ä»¥åƒCPUä¸€æ ·æ— é™è¶…åˆ† â†’ âœ… GPUæ˜¾å­˜æ˜¯ç¡¬é™åˆ¶,è¶…åˆ†ä¼šå¯¼è‡´OOM,åªæœ‰ç®—åŠ›å¯ä»¥æ—¶é—´åˆ‡ç‰‡å…±äº«
> - âŒ å°†åˆ†å¸ƒå¼è®­ç»ƒPodåˆ†æ•£åœ¨ä¸åŒå¯ç”¨åŒº â†’ âœ… åº”è°ƒåº¦åˆ°åŒä¸€ç½‘ç»œåŸŸ,å‡å°‘è·¨AZçš„é€šä¿¡å»¶è¿Ÿå’Œæˆæœ¬
> - âŒ ä¸è®¾ç½®Gangè°ƒåº¦å¯¼è‡´è®­ç»ƒä»»åŠ¡æ­»é” â†’ âœ… å¤šèŠ‚ç‚¹è®­ç»ƒå¿…é¡»ä½¿ç”¨Gangè°ƒåº¦,ç¡®ä¿æ‰€æœ‰PodåŒæ—¶å¯åŠ¨æˆ–åŒæ—¶å¤±è´¥

### 1.2 åˆ†å¸ƒå¼è®­ç»ƒä¼˜åŒ–æ¦‚å¿µ

| æ¦‚å¿µ | æ ¸å¿ƒåŸç† | ä¼˜åŒ–ç­–ç•¥ | æ€§èƒ½æŒ‡æ ‡ | å®æ–½å¤æ‚åº¦ |
|------|----------|----------|----------|------------|
| **æ•°æ®å¹¶è¡Œ** | å¤åˆ¶æ¨¡å‹åˆ°å¤šä¸ªè®¾å¤‡ï¼Œæ¯ä¸ªå¤„ç†ä¸åŒæ•°æ®æ‰¹æ¬¡ | AllReduceæ¢¯åº¦åŒæ­¥ã€æ¢¯åº¦å‹ç¼©ã€æ··åˆç²¾åº¦ | é€šä¿¡å¼€é”€ã€æ”¶æ•›é€Ÿåº¦ | â­â­ |
| **æ¨¡å‹å¹¶è¡Œ** | å°†æ¨¡å‹å‚æ•°åˆ†å‰²åˆ°ä¸åŒè®¾å¤‡ä¸Š | æµæ°´çº¿å¹¶è¡Œã€å¼ é‡å¹¶è¡Œã€ä¸“å®¶å¹¶è¡Œ | å†…å­˜å ç”¨ã€è®¡ç®—æ•ˆç‡ | â­â­â­â­ |
| **æµæ°´çº¿å¹¶è¡Œ** | å°†æ¨¡å‹æŒ‰å±‚åˆ†å‰²ï¼Œå½¢æˆè®¡ç®—æµæ°´çº¿ | å¾®æ‰¹æ¬¡ã€æ°”æ³¡æ¶ˆé™¤ã€é‡å è®¡ç®—é€šä¿¡ | ååé‡ã€å»¶è¿Ÿ | â­â­â­ |
| **ZeROä¼˜åŒ–** | é›¶å†—ä½™ä¼˜åŒ–å™¨ï¼Œå‡å°‘å†…å­˜å ç”¨ | ä¼˜åŒ–å™¨çŠ¶æ€åˆ†åŒºã€æ¢¯åº¦åˆ†åŒºã€å‚æ•°åˆ†åŒº | å†…å­˜æ•ˆç‡ã€è®­ç»ƒè§„æ¨¡ | â­â­â­ |
| **æ··åˆå¹¶è¡Œ** | ç»„åˆå¤šç§å¹¶è¡Œç­–ç•¥çš„å¤åˆæ–¹æ¡ˆ | æ•°æ®+æ¨¡å‹+æµæ°´çº¿å¹¶è¡ŒååŒ | æœ€å¤§åŒ–èµ„æºåˆ©ç”¨ç‡ | â­â­â­â­â­ |

> **ğŸ”° åˆå­¦è€…ç†è§£**: åˆ†å¸ƒå¼è®­ç»ƒæ˜¯è®©å¤šä¸ªGPUåä½œè®­ç»ƒå¤§æ¨¡å‹çš„æŠ€æœ¯ã€‚ç±»æ¯”ï¼šåƒå¤šäººåä½œæ‹¼ä¸€å¹…å·¨å¤§çš„æ‹¼å›¾,å¯ä»¥æ¯äººæ‹¼ä¸åŒåŒºåŸŸ(æ•°æ®å¹¶è¡Œ),æˆ–è€…æ‹¼å›¾å¤ªå¤§æ¯äººåªèƒ½çœ‹ä¸€éƒ¨åˆ†(æ¨¡å‹å¹¶è¡Œ)ã€‚
>
> **ğŸ”§ å·¥ä½œåŸç†**: 
> 1. **æ•°æ®å¹¶è¡Œ**: æ¯ä¸ªGPUæ‹¥æœ‰å®Œæ•´æ¨¡å‹å‰¯æœ¬,å¤„ç†ä¸åŒæ•°æ®æ‰¹æ¬¡,è®­ç»ƒååŒæ­¥æ¢¯åº¦(AllReduce)ã€‚é€‚åˆæ¨¡å‹è¾ƒå°ä½†æ•°æ®é‡å¤§çš„åœºæ™¯
> 2. **æ¨¡å‹å¹¶è¡Œ**: å•ä¸ªGPUè£…ä¸ä¸‹å®Œæ•´æ¨¡å‹æ—¶,å°†æ¨¡å‹åˆ‡åˆ†åˆ°å¤šä¸ªGPUã€‚ä¾‹å¦‚GPT-3æœ‰1750äº¿å‚æ•°,éœ€è¦æ¨¡å‹å¹¶è¡Œæ‰èƒ½è®­ç»ƒ
> 3. **æµæ°´çº¿å¹¶è¡Œ**: å°†æ¨¡å‹æŒ‰å±‚åˆ‡åˆ†,å‰å‡ å±‚åœ¨GPU1è®¡ç®—,åå‡ å±‚åœ¨GPU2è®¡ç®—,åƒå·¥å‚æµæ°´çº¿ä¸€æ ·æé«˜ååé‡
> 4. **æ··åˆå¹¶è¡Œ**: å¤§æ¨¡å‹è®­ç»ƒç»¼åˆä½¿ç”¨å¤šç§ç­–ç•¥,ä¾‹å¦‚8èŠ‚ç‚¹64å¡è®­ç»ƒå¯ä»¥ç”¨"èŠ‚ç‚¹å†…æ•°æ®å¹¶è¡Œ+èŠ‚ç‚¹é—´æ¨¡å‹å¹¶è¡Œ"
>
> **ğŸ“ æœ€å°ç¤ºä¾‹**:
> ```yaml
> apiVersion: kubeflow.org/v1
> kind: PyTorchJob
> metadata:
>   name: distributed-training
> spec:
>   pytorchReplicaSpecs:
>     Master:  # ä¸»èŠ‚ç‚¹
>       replicas: 1
>       template:
>         spec:
>           containers:
>           - name: pytorch
>             image: pytorch/pytorch:2.0
>             command: ["torchrun"]
>             args:
>             - "--nproc_per_node=8"  # æ¯èŠ‚ç‚¹8ä¸ªGPU
>             - "--nnodes=4"          # æ€»å…±4ä¸ªèŠ‚ç‚¹
>             - "train.py"
>             - "--strategy=ddp"      # æ•°æ®å¹¶è¡Œç­–ç•¥
>             resources:
>               limits:
>                 nvidia.com/gpu: 8  # è¯·æ±‚8å¡
>     Worker:  # å·¥ä½œèŠ‚ç‚¹
>       replicas: 3  # 3ä¸ªworkerèŠ‚ç‚¹
>       template:
>         spec:
>           containers:
>           - name: pytorch
>             image: pytorch/pytorch:2.0
>             resources:
>               limits:
>                 nvidia.com/gpu: 8
> ```
>
> **âš ï¸ å¸¸è§è¯¯åŒº**:
> - âŒ è®¤ä¸ºå¢åŠ GPUæ•°é‡å°±èƒ½çº¿æ€§åŠ é€Ÿè®­ç»ƒ â†’ âœ… é€šä¿¡å¼€é”€ä¼šæŠµæ¶ˆéƒ¨åˆ†æ”¶ç›Š,éœ€è¦ä¼˜åŒ–é€šä¿¡æ‹“æ‰‘å’ŒåŒæ­¥ç­–ç•¥
> - âŒ ç›²ç›®ä½¿ç”¨æ¨¡å‹å¹¶è¡Œå¯¼è‡´GPUåˆ©ç”¨ç‡ä½ â†’ âœ… èƒ½ç”¨æ•°æ®å¹¶è¡Œå°±ç”¨æ•°æ®å¹¶è¡Œ,æ¨¡å‹å¹¶è¡Œæœ‰æ›´å¤šç©ºé—²ç­‰å¾…æ—¶é—´
> - âŒ å¿½ç•¥æ¢¯åº¦ç´¯ç§¯å¯¼è‡´æ”¶æ•›æ•ˆæœå·® â†’ âœ… åˆ†å¸ƒå¼è®­ç»ƒæ—¶è¦è°ƒæ•´å­¦ä¹ ç‡å’Œæ‰¹æ¬¡å¤§å°,ä¿æŒæœ‰æ•ˆæ‰¹æ¬¡å¤§å°ä¸å˜

### 1.3 æ¨¡å‹æ¨ç†ä¼˜åŒ–æŠ€æœ¯

| æŠ€æœ¯ | ä¼˜åŒ–åŸç† | é€‚ç”¨åœºæ™¯ | æ€§èƒ½æå‡ | å®æ–½éš¾åº¦ |
|------|----------|----------|----------|----------|
| **æ¨¡å‹é‡åŒ–** | å°†FP32æƒé‡è½¬æ¢ä¸ºINT8/FP16ç­‰ä½ç²¾åº¦æ ¼å¼ | æ¨ç†åŠ é€Ÿã€å†…å­˜ä¼˜åŒ– | 2-4å€æ€§èƒ½æå‡ | â­â­ |
| **çŸ¥è¯†è’¸é¦** | ç”¨å¤§æ¨¡å‹æŒ‡å¯¼å°æ¨¡å‹è®­ç»ƒ | æ¨¡å‹å‹ç¼©ã€ç§»åŠ¨ç«¯éƒ¨ç½² | 30-50%ç²¾åº¦ä¿æŒ | â­â­â­ |
| **æ¨¡å‹å‰ªæ** | ç§»é™¤ä¸é‡è¦çš„ç¥ç»ç½‘ç»œè¿æ¥ | æ¨¡å‹ç˜¦èº«ã€è¾¹ç¼˜éƒ¨ç½² | 50-90%å‚æ•°å‡å°‘ | â­â­â­ |
| **åŠ¨æ€æ‰¹å¤„ç†** | è¿è¡Œæ—¶åˆå¹¶å¤šä¸ªæ¨ç†è¯·æ±‚ | æé«˜GPUåˆ©ç”¨ç‡ã€é™ä½å»¶è¿Ÿ | 2-5å€ååé‡æå‡ | â­â­ |
| **è¿ç»­æ‰¹å¤„ç†** | ä¿æŒæ¨¡å‹æŒç»­å¤„ç†è¯·æ±‚æµ | å‡å°‘å†·å¯åŠ¨ã€æé«˜æ•ˆç‡ | 30-70%å»¶è¿Ÿé™ä½ | â­â­â­ |

---

## 2. AIå¹³å°è¿ç»´

> **ğŸ”° åˆå­¦è€…å¯¼è¯»**: æœ¬èŠ‚ä»‹ç»å¦‚ä½•è¿ç»´ä¼ä¸šçº§AIå¹³å°,åŒ…æ‹¬Kubeflowç­‰MLå¹³å°çš„éƒ¨ç½²ç®¡ç†ã€æ¨¡å‹æ³¨å†Œä¸­å¿ƒå’Œæ¨ç†æœåŠ¡çš„è¿ç»´å®è·µã€‚

### 2.1 Kubeflowå¹³å°ç»„ä»¶

| ç»„ä»¶ | åŠŸèƒ½æè¿° | è¿ç»´è¦ç‚¹ | ç›‘æ§æŒ‡æ ‡ | æ•…éšœå¤„ç† |
|------|----------|----------|----------|----------|
| **KF Pipelines** | MLå·¥ä½œæµç¼–æ’å¼•æ“ | å·¥ä½œæµçŠ¶æ€ç›‘æ§ã€èµ„æºé…é¢ç®¡ç† | DAGæ‰§è¡ŒæˆåŠŸç‡ã€æ­¥éª¤å»¶è¿Ÿ | é‡è¯•æœºåˆ¶ã€èµ„æºæ‰©å®¹ |
| **Katib** | è¶…å‚æ•°è‡ªåŠ¨ä¼˜åŒ–å¹³å° | è¯•éªŒç®¡ç†ã€ç®—æ³•è°ƒä¼˜ | è¯•éªŒå®Œæˆç‡ã€æœ€ä¼˜å‚æ•°æ”¶æ•› | ç®—æ³•åˆ‡æ¢ã€èµ„æºè°ƒæ•´ |
| **Training Operator** | åˆ†å¸ƒå¼è®­ç»ƒä½œä¸šç®¡ç† | ä½œä¸šè°ƒåº¦ã€GPUèµ„æºåˆ†é… | è®­ç»ƒæˆåŠŸç‡ã€GPUåˆ©ç”¨ç‡ | Gangè°ƒåº¦ã€èŠ‚ç‚¹ä¿®å¤ |
| **Model Serving** | æ¨¡å‹éƒ¨ç½²å’ŒæœåŠ¡åŒ– | ç‰ˆæœ¬ç®¡ç†ã€æµé‡åˆ†æµ | QPSã€å»¶è¿Ÿã€é”™è¯¯ç‡ | è‡ªåŠ¨æ‰©ç¼©å®¹ã€è“ç»¿éƒ¨ç½² |
| **VOLUMES** | å­˜å‚¨ç®¡ç†ç³»ç»Ÿ | PVCç®¡ç†ã€å¤‡ä»½æ¢å¤ | å­˜å‚¨ä½¿ç”¨ç‡ã€IOPSæ€§èƒ½ | å­˜å‚¨æ‰©å®¹ã€å¿«ç…§æ¢å¤ |

> **ğŸ”° åˆå­¦è€…ç†è§£**: AIå¹³å°æ¶æ„æ˜¯æ”¯æ’‘æœºå™¨å­¦ä¹ å…¨æµç¨‹çš„åŸºç¡€è®¾æ–½ã€‚ç±»æ¯”ï¼šå°±åƒæ±½è½¦åˆ¶é€ å·¥å‚çš„æµæ°´çº¿,ä»åŸææ–™(æ•°æ®)è¿›å…¥,ç»è¿‡å„ä¸ªå·¥åº(è®­ç»ƒã€è¯„ä¼°ã€éƒ¨ç½²),æœ€ç»ˆäº§å‡ºæˆå“(æ¨ç†æœåŠ¡)ã€‚
>
> **ğŸ”§ å·¥ä½œåŸç†**: Kubeflowæ˜¯æ„å»ºåœ¨Kubernetesä¸Šçš„MLå¹³å°,æ ¸å¿ƒç»„ä»¶åŒ…æ‹¬:
> 1. **Pipelines**: å°†MLå·¥ä½œæµå®šä¹‰ä¸ºDAG(æœ‰å‘æ— ç¯å›¾),æ¯ä¸ªæ­¥éª¤æ˜¯ä¸€ä¸ªå®¹å™¨,è‡ªåŠ¨å¤„ç†ä¾èµ–å’Œæ•°æ®ä¼ é€’
> 2. **Training Operator**: æä¾›PyTorchJobã€TFJobç­‰CRD,ç®€åŒ–åˆ†å¸ƒå¼è®­ç»ƒé…ç½®,è‡ªåŠ¨ç®¡ç†å‚æ•°æœåŠ¡å™¨å’ŒworkerèŠ‚ç‚¹
> 3. **Katib**: è‡ªåŠ¨å°è¯•ä¸åŒè¶…å‚æ•°ç»„åˆ,ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–ç­‰ç®—æ³•æ‰¾åˆ°æœ€ä¼˜é…ç½®,ç±»ä¼¼AutoML
> 4. **KServe**: æä¾›ç»Ÿä¸€çš„æ¨¡å‹æœåŠ¡æ¥å£,æ”¯æŒè‡ªåŠ¨æ‰©ç¼©å®¹ã€é‡‘ä¸é›€å‘å¸ƒã€æµé‡åˆ†å‰²ç­‰é«˜çº§åŠŸèƒ½
>
> **ğŸ“ æœ€å°ç¤ºä¾‹**:
> ```yaml
> apiVersion: kubeflow.org/v1
> kind: Notebook
> metadata:
>   name: ml-workspace
>   namespace: kubeflow-user
> spec:
>   template:
>     spec:
>       containers:
>       - name: jupyter
>         image: jupyter/tensorflow-notebook:latest
>         resources:
>           limits:
>             nvidia.com/gpu: 1  # ä¸ºJupyteråˆ†é…1ä¸ªGPU
>         volumeMounts:
>         - name: workspace
>           mountPath: /home/jovyan/work  # æŒä¹…åŒ–å·¥ä½œç›®å½•
>       volumes:
>       - name: workspace
>         persistentVolumeClaim:
>           claimName: ml-workspace-pvc  # ä½¿ç”¨PVCæŒä¹…åŒ–æ•°æ®
> ---
> # Pipelineç¤ºä¾‹ - ç®€å•çš„è®­ç»ƒéƒ¨ç½²æµç¨‹
> apiVersion: argoproj.io/v1alpha1
> kind: Workflow
> metadata:
>   generateName: ml-pipeline-
> spec:
>   entrypoint: ml-workflow
>   templates:
>   - name: ml-workflow
>     dag:
>       tasks:
>       - name: data-prep
>         template: prepare-data
>       - name: train-model
>         dependencies: [data-prep]  # ä¾èµ–æ•°æ®å‡†å¤‡å®Œæˆ
>         template: training
>       - name: deploy
>         dependencies: [train-model]  # ä¾èµ–è®­ç»ƒå®Œæˆ
>         template: deployment
> ```
>
> **âš ï¸ å¸¸è§è¯¯åŒº**:
> - âŒ å°†Kubeflowä½œä¸ºå•ä½“åº”ç”¨éƒ¨ç½²å¯¼è‡´ç»„ä»¶è€¦åˆ â†’ âœ… æ ¹æ®éœ€æ±‚é€‰æ‹©æ€§å®‰è£…ç»„ä»¶,ä¾‹å¦‚åªç”¨Pipelinesè€Œä¸è£…Katib
> - âŒ æœªåšèµ„æºé…é¢é™åˆ¶å¯¼è‡´æŸä¸ªå®éªŒå æ»¡é›†ç¾¤ â†’ âœ… ä½¿ç”¨ResourceQuotaå’ŒLimitRangeé™åˆ¶å‘½åç©ºé—´èµ„æºä¸Šé™
> - âŒ Pipelineæ­¥éª¤é—´ç”¨å…±äº«æ–‡ä»¶ç³»ç»Ÿä¼ é€’å¤§é‡æ•°æ® â†’ âœ… ä¼˜å…ˆç”¨å¯¹è±¡å­˜å‚¨(S3/MinIO)ä¼ é€’æ•°æ®è·¯å¾„,å‡å°‘IOç“¶é¢ˆ

### 2.2 æ¨¡å‹æ³¨å†Œä¸­å¿ƒæ¦‚å¿µ

| æ¦‚å¿µ | å®šä¹‰ | æ ¸å¿ƒåŠŸèƒ½ | æŠ€æœ¯å®ç° | è¿ç»´è€ƒè™‘ |
|------|------|----------|----------|----------|
| **Model Versioning** | æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ | ç‰ˆæœ¬è¿½è¸ªã€å›æ»šèƒ½åŠ›ã€åˆ†æ”¯ç®¡ç† | Git + MLflow/MLeap | å­˜å‚¨ç®¡ç†ã€æƒé™æ§åˆ¶ |
| **Model Metadata** | æ¨¡å‹å…ƒæ•°æ®ç®¡ç† | è®­ç»ƒå‚æ•°ã€æ€§èƒ½æŒ‡æ ‡ã€è¡€ç¼˜å…³ç³» | æ•°æ®åº“ + å¯¹è±¡å­˜å‚¨ | æ•°æ®ä¸€è‡´æ€§ã€æŸ¥è¯¢æ€§èƒ½ |
| **Model Lineage** | æ¨¡å‹è¡€ç¼˜è¿½è¸ª | æ•°æ®->ç‰¹å¾->æ¨¡å‹->éƒ¨ç½²å…¨é“¾è·¯ | å›¾æ•°æ®åº“ + äº‹ä»¶æº¯æº | æ€§èƒ½ä¼˜åŒ–ã€å­˜å‚¨ç­–ç•¥ |
| **Model Governance** | æ¨¡å‹æ²»ç†æ¡†æ¶ | åˆè§„æ£€æŸ¥ã€è´¨é‡è¯„ä¼°ã€å®¡æ‰¹æµç¨‹ | ç­–ç•¥å¼•æ“ + å·¥ä½œæµ | è‡ªåŠ¨åŒ–ç¨‹åº¦ã€äººå·¥å¹²é¢„ |
| **Model Catalog** | æ¨¡å‹ç›®å½•æœåŠ¡ | å‘ç°ã€è¯„ä¼°ã€æ¯”è¾ƒä¸åŒæ¨¡å‹ | æœç´¢å¼•æ“ + è¯„ä»·ç³»ç»Ÿ | ç´¢å¼•ç»´æŠ¤ã€ç”¨æˆ·ä½“éªŒ |

### 2.3 æ¨ç†æœåŠ¡å¹³å°

| æœåŠ¡ç±»å‹ | æŠ€æœ¯ç‰¹ç‚¹ | éƒ¨ç½²æ¨¡å¼ | æ€§èƒ½ç‰¹å¾ | è¿ç»´å¤æ‚åº¦ |
|----------|----------|----------|----------|------------|
| **vLLM** | PagedAttentionå†…å­˜ä¼˜åŒ–ã€è¿ç»­æ‰¹å¤„ç† | Deployment/StatefulSet | é«˜ååã€ä½å»¶è¿Ÿ | â­â­â­ |
| **TGI** | Transformerä¼˜åŒ–ã€å¤šæ¨¡å‹æ”¯æŒ | Deployment | é€šç”¨æ€§å¼ºã€æ˜“é›†æˆ | â­â­ |
| **TensorRT-LLM** | NVIDIAä¼˜åŒ–ã€é«˜æ€§èƒ½æ¨ç† | DaemonSet | æè‡´æ€§èƒ½ã€ç¡¬ä»¶ç»‘å®š | â­â­â­â­ |
| **Seldon Core** | å¤šæ¡†æ¶æ”¯æŒã€ABæµ‹è¯• | Operator | çµæ´»æ€§é«˜ã€åŠŸèƒ½ä¸°å¯Œ | â­â­â­â­ |
| **KServe** | KubernetesåŸç”Ÿã€Serverless | Knative | è‡ªåŠ¨æ‰©ç¼©ã€æˆæœ¬ä¼˜åŒ– | â­â­â­ |

> **ğŸ”° åˆå­¦è€…ç†è§£**: GPUé›†ç¾¤è¿ç»´æ˜¯ç®¡ç†æ•°ç™¾å¼ GPUå¡ç»„æˆçš„è®¡ç®—èµ„æºæ± ã€‚ç±»æ¯”ï¼šåƒç®¡ç†ä¸€ä¸ªæ•°æ®ä¸­å¿ƒçš„GPUå†œåœº,éœ€è¦ç›‘æ§æ¯å¼ å¡çš„å¥åº·çŠ¶æ€ã€ä¼˜åŒ–æ•£çƒ­ã€å¤„ç†ç¡¬ä»¶æ•…éšœã€è°ƒåº¦ä»»åŠ¡åˆ°æœ€åˆé€‚çš„GPUã€‚
>
> **ğŸ”§ å·¥ä½œåŸç†**: GPUé›†ç¾¤è¿ç»´æ¶‰åŠå¤šä¸ªå±‚é¢:
> 1. **ç¡¬ä»¶ç›‘æ§**: ä½¿ç”¨NVIDIA DCGMé‡‡é›†GPUæ¸©åº¦ã€åŠŸè€—ã€æ˜¾å­˜ä½¿ç”¨ç‡ã€ECCé”™è¯¯ç­‰æŒ‡æ ‡,é€šè¿‡Prometheuså‘Šè­¦
> 2. **é©±åŠ¨ç®¡ç†**: ç»Ÿä¸€ç®¡ç†NVIDIAé©±åŠ¨ç‰ˆæœ¬,ä½¿ç”¨DaemonSetéƒ¨ç½²GPU Operatorè‡ªåŠ¨åŒ–é©±åŠ¨å®‰è£…å’Œæ›´æ–°
> 3. **ä»»åŠ¡è°ƒåº¦**: é…ç½®GPUäº²å’Œæ€§ã€ç‹¬å æ¨¡å¼ã€å…±äº«ç­–ç•¥,é¿å…ä»»åŠ¡é—´ç›¸äº’å¹²æ‰°,ä½¿ç”¨æ±¡ç‚¹å’Œå®¹å¿åº¦éš”ç¦»ä¸åŒå·¥ä½œè´Ÿè½½
> 4. **æ•…éšœæ¢å¤**: GPUæ•…éšœæ—¶è‡ªåŠ¨é©±é€Podåˆ°å¥åº·èŠ‚ç‚¹,ä½¿ç”¨Node Problem Detectoræ£€æµ‹ç¡¬ä»¶å¼‚å¸¸å¹¶æ ‡è®°èŠ‚ç‚¹
>
> **ğŸ“ æœ€å°ç¤ºä¾‹**:
> ```yaml
> # GPUèŠ‚ç‚¹å¥åº·æ£€æŸ¥DaemonSet
> apiVersion: apps/v1
> kind: DaemonSet
> metadata:
>   name: gpu-healthcheck
>   namespace: kube-system
> spec:
>   selector:
>     matchLabels:
>       app: gpu-healthcheck
>   template:
>     metadata:
>       labels:
>         app: gpu-healthcheck
>     spec:
>       nodeSelector:
>         accelerator: nvidia-gpu  # ä»…åœ¨GPUèŠ‚ç‚¹è¿è¡Œ
>       hostNetwork: true
>       containers:
>       - name: dcgm-exporter
>         image: nvcr.io/nvidia/k8s/dcgm-exporter:3.1.0
>         securityContext:
>           capabilities:
>             add: ["SYS_ADMIN"]  # è®¿é—®GPUè®¾å¤‡éœ€è¦ç‰¹æƒ
>         volumeMounts:
>         - name: gpu-metrics
>           mountPath: /run/prometheus  # æš´éœ²PrometheusæŒ‡æ ‡
>       volumes:
>       - name: gpu-metrics
>         hostPath:
>           path: /run/prometheus
> ---
> # GPUæ•…éšœè‡ªåŠ¨é©±é€é…ç½®
> apiVersion: v1
> kind: ConfigMap
> metadata:
>   name: node-problem-detector-config
> data:
>   gpu-problem.json: |
>     {
>       "plugin": "custom",
>       "rules": [
>         {
>           "type": "temporary",
>           "reason": "GPUMemoryError",
>           "pattern": "Xid.*: GPU has fallen off the bus"
>         },
>         {
>           "type": "permanent",
>           "reason": "GPUHardwareFailure", 
>           "pattern": "GPU.*has fallen off the bus"
>         }
>       ]
>     }
> ```
>
> **âš ï¸ å¸¸è§è¯¯åŒº**:
> - âŒ å¿½ç•¥ECCé”™è¯¯å¯¼è‡´è®­ç»ƒç»“æœä¸å¯é  â†’ âœ… å®šæœŸæ£€æŸ¥DCGMçš„ECCé”™è¯¯è®¡æ•°,è¶…è¿‡é˜ˆå€¼ç«‹å³ä¸‹çº¿GPUè¿›è¡ŒRMA
> - âŒ æœªé…ç½®GPUç‹¬å æ¨¡å¼å¯¼è‡´æ¨ç†å»¶è¿ŸæŠ–åŠ¨ â†’ âœ… ç”Ÿäº§æ¨ç†æœåŠ¡ä½¿ç”¨`nvidia.com/gpu.deploy.mode: "exclusive"`ç¡®ä¿ç‹¬å 
> - âŒ GPUé©±åŠ¨ç‰ˆæœ¬ä¸ä¸€è‡´å¯¼è‡´CUDAå…¼å®¹æ€§é—®é¢˜ â†’ âœ… ä½¿ç”¨GPU Operatorç»Ÿä¸€ç®¡ç†é©±åŠ¨,é€šè¿‡æ ‡ç­¾æ§åˆ¶ä¸åŒé©±åŠ¨ç‰ˆæœ¬çš„èŠ‚ç‚¹æ± 

---

## 3. AIæˆæœ¬æ²»ç†

> **ğŸ”° åˆå­¦è€…å¯¼è¯»**: æœ¬èŠ‚è®²è§£å¦‚ä½•æ§åˆ¶AIåŸºç¡€è®¾æ–½æˆæœ¬,é‡ç‚¹æ˜¯GPUèµ„æºåˆ©ç”¨ç‡ä¼˜åŒ–ã€Spotå®ä¾‹ä½¿ç”¨å’Œæˆæœ¬ç›‘æ§åˆ†ææ–¹æ³•ã€‚

### 3.1 GPUèµ„æºæˆæœ¬ä¼˜åŒ–

| ä¼˜åŒ–ç­–ç•¥ | å®æ–½æ–¹æ³• | æˆæœ¬èŠ‚çº¦æ½œåŠ› | æŠ€æœ¯å¤æ‚åº¦ | é£é™©ç­‰çº§ |
|----------|----------|--------------|------------|----------|
| **Spotå®ä¾‹åˆ©ç”¨** | æ··åˆä½¿ç”¨æŒ‰éœ€å’Œç«ä»·å®ä¾‹ | 50-80%æˆæœ¬èŠ‚çº¦ | â­â­ | ä¸­ç­‰ |
| **è‡ªåŠ¨æ‰©ç¼©å®¹** | åŸºäºè´Ÿè½½åŠ¨æ€è°ƒæ•´GPUèŠ‚ç‚¹ | 30-60%èµ„æºèŠ‚çº¦ | â­â­â­ | ä½ |
| **èµ„æºå…±äº«** | å¤šä»»åŠ¡å…±äº«GPUèµ„æºæ±  | 40-70%åˆ©ç”¨ç‡æå‡ | â­â­â­â­ | ä¸­ç­‰ |
| **æ—¶æ®µè°ƒåº¦** | éé«˜å³°æ—¶æ®µæ‰§è¡Œè®­ç»ƒä»»åŠ¡ | 20-40%æˆæœ¬ä¼˜åŒ– | â­â­ | ä½ |
| **æ¨¡å‹å‹ç¼©** | é‡åŒ–ã€è’¸é¦å‡å°‘è®¡ç®—éœ€æ±‚ | 30-50%ç¡¬ä»¶éœ€æ±‚é™ä½ | â­â­â­ | ä½ |

> **ğŸ”° åˆå­¦è€…ç†è§£**: GPUèµ„æºåˆ©ç”¨ç‡ä¼˜åŒ–æ˜¯æé«˜æ˜‚è´µGPUè®¾å¤‡ä½¿ç”¨æ•ˆç‡çš„å…³é”®ã€‚ç±»æ¯”ï¼šåƒåˆç§Ÿå…¬å¯“æœ€å¤§åŒ–åˆ©ç”¨ç©ºé—´,é€šè¿‡æ—¶é—´é”™å³°(ç™½å¤©åŠå…¬æ™šä¸Šç¡è§‰)ã€ç©ºé—´å…±äº«(å…±ç”¨å¨æˆ¿å®¢å…)ã€çµæ´»è°ƒé…(å®¢äººæ¥äº†åŠ åºŠä½)æ¥é™ä½äººå‡æˆæœ¬ã€‚
>
> **ğŸ”§ å·¥ä½œåŸç†**: GPUåˆ©ç”¨ç‡ä¼˜åŒ–çš„æ ¸å¿ƒç­–ç•¥åŒ…æ‹¬:
> 1. **æ—¶é—´ç»´åº¦å…±äº«**: ä½¿ç”¨GPUæ—¶é—´åˆ‡ç‰‡æŠ€æœ¯,è®©å¤šä¸ªæ¨ç†ä»»åŠ¡è½®æµä½¿ç”¨åŒä¸€GPU,ç±»ä¼¼CPUçš„æ—¶é—´ç‰‡è°ƒåº¦
> 2. **ç©ºé—´ç»´åº¦å…±äº«**: é€šè¿‡MIGå°†A100åˆ‡åˆ†ä¸º7ä¸ªå®ä¾‹,æ¯ä¸ªå®ä¾‹æœ‰ç‹¬ç«‹æ˜¾å­˜å’Œè®¡ç®—æ ¸å¿ƒ,é€‚åˆå°æ¨¡å‹æ¨ç†
> 3. **åŠ¨æ€æ‰©ç¼©å®¹**: ç›‘æ§GPUé˜Ÿåˆ—é•¿åº¦,æ— ä»»åŠ¡æ—¶ç¼©å®¹åˆ°0,æœ‰ä»»åŠ¡æ—¶è‡ªåŠ¨æ‰©å®¹,ä½¿ç”¨Karpenteræˆ–Cluster Autoscalerå®ç°
> 4. **èµ„æºæ± åŒ–**: å»ºç«‹å…±äº«GPUæ± ,ä¸åŒå›¢é˜ŸæŒ‰éœ€ç”³è¯·,é¿å…ç‹¬å æµªè´¹,é€šè¿‡èµ„æºé…é¢é™åˆ¶ä½¿ç”¨ä¸Šé™
>
> **ğŸ“ æœ€å°ç¤ºä¾‹**:
> ```yaml
> # GPUèµ„æºé…é¢ - é™åˆ¶å‘½åç©ºé—´GPUä½¿ç”¨é‡
> apiVersion: v1
> kind: ResourceQuota
> metadata:
>   name: gpu-quota
>   namespace: ml-team-a
> spec:
>   hard:
>     requests.nvidia.com/gpu: "10"  # æœ€å¤šç”³è¯·10ä¸ªGPU
>     limits.nvidia.com/gpu: "10"
> ---
> # GPUæ—¶é—´åˆ‡ç‰‡é…ç½® - å°†1ä¸ªç‰©ç†GPUè™šæ‹Ÿæˆ4ä¸ªé€»è¾‘GPU
> apiVersion: v1
> kind: ConfigMap
> metadata:
>   name: time-slicing-config
>   namespace: gpu-operator
> data:
>   any: |-
>     version: v1
>     sharing:
>       timeSlicing:
>         replicas: 4  # 1ä¸ªGPUåˆ†æˆ4ä»½
>         renameByDefault: true
> ---
> # ä½ä¼˜å…ˆçº§è®­ç»ƒä»»åŠ¡ - ä½¿ç”¨Spotå®ä¾‹
> apiVersion: batch/v1
> kind: Job
> metadata:
>   name: model-training-spot
> spec:
>   template:
>     spec:
>       priorityClassName: low-priority  # ä½ä¼˜å…ˆçº§å¯è¢«æŠ¢å 
>       nodeSelector:
>         karpenter.sh/capacity-type: spot  # é€‰æ‹©SpotèŠ‚ç‚¹
>       tolerations:
>       - key: nvidia.com/gpu
>         operator: Exists
>         effect: NoSchedule
>       containers:
>       - name: trainer
>         image: pytorch:latest
>         resources:
>           limits:
>             nvidia.com/gpu: 1
>         # è®­ç»ƒæ”¯æŒcheckpointæ–­ç‚¹ç»­è®­
>         env:
>         - name: CHECKPOINT_DIR
>           value: "/mnt/checkpoints"  # Spotä¸­æ–­æ—¶å¯æ¢å¤
> ```
>
> **âš ï¸ å¸¸è§è¯¯åŒº**:
> - âŒ è¿‡åº¦æ—¶é—´åˆ‡ç‰‡å¯¼è‡´ä»»åŠ¡ç›¸äº’å¹²æ‰° â†’ âœ… æ—¶é—´åˆ‡ç‰‡é€‚åˆæ¨ç†,è®­ç»ƒä»»åŠ¡åº”ç‹¬å GPUé¿å…æ€§èƒ½æ³¢åŠ¨
> - âŒ å°†æœ‰çŠ¶æ€è®­ç»ƒä»»åŠ¡ç›´æ¥è·‘åœ¨Spotä¸Š â†’ âœ… Spotä»»åŠ¡å¿…é¡»æ”¯æŒcheckpoint,èƒ½åœ¨ä¸­æ–­åä»æ–­ç‚¹æ¢å¤
> - âŒ æœªç›‘æ§åˆ©ç”¨ç‡å°±ç›²ç›®å…±äº«GPU â†’ âœ… å…ˆç”¨DCGMåˆ†æåˆ©ç”¨ç‡,ç¡®è®¤æœ‰é—²ç½®æ—¶æ®µå†å¯ç”¨å…±äº«ç­–ç•¥

### 3.2 æˆæœ¬ç›‘æ§ä¸åˆ†æ

| ç›‘æ§ç»´åº¦ | å…³é”®æŒ‡æ ‡ | åˆ†ææ–¹æ³• | å·¥å…·æ”¯æŒ | å®æ–½å»ºè®® |
|----------|----------|----------|----------|----------|
| **GPUåˆ©ç”¨ç‡** | å¹³å‡ä½¿ç”¨ç‡ã€å³°å€¼åˆ©ç”¨ç‡ | è¶‹åŠ¿åˆ†æã€å¼‚å¸¸æ£€æµ‹ | DCGM + Prometheus | è®¾ç½®å‘Šè­¦é˜ˆå€¼ |
| **è®­ç»ƒæˆæœ¬** | æ¯æ¬¡è®­ç»ƒæˆæœ¬ã€å•ä½ç²¾åº¦æˆæœ¬ | æˆæœ¬å½’å› ã€ROIåˆ†æ | Kubecost + MLflow | å»ºç«‹æˆæœ¬åŸºçº¿ |
| **æ¨ç†æˆæœ¬** | æ¯ä¸‡æ¬¡æ¨ç†æˆæœ¬ã€QPSæˆæœ¬æ•ˆç‡ | æ€§ä»·æ¯”åˆ†æã€å®¹é‡è§„åˆ’ | è‡ªå®šä¹‰ä»ªè¡¨æ¿ | ä¼˜åŒ–å®ä¾‹è§„æ ¼ |
| **å­˜å‚¨æˆæœ¬** | æ•°æ®é›†ã€æ¨¡å‹ã€æ—¥å¿—å­˜å‚¨è´¹ç”¨ | ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€å†·çƒ­åˆ†ç¦» | å¯¹è±¡å­˜å‚¨åˆ†çº§ | å®šæœŸæ¸…ç†ç­–ç•¥ |
| **äººåŠ›æˆæœ¬** | è¿ç»´æŠ•å…¥ã€å¼€å‘æ•ˆç‡ | æ—¶é—´è¿½è¸ªã€è‡ªåŠ¨åŒ–ç‡ | å†…éƒ¨å·¥æ—¶ç»Ÿè®¡ | æµç¨‹ä¼˜åŒ–å»ºè®® |

> **ğŸ”° åˆå­¦è€…ç†è§£**: Spotå®ä¾‹æ˜¯äº‘å‚å•†çš„é—²ç½®èµ„æºç‰¹ä»·å‡ºå”®,ä»·æ ¼ä¾¿å®œä½†éšæ—¶å¯èƒ½è¢«å›æ”¶ã€‚ç±»æ¯”ï¼šåƒèˆªç©ºå…¬å¸çš„ç‰¹ä»·æœºç¥¨,æœ€åä¸€åˆ»æ‰æ”¾å‡ºæ¥,ä»·æ ¼åªè¦æ­£ä»·çš„2-3æŠ˜,ä½†å¯èƒ½ä¸´æ—¶å–æ¶ˆèˆªç­,é€‚åˆæ—¶é—´çµæ´»çš„æ—…å®¢ã€‚
>
> **ğŸ”§ å·¥ä½œåŸç†**: Spotå®ä¾‹åœ¨AIè®­ç»ƒä¸­çš„åº”ç”¨ç­–ç•¥:
> 1. **ä¸­æ–­å®¹å¿**: äº‘å‚å•†èµ„æºç´§å¼ æ—¶ä¼šæå‰2åˆ†é’Ÿé€šçŸ¥å›æ”¶Spotå®ä¾‹,åº”ç”¨éœ€è¦ä¼˜é›…å…³é—­å¹¶ä¿å­˜checkpoint
> 2. **æ··åˆéƒ¨ç½²**: å…³é”®ç»„ä»¶(å‚æ•°æœåŠ¡å™¨)ç”¨æŒ‰éœ€å®ä¾‹ä¿è¯ç¨³å®š,workerèŠ‚ç‚¹ç”¨Spotå®ä¾‹é™ä½æˆæœ¬
> 3. **å¤šå®ä¾‹ç±»å‹**: é…ç½®å¤šç§GPUå‹å·(V100/A10/T4)çš„Spotæ± ,æŸä¸ªå‹å·ç¼ºè´§æ—¶è‡ªåŠ¨åˆ‡æ¢
> 4. **è‡ªåŠ¨é‡è¯•**: Spotä¸­æ–­åKubernetesä¼šè‡ªåŠ¨åœ¨å…¶ä»–èŠ‚ç‚¹é‡æ–°è°ƒåº¦Pod,ä»checkpointæ¢å¤è®­ç»ƒ
>
> **ğŸ“ æœ€å°ç¤ºä¾‹**:
> ```yaml
> # Karpenteré…ç½® - è‡ªåŠ¨é€‰æ‹©æœ€ä¾¿å®œçš„Spotå®ä¾‹
> apiVersion: karpenter.sh/v1alpha5
> kind: Provisioner
> metadata:
>   name: spot-gpu-provisioner
> spec:
>   requirements:
>   - key: karpenter.sh/capacity-type
>     operator: In
>     values: ["spot"]  # ä¼˜å…ˆä½¿ç”¨Spot
>   - key: node.kubernetes.io/instance-type
>     operator: In
>     values:  # å¤šç§GPUå®ä¾‹ç±»å‹
>     - "g4dn.xlarge"   # T4 GPU
>     - "g5.xlarge"     # A10G GPU  
>     - "p3.2xlarge"    # V100 GPU
>   limits:
>     resources:
>       nvidia.com/gpu: "100"  # æœ€å¤š100ä¸ªGPU
>   providerRef:
>     name: spot-provider
>   # Spotä¸­æ–­å¤„ç†
>   ttlSecondsAfterEmpty: 30  # ç©ºé—²30ç§’åå›æ”¶èŠ‚ç‚¹
>   ttlSecondsUntilExpired: 604800  # 7å¤©åå¼ºåˆ¶è½®æ¢
> ---
> # è®­ç»ƒä»»åŠ¡é…ç½® - æ”¯æŒSpotä¸­æ–­æ¢å¤
> apiVersion: batch/v1
> kind: Job
> metadata:
>   name: resilient-training
> spec:
>   backoffLimit: 10  # å…è®¸å¤±è´¥é‡è¯•10æ¬¡
>   template:
>     spec:
>       restartPolicy: OnFailure
>       containers:
>       - name: trainer
>         image: pytorch:latest
>         command: ["python", "train.py"]
>         args:
>         - "--checkpoint-dir=/mnt/checkpoints"
>         - "--resume-from-latest"  # è‡ªåŠ¨ä»æœ€æ–°checkpointæ¢å¤
>         volumeMounts:
>         - name: checkpoint-storage
>           mountPath: /mnt/checkpoints
>       volumes:
>       - name: checkpoint-storage
>         persistentVolumeClaim:
>           claimName: training-checkpoints  # æŒä¹…åŒ–å­˜å‚¨checkpoint
>       # å¤„ç†Spotä¸­æ–­ä¿¡å·
>       terminationGracePeriodSeconds: 120  # ç»™120ç§’ä¿å­˜checkpoint
> ```
>
> **âš ï¸ å¸¸è§è¯¯åŒº**:
> - âŒ ä¸ä¿å­˜checkpointå¯¼è‡´Spotä¸­æ–­åä»å¤´è®­ç»ƒ â†’ âœ… å¿…é¡»å®šæœŸä¿å­˜checkpoint,å»ºè®®æ¯Nä¸ªepochæˆ–æ¯Måˆ†é’Ÿä¿å­˜ä¸€æ¬¡
> - âŒ åªé…ç½®å•ä¸€å®ä¾‹ç±»å‹å¯¼è‡´ç»å¸¸ç¼ºè´§ â†’ âœ… é…ç½®3-5ç§åŒæ€§èƒ½æ¡£ä½çš„å®ä¾‹ç±»å‹,å¢åŠ Spotå¯ç”¨æ€§
> - âŒ å…³é”®åœ¨çº¿æœåŠ¡ä½¿ç”¨Spotå¯¼è‡´é¢‘ç¹ä¸­æ–­ â†’ âœ… Spotä»…ç”¨äºç¦»çº¿è®­ç»ƒ,æ¨ç†æœåŠ¡å¿…é¡»ç”¨æŒ‰éœ€æˆ–é¢„ç•™å®ä¾‹

### 3.3 æˆæœ¬ä¼˜åŒ–æœ€ä½³å®è·µ

```yaml
# ========== GPUæˆæœ¬ä¼˜åŒ–é…ç½®æ¨¡æ¿ ==========
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cost-optimized-llm-service
  namespace: ai-inference
spec:
  replicas: 3
  template:
    spec:
      # æ··åˆå®ä¾‹ç­–ç•¥
      nodeSelector:
        node.kubernetes.io/instance-type: g4dn.xlarge  # æŒ‰éœ€å®ä¾‹
      tolerations:
      - key: spot-instance
        operator: Equal
        value: "true"
        effect: NoSchedule
        
      containers:
      - name: inference-server
        image: vllm/vllm-openai:v0.4.2
        resources:
          requests:
            # ç²¾ç¡®çš„èµ„æºè¯·æ±‚ï¼Œé¿å…è¿‡åº¦åˆ†é…
            cpu: "2"
            memory: "8Gi"
            nvidia.com/gpu: "1"
          limits:
            # åˆç†çš„èµ„æºä¸Šé™
            cpu: "4"
            memory: "16Gi"
            nvidia.com/gpu: "1"
            
        # æˆæœ¬ä¼˜åŒ–å‚æ•°
        env:
        - name: VLLM_GPU_MEMORY_UTILIZATION
          value: "0.85"  # ä¼˜åŒ–GPUå†…å­˜ä½¿ç”¨ç‡
        - name: VLLM_MAX_NUM_BATCHED_TOKENS
          value: "4096"  # æ§åˆ¶æ‰¹å¤„ç†å¤§å°
        - name: VLLM_DTYPE
          value: "float16"  # ä½¿ç”¨åŠç²¾åº¦é™ä½å†…å­˜éœ€æ±‚
          
        # è‡ªåŠ¨æ‰©ç¼©å®¹é…ç½®
        startupProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 10
          
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          periodSeconds: 30
          
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          periodSeconds: 10

---
# ========== æˆæœ¬ç›‘æ§é…ç½® ==========
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: ai-cost-monitoring
  namespace: monitoring
spec:
  groups:
  - name: gpu.cost.rules
    rules:
    # GPUåˆ©ç”¨ç‡å‘Šè­¦
    - alert: LowGPUUtilization
      expr: |
        avg(rate(DCGM_FI_DEV_GPU_UTIL[5m])) < 30
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "GPUåˆ©ç”¨ç‡è¿‡ä½ ({{ $value }}%)"
        description: "æ£€æµ‹åˆ°GPUèµ„æºæµªè´¹ï¼Œå»ºè®®ä¼˜åŒ–èµ„æºé…ç½®"
        
    # è®­ç»ƒæˆæœ¬å¼‚å¸¸
    - alert: HighTrainingCost
      expr: |
        increase(kube_pod_container_resource_requests{resource="nvidia_com_gpu"}[1h]) * 
        avg_over_time(gpu_hourly_cost[1h]) > 100
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "å•æ¬¡è®­ç»ƒæˆæœ¬è¿‡é«˜"
        description: "å½“å‰è®­ç»ƒä»»åŠ¡é¢„è®¡æˆæœ¬è¶…è¿‡é˜ˆå€¼ï¼Œè¯·æ£€æŸ¥èµ„æºé…ç½®"
        
    # æ¨ç†æ€§ä»·æ¯”ä¸‹é™
    - alert: PoorInferenceCostEffectiveness
      expr: |
        rate(http_requests_total[5m]) / 
        avg(rate(DCGM_FI_DEV_GPU_UTIL[5m])) < 10
      for: 15m
      labels:
        severity: info
      annotations:
        summary: "æ¨ç†æ€§ä»·æ¯”ä¸‹é™"
        description: "å•ä½GPUåˆ©ç”¨ç‡äº§ç”Ÿçš„è¯·æ±‚æ•°åä½ï¼Œå»ºè®®ä¼˜åŒ–æ¨¡å‹æˆ–æ‰©å®¹"
```

---

## 4. AIå®‰å…¨åˆè§„

> **ğŸ”° åˆå­¦è€…å¯¼è¯»**: æœ¬èŠ‚ä»‹ç»AIç³»ç»Ÿçš„å®‰å…¨å¨èƒå’Œé˜²æŠ¤æªæ–½,åŒ…æ‹¬æ¨¡å‹å®‰å…¨ã€æ•°æ®éšç§ä¿æŠ¤å’Œåˆè§„å®¡è®¡æ¡†æ¶ã€‚

### 4.1 æ¨¡å‹å®‰å…¨æ¦‚å¿µ

| å®‰å…¨ç»´åº¦ | å¨èƒç±»å‹ | é˜²æŠ¤æªæ–½ | æ£€æµ‹æ–¹æ³• | åˆè§„è¦æ±‚ |
|----------|----------|----------|----------|----------|
| **æ¨¡å‹æŠ•æ¯’** | è®­ç»ƒæ•°æ®æ¶æ„æ±¡æŸ“ | æ•°æ®æ¸…æ´—ã€å¼‚å¸¸æ£€æµ‹ | ç»Ÿè®¡åˆ†æã€å¯¹æŠ—æ ·æœ¬æ£€æµ‹ | ISO/IEC 27001 |
| **å¯¹æŠ—æ”»å‡»** | è¾“å…¥æ‰°åŠ¨æ¬ºéª—æ¨¡å‹ | å¯¹æŠ—è®­ç»ƒã€è¾“å…¥éªŒè¯ | é»‘ç›’æµ‹è¯•ã€é²æ£’æ€§è¯„ä¼° | NIST AIé£é™©ç®¡ç†æ¡†æ¶ |
| **æ¨¡å‹çªƒå–** | é€šè¿‡APIé€†å‘å·¥ç¨‹ | æŸ¥è¯¢é™åˆ¶ã€æ°´å°åµŒå…¥ | è¡Œä¸ºåˆ†æã€è®¿é—®æ¨¡å¼æ£€æµ‹ | GDPRæ•°æ®ä¿æŠ¤ |
| **éšç§æ³„éœ²** | æ¨¡å‹è®°å¿†è®­ç»ƒæ•°æ® | å·®åˆ†éšç§ã€è”é‚¦å­¦ä¹  | æˆå‘˜æ¨ç†æ”»å‡»æ£€æµ‹ | CCPAæ¶ˆè´¹è€…éšç§ |
| **åé—¨æ”»å‡»** | æ¤å…¥éšè—è§¦å‘å™¨ | è§¦å‘å™¨æ£€æµ‹ã€æ¨¡å‹éªŒè¯ | è¾“å…¥è¾“å‡ºåˆ†æã€æ¿€æ´»æ¨¡å¼æ£€æŸ¥ | ç­‰ä¿2.0ä¸‰çº§ |

> **ğŸ”° åˆå­¦è€…ç†è§£**: æ¨¡å‹å®‰å…¨æ˜¯ä¿æŠ¤AIæ¨¡å‹ä¸è¢«æ”»å‡»æˆ–çªƒå–çš„æŠ€æœ¯ã€‚ç±»æ¯”ï¼šå°±åƒä¿æŠ¤çŸ¥è¯†äº§æƒå’Œå•†ä¸šç§˜å¯†,é˜²æ­¢ç«äº‰å¯¹æ‰‹é€šè¿‡é€†å‘å·¥ç¨‹å¤åˆ¶ä½ çš„æŠ€æœ¯(æ¨¡å‹çªƒå–),æˆ–è€…åœ¨äº§å“ä¸­æ¤å…¥ç¼ºé™·(åé—¨æ”»å‡»)ã€‚
>
> **ğŸ”§ å·¥ä½œåŸç†**: AIæ¨¡å‹é¢ä¸´çš„ä¸»è¦å®‰å…¨å¨èƒåŒ…æ‹¬:
> 1. **æ¨¡å‹çªƒå–**: æ”»å‡»è€…é€šè¿‡å¤§é‡æŸ¥è¯¢æ¨ç†API,æ”¶é›†è¾“å…¥è¾“å‡ºå¯¹,è®­ç»ƒå‡ºåŠŸèƒ½ç›¸ä¼¼çš„æ¨¡å‹ã€‚é˜²æŠ¤æ–¹æ³•æ˜¯é™åˆ¶æŸ¥è¯¢é¢‘ç‡ã€æ·»åŠ éšæœºå™ªå£°ã€æ£€æµ‹å¼‚å¸¸æŸ¥è¯¢æ¨¡å¼
> 2. **å¯¹æŠ—æ”»å‡»**: åœ¨è¾“å…¥æ•°æ®ä¸­æ·»åŠ äººçœ¼ä¸å¯è§çš„å¾®å°æ‰°åŠ¨,å¯¼è‡´æ¨¡å‹é”™è¯¯åˆ†ç±»ã€‚ä¾‹å¦‚åœ¨åœè½¦æ ‡å¿—è´´ä¸Šç‰¹æ®Šè´´çº¸è®©è‡ªåŠ¨é©¾é©¶è¯†åˆ«ä¸ºé™é€Ÿæ ‡å¿—
> 3. **åé—¨æ”»å‡»**: åœ¨è®­ç»ƒé˜¶æ®µæ¤å…¥éšè—è§„åˆ™,å¹³æ—¶æ­£å¸¸å·¥ä½œ,é‡åˆ°ç‰¹å®šè§¦å‘å™¨(å¦‚ç‰¹å®šåƒç´ æ¨¡å¼)å°±è¾“å‡ºé”™è¯¯ç»“æœ
> 4. **éšç§æ³„éœ²**: æ¨¡å‹å¯èƒ½è®°å¿†è®­ç»ƒæ•°æ®,æ”»å‡»è€…é€šè¿‡æˆå‘˜æ¨ç†æ”»å‡»åˆ¤æ–­æŸä¸ªæ ·æœ¬æ˜¯å¦åœ¨è®­ç»ƒé›†ä¸­,æ³„éœ²æ•æ„Ÿä¿¡æ¯
>
> **ğŸ“ æœ€å°ç¤ºä¾‹**:
> ```yaml
> # æ¨ç†æœåŠ¡å®‰å…¨åŠ å›ºé…ç½®
> apiVersion: serving.kserve.io/v1beta1
> kind: InferenceService
> metadata:
>   name: secure-model-serving
> spec:
>   predictor:
>     containers:
>     - name: model-server
>       image: my-secure-model:v1
>       env:
>       # å¯ç”¨æ¨¡å‹åŠ å¯†
>       - name: MODEL_ENCRYPTION
>         value: "true"
>       # é™åˆ¶è¯·æ±‚é¢‘ç‡
>       - name: RATE_LIMIT_PER_IP
>         value: "100"  # æ¯IPæ¯åˆ†é’Ÿæœ€å¤š100æ¬¡è¯·æ±‚
>       # æ·»åŠ è¾“å‡ºå™ªå£°é˜²æ­¢æ¨¡å‹çªƒå–
>       - name: OUTPUT_NOISE_LEVEL
>         value: "0.01"
>       securityContext:
>         runAsNonRoot: true
>         readOnlyRootFilesystem: true  # åªè¯»æ–‡ä»¶ç³»ç»Ÿ
>         capabilities:
>           drop: ["ALL"]  # ç¦ç”¨æ‰€æœ‰Linux capabilities
>   # é…ç½®è®¿é—®æ§åˆ¶
>   transformer:
>     containers:
>     - name: input-validator
>       image: input-validator:v1
>       # æ£€æµ‹å¯¹æŠ—æ ·æœ¬
>       args:
>       - "--detect-adversarial"
>       - "--max-perturbation=0.01"
> ---
> # æ¨¡å‹è®¿é—®å®¡è®¡ç­–ç•¥
> apiVersion: audit.k8s.io/v1
> kind: Policy
> rules:
> - level: RequestResponse
>   verbs: ["create", "update", "patch"]
>   resources:
>   - group: "serving.kserve.io"
>     resources: ["inferenceservices"]
>   # è®°å½•æ‰€æœ‰æ¨¡å‹éƒ¨ç½²æ“ä½œ
>   namespaces: ["production"]
> ```
>
> **âš ï¸ å¸¸è§è¯¯åŒº**:
> - âŒ è®¤ä¸ºæ¨¡å‹éƒ¨ç½²åœ¨å†…ç½‘å°±å®‰å…¨ â†’ âœ… å†…éƒ¨å‘˜å·¥ä¹Ÿå¯èƒ½çªƒå–æ¨¡å‹,éœ€è¦è®¿é—®æ§åˆ¶å’Œå®¡è®¡æ—¥å¿—
> - âŒ å¿½ç•¥æ¨¡å‹è¾“å‡ºä¸­çš„æ•æ„Ÿä¿¡æ¯æ³„éœ² â†’ âœ… å¤§æ¨¡å‹å¯èƒ½è®°å¿†è®­ç»ƒæ•°æ®,éœ€è¦è¿‡æ»¤è¾“å‡ºé˜²æ­¢æ³„éœ²ä¸ªäººä¿¡æ¯
> - âŒ æœªå¯¹æ¨ç†APIåšé€Ÿç‡é™åˆ¶ â†’ âœ… æ”»å‡»è€…å¯èƒ½é€šè¿‡æš´åŠ›æŸ¥è¯¢çªƒå–æ¨¡å‹,å¿…é¡»é™åˆ¶è¯·æ±‚é¢‘ç‡

### 4.2 æ•°æ®éšç§ä¿æŠ¤

| ä¿æŠ¤æŠ€æœ¯ | æŠ€æœ¯åŸç† | é€‚ç”¨åœºæ™¯ | æ€§èƒ½å½±å“ | å®æ–½å¤æ‚åº¦ |
|----------|----------|----------|----------|------------|
| **å·®åˆ†éšç§** | æ·»åŠ æ•°å­¦å™ªå£°ä¿æŠ¤ä¸ªä½“éšç§ | è”é‚¦å­¦ä¹ ã€ç»Ÿè®¡åˆ†æ | 5-15%ç²¾åº¦æŸå¤± | â­â­â­â­ |
| **è”é‚¦å­¦ä¹ ** | æ•°æ®ä¸å‡ºæœ¬åœ°ï¼Œæ¨¡å‹èšåˆ | å¤šæ–¹åä½œè®­ç»ƒ | é€šä¿¡å¼€é”€è¾ƒå¤§ | â­â­â­â­â­ |
| **åŒæ€åŠ å¯†** | å¯†æ–‡çŠ¶æ€ä¸‹ç›´æ¥è®¡ç®— | æ•æ„Ÿæ•°æ®å¤„ç† | æ€§èƒ½æŸå¤±å·¨å¤§ | â­â­â­â­â­ |
| **å®‰å…¨å¤šæ–¹è®¡ç®—** | å¤šæ–¹å…±åŒè®¡ç®—ä¸æ³„éœ²è¾“å…¥ | è”åˆå»ºæ¨¡ | è®¡ç®—å¤æ‚åº¦é«˜ | â­â­â­â­â­ |
| **å¯ä¿¡æ‰§è¡Œç¯å¢ƒ** | ç¡¬ä»¶çº§å®‰å…¨éš”ç¦» | æ•æ„Ÿæ¨ç†æœåŠ¡ | è½»å¾®æ€§èƒ½å½±å“ | â­â­â­ |

> **ğŸ”° åˆå­¦è€…ç†è§£**: æ•°æ®å®‰å…¨æ˜¯ä¿æŠ¤AIè®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­çš„æ•æ„Ÿæ•°æ®ä¸è¢«æ³„éœ²ã€‚ç±»æ¯”ï¼šå°±åƒé“¶è¡Œé‡‘åº“çš„å¤šå±‚é˜²æŠ¤,éœ€è¦ç‰©ç†éš”ç¦»(åŠ å¯†)ã€è®¿é—®æ§åˆ¶(æƒé™ç®¡ç†)ã€å®¡è®¡è¿½è¸ª(æ—¥å¿—è®°å½•)æ¥ä¿æŠ¤å®¢æˆ·èµ„äº§ã€‚
>
> **ğŸ”§ å·¥ä½œåŸç†**: Kubernetesç¯å¢ƒä¸‹çš„AIæ•°æ®å®‰å…¨ç­–ç•¥:
> 1. **é™æ€åŠ å¯†**: ä½¿ç”¨KMS(å¯†é’¥ç®¡ç†æœåŠ¡)åŠ å¯†å­˜å‚¨åœ¨PVä¸­çš„è®­ç»ƒæ•°æ®å’Œæ¨¡å‹æ–‡ä»¶,SecretåŠ å¯†å­˜å‚¨APIå¯†é’¥
> 2. **ä¼ è¾“åŠ å¯†**: æ‰€æœ‰æ•°æ®ä¼ è¾“ä½¿ç”¨TLS/mTLS,åŒ…æ‹¬èŠ‚ç‚¹é—´çš„æ¢¯åº¦åŒæ­¥ã€å®¢æˆ·ç«¯åˆ°æ¨ç†æœåŠ¡çš„è¯·æ±‚
> 3. **è®¿é—®æ§åˆ¶**: ä½¿ç”¨RBACé™åˆ¶Podå¯¹æ•æ„Ÿæ•°æ®çš„è®¿é—®,NetworkPolicyéš”ç¦»ä¸åŒå®‰å…¨åŸŸçš„å·¥ä½œè´Ÿè½½
> 4. **æ•°æ®è„±æ•**: è®­ç»ƒå‰å¯¹æ•æ„Ÿå­—æ®µ(å§“åã€èº«ä»½è¯å·)è¿›è¡Œè„±æ•å¤„ç†,ä½¿ç”¨å·®åˆ†éšç§æŠ€æœ¯ä¿æŠ¤ä¸ªä½“éšç§
>
> **ğŸ“ æœ€å°ç¤ºä¾‹**:
> ```yaml
> # ä½¿ç”¨SecretsåŠ å¯†å­˜å‚¨æ•æ„Ÿé…ç½®
> apiVersion: v1
> kind: Secret
> metadata:
>   name: model-secrets
> type: Opaque
> data:
>   # Base64ç¼–ç çš„æ•æ„Ÿä¿¡æ¯
>   api-key: bXktc2VjcmV0LWFwaS1rZXk=
>   database-password: cGFzc3dvcmQxMjM=
> ---
> # è®­ç»ƒä»»åŠ¡é…ç½® - æ•°æ®åŠ å¯†å’Œè®¿é—®æ§åˆ¶
> apiVersion: batch/v1
> kind: Job
> metadata:
>   name: secure-training
> spec:
>   template:
>     spec:
>       serviceAccountName: ml-trainer  # ä¸“ç”¨æœåŠ¡è´¦å·
>       securityContext:
>         fsGroup: 1000  # æ–‡ä»¶æƒé™ç»„
>         runAsNonRoot: true
>         runAsUser: 1000
>       containers:
>       - name: trainer
>         image: secure-trainer:v1
>         env:
>         # ä»Secretæ³¨å…¥æ•æ„Ÿé…ç½®
>         - name: API_KEY
>           valueFrom:
>             secretKeyRef:
>               name: model-secrets
>               key: api-key
>         volumeMounts:
>         - name: encrypted-data
>           mountPath: /data
>           readOnly: true  # åªè¯»æŒ‚è½½é˜²æ­¢ç¯¡æ”¹
>       volumes:
>       - name: encrypted-data
>         persistentVolumeClaim:
>           claimName: encrypted-training-data
> ---
> # NetworkPolicy - éš”ç¦»æ•æ„Ÿå·¥ä½œè´Ÿè½½
> apiVersion: networking.k8s.io/v1
> kind: NetworkPolicy
> metadata:
>   name: isolate-sensitive-ml
> spec:
>   podSelector:
>     matchLabels:
>       security: high  # é«˜æ•æ„Ÿåº¦æ ‡ç­¾
>   policyTypes:
>   - Ingress
>   - Egress
>   ingress:
>   - from:
>     - podSelector:
>         matchLabels:
>           role: ml-admin  # ä»…å…è®¸ç®¡ç†å‘˜è®¿é—®
>   egress:
>   - to:
>     - podSelector:
>         matchLabels:
>           app: model-registry  # ä»…å…è®¸è®¿é—®æ¨¡å‹ä»“åº“
> ```
>
> **âš ï¸ å¸¸è§è¯¯åŒº**:
> - âŒ å°†APIå¯†é’¥ç¡¬ç¼–ç åœ¨ä»£ç æˆ–ConfigMapä¸­ â†’ âœ… å¿…é¡»ä½¿ç”¨Secretå­˜å‚¨æ•æ„Ÿä¿¡æ¯,å¹¶å¯ç”¨etcdåŠ å¯†
> - âŒ æœªå¯¹è®­ç»ƒæ•°æ®åšè®¿é—®æ§åˆ¶ â†’ âœ… ä½¿ç”¨RBACå’ŒPVçš„accessModesé™åˆ¶æ•°æ®è®¿é—®æƒé™
> - âŒ è·¨ç¯å¢ƒå…±äº«åŒä¸€å¥—å¯†é’¥ â†’ âœ… å¼€å‘/æµ‹è¯•/ç”Ÿäº§ç¯å¢ƒå¿…é¡»ä½¿ç”¨ä¸åŒçš„å¯†é’¥,å®šæœŸè½®æ¢

### 4.3 åˆè§„å®¡è®¡æ¡†æ¶

```yaml
# ========== AIåˆè§„å®¡è®¡ç­–ç•¥ ==========
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: ai-model-compliance
spec:
  validationFailureAction: audit  # å®¡è®¡æ¨¡å¼ï¼Œä¸é˜»æ–­éƒ¨ç½²
  background: true
  rules:
  # æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶æ£€æŸ¥
  - name: model-version-tracking
    match:
      any:
      - resources:
          kinds:
          - Deployment
          selector:
            matchLabels:
              app-type: ml-model
    validate:
      message: "AIæ¨¡å‹éƒ¨ç½²å¿…é¡»åŒ…å«ç‰ˆæœ¬æ ‡ç­¾å’Œè®­ç»ƒæ•°æ®æ¥æºä¿¡æ¯"
      pattern:
        metadata:
          labels:
            model.version: "?*"
            training.data.source: "?*"
            compliance.level: "restricted|baseline"
            
  # GPUèµ„æºä½¿ç”¨åˆè§„æ£€æŸ¥
  - name: gpu-resource-compliance
    match:
      any:
      - resources:
          kinds:
          - Pod
    validate:
      message: "GPUèµ„æºä½¿ç”¨éœ€è¦æ˜ç¡®ä¸šåŠ¡ç”¨é€”å’Œæˆæœ¬å½’å±"
      pattern:
        spec:
          containers:
          - resources:
              limits:
                nvidia.com/gpu: "?*"
            env:
            - name: BUSINESS_PURPOSE
              value: "?*"
            - name: COST_CENTER
              value: "?*"
              
  # æ¨¡å‹å®‰å…¨æ‰«æ
  - name: model-security-scan
    match:
      any:
      - resources:
          kinds:
          - Job
          selector:
            matchLabels:
              job-type: model-training
    validate:
      message: "æ¨¡å‹è®­ç»ƒä»»åŠ¡å¿…é¡»åŒ…å«å®‰å…¨æ‰«ææ­¥éª¤"
      foreach:
      - list: "request.object.spec.template.spec.initContainers"
        deny:
          conditions:
            any:
            - key: "{{ element.name }}"
              operator: NotEquals
              value: "security-scan"
              
---
# ========== åˆè§„ç›‘æ§ä»ªè¡¨æ¿é…ç½® ==========
apiVersion: grafana.integreatly.org/v1beta1
kind: GrafanaDashboard
metadata:
  name: ai-compliance-dashboard
  namespace: monitoring
spec:
  json: |
    {
      "dashboard": {
        "title": "AIåˆè§„ç›‘æ§ä»ªè¡¨æ¿",
        "panels": [
          {
            "title": "æ¨¡å‹åˆè§„çŠ¶æ€",
            "type": "stat",
            "targets": [
              {
                "expr": "count(kube_pod_labels{label_app_type=\"ml-model\",label_compliance_level=\"restricted\"})",
                "legendFormat": "å—é™æ¨¡å‹æ•°é‡"
              },
              {
                "expr": "count(kube_pod_labels{label_app_type=\"ml-model\",label_training_data_source=~\".*pii.*\"})",
                "legendFormat": "å¤„ç†PIIæ•°æ®æ¨¡å‹"
              }
            ]
          },
          {
            "title": "GPUåˆè§„ä½¿ç”¨ç‡",
            "type": "graph",
            "targets": [
              {
                "expr": "sum by(pod) (DCGM_FI_DEV_GPU_UTIL * on(pod) group_left(label_business_purpose) kube_pod_labels{label_app_type=\"ml-model\"})",
                "legendFormat": "{{pod}} - {{label_business_purpose}}"
              }
            ]
          },
          {
            "title": "åˆè§„è¿è§„äº‹ä»¶",
            "type": "table",
            "targets": [
              {
                "expr": "kyverno_policy_results_total{rule_result=\"fail\",policy_name=~\"ai-model-compliance.*\"}",
                "format": "table"
              }
            ]
          }
        ]
      }
    }
```

---

## 5. AIæ¨¡å‹ç”Ÿå‘½å‘¨æœŸç®¡ç†

> **ğŸ”° åˆå­¦è€…å¯¼è¯»**: æœ¬èŠ‚è®²è§£MLOpsæµç¨‹,ä»æ¨¡å‹è®­ç»ƒã€è¯„ä¼°ã€éƒ¨ç½²åˆ°ç›‘æ§çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†,ä»¥åŠæ¨¡å‹ç‰ˆæœ¬æ§åˆ¶å’Œæ²»ç†ç­–ç•¥ã€‚

### 5.1 MLOpsæµæ°´çº¿é˜¶æ®µ

| é˜¶æ®µ | æ ¸å¿ƒæ´»åŠ¨ | å…³é”®æŒ‡æ ‡ | è‡ªåŠ¨åŒ–ç¨‹åº¦ | è´¨é‡é—¨ç¦ |
|------|----------|----------|------------|----------|
| **æ•°æ®å‡†å¤‡** | æ•°æ®æ”¶é›†ã€æ¸…æ´—ã€æ ‡æ³¨ | æ•°æ®è´¨é‡åˆ†æ•°ã€æ ‡æ³¨å‡†ç¡®ç‡ | 70% | æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ |
| **ç‰¹å¾å·¥ç¨‹** | ç‰¹å¾æå–ã€é€‰æ‹©ã€è½¬æ¢ | ç‰¹å¾é‡è¦æ€§ã€ç›¸å…³æ€§åˆ†æ | 80% | ç‰¹å¾ç¨³å®šæ€§éªŒè¯ |
| **æ¨¡å‹è®­ç»ƒ** | è¶…å‚æ•°è°ƒä¼˜ã€åˆ†å¸ƒå¼è®­ç»ƒ | éªŒè¯é›†ç²¾åº¦ã€æ”¶æ•›é€Ÿåº¦ | 90% | æ€§èƒ½åŸºçº¿å¯¹æ¯” |
| **æ¨¡å‹è¯„ä¼°** | ç¦»çº¿è¯„ä¼°ã€A/Bæµ‹è¯• | ä¸šåŠ¡æŒ‡æ ‡ã€å…¬å¹³æ€§æ£€æŸ¥ | 85% | å‡†å…¥æ ‡å‡†æµ‹è¯• |
| **æ¨¡å‹éƒ¨ç½²** | ç°åº¦å‘å¸ƒã€è“ç»¿éƒ¨ç½² | éƒ¨ç½²æˆåŠŸç‡ã€å›æ»šæ—¶é—´ | 95% | é¢„å‘ç¯å¢ƒéªŒè¯ |
| **åœ¨çº¿ç›‘æ§** | æ€§èƒ½ç›‘æ§ã€æ¦‚å¿µæ¼‚ç§»æ£€æµ‹ | å»¶è¿Ÿã€å‡†ç¡®ç‡ã€æ•°æ®åˆ†å¸ƒ | 90% | å¼‚å¸¸è‡ªåŠ¨å‘Šè­¦ |
| **æ¨¡å‹æ›´æ–°** | å¢é‡å­¦ä¹ ã€ç‰ˆæœ¬è¿­ä»£ | æ›´æ–°é¢‘ç‡ã€æ”¹è¿›å¹…åº¦ | 75% | å›å½’æµ‹è¯•éªŒè¯ |

> **ğŸ”° åˆå­¦è€…ç†è§£**: æ¨¡å‹è®­ç»ƒPipelineæ˜¯å°†æ•°æ®è½¬åŒ–ä¸ºå¯éƒ¨ç½²æ¨¡å‹çš„è‡ªåŠ¨åŒ–æµç¨‹ã€‚ç±»æ¯”ï¼šåƒæ±½è½¦ç»„è£…æµæ°´çº¿,åŸææ–™(æ•°æ®)ç»è¿‡å†²å‹(ç‰¹å¾å·¥ç¨‹)ã€ç„Šæ¥(æ¨¡å‹è®­ç»ƒ)ã€å–·æ¼†(ä¼˜åŒ–)ã€è´¨æ£€(è¯„ä¼°)ç­‰å·¥åº,æœ€ç»ˆäº§å‡ºæˆå“è½¦(æ¨¡å‹)ã€‚
>
> **ğŸ”§ å·¥ä½œåŸç†**: ML Pipelineåœ¨Kubernetesä¸Šçš„å®ç°:
> 1. **å®¹å™¨åŒ–æ­¥éª¤**: æ¯ä¸ªæµæ°´çº¿æ­¥éª¤(æ•°æ®é¢„å¤„ç†ã€è®­ç»ƒã€è¯„ä¼°)éƒ½æ˜¯ç‹¬ç«‹çš„å®¹å™¨é•œåƒ,å¯å¤ç”¨å’Œç‰ˆæœ¬åŒ–
> 2. **DAGç¼–æ’**: ä½¿ç”¨Argo Workflowsæˆ–Kubeflow Pipelineså®šä¹‰ä»»åŠ¡ä¾èµ–å…³ç³»,è‡ªåŠ¨å¤„ç†æ•°æ®ä¼ é€’å’Œé”™è¯¯é‡è¯•
> 3. **èµ„æºåŠ¨æ€åˆ†é…**: æ•°æ®å¤„ç†ç”¨CPUèŠ‚ç‚¹,è®­ç»ƒç”¨GPUèŠ‚ç‚¹,è¯„ä¼°ç”¨å°å†…å­˜å®ä¾‹,æ ¹æ®æ­¥éª¤éœ€æ±‚è‡ªåŠ¨è°ƒåº¦
> 4. **ç¼“å­˜ä¼˜åŒ–**: ç›¸åŒè¾“å…¥çš„æ­¥éª¤ç»“æœå¯ç¼“å­˜,é¿å…é‡å¤è®¡ç®—,åŠ é€Ÿè¿­ä»£è°ƒè¯•
>
> **ğŸ“ æœ€å°ç¤ºä¾‹**:
> ```yaml
> # Kubeflow Pipelineå®šä¹‰ - Python DSL
> apiVersion: argoproj.io/v1alpha1
> kind: Workflow
> metadata:
>   generateName: ml-training-pipeline-
> spec:
>   entrypoint: ml-workflow
>   arguments:
>     parameters:
>     - name: dataset-path
>       value: "s3://ml-data/dataset-v1"
>     - name: model-name
>       value: "text-classifier-v2"
>   
>   templates:
>   # æ­¥éª¤1: æ•°æ®é¢„å¤„ç†
>   - name: preprocess
>     inputs:
>       parameters:
>       - name: dataset-path
>     outputs:
>       artifacts:
>       - name: processed-data
>         path: /output/data.tfrecord
>         s3:
>           key: "{{workflow.name}}/processed-data"
>     container:
>       image: data-processor:v1
>       command: ["python", "preprocess.py"]
>       args: ["--input={{inputs.parameters.dataset-path}}"]
>       resources:
>         requests:
>           cpu: "4"
>           memory: "16Gi"
>   
>   # æ­¥éª¤2: æ¨¡å‹è®­ç»ƒ
>   - name: train
>     inputs:
>       artifacts:
>       - name: processed-data
>         path: /input/data.tfrecord
>     outputs:
>       artifacts:
>       - name: trained-model
>         path: /output/model
>     container:
>       image: trainer:v1
>       command: ["python", "train.py"]
>       resources:
>         limits:
>           nvidia.com/gpu: 4  # ä½¿ç”¨4å¡è®­ç»ƒ
>   
>   # æ­¥éª¤3: æ¨¡å‹è¯„ä¼°
>   - name: evaluate
>     inputs:
>       artifacts:
>       - name: trained-model
>     container:
>       image: evaluator:v1
>       command: ["python", "evaluate.py"]
>       args: ["--threshold=0.85"]  # å‡†ç¡®ç‡é—¨æ§›
>   
>   # å·¥ä½œæµDAG
>   - name: ml-workflow
>     dag:
>       tasks:
>       - name: data-prep
>         template: preprocess
>         arguments:
>           parameters:
>           - name: dataset-path
>             value: "{{workflow.parameters.dataset-path}}"
>       - name: training
>         template: train
>         dependencies: [data-prep]  # ä¾èµ–é¢„å¤„ç†å®Œæˆ
>       - name: evaluation
>         template: evaluate
>         dependencies: [training]  # ä¾èµ–è®­ç»ƒå®Œæˆ
> ```
>
> **âš ï¸ å¸¸è§è¯¯åŒº**:
> - âŒ Pipelineæ­¥éª¤é—´ç”¨æœ¬åœ°ç£ç›˜ä¼ é€’å¤§æ–‡ä»¶ â†’ âœ… ä½¿ç”¨å¯¹è±¡å­˜å‚¨(S3/MinIO)ä¼ é€’æ•°æ®è·¯å¾„,é¿å…è·¨èŠ‚ç‚¹æ‹·è´
> - âŒ æœªåšæ­¥éª¤ç¼“å­˜å¯¼è‡´è°ƒè¯•æ•ˆç‡ä½ â†’ âœ… å¯ç”¨Kubeflowçš„ç¼“å­˜åŠŸèƒ½,ç›¸åŒè¾“å…¥è‡ªåŠ¨å¤ç”¨å†å²ç»“æœ
> - âŒ æ‰€æœ‰æ­¥éª¤ä¸²è¡Œæ‰§è¡Œæµªè´¹æ—¶é—´ â†’ âœ… è¯†åˆ«å¯å¹¶è¡Œçš„æ­¥éª¤(å¦‚å¤šä¸ªç‰¹å¾å·¥ç¨‹ä»»åŠ¡),ä½¿ç”¨DAGå¹¶è¡Œæ‰§è¡Œ

### 5.2 æ¨¡å‹ç‰ˆæœ¬ç®¡ç†ç­–ç•¥

| ç­–ç•¥ç±»å‹ | å®æ–½æ–¹å¼ | ä¼˜åŠ¿ | åŠ£åŠ¿ | é€‚ç”¨åœºæ™¯ |
|----------|----------|------|------|----------|
| **è¯­ä¹‰ç‰ˆæœ¬** | MAJOR.MINOR.PATCHæ ¼å¼ | æ¸…æ™°çš„ç‰ˆæœ¬è¯­ä¹‰ã€æ˜“äºç†è§£ | ç®¡ç†å¤æ‚ã€éœ€è¦äººå·¥åˆ¤æ–­ | æˆç†Ÿä¸šåŠ¡åœºæ™¯ |
| **æ—¶é—´æˆ³ç‰ˆæœ¬** | YYYYMMDD.HHMMSSæ ¼å¼ | è‡ªåŠ¨ç”Ÿæˆã€å”¯ä¸€æ€§å¼º | è¯­ä¹‰ä¸ç›´è§‚ã€éš¾ä»¥æ¯”è¾ƒ | å¿«é€Ÿè¿­ä»£åœºæ™¯ |
| **Git SHAç‰ˆæœ¬** | åŸºäºä»£ç æäº¤å“ˆå¸Œ | å®Œå…¨å¯è¿½æº¯ã€ä¸ä»£ç ç»‘å®š | ä¸æ˜“è¯»ã€é•¿åº¦è¾ƒé•¿ | ç ”å‘å›¢é˜Ÿä½¿ç”¨ |
| **å®éªŒIDç‰ˆæœ¬** | åŸºäºè®­ç»ƒå®éªŒæ ‡è¯† | ä¸å®éªŒæ•°æ®å…³è”ã€ä¾¿äºè¿½è¸ª | ç³»ç»Ÿè€¦åˆåº¦é«˜ | MLå¹³å°å†…éƒ¨ |
| **æ··åˆç‰ˆæœ¬** | è¯­ä¹‰+æ—¶é—´æˆ³ç»„åˆ | å…¼é¡¾è¯­ä¹‰å’Œå”¯ä¸€æ€§ | å¤æ‚åº¦è¾ƒé«˜ | ä¼ä¸šçº§åº”ç”¨ |

> **ğŸ”° åˆå­¦è€…ç†è§£**: æ¨¡å‹éƒ¨ç½²ç­–ç•¥å†³å®šå¦‚ä½•å®‰å…¨åœ°å°†æ–°æ¨¡å‹æ¨å‘ç”Ÿäº§ç¯å¢ƒã€‚ç±»æ¯”ï¼šåƒæ–°å“ä¸Šå¸‚çš„å‘å¸ƒç­–ç•¥,å¯ä»¥å…ˆåœ¨éƒ¨åˆ†åŸå¸‚è¯•ç‚¹(ç°åº¦å‘å¸ƒ),å‡†å¤‡ä¸¤å¥—ç”Ÿäº§çº¿éšæ—¶åˆ‡æ¢(è“ç»¿éƒ¨ç½²),æˆ–è€…è®©æ–°æ—§äº§å“å…±å­˜é€æ­¥æ›¿æ¢(é‡‘ä¸é›€å‘å¸ƒ)ã€‚
>
> **ğŸ”§ å·¥ä½œåŸç†**: Kubernetesä¸Šçš„æ¨¡å‹éƒ¨ç½²ç­–ç•¥:
> 1. **è“ç»¿éƒ¨ç½²**: åŒæ—¶è¿è¡Œæ—§ç‰ˆæœ¬(è“)å’Œæ–°ç‰ˆæœ¬(ç»¿),éªŒè¯ååˆ‡æ¢æµé‡,å¯å¿«é€Ÿå›æ»šã€‚é€‚åˆé£é™©æ•æ„Ÿçš„åœºæ™¯
> 2. **é‡‘ä¸é›€å‘å¸ƒ**: æ–°ç‰ˆæœ¬å…ˆæ¥æ”¶5%æµé‡,é€æ­¥å¢åŠ åˆ°10%/50%/100%,å‡ºé—®é¢˜ç«‹å³å›æ»šã€‚é€‚åˆéœ€è¦éªŒè¯çš„åœºæ™¯
> 3. **A/Bæµ‹è¯•**: åŒæ—¶è¿è¡Œå¤šä¸ªæ¨¡å‹ç‰ˆæœ¬,æ ¹æ®ç”¨æˆ·ç‰¹å¾è·¯ç”±åˆ°ä¸åŒç‰ˆæœ¬,å¯¹æ¯”ä¸šåŠ¡æŒ‡æ ‡é€‰æ‹©æœ€ä¼˜ç‰ˆæœ¬
> 4. **å½±å­éƒ¨ç½²**: æ–°ç‰ˆæœ¬æ¥æ”¶çœŸå®æµé‡ä½†ä¸è¿”å›ç»“æœ,ä»…è®°å½•é¢„æµ‹ç”¨äºç¦»çº¿å¯¹æ¯”ã€‚é€‚åˆé«˜é£é™©å˜æ›´
>
> **ğŸ“ æœ€å°ç¤ºä¾‹**:
> ```yaml
> # KServe InferenceService - é‡‘ä¸é›€å‘å¸ƒ
> apiVersion: serving.kserve.io/v1beta1
> kind: InferenceService
> metadata:
>   name: text-classifier
> spec:
>   predictor:
>     # ç¨³å®šç‰ˆæœ¬ - æ¥æ”¶90%æµé‡
>     canaryTrafficPercent: 10  # é‡‘ä¸é›€ç‰ˆæœ¬å 10%
>     minReplicas: 3
>     maxReplicas: 10
>     containers:
>     - name: model-v1
>       image: classifier:v1.0.0
>       resources:
>         limits:
>           nvidia.com/gpu: 1
>   # é‡‘ä¸é›€ç‰ˆæœ¬ - æ¥æ”¶10%æµé‡
>   canary:
>     predictor:
>       containers:
>       - name: model-v2
>         image: classifier:v2.0.0
>         resources:
>           limits:
>             nvidia.com/gpu: 1
> ---
> # Istio VirtualService - A/Bæµ‹è¯•æµé‡åˆ†å‰²
> apiVersion: networking.istio.io/v1beta1
> kind: VirtualService
> metadata:
>   name: model-ab-test
> spec:
>   hosts:
>   - model-service.prod.svc.cluster.local
>   http:
>   - match:
>     - headers:
>         user-segment:
>           exact: "premium"  # é«˜çº§ç”¨æˆ·ä½¿ç”¨æ–°æ¨¡å‹
>     route:
>     - destination:
>         host: model-service
>         subset: v2
>       weight: 100
>   - route:
>     - destination:
>         host: model-service
>         subset: v1
>       weight: 50  # æ™®é€šç”¨æˆ·50%ä½¿ç”¨æ–°æ¨¡å‹
>     - destination:
>         host: model-service
>         subset: v2
>       weight: 50
> ---
> # Argo Rollout - è‡ªåŠ¨åŒ–æ¸è¿›å¼å‘å¸ƒ
> apiVersion: argoproj.io/v1alpha1
> kind: Rollout
> metadata:
>   name: model-rollout
> spec:
>   replicas: 10
>   strategy:
>     canary:
>       steps:
>       - setWeight: 10   # å…ˆç»™10%æµé‡
>       - pause: {duration: 10m}  # è§‚å¯Ÿ10åˆ†é’Ÿ
>       - setWeight: 30   # å¢åŠ åˆ°30%
>       - pause: {duration: 10m}
>       - setWeight: 50   # å¢åŠ åˆ°50%
>       - pause: {duration: 10m}
>       # è‡ªåŠ¨åˆ†ææŒ‡æ ‡å†³å®šæ˜¯å¦ç»§ç»­
>       analysis:
>         templates:
>         - templateName: error-rate-check
>         args:
>         - name: error-rate-threshold
>           value: "0.01"  # é”™è¯¯ç‡ä½äº1%æ‰ç»§ç»­
>   template:
>     spec:
>       containers:
>       - name: model-server
>         image: model:v2.1.0
> ```
>
> **âš ï¸ å¸¸è§è¯¯åŒº**:
> - âŒ æ–°ç‰ˆæœ¬ç›´æ¥100%ä¸Šçº¿å¯¼è‡´æ•…éšœå½±å“å…¨é‡ç”¨æˆ· â†’ âœ… å¿…é¡»ä½¿ç”¨é‡‘ä¸é›€å‘å¸ƒ,ä»å°æµé‡å¼€å§‹é€æ­¥æ”¾é‡
> - âŒ é‡‘ä¸é›€æœŸé—´æœªç›‘æ§å…³é”®æŒ‡æ ‡ â†’ âœ… é…ç½®è‡ªåŠ¨åŒ–æŒ‡æ ‡åˆ†æ(é”™è¯¯ç‡ã€å»¶è¿Ÿã€ä¸šåŠ¡è½¬åŒ–ç‡),å¼‚å¸¸è‡ªåŠ¨å›æ»š
> - âŒ è“ç»¿éƒ¨ç½²åç«‹å³é”€æ¯æ—§ç‰ˆæœ¬ â†’ âœ… ä¿ç•™æ—§ç‰ˆæœ¬è‡³å°‘24å°æ—¶,ç¡®ä¿æ²¡æœ‰å»¶è¿Ÿå‘ç°çš„é—®é¢˜å†é”€æ¯

### 5.3 æ¨¡å‹æ²»ç†æ¡†æ¶

```yaml
# ========== æ¨¡å‹æ²»ç†ç­–ç•¥é…ç½® ==========
apiVersion: ml.kubeflow.org/v1
kind: ModelGovernancePolicy
metadata:
  name: enterprise-model-governance
spec:
  # æ¨¡å‹å‡†å…¥æ§åˆ¶
  admissionControl:
    enabled: true
    rules:
    - name: "model-card-required"
      condition: "metadata.annotations['model-card'] != ''"
      action: "reject"
      message: "éƒ¨ç½²AIæ¨¡å‹å¿…é¡»æä¾›å®Œæ•´çš„æ¨¡å‹å¡ç‰‡"
      
    - name: "fairness-check"
      condition: "evaluation.fairness_score >= 0.8"
      action: "warn"
      message: "æ¨¡å‹å…¬å¹³æ€§æŒ‡æ ‡ä½äºæ ‡å‡†é˜ˆå€¼"
      
    - name: "privacy-compliance"
      condition: "training.data.contains_pii ? encryption.enabled == true : true"
      action: "reject"
      message: "å¤„ç†PIIæ•°æ®çš„æ¨¡å‹å¿…é¡»å¯ç”¨åŠ å¯†"

  # æ¨¡å‹ç›‘æ§è¦æ±‚
  monitoringRequirements:
    metrics:
    - name: "accuracy_drift"
      threshold: 0.05
      alert_severity: "warning"
      remediation: "automatic_rollback"
      
    - name: "latency_slo"
      threshold: 200  # ms
      alert_severity: "critical"
      remediation: "scale_up"
      
    - name: "cost_efficiency"
      threshold: 5.0  # $/1000è¯·æ±‚
      alert_severity: "info"
      remediation: "recommend_optimization"

  # ç”Ÿå‘½å‘¨æœŸç®¡ç†
  lifecycleManagement:
    retention:
      active_models: "180d"      # æ´»è·ƒæ¨¡å‹ä¿ç•™180å¤©
      archived_models: "2y"      # å½’æ¡£æ¨¡å‹ä¿ç•™2å¹´
      failed_experiments: "30d"  # å¤±è´¥å®éªŒä¿ç•™30å¤©
      
    promotion:
      criteria:
      - offline_accuracy_improvement: ">= 2%"  # ç¦»çº¿ç²¾åº¦æå‡
      - online_metric_improvement: ">= 1%"     # åœ¨çº¿æŒ‡æ ‡æå‡
      - stability_period: "7d"                 # ç¨³å®šæœŸ7å¤©
      - traffic_split_max: "10%"               # æœ€å¤§æµé‡æ¯”ä¾‹
      
    rollback:
      triggers:
      - accuracy_degradation: "> 5%"
      - latency_increase: "> 50%"
      - error_rate_spike: "> 200%"
      - cost_spike: "> 100%"
      
      procedure:
        step1: "reduce_traffic_to_10_percent"
        step2: "health_check_validation"
        step3: "complete_rollback_if_failed"
        timeout: "5m"
```

---

## 6. AIåŸºç¡€è®¾æ–½æ¶æ„

> **ğŸ”° åˆå­¦è€…å¯¼è¯»**: æœ¬èŠ‚ä»‹ç»AIåŸºç¡€è®¾æ–½çš„æ•´ä½“æ¶æ„è®¾è®¡,åŒ…æ‹¬GPUé›†ç¾¤æ¶æ„ã€å­˜å‚¨æ¶æ„å’Œä¸åŒçš„è®­ç»ƒ/æ¨ç†éƒ¨ç½²æ¨¡å¼ã€‚

### 6.1 è®­ç»ƒåŸºç¡€è®¾æ–½æ¨¡å¼

| æ¶æ„æ¨¡å¼ | æ ¸å¿ƒç‰¹å¾ | é€‚ç”¨åœºæ™¯ | ä¼˜åŠ¿ | åŠ£åŠ¿ |
|----------|----------|----------|------|------|
| **é›†ä¸­å¼è®­ç»ƒ** | ç»Ÿä¸€GPUèµ„æºæ± ï¼Œé›†ä¸­è°ƒåº¦ | å¤§å‹ä¼ä¸šã€ç ”ç©¶æœºæ„ | èµ„æºåˆ©ç”¨ç‡é«˜ã€ç®¡ç†ç®€å• | å•ç‚¹æ•…éšœé£é™© |
| **åˆ†å¸ƒå¼è®­ç»ƒ** | è·¨å¤šèŠ‚ç‚¹å¹¶è¡Œè®­ç»ƒ | è¶…å¤§æ¨¡å‹ã€ç§‘ç ”é¡¹ç›® | è®­ç»ƒè§„æ¨¡æ— é™ã€æ€§èƒ½å“è¶Š | ç½‘ç»œè¦æ±‚é«˜ã€è°ƒè¯•å¤æ‚ |
| **æ··åˆè®­ç»ƒ** | æŒ‰éœ€æ··åˆäº‘èµ„æº | æˆæœ¬æ•æ„Ÿé¡¹ç›® | çµæ´»æ€§å¼ºã€æˆæœ¬ä¼˜åŒ– | ç®¡ç†å¤æ‚ã€ç½‘ç»œå»¶è¿Ÿ |
| **è¾¹ç¼˜è®­ç»ƒ** | æœ¬åœ°è®¾å¤‡ä¸Šè®­ç»ƒ | IoTã€éšç§æ•æ„Ÿåœºæ™¯ | æ•°æ®æœ¬åœ°åŒ–ã€ä½å»¶è¿Ÿ | è®¡ç®—èƒ½åŠ›å—é™ |
| **è”é‚¦è®­ç»ƒ** | å¤šæ–¹åä½œä¸å…±äº«æ•°æ® | é‡‘èæœºæ„ã€åŒ»ç–—æœºæ„ | éšç§ä¿æŠ¤ã€åˆè§„å‹å¥½ | æ”¶æ•›é€Ÿåº¦æ…¢ |

> **ğŸ”° åˆå­¦è€…ç†è§£**: GPUé›†ç¾¤æ¶æ„æ˜¯å¤§è§„æ¨¡AIè®­ç»ƒçš„ç¡¬ä»¶å’Œç½‘ç»œå¸ƒå±€æ–¹æ¡ˆã€‚ç±»æ¯”ï¼šåƒè¶…çº§è®¡ç®—ä¸­å¿ƒçš„è®¾è®¡è“å›¾,éœ€è¦è§„åˆ’æœºæˆ¿å¸ƒå±€(æœºæ¶æ’åˆ—)ã€ä¾›ç”µæ•£çƒ­(ç”µæºå’Œå†·å´)ã€é«˜é€Ÿäº’è”(ç½‘ç»œæ‹“æ‰‘),ç¡®ä¿æ•°ç™¾å¼ GPUå¡èƒ½é«˜æ•ˆåä½œã€‚
>
> **ğŸ”§ å·¥ä½œåŸç†**: GPUé›†ç¾¤æ¶æ„çš„å…³é”®è®¾è®¡è¦ç´ :
> 1. **ç½‘ç»œæ‹“æ‰‘**: ä½¿ç”¨NVLinkè¿æ¥åŒèŠ‚ç‚¹GPU(900GB/så¸¦å®½),InfiniBand/RoCEè¿æ¥è·¨èŠ‚ç‚¹(200-400Gb/s),å‡å°‘é€šä¿¡ç“¶é¢ˆ
> 2. **å­˜å‚¨åˆ†å±‚**: è®­ç»ƒæ•°æ®æ”¾åœ¨é«˜æ€§èƒ½å¹¶è¡Œæ–‡ä»¶ç³»ç»Ÿ(Lustre/GPFS),checkpointç”¨NVMe SSD,æœ€ç»ˆæ¨¡å‹å½’æ¡£åˆ°å¯¹è±¡å­˜å‚¨
> 3. **èŠ‚ç‚¹é…ç½®**: æ ¹æ®å·¥ä½œè´Ÿè½½ç‰¹ç‚¹é…ç½®ä¸åŒGPUå¯†åº¦èŠ‚ç‚¹,è®­ç»ƒç”¨8å¡é«˜å¯†åº¦èŠ‚ç‚¹,æ¨ç†ç”¨å•å¡ä½å»¶è¿ŸèŠ‚ç‚¹
> 4. **èµ„æºæ± åŒ–**: é€šè¿‡KubernetesæŠ½è±¡ç‰©ç†èµ„æºä¸ºé€»è¾‘èµ„æºæ± ,æ”¯æŒåŠ¨æ€è°ƒåº¦å’Œæ•…éšœè‡ªæ„ˆ
>
> **ğŸ“ æœ€å°ç¤ºä¾‹**:
> ```yaml
> # GPUèŠ‚ç‚¹æ± é…ç½® - åŒºåˆ†è®­ç»ƒå’Œæ¨ç†
> apiVersion: karpenter.sh/v1alpha5
> kind: Provisioner
> metadata:
>   name: training-node-pool
> spec:
>   labels:
>     workload-type: training  # è®­ç»ƒèŠ‚ç‚¹æ ‡ç­¾
>     gpu-topology: nvlink     # NVLinkæ‹“æ‰‘
>   requirements:
>   - key: node.kubernetes.io/instance-type
>     operator: In
>     values:
>     - "p4d.24xlarge"   # 8x A100 with NVLink
>     - "p4de.24xlarge"  # 8x A100 80GB
>   - key: topology.kubernetes.io/zone
>     operator: In
>     values: ["us-west-2a"]  # åŒå¯ç”¨åŒºå‡å°‘å»¶è¿Ÿ
>   taints:
>   - key: nvidia.com/gpu
>     value: training
>     effect: NoSchedule  # ä»…è®­ç»ƒä»»åŠ¡å¯è°ƒåº¦
> ---
> apiVersion: karpenter.sh/v1alpha5
> kind: Provisioner
> metadata:
>   name: inference-node-pool
> spec:
>   labels:
>     workload-type: inference
>   requirements:
>   - key: node.kubernetes.io/instance-type
>     operator: In
>     values:
>     - "g5.xlarge"    # 1x A10G ä½æˆæœ¬æ¨ç†
>     - "g5.2xlarge"   # 1x A10G 24GB
>   taints:
>   - key: nvidia.com/gpu
>     value: inference
>     effect: NoSchedule
> ---
> # åˆ†å¸ƒå¼è®­ç»ƒä»»åŠ¡ - åˆ©ç”¨NVLinkæ‹“æ‰‘
> apiVersion: kubeflow.org/v1
> kind: PyTorchJob
> metadata:
>   name: distributed-training-nvlink
> spec:
>   pytorchReplicaSpecs:
>     Master:
>       replicas: 1
>       template:
>         spec:
>           nodeSelector:
>             workload-type: training
>             gpu-topology: nvlink  # é€‰æ‹©NVLinkèŠ‚ç‚¹
>           tolerations:
>           - key: nvidia.com/gpu
>             value: training
>             effect: NoSchedule
>           containers:
>           - name: pytorch
>             image: nvcr.io/nvidia/pytorch:23.12-py3
>             command: ["torchrun"]
>             args:
>             - "--nproc_per_node=8"
>             - "--nnodes=4"
>             - "--rdzv_backend=c10d"
>             - "--rdzv_endpoint=master-0:29400"
>             - "train.py"
>             resources:
>               limits:
>                 nvidia.com/gpu: 8
>             env:
>             - name: NCCL_DEBUG
>               value: "INFO"
>             - name: NCCL_IB_DISABLE
>               value: "0"  # å¯ç”¨InfiniBand
>     Worker:
>       replicas: 3
>       template:
>         spec:
>           nodeSelector:
>             workload-type: training
>             gpu-topology: nvlink
>           containers:
>           - name: pytorch
>             resources:
>               limits:
>                 nvidia.com/gpu: 8
> ```
>
> **âš ï¸ å¸¸è§è¯¯åŒº**:
> - âŒ å°†è®­ç»ƒå’Œæ¨ç†æ··éƒ¨åœ¨åŒä¸€èŠ‚ç‚¹æ±  â†’ âœ… åˆ†ç¦»è®­ç»ƒ(é«˜å¯†åº¦8å¡èŠ‚ç‚¹)å’Œæ¨ç†(ä½æˆæœ¬å•å¡èŠ‚ç‚¹)èŠ‚ç‚¹æ± 
> - âŒ å¿½ç•¥GPUæ‹“æ‰‘å¯¼è‡´è·¨PCIeé€šä¿¡ â†’ âœ… ä½¿ç”¨æ‹“æ‰‘æ„ŸçŸ¥è°ƒåº¦,ä¼˜å…ˆå°†åˆ†å¸ƒå¼è®­ç»ƒè°ƒåº¦åˆ°NVLinkè¿æ¥çš„GPU
> - âŒ ä½¿ç”¨é€šç”¨ç½‘ç»œå­˜å‚¨è®­ç»ƒå¤§æ¨¡å‹ â†’ âœ… è®­ç»ƒæ•°æ®åº”æ”¾åœ¨é«˜æ€§èƒ½å¹¶è¡Œæ–‡ä»¶ç³»ç»Ÿæˆ–æœ¬åœ°NVMe,é¿å…IOç“¶é¢ˆ

### 6.2 æ¨ç†éƒ¨ç½²æ¶æ„

| éƒ¨ç½²æ¨¡å¼ | æŠ€æœ¯ç‰¹ç‚¹ | æ€§èƒ½ç‰¹å¾ | æˆæœ¬è€ƒé‡ | è¿ç»´å¤æ‚åº¦ |
|----------|----------|----------|----------|------------|
| **Serverlessæ¨ç†** | æŒ‰éœ€å¯åŠ¨ã€è‡ªåŠ¨æ‰©ç¼© | å†·å¯åŠ¨å»¶è¿Ÿã€æˆæœ¬ä¼˜åŒ– | æŒ‰ä½¿ç”¨ä»˜è´¹ã€æ— é—²ç½®æˆæœ¬ | ä½ |
| **å¸¸é©»æœåŠ¡** | æŒç»­è¿è¡Œã€é¢„çƒ­å®Œæˆ | ä½å»¶è¿Ÿã€é«˜QPS | å›ºå®šæˆæœ¬ã€èµ„æºé¢„ç•™ | ä¸­ |
| **è¾¹ç¼˜æ¨ç†** | æœ¬åœ°éƒ¨ç½²ã€å°±è¿‘æœåŠ¡ | è¶…ä½å»¶è¿Ÿã€ç¦»çº¿å¯ç”¨ | å‡å°‘å¸¦å®½æˆæœ¬ã€ç¡¬ä»¶æŠ•èµ„ | é«˜ |
| **æ··åˆéƒ¨ç½²** | äº‘ç«¯+è¾¹ç¼˜ååŒ | å…¨å±€ä¼˜åŒ–ã€å®¹é”™æ€§å¼º | æˆæœ¬åˆ†æ‘Šã€èµ„æºäº’è¡¥ | é«˜ |
| **æ¨¡å‹ç½‘æ ¼** | å¤šç‰ˆæœ¬å¹¶å­˜ã€æ™ºèƒ½è·¯ç”± | A/Bæµ‹è¯•ã€æ¸è¿›å‘å¸ƒ | ç°åº¦æˆæœ¬ã€ç‰ˆæœ¬ç®¡ç† | ä¸­é«˜ |

> **ğŸ”° åˆå­¦è€…ç†è§£**: å­˜å‚¨æ¶æ„æ˜¯AIå¹³å°æ•°æ®ç®¡ç†çš„åˆ†å±‚ç­–ç•¥ã€‚ç±»æ¯”ï¼šåƒå›¾ä¹¦é¦†çš„åˆ†çº§å­˜å‚¨ç³»ç»Ÿ,çƒ­é—¨æ–°ä¹¦æ”¾åœ¨å…¥å£å±•ç¤ºæ¶(é«˜é€ŸSSD),å¸¸ç”¨ä¹¦åœ¨é˜…è§ˆå®¤ä¹¦æ¶(å¹¶è¡Œæ–‡ä»¶ç³»ç»Ÿ),æ—§ä¹¦åœ¨åœ°ä¸‹ä»“åº“(å¯¹è±¡å­˜å‚¨),æ ¹æ®è®¿é—®é¢‘ç‡å’Œæˆæœ¬å¹³è¡¡é€‰æ‹©å­˜å‚¨ä½ç½®ã€‚
>
> **ğŸ”§ å·¥ä½œåŸç†**: AIå­˜å‚¨æ¶æ„çš„ä¸‰å±‚è®¾è®¡:
> 1. **çƒ­å­˜å‚¨å±‚**: è®­ç»ƒä¸­çš„æ´»è·ƒæ•°æ®é›†å’Œcheckpoint,ä½¿ç”¨æœ¬åœ°NVMe SSDæˆ–å¹¶è¡Œæ–‡ä»¶ç³»ç»Ÿ(Lustre),æä¾›æœ€é«˜IOPSå’Œå¸¦å®½(>10GB/s)
> 2. **æ¸©å­˜å‚¨å±‚**: è¿‘æœŸå®éªŒæ•°æ®å’Œå¸¸ç”¨æ¨¡å‹,ä½¿ç”¨ç½‘ç»œå—å­˜å‚¨(EBS/äº‘ç›˜)æˆ–åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ(CephFS),å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬
> 3. **å†·å­˜å‚¨å±‚**: å†å²æ•°æ®é›†ã€å½’æ¡£æ¨¡å‹å’Œå®¡è®¡æ—¥å¿—,ä½¿ç”¨å¯¹è±¡å­˜å‚¨(S3/OSS),æˆæœ¬æœ€ä½ä½†è®¿é—®å»¶è¿Ÿè¾ƒé«˜(ç§’çº§)
> 4. **ç”Ÿå‘½å‘¨æœŸç­–ç•¥**: è‡ªåŠ¨å°†30å¤©æœªè®¿é—®çš„æ•°æ®é™çº§åˆ°æ¸©å­˜å‚¨,90å¤©æœªè®¿é—®é™çº§åˆ°å†·å­˜å‚¨,å‡å°‘å­˜å‚¨æˆæœ¬
>
> **ğŸ“ æœ€å°ç¤ºä¾‹**:
> ```yaml
> # çƒ­å­˜å‚¨ - æœ¬åœ°NVMe forè®­ç»ƒæ•°æ®
> apiVersion: storage.k8s.io/v1
> kind: StorageClass
> metadata:
>   name: local-nvme-hot
> provisioner: kubernetes.io/no-provisioner
> volumeBindingMode: WaitForFirstConsumer
> ---
> apiVersion: v1
> kind: PersistentVolume
> metadata:
>   name: nvme-pv-node1
> spec:
>   capacity:
>     storage: 2Ti
>   accessModes:
>   - ReadWriteOnce
>   persistentVolumeReclaimPolicy: Retain
>   storageClassName: local-nvme-hot
>   local:
>     path: /mnt/nvme0  # æœ¬åœ°NVMeæŒ‚è½½ç‚¹
>   nodeAffinity:
>     required:
>       nodeSelectorTerms:
>       - matchExpressions:
>         - key: storage-tier
>           operator: In
>           values: ["nvme"]
> ---
> # æ¸©å­˜å‚¨ - ç½‘ç»œå—å­˜å‚¨forå®éªŒæ•°æ®
> apiVersion: storage.k8s.io/v1
> kind: StorageClass
> metadata:
>   name: ebs-warm
> provisioner: ebs.csi.aws.com
> parameters:
>   type: gp3
>   iops: "3000"
>   throughput: "125"  # MB/s
> allowVolumeExpansion: true
> ---
> # å†·å­˜å‚¨ - S3å¯¹è±¡å­˜å‚¨forå½’æ¡£
> apiVersion: v1
> kind: PersistentVolumeClaim
> metadata:
>   name: archive-storage
> spec:
>   accessModes:
>   - ReadWriteMany
>   storageClassName: s3-cold
>   resources:
>     requests:
>       storage: 100Ti  # å¤§å®¹é‡ä½æˆæœ¬
> ---
> # è®­ç»ƒä»»åŠ¡ - ä½¿ç”¨åˆ†å±‚å­˜å‚¨
> apiVersion: batch/v1
> kind: Job
> metadata:
>   name: model-training-tiered
> spec:
>   template:
>     spec:
>       initContainers:
>       # ä»å†·å­˜å‚¨é¢„åŠ è½½æ•°æ®åˆ°çƒ­å­˜å‚¨
>       - name: data-loader
>         image: aws-cli:latest
>         command: ["aws", "s3", "sync"]
>         args:
>         - "s3://ml-archive/dataset-v1"  # å†·å­˜å‚¨æº
>         - "/cache/dataset"               # æœ¬åœ°NVMeç›®æ ‡
>         volumeMounts:
>         - name: nvme-cache
>           mountPath: /cache
>       containers:
>       - name: trainer
>         image: pytorch:latest
>         volumeMounts:
>         - name: nvme-cache
>           mountPath: /data  # ä»NVMeè¯»å–è®­ç»ƒæ•°æ®
>         - name: checkpoint-storage
>           mountPath: /checkpoints  # checkpointå†™å…¥æ¸©å­˜å‚¨
>       volumes:
>       - name: nvme-cache
>         persistentVolumeClaim:
>           claimName: nvme-hot-pvc  # çƒ­å­˜å‚¨
>       - name: checkpoint-storage
>         persistentVolumeClaim:
>           claimName: ebs-warm-pvc  # æ¸©å­˜å‚¨
> ---
> # ç”Ÿå‘½å‘¨æœŸç®¡ç† - è‡ªåŠ¨é™çº§ç­–ç•¥
> apiVersion: batch/v1
> kind: CronJob
> metadata:
>   name: storage-lifecycle-manager
> spec:
>   schedule: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ
>   jobTemplate:
>     spec:
>       template:
>         spec:
>           containers:
>           - name: lifecycle
>             image: storage-manager:v1
>             command: ["python", "lifecycle.py"]
>             args:
>             - "--move-to-warm-after-days=30"
>             - "--move-to-cold-after-days=90"
>             - "--delete-after-days=365"
> ```
>
> **âš ï¸ å¸¸è§è¯¯åŒº**:
> - âŒ æ‰€æœ‰æ•°æ®éƒ½æ”¾åœ¨é«˜æ€§èƒ½å­˜å‚¨å¯¼è‡´æˆæœ¬çˆ†ç‚¸ â†’ âœ… æ ¹æ®è®¿é—®é¢‘ç‡åˆ†å±‚å­˜å‚¨,è®­ç»ƒç”¨NVMe,å½’æ¡£ç”¨S3
> - âŒ è®­ç»ƒæ—¶ç›´æ¥ä»S3è¯»å–æ•°æ® â†’ âœ… å…ˆç”¨initContainerå°†æ•°æ®é¢„åŠ è½½åˆ°æœ¬åœ°NVMe,é¿å…ç½‘ç»œIOç“¶é¢ˆ
> - âŒ checkpointå’Œè®­ç»ƒæ•°æ®å…±ç”¨å­˜å‚¨å· â†’ âœ… checkpointéœ€è¦æŒä¹…åŒ–ç”¨ç½‘ç»œå­˜å‚¨,è®­ç»ƒæ•°æ®ç”¨ä¸´æ—¶é«˜æ€§èƒ½æœ¬åœ°å­˜å‚¨

### 6.3 AIå¹³å°å‚è€ƒæ¶æ„

```mermaid
graph TB
    subgraph "æ•°æ®å±‚"
        A1[æ•°æ®æ¹–/æ•°æ®ä»“åº“] --> A2[ç‰¹å¾å­˜å‚¨]
        A2 --> A3[è®­ç»ƒæ•°æ®é›†]
        A3 --> A4[éªŒè¯æ•°æ®é›†]
    end
    
    subgraph "è®­ç»ƒå±‚"
        B1[åˆ†å¸ƒå¼è®­ç»ƒå¹³å°] --> B2[è¶…å‚æ•°ä¼˜åŒ–]
        B2 --> B3[æ¨¡å‹ç‰ˆæœ¬ç®¡ç†]
        B3 --> B4[æ¨¡å‹è¯„ä¼°]
    end
    
    subgraph "éƒ¨ç½²å±‚"
        C1[æ¨¡å‹æ³¨å†Œä¸­å¿ƒ] --> C2[æ¨ç†æœåŠ¡ç½‘æ ¼]
        C2 --> C3[ABæµ‹è¯•å¹³å°]
        C3 --> C4[è“ç»¿éƒ¨ç½²]
    end
    
    subgraph "ç›‘æ§å±‚"
        D1[æ€§èƒ½ç›‘æ§] --> D2[æˆæœ¬ç›‘æ§]
        D2 --> D3[åˆè§„å®¡è®¡]
        D3 --> D4[å¼‚å¸¸æ£€æµ‹]
    end
    
    subgraph "æ²»ç†å±‚"
        E1[è®¿é—®æ§åˆ¶] --> E2[å®¡æ‰¹æµç¨‹]
        E2 --> E3[åˆè§„æ£€æŸ¥]
        E3 --> E4[é£é™©ç®¡æ§]
    end
    
    A4 --> B1
    B4 --> C1
    C4 --> D1
    D4 --> E1
    
    style A1 fill:#e1f5fe
    style B1 fill:#f3e5f5
    style C1 fill:#e8f5e8
    style D1 fill:#fff3e0
    style E1 fill:#ffebee
```

---

**è¡¨æ ¼åº•éƒ¨æ ‡è®°**: Kusheet Project | ä½œè€…: Allen Galler (allengaller@gmail.com) | æœ€åæ›´æ–°: 2026-02 | ç‰ˆæœ¬: v1.25-v1.32 | è´¨é‡ç­‰çº§: â­â­â­â­â­ ä¸“å®¶çº§