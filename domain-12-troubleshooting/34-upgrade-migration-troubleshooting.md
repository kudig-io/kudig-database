# 34 - å‡çº§è¿ç§»æ•…éšœæ’æŸ¥ (Upgrade and Migration Troubleshooting)

> **é€‚ç”¨ç‰ˆæœ¬**: Kubernetes v1.25-v1.32 | **æœ€åæ›´æ–°**: 2026-02 | **å‚è€ƒ**: [Kubernetes Upgrade](https://kubernetes.io/docs/tasks/administer-cluster/cluster-upgrade/)

---

## 1. å‡çº§è¿ç§»æ•…éšœè¯Šæ–­æ€»è§ˆ (Upgrade and Migration Diagnosis Overview)

### 1.1 å¸¸è§å‡çº§é—®é¢˜åˆ†ç±»

| æ•…éšœç±»å‹ | ç—‡çŠ¶è¡¨ç° | å½±å“èŒƒå›´ | ç´§æ€¥ç¨‹åº¦ |
|---------|---------|---------|---------|
| **ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜** | APIåºŸå¼ƒ/å˜æ›´ | é›†ç¾¤åŠŸèƒ½å¼‚å¸¸ | P0 - ç´§æ€¥ |
| **ç»„ä»¶å‡çº§å¤±è´¥** | Control Planeç»„ä»¶å®•æœº | é›†ç¾¤ç®¡æ§å¤±æ•ˆ | P0 - ç´§æ€¥ |
| **å·¥ä½œè´Ÿè½½ä¸­æ–­** | Podæ— æ³•è°ƒåº¦/è¿è¡Œ | åº”ç”¨æœåŠ¡ä¸­æ–­ | P0 - ç´§æ€¥ |
| **å­˜å‚¨æ•°æ®ä¸¢å¤±** | PV/PVCä¸å…¼å®¹ | æ•°æ®æŒä¹…åŒ–å¤±è´¥ | P0 - ç´§æ€¥ |
| **ç½‘ç»œæ’ä»¶å¤±æ•ˆ** | CNIæ’ä»¶ä¸å…¼å®¹ | ç½‘ç»œé€šä¿¡ä¸­æ–­ | P0 - ç´§æ€¥ |

### 1.2 å‡çº§è¿ç§»æ¶æ„å›é¡¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                å‡çº§è¿ç§»æ•…éšœè¯Šæ–­æ¶æ„                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                       åº”ç”¨å±‚å…¼å®¹æ€§                                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚  â”‚
â”‚  â”‚  â”‚   å·¥ä½œè´Ÿè½½   â”‚   â”‚   é…ç½®ç®¡ç†   â”‚   â”‚   æœåŠ¡å‘ç°   â”‚              â”‚  â”‚
â”‚  â”‚  â”‚ (Workloads) â”‚   â”‚ (Config)    â”‚   â”‚ (Discovery) â”‚              â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                              â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚         â”‚                    â”‚                    â”‚                       â”‚
â”‚         â–¼                    â–¼                    â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   APIç‰ˆæœ¬    â”‚   â”‚   å­˜å‚¨å…¼å®¹   â”‚   â”‚   ç½‘ç»œå…¼å®¹   â”‚                   â”‚
â”‚  â”‚ (API Version)â”‚   â”‚ (Storage)   â”‚   â”‚ (Network)   â”‚                   â”‚
â”‚  â”‚   å…¼å®¹æ€§     â”‚   â”‚   æ€§       â”‚   â”‚   æ€§       â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â”‚                    â”‚                    â”‚                       â”‚
â”‚         â–¼                    â–¼                    â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                      Control Planeå±‚                                â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚                   kube-apiserver                              â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚   etcd      â”‚  â”‚   æ§åˆ¶å™¨     â”‚  â”‚   è°ƒåº¦å™¨     â”‚           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  (å­˜å‚¨)     â”‚  â”‚  (Manager)  â”‚  â”‚  (Scheduler)â”‚           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                              â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚         â”‚                    â”‚                    â”‚                       â”‚
â”‚         â–¼                    â–¼                    â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   èŠ‚ç‚¹ç»„ä»¶   â”‚   â”‚   ç½‘ç»œæ’ä»¶   â”‚   â”‚   å­˜å‚¨æ’ä»¶   â”‚                   â”‚
â”‚  â”‚ (Node Comp) â”‚   â”‚ (CNI)       â”‚   â”‚ (CSI)       â”‚                   â”‚
â”‚  â”‚   å‡çº§      â”‚   â”‚   å…¼å®¹æ€§     â”‚   â”‚   å…¼å®¹æ€§     â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                              â”‚                                              â”‚
â”‚                              â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                      æ•°æ®å¹³é¢å±‚                                     â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚  â”‚
â”‚  â”‚  â”‚   kubelet   â”‚    â”‚   kube-proxyâ”‚   â”‚   å®¹å™¨è¿è¡Œæ—¶  â”‚              â”‚  â”‚
â”‚  â”‚  â”‚   å‡çº§      â”‚    â”‚   å‡çº§      â”‚   â”‚  (Container) â”‚              â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. å‡çº§å‰å‡†å¤‡æ£€æŸ¥ (Pre-Upgrade Preparation Check)

### 2.1 ç‰ˆæœ¬å…¼å®¹æ€§éªŒè¯

```bash
# ========== 1. å½“å‰ç‰ˆæœ¬æ£€æŸ¥ ==========
# æ£€æŸ¥é›†ç¾¤å½“å‰ç‰ˆæœ¬
kubectl version --short

# æŸ¥çœ‹å„ç»„ä»¶ç‰ˆæœ¬
kubectl get nodes -o jsonpath='{
    range .items[*]
}{
        .metadata.name
}{
        "\t"
}{
        .status.nodeInfo.kubeletVersion
}{
        "\t"
}{
        .status.nodeInfo.containerRuntimeVersion
}{
        "\n"
}{
    end
}'

# æ£€æŸ¥Control Planeç‰ˆæœ¬
kubectl get pods -n kube-system -l component=kube-apiserver -o jsonpath='{
    .items[*].spec.containers[*].image
}'

# ========== 2. åºŸå¼ƒAPIæ£€æŸ¥ ==========
# æ£€æŸ¥å°†è¢«åºŸå¼ƒçš„APIç‰ˆæœ¬
cat <<'EOF' > deprecated-api-checker.sh
#!/bin/bash

TARGET_VERSION=${1:-v1.26.0}

echo "Checking deprecated APIs for upgrade to $TARGET_VERSION"

# ä½¿ç”¨kubevalæˆ–ç±»ä¼¼çš„å·¥å…·æ£€æŸ¥èµ„æºé…ç½®
for ns in $(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'); do
    echo "Checking namespace: $ns"
    
    # æ£€æŸ¥Deployments
    kubectl get deployments -n $ns -o yaml | grep -E "apiVersion:.*extensions/v1beta1|apiVersion:.*apps/v1beta1" && \
        echo "  âš ï¸  Deprecated API found in Deployments"
    
    # æ£€æŸ¥Ingress
    kubectl get ingress -n $ns -o yaml | grep -E "apiVersion:.*extensions/v1beta1" && \
        echo "  âš ï¸  Deprecated API found in Ingress"
    
    # æ£€æŸ¥NetworkPolicy
    kubectl get networkpolicy -n $ns -o yaml | grep -E "apiVersion:.*extensions/v1beta1" && \
        echo "  âš ï¸  Deprecated API found in NetworkPolicy"
done

echo "Deprecated API check completed"
EOF

chmod +x deprecated-api-checker.sh

# ========== 3. å‡çº§è·¯å¾„éªŒè¯ ==========
# æ£€æŸ¥æ”¯æŒçš„å‡çº§è·¯å¾„
kubectl get nodes --no-headers | awk '{print $5}' | sort | uniq -c

# éªŒè¯æœ€å°å‡çº§è·³è·ƒ
CURRENT_VERSION=$(kubectl version --short | grep Server | awk '{print $3}')
echo "Current version: $CURRENT_VERSION"

# æ£€æŸ¥æ˜¯å¦æœ‰è·³ç‰ˆæœ¬å‡çº§çš„é£é™©
if [[ $CURRENT_VERSION == *"v1.22"* ]] && [[ $TARGET_VERSION == *"v1.24"* ]]; then
    echo "âš ï¸  Risk of skipping versions detected"
fi
```

### 2.2 å¤‡ä»½å’Œå›æ»šå‡†å¤‡

```bash
# ========== etcdå¤‡ä»½ ==========
# æ‰§è¡Œetcdå®Œæ•´å¤‡ä»½
ETCD_POD=$(kubectl get pods -n kube-system -l component=etcd -o jsonpath='{.items[0].metadata.name}')
ETCDCTL_API=3 kubectl exec -n kube-system $ETCD_POD -- sh -c "
export ETCDCTL_ENDPOINTS=https://127.0.0.1:2379
export ETCDCTL_CACERT=/etc/kubernetes/pki/etcd/ca.crt
export ETCDCTL_CERT=/etc/kubernetes/pki/etcd/server.crt
export ETCDCTL_KEY=/etc/kubernetes/pki/etcd/server.key

echo 'Creating etcd snapshot...'
etcdctl snapshot save /tmp/etcd-backup-$(date +%Y%m%d-%H%M%S).db
echo 'Snapshot created successfully'

# éªŒè¯å¤‡ä»½
etcdctl --write-out=table snapshot status /tmp/etcd-backup-*.db
"

# ========== èµ„æºé…ç½®å¤‡ä»½ ==========
# å¤‡ä»½æ‰€æœ‰å‘½åç©ºé—´çš„èµ„æºé…ç½®
cat <<'EOF' > full-cluster-backup.sh
#!/bin/bash

BACKUP_DIR="/tmp/cluster-backup-$(date +%Y%m%d-%H%M%S)"
mkdir -p $BACKUP_DIR

echo "Creating full cluster backup to: $BACKUP_DIR"

# å¤‡ä»½æ‰€æœ‰å‘½åç©ºé—´
for ns in $(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'); do
    echo "Backing up namespace: $ns"
    mkdir -p $BACKUP_DIR/$ns
    
    # å¤‡ä»½å„ç§èµ„æºç±»å‹
    RESOURCES=("deployments" "services" "configmaps" "secrets" "daemonsets" "statefulsets" "jobs" "cronjobs" "ingresses" "networkpolicies")
    
    for resource in "${RESOURCES[@]}"; do
        kubectl get $resource -n $ns -o yaml > $BACKUP_DIR/$ns/$resource.yaml 2>/dev/null || echo "No $resource in $ns"
    done
    
    # å¤‡ä»½PVC
    kubectl get pvc -n $ns -o yaml > $BACKUP_DIR/$ns/pvc.yaml 2>/dev/null
    
    # å¤‡ä»½RBACé…ç½®
    kubectl get role,rolebinding,clusterrole,clusterrolebinding -n $ns -o yaml > $BACKUP_DIR/$ns/rbac.yaml 2>/dev/null
done

# å¤‡ä»½é›†ç¾¤çº§åˆ«èµ„æº
echo "Backing up cluster-level resources..."
mkdir -p $BACKUP_DIR/cluster

CLUSTER_RESOURCES=("namespaces" "nodes" "persistentvolumes" "storageclasses" "customresourcedefinitions")
for resource in "${CLUSTER_RESOURCES[@]}"; do
    kubectl get $resource -o yaml > $BACKUP_DIR/cluster/$resource.yaml 2>/dev/null
done

# åˆ›å»ºå¤‡ä»½æ‘˜è¦
cat > $BACKUP_DIR/backup-summary.txt <<SUMMARY
Cluster Backup Summary
=====================
Backup Time: $(date)
Kubernetes Version: $(kubectl version --short | grep Server | awk '{print $3}')
Nodes Count: $(kubectl get nodes --no-headers | wc -l)
Namespaces Count: $(kubectl get namespaces --no-headers | wc -l)

Backup Location: $BACKUP_DIR
SUMMARY

echo "Full cluster backup completed"
echo "Backup location: $BACKUP_DIR"
ls -la $BACKUP_DIR
EOF

chmod +x full-cluster-backup.sh
```

---

## 3. Control Planeå‡çº§æ•…éšœæ’æŸ¥ (Control Plane Upgrade Troubleshooting)

### 3.1 API Serverå‡çº§é—®é¢˜

```bash
# ========== 1. API Serverå‡çº§çŠ¶æ€æ£€æŸ¥ ==========
# æ£€æŸ¥API Server PodçŠ¶æ€
kubectl get pods -n kube-system -l component=kube-apiserver

# æŸ¥çœ‹API Serverè¯¦ç»†ä¿¡æ¯
kubectl describe pods -n kube-system -l component=kube-apiserver

# æ£€æŸ¥API Serveræ—¥å¿—
kubectl logs -n kube-system -l component=kube-apiserver --tail=100

# éªŒè¯API Serverå¥åº·çŠ¶æ€
kubectl get componentstatuses

# ========== 2. APIç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ ==========
# æ£€æŸ¥APIèµ„æºç‰ˆæœ¬æ”¯æŒ
kubectl api-versions | grep -E "(v1beta1|v1alpha1)" && echo "âš ï¸  Deprecated API versions found"

# éªŒè¯APIç»„å¯ç”¨æ€§
kubectl api-resources --api-group=apps
kubectl api-resources --api-group=networking.k8s.io

# æ£€æŸ¥è‡ªå®šä¹‰èµ„æºå®šä¹‰å…¼å®¹æ€§
kubectl get crds -o jsonpath='{
    range .items[*]
}{
        .metadata.name
}{
        "\t"
}{
        .spec.versions[*].name
}{
        "\n"
}{
    end
}'

# ========== 3. è¯ä¹¦å’Œè®¤è¯é—®é¢˜ ==========
# æ£€æŸ¥è¯ä¹¦æœ‰æ•ˆæœŸ
kubectl exec -n kube-system $ETCD_POD -- openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout | grep "Not After"

# éªŒè¯è¯ä¹¦é“¾
kubectl exec -n kube-system $ETCD_POD -- openssl verify -CAfile /etc/kubernetes/pki/ca.crt /etc/kubernetes/pki/apiserver.crt

# æ£€æŸ¥RBACæƒé™å˜æ›´
kubectl auth can-i list pods --all-namespaces
kubectl auth can-i create deployments --all-namespaces
```

### 3.2 etcdå‡çº§é—®é¢˜

```bash
# ========== etcdå‡çº§çŠ¶æ€æ£€æŸ¥ ==========
# æ£€æŸ¥etcdé›†ç¾¤å¥åº·çŠ¶æ€
ETCD_POD=$(kubectl get pods -n kube-system -l component=etcd -o jsonpath='{.items[0].metadata.name}')
kubectl exec -n kube-system $ETCD_POD -- sh -c "
export ETCDCTL_ENDPOINTS=https://127.0.0.1:2379
export ETCDCTL_CACERT=/etc/kubernetes/pki/etcd/ca.crt
export ETCDCTL_CERT=/etc/kubernetes/pki/etcd/server.crt
export ETCDCTL_KEY=/etc/kubernetes/pki/etcd/server.key

echo '=== etcd Cluster Health ==='
etcdctl endpoint health

echo '=== etcd Cluster Status ==='
etcdctl endpoint status -w table

echo '=== etcd Version Info ==='
etcdctl version
"

# ========== etcdæ•°æ®å…¼å®¹æ€§æ£€æŸ¥ ==========
# æ£€æŸ¥etcdæ•°æ®ç‰ˆæœ¬
kubectl exec -n kube-system $ETCD_POD -- sh -c "
export ETCDCTL_ENDPOINTS=https://127.0.0.1:2379
export ETCDCTL_CACERT=/etc/kubernetes/pki/etcd/ca.crt
export ETCDCTL_CERT=/etc/kubernetes/pki/etcd/server.crt
export ETCDCTL_KEY=/etc/kubernetes/pki/etcd/server.key

echo 'Checking etcd data version:'
etcdctl get /registry --prefix --keys-only | head -20
"

# éªŒè¯å…³é”®æ•°æ®å®Œæ•´æ€§
kubectl exec -n kube-system $ETCD_POD -- sh -c "
export ETCDCTL_ENDPOINTS=https://127.0.0.1:2379
export ETCDCTL_CACERT=/etc/kubernetes/pki/etcd/ca.crt
export ETCDCTL_CERT=/etc/kubernetes/pki/etcd/server.crt
export ETCDCTL_KEY=/etc/kubernetes/pki/etcd/server.key

echo 'Verifying critical data:'
etcdctl get /registry/namespaces/default
etcdctl get /registry/deployments --prefix | wc -l
"

# ========== etcdå‡çº§å›æ»šå‡†å¤‡ ==========
# åˆ›å»ºetcdå›æ»šè„šæœ¬
cat <<'EOF' > etcd-rollback.sh
#!/bin/bash

BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <etcd-backup-file.db>"
    exit 1
fi

echo "=== etcd Rollback Procedure ==="
echo "Backup file: $BACKUP_FILE"

# 1. åœæ­¢etcd
echo "1. Stopping etcd..."
kubectl scale deployment -n kube-system etcd-operator --replicas=0

# 2. æ¢å¤å¤‡ä»½
echo "2. Restoring backup..."
ETCD_POD=$(kubectl get pods -n kube-system -l component=etcd -o jsonpath='{.items[0].metadata.name}')
kubectl cp $BACKUP_FILE kube-system/$ETCD_POD:/tmp/

kubectl exec -n kube-system $ETCD_POD -- sh -c "
export ETCDCTL_ENDPOINTS=https://127.0.0.1:2379
export ETCDCTL_CACERT=/etc/kubernetes/pki/etcd/ca.crt
export ETCDCTL_CERT=/etc/kubernetes/pki/etcd/server.crt
export ETCDCTL_KEY=/etc/kubernetes/pki/etcd/server.key

# åœæ­¢etcdæœåŠ¡
pkill etcd

# æ¢å¤æ•°æ®
etcdctl snapshot restore /tmp/$(basename $BACKUP_FILE) \
    --data-dir=/var/lib/etcd-restored \
    --initial-cluster=default=https://127.0.0.1:2380 \
    --initial-advertise-peer-urls=https://127.0.0.1:2380

# æ›¿æ¢æ•°æ®ç›®å½•
mv /var/lib/etcd /var/lib/etcd.backup.$(date +%Y%m%d-%H%M%S)
mv /var/lib/etcd-restored /var/lib/etcd

# é‡å¯etcd
systemctl start etcd
"

# 3. éªŒè¯æ¢å¤
echo "3. Verifying restoration..."
sleep 30
kubectl exec -n kube-system $ETCD_POD -- sh -c "
export ETCDCTL_ENDPOINTS=https://127.0.0.1:2379
export ETCDCTL_CACERT=/etc/kubernetes/pki/etcd/ca.crt
export ETCDCTL_CERT=/etc/kubernetes/pki/etcd/server.crt
export ETCDCTL_KEY=/etc/kubernetes/pki/etcd/server.key

etcdctl endpoint health
etcdctl get /registry/namespaces/default
"

echo "etcd rollback completed"
EOF

chmod +x etcd-rollback.sh
```

---

## 4. èŠ‚ç‚¹ç»„ä»¶å‡çº§æ•…éšœæ’æŸ¥ (Node Component Upgrade Troubleshooting)

### 4.1 kubeletå‡çº§é—®é¢˜

```bash
# ========== 1. kubeletçŠ¶æ€æ£€æŸ¥ ==========
# æ£€æŸ¥èŠ‚ç‚¹kubeletç‰ˆæœ¬
kubectl get nodes -o jsonpath='{
    range .items[*]
}{
        .metadata.name
}{
        "\t"
}{
        .status.nodeInfo.kubeletVersion
}{
        "\t"
}{
        .status.conditions[?(@.type=="Ready")].status
}{
        "\n"
}{
    end
}'

# æŸ¥çœ‹èŠ‚ç‚¹è¯¦ç»†çŠ¶æ€
kubectl describe node <node-name>

# æ£€æŸ¥kubeleté…ç½®
kubectl debug node/<node-name> --image=busybox -it -- sh -c "
cat /var/lib/kubelet/config.yaml
ps aux | grep kubelet
"

# ========== 2. å‡çº§å…¼å®¹æ€§éªŒè¯ ==========
# æ£€æŸ¥èŠ‚ç‚¹æ±¡ç‚¹å’Œå®¹å¿åº¦
kubectl get nodes -o jsonpath='{
    range .items[*]
}{
        .metadata.name
}{
        "\t"
}{
        .spec.taints
}{
        "\n"
}{
    end
}'

# éªŒè¯Podé©±é€ç­–ç•¥
kubectl get pods -A -o jsonpath='{
    range .items[*]
}{
        .metadata.namespace
}{
        "/"
}{
        .metadata.name
}{
        "\t"
}{
        .metadata.annotations."cluster-autoscaler\.kubernetes\.io/safe-to-evict"
}{
        "\n"
}{
    end
}' | grep -v "true"

# ========== 3. å‡çº§è¿‡ç¨‹ç›‘æ§ ==========
# ç›‘æ§èŠ‚ç‚¹å‡çº§è¿›åº¦
cat <<'EOF' > node-upgrade-monitor.sh
#!/bin/bash

echo "Monitoring node upgrade progress..."

while true; do
    TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S')
    
    echo "$TIMESTAMP === Node Status ==="
    kubectl get nodes -o jsonpath='{
        range .items[*]
    }{
            .metadata.name
    }{
            "\t"
    }{
            .status.nodeInfo.kubeletVersion
    }{
            "\t"
    }{
            .status.conditions[?(@.type=="Ready")].status
    }{
            "\n"
    }{
        end
    }'
    
    # æ£€æŸ¥å‡çº§ç›¸å…³çš„äº‹ä»¶
    echo "$TIMESTAMP === Recent Upgrade Events ==="
    kubectl get events --field-selector reason=NodeReady,reason=NodeNotReady --sort-by='.lastTimestamp' | tail -5
    
    # æ£€æŸ¥DaemonSetçŠ¶æ€
    echo "$TIMESTAMP === DaemonSet Status ==="
    kubectl get daemonsets -A -o jsonpath='{
        range .items[*]
    }{
            .metadata.namespace
    }{
            "/"
    }{
            .metadata.name
    }{
            "\t"
    }{
            .status.numberReady
    }{
            "/"
    }{
            .status.desiredNumberScheduled
    }{
            "\n"
    }{
        end
    }'
    
    echo "---"
    sleep 30
done
EOF

chmod +x node-upgrade-monitor.sh
```

### 4.2 å®¹å™¨è¿è¡Œæ—¶å…¼å®¹æ€§

```bash
# ========== å®¹å™¨è¿è¡Œæ—¶çŠ¶æ€æ£€æŸ¥ ==========
# æ£€æŸ¥å®¹å™¨è¿è¡Œæ—¶ç‰ˆæœ¬
kubectl get nodes -o jsonpath='{
    range .items[*]
}{
        .metadata.name
}{
        "\t"
}{
        .status.nodeInfo.containerRuntimeVersion
}{
        "\n"
}{
    end
}'

# éªŒè¯CRIå…¼å®¹æ€§
kubectl debug node/<node-name> --image=busybox -it -- crictl info

# æ£€æŸ¥é•œåƒå…¼å®¹æ€§
kubectl debug node/<node-name> --image=busybox -it -- crictl images

# ========== è¿è¡Œæ—¶å‡çº§éªŒè¯ ==========
# åˆ›å»ºå®¹å™¨è¿è¡Œæ—¶å…¼å®¹æ€§æµ‹è¯•
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: runtime-compatibility-test
  namespace: default
spec:
  containers:
  - name: test-container
    image: busybox
    command: ["sh", "-c", "echo 'Runtime test successful' && sleep 3600"]
    # æµ‹è¯•ä¸åŒçš„å®‰å…¨ä¸Šä¸‹æ–‡
    securityContext:
      runAsNonRoot: true
      runAsUser: 1000
  # æµ‹è¯•ç‰¹æƒå®¹å™¨
  - name: privileged-test
    image: busybox
    command: ["sh", "-c", "mount && sleep 3600"]
    securityContext:
      privileged: true
  # æµ‹è¯•ä¸»æœºç½‘ç»œ
  hostNetwork: true
EOF

# éªŒè¯æµ‹è¯•ç»“æœ
kubectl logs runtime-compatibility-test -c test-container
kubectl logs runtime-compatibility-test -c privileged-test
```

---

## 5. å·¥ä½œè´Ÿè½½è¿ç§»é—®é¢˜æ’æŸ¥ (Workload Migration Troubleshooting)

### 5.1 åº”ç”¨å…¼å®¹æ€§éªŒè¯

```bash
# ========== 1. APIå…¼å®¹æ€§æ£€æŸ¥ ==========
# æ£€æŸ¥åº”ç”¨ä½¿ç”¨çš„APIç‰ˆæœ¬
kubectl get deployments --all-namespaces -o jsonpath='{
    range .items[*]
}{
        .metadata.namespace
}{
        "/"
}{
        .metadata.name
}{
        "\t"
}{
        .spec.template.spec.containers[*].env[*].valueFrom.fieldRef.apiVersion
}{
        "\n"
}{
    end
}' | sort | uniq -c

# éªŒè¯Ingress APIç‰ˆæœ¬
kubectl get ingress --all-namespaces -o jsonpath='{
    range .items[*]
}{
        .metadata.namespace
}{
        "/"
}{
        .metadata.name
}{
        "\t"
}{
        .apiVersion
}{
        "\n"
}{
    end
}'

# æ£€æŸ¥NetworkPolicyå…¼å®¹æ€§
kubectl get networkpolicy --all-namespaces -o jsonpath='{
    range .items[*]
}{
        .metadata.namespace
}{
        "/"
}{
        .metadata.name
}{
        "\t"
}{
        .apiVersion
}{
        "\n"
}{
    end
}'

# ========== 2. å­˜å‚¨å…¼å®¹æ€§æ£€æŸ¥ ==========
# æ£€æŸ¥PV/PVCé…ç½®
kubectl get pv -o jsonpath='{
    range .items[*]
}{
        .metadata.name
}{
        "\t"
}{
        .spec.csi.driver
}{
        "\t"
}{
        .spec.accessModes
}{
        "\n"
}{
    end
}'

# éªŒè¯å­˜å‚¨ç±»å…¼å®¹æ€§
kubectl get storageclass -o jsonpath='{
    range .items[*]
}{
        .metadata.name
}{
        "\t"
}{
        .provisioner
}{
        "\t"
}{
        .parameters
}{
        "\n"
}{
    end
}'

# ========== 3. ç½‘ç»œç­–ç•¥éªŒè¯ ==========
# æ£€æŸ¥CNIæ’ä»¶å…¼å®¹æ€§
kubectl get pods -n kube-system -l k8s-app -o jsonpath='{
    range .items[*]
}{
        .metadata.labels.k8s-app
}{
        "\t"
}{
        .spec.containers[*].image
}{
        "\n"
}{
    end
}' | grep -E "(calico|flannel|cilium|weave)"

# éªŒè¯ç½‘ç»œç­–ç•¥åŠŸèƒ½
kubectl run network-test --image=busybox -n test -it --rm -- sh -c "
ping -c 3 8.8.8.8
nslookup kubernetes.default
"
```

### 5.2 æ»šåŠ¨å‡çº§ç­–ç•¥ä¼˜åŒ–

```bash
# ========== ä¼˜é›…å‡çº§é…ç½® ==========
# é…ç½®æ»šåŠ¨å‡çº§ç­–ç•¥
cat <<EOF > graceful-upgrade-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: graceful-upgrade-app
  namespace: production
spec:
  replicas: 6
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1      # æœ€å¤§ä¸å¯ç”¨Podæ•°
      maxSurge: 1            # æœ€å¤§é¢å¤–Podæ•°
  selector:
    matchLabels:
      app: graceful-app
  template:
    metadata:
      labels:
        app: graceful-app
    spec:
      containers:
      - name: app
        image: myapp:latest
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        # ä¼˜é›…ç»ˆæ­¢é…ç½®
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 15"]
        terminationGracePeriodSeconds: 30
      # å‡çº§æœŸé—´çš„å®¹å¿åº¦
      tolerations:
      - key: "node.kubernetes.io/not-ready"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 300
      - key: "node.kubernetes.io/unreachable"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 300
EOF

# ========== è“ç»¿éƒ¨ç½²ç­–ç•¥ ==========
# åˆ›å»ºè“ç»¿éƒ¨ç½²é…ç½®
cat <<EOF > blue-green-deployment.yaml
# è“è‰²ç¯å¢ƒ (å½“å‰ç‰ˆæœ¬)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-blue
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: blue
  template:
    metadata:
      labels:
        app: myapp
        version: blue
    spec:
      containers:
      - name: app
        image: myapp:v1.0
---
# ç»¿è‰²ç¯å¢ƒ (æ–°ç‰ˆæœ¬)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-green
  namespace: production
spec:
  replicas: 0  # åˆå§‹ä¸º0ï¼Œå‡çº§æ—¶å¢åŠ 
  selector:
    matchLabels:
      app: myapp
      version: green
  template:
    metadata:
      labels:
        app: myapp
        version: green
    spec:
      containers:
      - name: app
        image: myapp:v2.0
---
# æœåŠ¡æŒ‡å‘è“è‰²ç¯å¢ƒ
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
  namespace: production
spec:
  selector:
    app: myapp
    version: blue  # å‡çº§æ—¶åˆ‡æ¢åˆ°green
  ports:
  - port: 80
    targetPort: 8080
EOF
```

---

## 6. å›æ»šå’Œæ¢å¤ç­–ç•¥ (Rollback and Recovery Strategies)

### 6.1 è‡ªåŠ¨å›æ»šæœºåˆ¶

```bash
# ========== å¥åº·æ£€æŸ¥å’Œå›æ»š ==========
# é…ç½®å¸¦æœ‰å¥åº·æ£€æŸ¥çš„Deployment
cat <<EOF > self-healing-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: self-healing-app
  namespace: production
spec:
  replicas: 3
  revisionHistoryLimit: 10  # ä¿ç•™10ä¸ªå†å²ç‰ˆæœ¬
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app: self-healing-app
  template:
    metadata:
      labels:
        app: self-healing-app
    spec:
      containers:
      - name: app
        image: myapp:latest
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          failureThreshold: 3
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          failureThreshold: 5
          periodSeconds: 15
---
# é…ç½®Pod Disruption Budget
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: self-healing-pdb
  namespace: production
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: self-healing-app
EOF

# ========== å›æ»šæ£€æµ‹è„šæœ¬ ==========
cat <<'EOF' > rollback-detector.sh
#!/bin/bash

DEPLOYMENT_NAME=$1
NAMESPACE=${2:-default}
FAILURE_THRESHOLD=${3:-5}

if [ -z "$DEPLOYMENT_NAME" ]; then
    echo "Usage: $0 <deployment-name> [namespace] [failure-threshold]"
    exit 1
fi

echo "Monitoring deployment: $DEPLOYMENT_NAME in namespace: $NAMESPACE"

CONSECUTIVE_FAILURES=0
LAST_REVISION=$(kubectl rollout history deployment/$DEPLOYMENT_NAME -n $NAMESPACE --revision=0 2>/dev/null | tail -1 | awk '{print $1}')

while true; do
    # æ£€æŸ¥éƒ¨ç½²çŠ¶æ€
    READY_REPLICAS=$(kubectl get deployment $DEPLOYMENT_NAME -n $NAMESPACE -o jsonpath='{.status.readyReplicas}')
    AVAILABLE_REPLICAS=$(kubectl get deployment $DEPLOYMENT_NAME -n $NAMESPACE -o jsonpath='{.status.availableReplicas}')
    UPDATED_REPLICAS=$(kubectl get deployment $DEPLOYMENT_NAME -n $NAMESPACE -o jsonpath='{.status.updatedReplicas}')
    REPLICAS=$(kubectl get deployment $DEPLOYMENT_NAME -n $NAMESPACE -o jsonpath='{.spec.replicas}')
    
    echo "$(date): Ready: $READY_REPLICAS/$REPLICAS, Available: $AVAILABLE_REPLICAS/$REPLICAS, Updated: $UPDATED_REPLICAS/$REPLICAS"
    
    # æ£€æŸ¥å¥åº·çŠ¶å†µ
    if [ "$READY_REPLICAS" -lt "$REPLICAS" ] || [ "$AVAILABLE_REPLICAS" -lt "$REPLICAS" ]; then
        CONSECUTIVE_FAILURES=$((CONSECUTIVE_FAILURES + 1))
        echo "âš ï¸  Health check failed ($CONSECUTIVE_FAILURES/$FAILURE_THRESHOLD)"
        
        if [ $CONSECUTIVE_FAILURES -ge $FAILURE_THRESHOLD ]; then
            echo "ğŸš¨ Initiating rollback due to consecutive failures"
            
            # æ‰§è¡Œå›æ»š
            kubectl rollout undo deployment/$DEPLOYMENT_NAME -n $NAMESPACE
            
            # ç­‰å¾…å›æ»šå®Œæˆ
            kubectl rollout status deployment/$DEPLOYMENT_NAME -n $NAMESPACE --timeout=300s
            
            echo "âœ… Rollback completed"
            break
        fi
    else
        CONSECUTIVE_FAILURES=0
        echo "âœ“ Health check passed"
    fi
    
    sleep 30
done
EOF

chmod +x rollback-detector.sh
```

### 6.2 ç¾éš¾æ¢å¤æµç¨‹

```bash
# ========== å®Œæ•´é›†ç¾¤æ¢å¤ ==========
# åˆ›å»ºç¾éš¾æ¢å¤è„šæœ¬
cat <<'EOF' > disaster-recovery.sh
#!/bin/bash

BACKUP_LOCATION=$1
RESTORE_NAMESPACE=${2:-all}

if [ -z "$BACKUP_LOCATION" ]; then
    echo "Usage: $0 <backup-location> [namespace]"
    exit 1
fi

echo "=== Kubernetes Disaster Recovery ==="
echo "Backup location: $BACKUP_LOCATION"
echo "Restore namespace: $RESTORE_NAMESPACE"

# 1. ç¯å¢ƒå‡†å¤‡
echo "1. Preparing recovery environment..."
kubectl create namespace recovery-temp 2>/dev/null || echo "Namespace already exists"

# 2. æ¢å¤é›†ç¾¤èµ„æº
echo "2. Restoring cluster resources..."

if [ "$RESTORE_NAMESPACE" = "all" ]; then
    # æ¢å¤æ‰€æœ‰å‘½åç©ºé—´
    for ns_dir in $BACKUP_LOCATION/*/; do
        NS_NAME=$(basename $ns_dir)
        echo "Restoring namespace: $NS_NAME"
        
        # åˆ›å»ºå‘½åç©ºé—´
        kubectl create namespace $NS_NAME 2>/dev/null || echo "Namespace $NS_NAME already exists"
        
        # æ¢å¤èµ„æº
        for resource_file in $ns_dir/*.yaml; do
            if [ -f "$resource_file" ]; then
                echo "  Applying $resource_file"
                kubectl apply -f $resource_file -n $NS_NAME 2>/dev/null || echo "    Failed to apply $resource_file"
            fi
        done
    done
else
    # æ¢å¤ç‰¹å®šå‘½åç©ºé—´
    echo "Restoring namespace: $RESTORE_NAMESPACE"
    kubectl create namespace $RESTORE_NAMESPACE 2>/dev/null || echo "Namespace already exists"
    
    for resource_file in $BACKUP_LOCATION/$RESTORE_NAMESPACE/*.yaml; do
        if [ -f "$resource_file" ]; then
            echo "  Applying $resource_file"
            kubectl apply -f $resource_file -n $RESTORE_NAMESPACE 2>/dev/null || echo "    Failed to apply $resource_file"
        fi
    done
fi

# 3. éªŒè¯æ¢å¤çŠ¶æ€
echo "3. Verifying recovery status..."

if [ "$RESTORE_NAMESPACE" = "all" ]; then
    kubectl get namespaces
    for ns in $(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}' | xargs -n1 | grep -v -E "(kube-system|kube-public|kube-node-lease)"); do
        echo "Checking namespace: $ns"
        kubectl get deployments,services -n $ns
    done
else
    echo "Checking namespace: $RESTORE_NAMESPACE"
    kubectl get deployments,services -n $RESTORE_NAMESPACE
fi

# 4. åº”ç”¨å¥åº·æ£€æŸ¥
echo "4. Performing health checks..."
HEALTHY_DEPLOYMENTS=0
TOTAL_DEPLOYMENTS=0

for deploy in $(kubectl get deployments --all-namespaces -o jsonpath='{range .items[*]}{.metadata.namespace}/{.metadata.name}{"\n"}{end}'); do
    NS=$(echo $deploy | cut -d/ -f1)
    DEPLOY_NAME=$(echo $deploy | cut -d/ -f2)
    
    READY=$(kubectl get deployment $DEPLOY_NAME -n $NS -o jsonpath='{.status.readyReplicas}')
    DESIRED=$(kubectl get deployment $DEPLOY_NAME -n $NS -o jsonpath='{.status.replicas}')
    
    TOTAL_DEPLOYMENTS=$((TOTAL_DEPLOYMENTS + 1))
    if [ "$READY" = "$DESIRED" ] && [ -n "$READY" ]; then
        HEALTHY_DEPLOYMENTS=$((HEALTHY_DEPLOYMENTS + 1))
        echo "  âœ“ $deploy: $READY/$DESIRED ready"
    else
        echo "  âœ— $deploy: $READY/$DESIRED ready"
    fi
done

echo "Recovery Summary:"
echo "  Healthy deployments: $HEALTHY_DEPLOYMENTS/$TOTAL_DEPLOYMENTS"
echo "  Success rate: $((HEALTHY_DEPLOYMENTS * 100 / TOTAL_DEPLOYMENTS))%"

# 5. æ¸…ç†ä¸´æ—¶èµ„æº
kubectl delete namespace recovery-temp

echo "Disaster recovery process completed"
EOF

chmod +x disaster-recovery.sh

# ========== æ¢å¤éªŒè¯æ¸…å• ==========
cat <<'EOF' > recovery-validation-checklist.md
# Kubernetes æ¢å¤éªŒè¯æ¸…å•

## åŸºç¡€è®¾æ–½éªŒè¯
- [ ] Control Planeç»„ä»¶è¿è¡Œæ­£å¸¸
- [ ] etcdé›†ç¾¤å¥åº·çŠ¶æ€
- [ ] æ‰€æœ‰èŠ‚ç‚¹å¤„äºReadyçŠ¶æ€
- [ ] ç½‘ç»œæ’ä»¶åŠŸèƒ½æ­£å¸¸
- [ ] å­˜å‚¨æ’ä»¶åŠŸèƒ½æ­£å¸¸

## åº”ç”¨éªŒè¯
- [ ] æ ¸å¿ƒåº”ç”¨Podè¿è¡Œæ­£å¸¸
- [ ] æœåŠ¡ç«¯ç‚¹å¯è¾¾
- [ ] Ingressè·¯ç”±åŠŸèƒ½æ­£å¸¸
- [ ] æ•°æ®åº“è¿æ¥æ­£å¸¸
- [ ] å¤–éƒ¨ä¾èµ–æœåŠ¡å¯è¾¾

## ç›‘æ§å’Œå‘Šè­¦
- [ ] PrometheusæŒ‡æ ‡æ”¶é›†æ­£å¸¸
- [ ] Alertmanagerå‘Šè­¦åŠŸèƒ½æ­£å¸¸
- [ ] Grafanaä»ªè¡¨æ¿æ˜¾ç¤ºæ­£å¸¸
- [ ] æ—¥å¿—æ”¶é›†ç³»ç»Ÿè¿è¡Œæ­£å¸¸

## å®‰å…¨éªŒè¯
- [ ] RBACæƒé™é…ç½®æ­£ç¡®
- [ ] ç½‘ç»œç­–ç•¥ç”Ÿæ•ˆ
- [ ] Secretå’ŒConfigMapåŠ è½½æ­£å¸¸
- [ ] TLSè¯ä¹¦æœ‰æ•ˆ

## æ€§èƒ½éªŒè¯
- [ ] åº”ç”¨å“åº”æ—¶é—´åœ¨å¯æ¥å—èŒƒå›´å†…
- [ ] èµ„æºä½¿ç”¨ç‡æ­£å¸¸
- [ ] æ²¡æœ‰æ˜æ˜¾çš„æ€§èƒ½é€€åŒ–

## ä¸šåŠ¡éªŒè¯
- [ ] æ ¸å¿ƒä¸šåŠ¡æµç¨‹å¯æ‰§è¡Œ
- [ ] ç”¨æˆ·å¯ä»¥æ­£å¸¸è®¿é—®æœåŠ¡
- [ ] æ•°æ®ä¸€è‡´æ€§å’Œå®Œæ•´æ€§éªŒè¯
- [ ] ç¬¬ä¸‰æ–¹é›†æˆæœåŠ¡æ­£å¸¸
EOF
```

---

## 7. å‡çº§æœ€ä½³å®è·µ (Upgrade Best Practices)

### 7.1 åˆ†é˜¶æ®µå‡çº§ç­–ç•¥

```bash
# ========== é‡‘ä¸é›€å‡çº§é…ç½® ==========
# åˆ›å»ºé‡‘ä¸é›€å‡çº§éƒ¨ç½²
cat <<EOF > canary-upgrade.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-canary
  namespace: production
  labels:
    app: myapp
    track: canary
spec:
  replicas: 1  # å°‘é‡å‰¯æœ¬ç”¨äºæµ‹è¯•
  selector:
    matchLabels:
      app: myapp
      track: canary
  template:
    metadata:
      labels:
        app: myapp
        track: canary
    spec:
      containers:
      - name: app
        image: myapp:new-version
        ports:
        - containerPort: 8080
        env:
        - name: CANARY_ENABLED
          value: "true"
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "200m"
            memory: "256Mi"
---
# é‡‘ä¸é›€æœåŠ¡
apiVersion: v1
kind: Service
metadata:
  name: app-canary-service
  namespace: production
spec:
  selector:
    app: myapp
    track: canary
  ports:
  - port: 80
    targetPort: 8080
---
# é‡‘ä¸é›€Ingressï¼ˆå¯é€‰ï¼‰
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app-canary-ingress
  namespace: production
  annotations:
    nginx.ingress.kubernetes.io/canary: "true"
    nginx.ingress.kubernetes.io/canary-weight: "10"  # 10%æµé‡
spec:
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: app-canary-service
            port:
              number: 80
EOF

# ========== åˆ†åŒºå‡çº§è„šæœ¬ ==========
cat <<'EOF' > phased-upgrade.sh
#!/bin/bash

UPGRADE_VERSION=$1
NODE_GROUPS=("control-plane" "worker-pool-1" "worker-pool-2")

if [ -z "$UPGRADE_VERSION" ]; then
    echo "Usage: $0 <target-version>"
    exit 1
fi

echo "=== Phased Upgrade to $UPGRADE_VERSION ==="

# 1. å‡çº§Control Plane
echo "Phase 1: Upgrading Control Plane"
for node in $(kubectl get nodes -l node-role.kubernetes.io/control-plane -o jsonpath='{.items[*].metadata.name}'); do
    echo "Upgrading control plane node: $node"
    # è¿™é‡Œæ·»åŠ å…·ä½“çš„å‡çº§å‘½ä»¤
    # kubeadm upgrade node ...
done

# ç­‰å¾…Control Planeç¨³å®š
echo "Waiting for Control Plane stabilization..."
sleep 120

# 2. éªŒè¯Control Plane
echo "Verifying Control Plane..."
kubectl get componentstatuses
kubectl get nodes -l node-role.kubernetes.io/control-plane

# 3. åˆ†æ‰¹å‡çº§WorkerèŠ‚ç‚¹
for group in "${NODE_GROUPS[@]:1}"; do
    echo "Phase: Upgrading $group"
    
    NODES=$(kubectl get nodes -l node-group=$group -o jsonpath='{.items[*].metadata.name}')
    NODE_ARRAY=($NODES)
    
    # åˆ†æ‰¹å¤„ç†ï¼ˆæ¯æ¬¡2ä¸ªèŠ‚ç‚¹ï¼‰
    for ((i=0; i<${#NODE_ARRAY[@]}; i+=2)); do
        BATCH_NODES=("${NODE_ARRAY[@]:i:2}")
        echo "Upgrading batch: ${BATCH_NODES[*]}"
        
        # é©±é€Pod
        for node in "${BATCH_NODES[@]}"; do
            echo "Draining node: $node"
            kubectl drain $node --ignore-daemonsets --delete-emptydir-data
        done
        
        # æ‰§è¡Œå‡çº§
        for node in "${BATCH_NODES[@]}"; do
            echo "Upgrading node: $node"
            # ssh $node "yum update kubelet kubeadm kubectl"
            # systemctl restart kubelet
        done
        
        # éªŒè¯èŠ‚ç‚¹çŠ¶æ€
        sleep 60
        for node in "${BATCH_NODES[@]}"; do
            kubectl uncordon $node
            kubectl get node $node
        done
        
        # éªŒè¯å·¥ä½œè´Ÿè½½
        sleep 120
        kubectl get pods -A --field-selector=spec.nodeName==$node
    done
done

echo "Phased upgrade completed"
EOF

chmod +x phased-upgrade.sh
```

### 7.2 å‡çº§éªŒè¯å’Œç›‘æ§

```bash
# ========== å‡çº§éªŒè¯å·¥å…· ==========
cat <<'EOF' > upgrade-validator.sh
#!/bin/bash

TARGET_VERSION=$1

if [ -z "$TARGET_VERSION" ]; then
    echo "Usage: $0 <target-version>"
    exit 1
fi

echo "=== Kubernetes Upgrade Validator ==="
echo "Target version: $TARGET_VERSION"

# 1. é¢„å‡çº§æ£€æŸ¥
echo "1. Pre-upgrade validation..."

# æ£€æŸ¥å½“å‰ç‰ˆæœ¬
CURRENT_VERSION=$(kubectl version --short | grep Server | awk '{print $3}')
echo "Current version: $CURRENT_VERSION"

# æ£€æŸ¥å‡çº§è·¯å¾„
if [[ "$CURRENT_VERSION" != *"$TARGET_VERSION"* ]]; then
    echo "âœ“ Version upgrade path valid"
else
    echo "âš ï¸  Same version detected"
fi

# 2. èµ„æºå…¼å®¹æ€§æ£€æŸ¥
echo "2. Resource compatibility check..."
./deprecated-api-checker.sh $TARGET_VERSION

# 3. ç»„ä»¶å¥åº·æ£€æŸ¥
echo "3. Component health check..."
kubectl get componentstatuses -o jsonpath='{
    range .items[*]
}{
        .metadata.name
}{
        "\t"
}{
        .conditions[?(@.type=="Healthy")].status
}{
        "\n"
}{
    end
}'

# 4. èŠ‚ç‚¹çŠ¶æ€æ£€æŸ¥
echo "4. Node status check..."
kubectl get nodes -o jsonpath='{
    range .items[*]
}{
        .metadata.name
}{
        "\t"
}{
        .status.conditions[?(@.type=="Ready")].status
}{
        "\n"
}{
    end
}' | grep -v "True" && echo "âš ï¸  Some nodes not ready"

# 5. å·¥ä½œè´Ÿè½½æ£€æŸ¥
echo "5. Workload status check..."
kubectl get deployments --all-namespaces -o jsonpath='{
    range .items[*]
}{
        .metadata.namespace
}{
        "/"
}{
        .metadata.name
}{
        "\t"
}{
        .status.readyReplicas
}{
        "/"
}{
        .status.replicas
}{
        "\n"
}{
    end
}' | awk '$3 != $4 {print "âš ï¸  " $0}'

echo "Upgrade validation completed"
EOF

chmod +x upgrade-validator.sh

# ========== å‡çº§ç›‘æ§ä»ªè¡¨æ¿ ==========
cat <<'EOF' > upgrade-monitoring-dashboard.json
{
  "dashboard": {
    "title": "Kubernetes Upgrade Monitoring",
    "panels": [
      {
        "title": "Upgrade Progress",
        "type": "stat",
        "targets": [
          {
            "expr": "count(kube_node_info{version=\"$target_version\"})",
            "legendFormat": "Upgraded Nodes"
          },
          {
            "expr": "count(kube_node_info)",
            "legendFormat": "Total Nodes"
          }
        ]
      },
      {
        "title": "Component Health",
        "type": "graph",
        "targets": [
          {
            "expr": "up{job=\"kubernetes-apiservers\"}",
            "legendFormat": "API Server"
          },
          {
            "expr": "up{job=\"kubernetes-nodes\"}",
            "legendFormat": "Kubelet"
          }
        ]
      },
      {
        "title": "Workload Availability",
        "type": "graph",
        "targets": [
          {
            "expr": "kube_deployment_status_replicas_available",
            "legendFormat": "{{deployment}}"
          }
        ]
      },
      {
        "title": "Upgrade Events",
        "type": "table",
        "targets": [
          {
            "expr": "kube_event_count{reason=~\"NodeReady|NodeNotReady|Upgrade\"}",
            "legendFormat": "{{reason}}"
          }
        ]
      }
    ]
  }
}
EOF
```

---