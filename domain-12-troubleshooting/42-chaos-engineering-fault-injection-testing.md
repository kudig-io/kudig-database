# 42 - æ··æ²Œå·¥ç¨‹å’Œæ•…éšœæ³¨å…¥æµ‹è¯• (Chaos Engineering and Fault Injection Testing)

> **é€‚ç”¨ç‰ˆæœ¬**: Kubernetes v1.25-v1.32 | **æœ€åæ›´æ–°**: 2026-02 | **ä¸“å®¶çº§åˆ«**: â­â­â­â­â­ | **å‚è€ƒ**: [Chaos Engineering Principles](https://principlesofchaos.org/), [Chaos Mesh Documentation](https://chaos-mesh.org/docs/), [LitmusChaos Documentation](https://docs.litmuschaos.io/)

---

## ç›¸å…³æ–‡æ¡£äº¤å‰å¼•ç”¨

### ğŸ”— å…³è”æ•…éšœæ’æŸ¥æ–‡æ¡£
- **[06-Node NotReadyè¯Šæ–­](./06-node-notready-diagnosis.md)** - èŠ‚ç‚¹æ•…éšœæ³¨å…¥æµ‹è¯•
- **[07-OOMå†…å­˜è¯Šæ–­](./07-oom-memory-diagnosis.md)** - å†…å­˜å‹åŠ›æ•…éšœæµ‹è¯•
- **[33-æ€§èƒ½ç“¶é¢ˆæ•…éšœæ’æŸ¥](./33-performance-bottleneck-troubleshooting.md)** - æ€§èƒ½é€€åŒ–æµ‹è¯•
- **[34-å‡çº§è¿ç§»æ•…éšœæ’æŸ¥](./34-upgrade-migration-troubleshooting.md)** - å‡çº§è¿‡ç¨‹ä¸­æ–­æµ‹è¯•
- **[39-ä¼ä¸šçº§ç›‘æ§å‘Šè­¦ä½“ç³»](./39-enterprise-monitoring-alerting-system.md)** - æ··æ²Œå®éªŒç›‘æ§å‘Šè­¦é…ç½®
- **[41-äº‹ä»¶é©±åŠ¨æ¶æ„æ•…éšœæ’æŸ¥](./41-event-driven-architecture-troubleshooting.md)** - äº‹ä»¶æµç³»ç»ŸéŸ§æ€§æµ‹è¯•

### ğŸ“š æ‰©å±•å­¦ä¹ èµ„æ–™
- **[æ··æ²Œå·¥ç¨‹åŸåˆ™](https://principlesofchaos.org/)** - æ··æ²Œå·¥ç¨‹ç†è®ºåŸºç¡€
- **[Gremlinæ··æ²Œå¹³å°](https://www.gremlin.com/)** - å•†ä¸šæ··æ²Œå·¥ç¨‹å¹³å°
- **[Netflix Chaos Monkey](https://github.com/Netflix/chaosmonkey)** - ç»å…¸æ··æ²Œå·¥ç¨‹å·¥å…·

---

## ç›®å½•

1. [æ··æ²Œå·¥ç¨‹åŸºç¡€ç†è®º](#1-æ··æ²Œå·¥ç¨‹åŸºç¡€ç†è®º)
2. [Chaos Meshå®æˆ˜æŒ‡å—](#2-chaos-meshå®æˆ˜æŒ‡å—)
3. [LitmusChaoså®è·µ](#3-litmuschaoså®è·µ)
4. [æ•…éšœæ³¨å…¥åœºæ™¯è®¾è®¡](#4-æ•…éšœæ³¨å…¥åœºæ™¯è®¾è®¡)
5. [å®éªŒç›‘æ§ä¸åˆ†æ](#5-å®éªŒç›‘æ§ä¸åˆ†æ)
6. [å®‰å…¨ä¸é£é™©æ§åˆ¶](#6-å®‰å…¨ä¸é£é™©æ§åˆ¶)
7. [æœ€ä½³å®è·µä¸æ¡ˆä¾‹](#7-æœ€ä½³å®è·µä¸æ¡ˆä¾‹)

---

## 1. æ··æ²Œå·¥ç¨‹åŸºç¡€ç†è®º

### 1.1 æ··æ²Œå·¥ç¨‹æ ¸å¿ƒåŸåˆ™

#### æ··æ²Œå·¥ç¨‹å››åŸåˆ™ä½“ç³»
```
æ··æ²Œå·¥ç¨‹æ ¸å¿ƒåŸåˆ™æ¶æ„:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          æ··æ²Œå·¥ç¨‹åŸåˆ™ä½“ç³»                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Principle 1: Build Hypothesis around Steady State Behavior                 â”‚
â”‚  åŸåˆ™ä¸€ï¼šå›´ç»•ç¨³æ€è¡Œä¸ºå»ºç«‹å‡è®¾                                               â”‚
â”‚  â”œâ”€ å®šä¹‰ç³»ç»Ÿæ­£å¸¸è¡Œä¸ºåŸºçº¿                                                   â”‚
â”‚  â”œâ”€ å»ºç«‹å…³é”®ä¸šåŠ¡æŒ‡æ ‡                                                       â”‚
â”‚  â””â”€ ç¡®å®šå¯æ¥å—çš„åå·®èŒƒå›´                                                   â”‚
â”‚                                                                             â”‚
â”‚  Principle 2: Vary Real-world Events                                        â”‚
â”‚  åŸåˆ™äºŒï¼šå¼•å…¥çœŸå®ä¸–ç•Œäº‹ä»¶                                                   â”‚
â”‚  â”œâ”€ ç¡¬ä»¶æ•…éšœï¼ˆç£ç›˜ã€ç½‘ç»œã€CPUï¼‰                                            â”‚
â”‚  â”œâ”€ è½¯ä»¶æ•…éšœï¼ˆè¿›ç¨‹å´©æºƒã€å†…å­˜æ³„æ¼ï¼‰                                         â”‚
â”‚  â”œâ”€ ç½‘ç»œé—®é¢˜ï¼ˆå»¶è¿Ÿã€ä¸¢åŒ…ã€åˆ†åŒºï¼‰                                           â”‚
â”‚  â””â”€ èµ„æºç«äº‰ï¼ˆCPUã€å†…å­˜ã€I/Oäº‰ç”¨ï¼‰                                         â”‚
â”‚                                                                             â”‚
â”‚  Principle 3: Run Experiments in Production                                â”‚
â”‚  åŸåˆ™ä¸‰ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒä¸­è¿è¡Œå®éªŒ                                               â”‚
â”‚  â”œâ”€ æ¸è¿›å¼å®éªŒç­–ç•¥                                                         â”‚
â”‚  â”œâ”€ æœ€å°åŒ–çˆ†ç‚¸åŠå¾„                                                         â”‚
â”‚  â”œâ”€ å®æ—¶ç›‘æ§å’Œå¿«é€Ÿå›æ»š                                                     â”‚
â”‚  â””â”€ ä¸¥æ ¼çš„å‡†å…¥æ§åˆ¶                                                         â”‚
â”‚                                                                             â”‚
â”‚  Principle 4: Automate Experiments to Run Continuously                     â”‚
â”‚  åŸåˆ™å››ï¼šè‡ªåŠ¨åŒ–æŒç»­è¿è¡Œå®éªŒ                                                 â”‚
â”‚  â”œâ”€ å®šæœŸè‡ªåŠ¨åŒ–æµ‹è¯•                                                         â”‚
â”‚  â”œâ”€ CI/CDé›†æˆ                                                              â”‚
â”‚  â”œâ”€ æ™ºèƒ½å®éªŒè°ƒåº¦                                                           â”‚
â”‚  â””â”€ ç»“æœè‡ªåŠ¨åˆ†æ                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 å®éªŒè®¾è®¡æ–¹æ³•è®º

#### æ··æ²Œå®éªŒè®¾è®¡æµç¨‹
```mermaid
graph TD
    A[ç¡®å®šå®éªŒç›®æ ‡] --> B{é£é™©è¯„ä¼°}
    B -->|é«˜é£é™©| C[åˆ¶å®šå®‰å…¨é¢„æ¡ˆ]
    B -->|ä½é£é™©| D[è®¾è®¡å®éªŒåœºæ™¯]
    C --> D
    D --> E[é€‰æ‹©ç›®æ ‡ç³»ç»Ÿ]
    E --> F[å®šä¹‰éªŒè¯æŒ‡æ ‡]
    F --> G[é…ç½®ç›‘æ§å‘Šè­¦]
    G --> H[æ‰§è¡Œå®éªŒ]
    H --> I{è§‚å¯Ÿç³»ç»Ÿååº”}
    I -->|æ­£å¸¸| J[è®°å½•å®éªŒç»“æœ]
    I -->|å¼‚å¸¸| K[è§¦å‘è‡ªåŠ¨å›æ»š]
    K --> L[åˆ†ææ ¹æœ¬åŸå› ]
    J --> L
    L --> M[ä¼˜åŒ–ç³»ç»Ÿè®¾è®¡]
    M --> N[æ›´æ–°æ–‡æ¡£å’Œæµç¨‹]
```

#### å®éªŒå‡è®¾æ¨¡æ¿
```yaml
# chaos_experiment_hypothesis.yaml
experiment:
  name: "pod-kill-under-load-test"
  description: "éªŒè¯åœ¨é«˜è´Ÿè½½æƒ…å†µä¸‹æ€æ­»Podåç³»ç»Ÿçš„è‡ªæ„ˆèƒ½åŠ›"
  
  steady_state_hypothesis:
    title: "ç³»ç»Ÿåœ¨æ­£å¸¸è´Ÿè½½ä¸‹çš„ç¨³æ€è¡Œä¸º"
    probes:
      - name: "api-response-time"
        type: "probe"
        tolerance: 200  # 200mså“åº”æ—¶é—´
        provider:
          type: "python"
          module: "requests"
          func: "get"
          arguments:
            url: "http://my-service/health"
            
      - name: "pod-availability"
        type: "probe"
        tolerance: 0.95  # 95%å¯ç”¨æ€§
        provider:
          type: "kubernetes"
          resource: "deployment"
          name: "my-app"
          
  method:
    - type: "action"
      name: "kill-random-pod"
      provider:
        type: "kubernetes"
        resource: "pod"
        action: "delete"
        selector:
          labels:
            app: "my-app"
          count: 1
          
  rollbacks:
    - type: "action"
      name: "scale-up-deployment"
      provider:
        type: "kubernetes"
        resource: "deployment"
        action: "scale"
        name: "my-app"
        replicas: 3
```

---

## 2. Chaos Meshå®æˆ˜æŒ‡å—

### 2.1 Chaos Meshéƒ¨ç½²é…ç½®

#### 2.1.1 ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
```yaml
# chaos-mesh-production.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: chaos-testing
  labels:
    chaos-mesh.org/role: "control-plane"
    
---
apiVersion: helm.cattle.io/v1
kind: HelmChart
metadata:
  name: chaos-mesh
  namespace: kube-system
spec:
  chart: chaos-mesh
  repo: https://charts.chaos-mesh.org
  targetNamespace: chaos-testing
  valuesContent: |
    controllerManager:
      replicaCount: 3
      resources:
        limits:
          cpu: 500m
          memory: 1Gi
        requests:
          cpu: 100m
          memory: 256Mi
          
    chaosDaemon:
      runtime: containerd
      privileged: true
      resources:
        limits:
          cpu: 200m
          memory: 256Mi
        requests:
          cpu: 50m
          memory: 64Mi
          
    dashboard:
      create: true
      service:
        type: ClusterIP
      resources:
        limits:
          cpu: 200m
          memory: 256Mi
        requests:
          cpu: 50m
          memory: 64Mi
          
    # å®‰å…¨é…ç½®
    securityMode: true
    enableProfiling: false
    enableLeaderElection: true
    
    # ç›‘æ§é›†æˆ
    prometheus:
      create: true
      serviceMonitor:
        enabled: true
```

#### 2.1.2 RBACæƒé™é…ç½®
```yaml
# chaos-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: chaos-operator
  namespace: chaos-testing
  
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: chaos-cluster-role
rules:
# Podç›¸å…³æƒé™
- apiGroups: [""]
  resources: ["pods", "pods/exec", "pods/log"]
  verbs: ["get", "list", "watch", "delete", "create"]
  
# Deploymentç›¸å…³æƒé™
- apiGroups: ["apps"]
  resources: ["deployments", "statefulsets", "daemonsets"]
  verbs: ["get", "list", "watch", "patch", "update"]
  
# ç½‘ç»œç­–ç•¥æƒé™
- apiGroups: ["networking.k8s.io"]
  resources: ["networkpolicies"]
  verbs: ["get", "list", "create", "delete"]
  
# å­˜å‚¨ç›¸å…³æƒé™
- apiGroups: [""]
  resources: ["persistentvolumeclaims", "persistentvolumes"]
  verbs: ["get", "list", "delete"]
  
# ç›‘æ§æƒé™
- apiGroups: ["monitoring.coreos.com"]
  resources: ["servicemonitors"]
  verbs: ["get", "create", "delete"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: chaos-cluster-role-binding
subjects:
- kind: ServiceAccount
  name: chaos-operator
  namespace: chaos-testing
roleRef:
  kind: ClusterRole
  name: chaos-cluster-role
  apiGroup: rbac.authorization.k8s.io
```

### 2.2 æ ¸å¿ƒæ•…éšœç±»å‹å®è·µ

#### 2.2.1 Podæ•…éšœæ³¨å…¥
```yaml
# pod_chaos_experiment.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: pod-kill-experiment
  namespace: chaos-testing
spec:
  action: pod-kill
  mode: one
  selector:
    namespaces:
      - production
    labelSelectors:
      app: user-service
  scheduler:
    cron: "@every 30m"  # æ¯30åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
  duration: "10s"       # æŒç»­10ç§’
  gracePeriod: 0        # ç«‹å³ç»ˆæ­¢
  
---
apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: pod-failure-experiment
  namespace: chaos-testing
spec:
  action: pod-failure
  mode: fixed-percent
  value: "30"  # 30%çš„Pod
  selector:
    namespaces:
      - staging
    labelSelectors:
      app: order-service
  scheduler:
    cron: "@hourly"
  duration: "5m"
```

#### 2.2.2 ç½‘ç»œæ•…éšœæ³¨å…¥
```yaml
# network_chaos_experiment.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: network-delay-experiment
  namespace: chaos-testing
spec:
  action: delay
  mode: all
  selector:
    namespaces:
      - production
    labelSelectors:
      app: payment-service
  delay:
    latency: "300ms"
    correlation: "80"
    jitter: "50ms"
  duration: "2m"
  
---
apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: network-partition-experiment
  namespace: chaos-testing
spec:
  action: partition
  mode: all
  selector:
    namespaces:
      - production
    labelSelectors:
      app: inventory-service
  direction: to
  target:
    selector:
      namespaces:
        - production
      labelSelectors:
        app: database
  duration: "1m"
```

#### 2.2.3 èµ„æºå‹åŠ›æµ‹è¯•
```yaml
# stress_chaos_experiment.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: StressChaos
metadata:
  name: cpu-stress-experiment
  namespace: chaos-testing
spec:
  mode: one
  selector:
    namespaces:
      - staging
    labelSelectors:
      app: recommendation-engine
  stressors:
    cpu:
      workers: 4
      load: 80
  duration: "3m"
  
---
apiVersion: chaos-mesh.org/v1alpha1
kind: StressChaos
metadata:
  name: memory-stress-experiment
  namespace: chaos-testing
spec:
  mode: fixed-percent
  value: "50"
  selector:
    namespaces:
      - production
    labelSelectors:
      component: cache
  stressors:
    memory:
      workers: 2
      size: "1GB"
  duration: "5m"
```

### 2.3 å®éªŒç›‘æ§å’Œå‘Šè­¦

#### 2.3.1 Chaos Meshç›‘æ§é…ç½®
```yaml
# chaos_monitoring.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: chaos-mesh-monitor
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: chaos-mesh
  endpoints:
  - port: http
    interval: 30s
    path: /metrics
    
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: chaos-alerts
  namespace: monitoring
spec:
  groups:
  - name: chaos.rules
    rules:
    # å®éªŒæ‰§è¡Œå‘Šè­¦
    - alert: ChaosExperimentRunning
      expr: chaos_experiment_running == 1
      for: 0m
      labels:
        severity: info
        category: chaos-engineering
      annotations:
        summary: "Chaos experiment {{ $labels.experiment }} is running"
        
    # å®éªŒå¤±è´¥å‘Šè­¦
    - alert: ChaosExperimentFailed
      expr: chaos_experiment_status{status="failed"} == 1
      for: 1m
      labels:
        severity: warning
        category: chaos-engineering
      annotations:
        summary: "Chaos experiment {{ $labels.experiment }} failed"
        
    # ç³»ç»ŸæŒ‡æ ‡å¼‚å¸¸
    - alert: SystemMetricsDegradedDuringChaos
      expr: |
        (rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])) > 2
        and chaos_experiment_running == 1
      for: 2m
      labels:
        severity: critical
        category: chaos-engineering
      annotations:
        summary: "System performance degraded during chaos experiment"
```

---

## 3. LitmusChaoså®è·µ

### 3.1 LitmusChaoséƒ¨ç½²

#### 3.1.1 Operatorå®‰è£…
```bash
# ========== 1. å®‰è£…LitmusChaos Operator ==========
# æ·»åŠ LitmusChaos Helmä»“åº“
helm repo add litmuschaos https://litmuschaos.github.io/litmus-helm/
helm repo update

# åˆ›å»ºLitmuså‘½åç©ºé—´
kubectl create ns litmus

# å®‰è£…LitmusChaos Operator
helm install chaos-operator litmuschaos/litmuschaos \
  --namespace litmus \
  --set portal.frontend.service.type=ClusterIP \
  --set portal.server.service.type=ClusterIP

# éªŒè¯å®‰è£…
kubectl get pods -n litmus
kubectl get crds | grep litmus
```

#### 3.1.2 å®éªŒæ‰§è¡Œå™¨å®‰è£…
```yaml
# litmus_experiment_runners.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: litmus-admin
  namespace: litmus
  
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: litmus-cluster-role
rules:
- apiGroups: ["","apps","batch","extensions","litmuschaos.io","monitoring.coreos.com"]
  resources: ["*"]
  verbs: ["*"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: litmus-cluster-role-binding
subjects:
- kind: ServiceAccount
  name: litmus-admin
  namespace: litmus
roleRef:
  kind: ClusterRole
  name: litmus-cluster-role
  apiGroup: rbac.authorization.k8s.io
```

### 3.2 æ ¸å¿ƒå®éªŒåœºæ™¯

#### 3.2.1 Podåˆ é™¤å®éªŒ
```yaml
# pod_delete_experiment.yaml
apiVersion: litmuschaos.io/v1alpha1
kind: ChaosEngine
metadata:
  name: pod-delete-test
  namespace: litmus
spec:
  appinfo:
    appns: production
    applabel: app=shopping-cart
    appkind: deployment
    
  engineState: active
  chaosServiceAccount: litmus-admin
  
  experiments:
    - name: pod-delete
      spec:
        components:
          env:
            # å®éªŒå‚æ•°
            - name: TOTAL_CHAOS_DURATION
              value: '60'  # ç§’
              
            - name: CHAOS_INTERVAL
              value: '30'  # ç§’
              
            - name: FORCE
              value: 'false'
              
            - name: TARGET_PODS
              value: ''  # ç©ºè¡¨ç¤ºéšæœºé€‰æ‹©
            
        probe:
          - name: check-app-availability
            type: cmdProbe
            mode: Continuous
            source:
              image: busybox
              command: 
                - "wget"
                - "-q"
                - "-O-"
                - "http://shopping-cart.production:8080/health"
              comparator:
                type: string
                criteria: equals
                value: '{"status":"ok"}'
```

#### 3.2.2 CPUè€—å°½å®éªŒ
```yaml
# cpu_hog_experiment.yaml
apiVersion: litmuschaos.io/v1alpha1
kind: ChaosEngine
metadata:
  name: cpu-hog-test
  namespace: litmus
spec:
  appinfo:
    appns: staging
    applabel: app=analytics-service
    appkind: deployment
    
  engineState: active
  chaosServiceAccount: litmus-admin
  
  experiments:
    - name: pod-cpu-hog
      spec:
        components:
          env:
            # CPUå‹åŠ›å‚æ•°
            - name: TOTAL_CHAOS_DURATION
              value: '120'
              
            - name: CPU_CORES
              value: '2'
              
            - name: CPU_LOAD
              value: '80'
              
            - name: TARGET_PODS
              value: ''
              
            - name: LIB_IMAGE
              value: 'litmuschaos/go-runner:latest'
              
        probe:
          - name: check-cpu-usage
            type: k8sProbe
            mode: Continuous
            source:
              command: 
                - "kubectl"
                - "top"
                - "pods"
                - "--no-headers"
                - "-n"
                - "staging"
              comparator:
                type: numeric
                criteria: "<="
                value: "1500m"  # CPUä½¿ç”¨ä¸è¶…è¿‡1.5æ ¸
```

---

## 4. æ•…éšœæ³¨å…¥åœºæ™¯è®¾è®¡

### 4.1 å…¸å‹æ•…éšœåœºæ™¯çŸ©é˜µ

#### 4.1.1 å¾®æœåŠ¡æ¶æ„æ•…éšœåœºæ™¯
```yaml
# microservice_failure_scenarios.yaml
failure_scenarios:
  # ç½‘ç»œç›¸å…³æ•…éšœ
  network_failures:
    - name: "service-to-service-network-delay"
      description: "æ¨¡æ‹Ÿå¾®æœåŠ¡é—´ç½‘ç»œå»¶è¿Ÿ"
      chaos_type: "network_chaos"
      parameters:
        delay: "200ms"
        jitter: "50ms"
        correlation: "70%"
      target_services: ["order-service", "inventory-service"]
      blast_radius: "inter-service"
      
    - name: "external-api-timeout"
      description: "æ¨¡æ‹Ÿç¬¬ä¸‰æ–¹APIè¶…æ—¶"
      chaos_type: "http_chaos"
      parameters:
        delay: "5s"
        target_hosts: ["payment-gateway.com", "shipping-api.com"]
      blast_radius: "egress"
      
  # èµ„æºç›¸å…³æ•…éšœ
  resource_failures:
    - name: "memory-leak-simulation"
      description: "æ¨¡æ‹Ÿå†…å­˜æ³„æ¼å¯¼è‡´OOM"
      chaos_type: "stress_chaos"
      parameters:
        memory_size: "2GB"
        duration: "300s"
      target_services: ["cache-service"]
      blast_radius: "pod"
      
    - name: "cpu-starvation"
      description: "æ¨¡æ‹ŸCPUèµ„æºäº‰ç”¨"
      chaos_type: "stress_chaos"
      parameters:
        cpu_workers: 4
        cpu_load: 90
        duration: "180s"
      target_services: ["compute-intensive-service"]
      blast_radius: "node"
      
  # åº”ç”¨å±‚æ•…éšœ
  application_failures:
    - name: "database-connection-failure"
      description: "æ¨¡æ‹Ÿæ•°æ®åº“è¿æ¥ä¸­æ–­"
      chaos_type: "pod_chaos"
      parameters:
        action: "pod-kill"
        count: 1
      target_services: ["database-primary"]
      blast_radius: "cluster"
      
    - name: "config-map-corruption"
      description: "æ¨¡æ‹Ÿé…ç½®æ–‡ä»¶æŸå"
      chaos_type: "config_chaos"
      parameters:
        corrupt_percentage: 30
        keys_to_corrupt: ["database_url", "api_key"]
      target_services: ["config-service"]
      blast_radius: "namespace"
```

### 4.2 åœºæ™¯ç»„åˆæµ‹è¯•

#### 4.2.1 æ··åˆæ•…éšœæ³¨å…¥
```yaml
# composite_failure_scenario.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: Workflow
metadata:
  name: composite-failure-test
  namespace: chaos-testing
spec:
  entry: entry
  templates:
    - name: entry
      templateType: Serial
      deadline: 600s  # 10åˆ†é’Ÿè¶…æ—¶
      children:
        - network-delay-phase
        - pod-kill-phase
        - recovery-phase
        
    - name: network-delay-phase
      templateType: Suspend
      deadline: 120s
      children:
        - inject-network-delay
        
    - name: inject-network-delay
      templateType: Parallel
      deadline: 120s
      children:
        - delay-order-service
        - delay-inventory-service
        
    - name: delay-order-service
      templateType: NetworkChaos
      deadline: 120s
      embedChaos:
        networkChaos:
          action: delay
          mode: all
          selector:
            namespaces: ["production"]
            labelSelectors:
              app: order-service
          delay:
            latency: "300ms"
            
    - name: delay-inventory-service
      templateType: NetworkChaos
      deadline: 120s
      embedChaos:
        networkChaos:
          action: delay
          mode: all
          selector:
            namespaces: ["production"]
            labelSelectors:
              app: inventory-service
          delay:
            latency: "200ms"
            
    - name: pod-kill-phase
      templateType: Suspend
      deadline: 60s
      children:
        - kill-payment-pod
        
    - name: kill-payment-pod
      templateType: PodChaos
      deadline: 30s
      embedChaos:
        podChaos:
          action: pod-kill
          mode: one
          selector:
            namespaces: ["production"]
            labelSelectors:
              app: payment-service
              
    - name: recovery-phase
      templateType: Suspend
      deadline: 300s  # ç»™ç³»ç»Ÿæ¢å¤æ—¶é—´
```

---

## 5. å®éªŒç›‘æ§ä¸åˆ†æ

### 5.1 å®æ—¶ç›‘æ§ä»ªè¡¨æ¿

#### 5.1.1 Grafanaæ··æ²Œå®éªŒä»ªè¡¨æ¿
```json
{
  "dashboard": {
    "title": "Chaos Engineering Experiment Dashboard",
    "panels": [
      {
        "title": "Experiment Status Overview",
        "type": "stat",
        "targets": [
          {
            "expr": "count(chaos_experiment_running)",
            "legendFormat": "Active Experiments"
          },
          {
            "expr": "count(chaos_experiment_status{status=\"completed\"})",
            "legendFormat": "Completed Today"
          },
          {
            "expr": "count(chaos_experiment_status{status=\"failed\"})",
            "legendFormat": "Failed Today"
          }
        ]
      },
      {
        "title": "System Metrics During Experiments",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "Request Rate"
          },
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th Percentile Latency"
          },
          {
            "expr": "chaos_experiment_running",
            "legendFormat": "Chaos Active"
          }
        ]
      },
      {
        "title": "Error Rates Comparison",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m]) * 100",
            "legendFormat": "Error Rate %"
          },
          {
            "expr": "chaos_experiment_running",
            "legendFormat": "During Chaos"
          }
        ]
      }
    ]
  }
}
```

### 5.2 å®éªŒç»“æœåˆ†æ

#### 5.2.1 è‡ªåŠ¨åŒ–åˆ†æè„šæœ¬
```python
# chaos_experiment_analyzer.py
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns

class ChaosExperimentAnalyzer:
    def __init__(self, prometheus_url: str):
        self.prometheus_url = prometheus_url
        self.metrics_data = {}
        
    def collect_experiment_data(self, experiment_name: str, start_time: datetime, end_time: datetime):
        """æ”¶é›†èšéªŒæœŸé—´çš„æŒ‡æ ‡æ•°æ®"""
        metrics = [
            'http_requests_total',
            'http_request_duration_seconds',
            'system_cpu_usage',
            'system_memory_usage',
            'chaos_experiment_running'
        ]
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨Prometheus APIè·å–æ•°æ®
        # ä¸ºæ¼”ç¤ºç›®çš„ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        self._generate_sample_data(start_time, end_time)
        
    def _generate_sample_data(self, start_time: datetime, end_time: datetime):
        """ç”Ÿæˆç¤ºä¾‹æ•°æ®ç”¨äºæ¼”ç¤º"""
        time_points = pd.date_range(start_time, end_time, freq='30S')
        
        # æ­£å¸¸çŠ¶æ€æ•°æ®
        normal_period = len(time_points) // 3
        chaos_period = len(time_points) // 3
        recovery_period = len(time_points) - normal_period - chaos_period
        
        # è¯·æ±‚ç‡æ•°æ®
        request_rates = []
        request_rates.extend(np.random.normal(100, 10, normal_period))  # æ­£å¸¸çŠ¶æ€
        request_rates.extend(np.random.normal(80, 15, chaos_period))    # æ··æ²ŒæœŸé—´
        request_rates.extend(np.random.normal(95, 12, recovery_period)) # æ¢å¤æœŸ
        
        # å»¶è¿Ÿæ•°æ®
        latencies = []
        latencies.extend(np.random.exponential(0.1, normal_period))     # æ­£å¸¸å»¶è¿Ÿ
        latencies.extend(np.random.exponential(0.3, chaos_period))      # é«˜å»¶è¿Ÿ
        latencies.extend(np.random.exponential(0.15, recovery_period))  # æ¢å¤å»¶è¿Ÿ
        
        self.metrics_data = {
            'timestamps': time_points,
            'request_rate': request_rates,
            'latency_95th': latencies,
            'chaos_active': [0]*normal_period + [1]*chaos_period + [0]*recovery_period
        }
        
    def analyze_steady_state_deviation(self):
        """åˆ†æç¨³æ€åå·®"""
        df = pd.DataFrame(self.metrics_data)
        
        # è®¡ç®—æ­£å¸¸æœŸé—´çš„åŸºçº¿
        normal_mask = df['chaos_active'] == 0
        baseline_mean = df[normal_mask]['request_rate'].mean()
        baseline_std = df[normal_mask]['request_rate'].std()
        
        # è®¡ç®—æ··æ²ŒæœŸé—´çš„åå·®
        chaos_mask = df['chaos_active'] == 1
        chaos_mean = df[chaos_mask]['request_rate'].mean()
        
        deviation = abs(chaos_mean - baseline_mean) / baseline_std
        
        return {
            'baseline_mean': baseline_mean,
            'baseline_std': baseline_std,
            'chaos_mean': chaos_mean,
            'deviation_sigma': deviation,
            'hypothesis_valid': deviation < 2  # 2ä¸ªæ ‡å‡†å·®å†…è®¤ä¸ºå‡è®¾æˆç«‹
        }
        
    def generate_report(self, experiment_name: str) -> dict:
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        analysis_results = self.analyze_steady_state_deviation()
        
        report = {
            'experiment_name': experiment_name,
            'analysis_time': datetime.now().isoformat(),
            'results': analysis_results,
            'recommendations': []
        }
        
        # åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®
        if analysis_results['deviation_sigma'] > 3:
            report['recommendations'].append("ç³»ç»Ÿåœ¨æ··æ²Œæ¡ä»¶ä¸‹è¡¨ç°å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥å®¹é”™æœºåˆ¶")
        elif analysis_results['deviation_sigma'] > 2:
            report['recommendations'].append("ç³»ç»Ÿæœ‰ä¸€å®šæ³¢åŠ¨ï¼Œå»ºè®®ä¼˜åŒ–å¼¹æ€§é…ç½®")
        else:
            report['recommendations'].append("ç³»ç»Ÿè¡¨ç°å‡ºè‰¯å¥½çš„å¼¹æ€§ï¼Œç¨³æ€å‡è®¾æˆç«‹")
            
        return report
        
    def visualize_results(self, output_file: str = "chaos_analysis.png"):
        """å¯è§†åŒ–åˆ†æç»“æœ"""
        df = pd.DataFrame(self.metrics_data)
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Chaos Experiment Analysis Results', fontsize=16)
        
        # è¯·æ±‚ç‡å›¾è¡¨
        axes[0, 0].plot(df['timestamps'], df['request_rate'], 'b-', alpha=0.7)
        axes[0, 0].fill_between(df['timestamps'], 0, 1, 
                               where=df['chaos_active']==1, 
                               color='red', alpha=0.3, 
                               label='Chaos Active')
        axes[0, 0].set_title('Request Rate Over Time')
        axes[0, 0].set_ylabel('Requests/sec')
        axes[0, 0].legend()
        
        # å»¶è¿Ÿå›¾è¡¨
        axes[0, 1].plot(df['timestamps'], df['latency_95th'], 'g-', alpha=0.7)
        axes[0, 1].fill_between(df['timestamps'], 0, 1, 
                               where=df['chaos_active']==1, 
                               color='red', alpha=0.3)
        axes[0, 1].set_title('95th Percentile Latency')
        axes[0, 1].set_ylabel('Latency (seconds)')
        
        # ç»Ÿè®¡åˆ†å¸ƒ
        normal_data = df[df['chaos_active']==0]['request_rate']
        chaos_data = df[df['chaos_active']==1]['request_rate']
        
        axes[1, 0].hist(normal_data, alpha=0.7, label='Normal', bins=20)
        axes[1, 0].hist(chaos_data, alpha=0.7, label='Chaos', bins=20)
        axes[1, 0].set_title('Request Rate Distribution')
        axes[1, 0].set_xlabel('Requests/sec')
        axes[1, 0].legend()
        
        # ç®±çº¿å›¾æ¯”è¾ƒ
        data_to_plot = [normal_data, chaos_data]
        axes[1, 1].boxplot(data_to_plot, labels=['Normal', 'Chaos'])
        axes[1, 1].set_title('Request Rate Comparison')
        axes[1, 1].set_ylabel('Requests/sec')
        
        plt.tight_layout()
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.show()
        
        return output_file

# ä½¿ç”¨ç¤ºä¾‹
analyzer = ChaosExperimentAnalyzer("http://prometheus:9090")
analyzer.collect_experiment_data(
    "pod-kill-test", 
    datetime.now() - timedelta(minutes=30),
    datetime.now()
)

report = analyzer.generate_report("Pod Kill Experiment")
print(json.dumps(report, indent=2))

# ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
analyzer.visualize_results("pod_kill_analysis.png")
```

---

## 6. å®‰å…¨ä¸é£é™©æ§åˆ¶

### 6.1 å®‰å…¨å‡†å…¥æ§åˆ¶

#### 6.1.1 å®éªŒå®¡æ‰¹æµç¨‹
```yaml
# chaos_approval_workflow.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: chaos-approval-policy
  namespace: chaos-testing
data:
  approval_policy.yaml: |
    approval_workflow:
      # å®éªŒåˆ†çº§åˆ¶åº¦
      experiment_tiers:
        tier_1_safe:
          description: "ä½é£é™©å®éªŒï¼Œæ— éœ€å®¡æ‰¹"
          max_blast_radius: "single_pod"
          max_duration: "60s"
          allowed_actions: ["pod-kill", "network-delay"]
          
        tier_2_review:
          description: "ä¸­ç­‰é£é™©å®éªŒï¼Œéœ€è¦å›¢é˜Ÿè´Ÿè´£äººå®¡æ‰¹"
          max_blast_radius: "service"
          max_duration: "300s"
          allowed_actions: ["pod-failure", "cpu-stress", "memory-stress"]
          approval_required: true
          approvers: ["team-lead", "sre-engineer"]
          
        tier_3_executive:
          description: "é«˜é£é™©å®éªŒï¼Œéœ€è¦ç®¡ç†å±‚å®¡æ‰¹"
          max_blast_radius: "namespace_or_more"
          max_duration: "600s"
          allowed_actions: ["node-drain", "network-partition"]
          approval_required: true
          approvers: ["engineering-director", "cto"]
          
      # è‡ªåŠ¨åŒ–å®‰å…¨æ£€æŸ¥
      safety_checks:
        - name: "business_hours_check"
          type: "time_based"
          allow_outside_hours: false
          business_hours: "09:00-18:00"
          
        - name: "min_replica_check"
          type: "resource_based"
          minimum_replicas: 2
          check_before_experiment: true
          
        - name: "health_check_validation"
          type: "application_based"
          health_endpoint: "/health"
          minimum_healthy_pods: 80
```

#### 6.1.2 èµ„æºé…é¢é™åˆ¶
```yaml
# chaos_resource_quotas.yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: chaos-testing-quota
  namespace: chaos-testing
spec:
  hard:
    # é™åˆ¶æ··æ²Œå®éªŒèµ„æºä½¿ç”¨
    requests.cpu: "2"
    requests.memory: "4Gi"
    limits.cpu: "4"
    limits.memory: "8Gi"
    # é™åˆ¶å¹¶å‘å®éªŒæ•°é‡
    count/pods: "20"
    count/chaosengines.chaos-mesh.org: "5"
    
---
apiVersion: v1
kind: LimitRange
metadata:
  name: chaos-limit-range
  namespace: chaos-testing
spec:
  limits:
  - type: Container
    default:
      cpu: "500m"
      memory: "1Gi"
    defaultRequest:
      cpu: "100m"
      memory: "256Mi"
    max:
      cpu: "2"
      memory: "4Gi"
    min:
      cpu: "50m"
      memory: "64Mi"
```

### 6.2 åº”æ€¥å“åº”æœºåˆ¶

#### 6.2.1 è‡ªåŠ¨å›æ»šç­–ç•¥
```yaml
# chaos_auto_rollback.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: Schedule
metadata:
  name: auto-rollback-policy
  namespace: chaos-testing
spec:
  schedule: "@every 1m"
  concurrencyPolicy: Forbid
  historyLimit: 5
  type: Workflow
  workflow:
    entry: monitor-and-rollback
    templates:
      - name: monitor-and-rollback
        templateType: Serial
        deadline: 300s
        children:
          - check-system-health
          - rollback-if-needed
          
      - name: check-system-health
        templateType: Suspend
        deadline: 60s
        children:
          - evaluate-metrics
          
      - name: evaluate-metrics
        templateType: HTTPChaos
        embedChaos:
          httpChaos:
            action: abort
            mode: all
            selector:
              namespaces: ["monitoring"]
            target: "prometheus"
            port: 9090
            path: "/api/v1/query?query=up"
            
      - name: rollback-if-needed
        templateType: Conditional
        conditionalBranches:
          - target: system-degraded
            expression: "avg_over_time(system_health_score[5m]) < 0.7"
            children: [execute-rollback]
          - target: system-healthy
            expression: "avg_over_time(system_health_score[5m]) >= 0.7"
            children: [continue-monitoring]
            
      - name: execute-rollback
        templateType: PodChaos
        embedChaos:
          podChaos:
            action: pod-kill
            mode: one
            selector:
              namespaces: ["chaos-testing"]
              labelSelectors:
                app: chaos-controller
```

---

## 7. æœ€ä½³å®è·µä¸æ¡ˆä¾‹

### 7.1 å®æ–½è·¯çº¿å›¾

#### 7.1.1 æ¸è¿›å¼å®æ–½è®¡åˆ’
```markdown
## æ··æ²Œå·¥ç¨‹å®æ–½è·¯çº¿å›¾

### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€èƒ½åŠ›å»ºè®¾ (1-2ä¸ªæœˆ)
- [ ] éƒ¨ç½²æ··æ²Œå·¥ç¨‹å¹³å°(Chaos Mesh/LitmusChaos)
- [ ] å»ºç«‹åŸºç¡€ç›‘æ§å’Œå‘Šè­¦ä½“ç³»
- [ ] åˆ¶å®šå®‰å…¨å‡†å…¥å’Œå®¡æ‰¹æµç¨‹
- [ ] åœ¨æµ‹è¯•ç¯å¢ƒå¼€å±•åˆæ­¥å®éªŒ

### ç¬¬äºŒé˜¶æ®µï¼šèƒ½åŠ›æå‡ (2-4ä¸ªæœˆ)
- [ ] è®¾è®¡æ ¸å¿ƒä¸šåŠ¡åœºæ™¯æ•…éšœæ³¨å…¥
- [ ] å»ºç«‹è‡ªåŠ¨åŒ–å®éªŒæµæ°´çº¿
- [ ] å®Œå–„ç›‘æ§æŒ‡æ ‡å’Œåˆ†æå·¥å…·
- [ ] åœ¨é¢„ç”Ÿäº§ç¯å¢ƒæ‰©å¤§å®éªŒèŒƒå›´

### ç¬¬ä¸‰é˜¶æ®µï¼šç”Ÿäº§å°±ç»ª (4-6ä¸ªæœˆ)
- [ ] å»ºç«‹ç”Ÿäº§ç¯å¢ƒå®éªŒè§„èŒƒ
- [ ] å®ç°æ™ºèƒ½å®éªŒè°ƒåº¦å’Œåˆ†æ
- [ ] å»ºç«‹æ··æ²Œå·¥ç¨‹æ–‡åŒ–
- [ ] å®šæœŸå¼€å±•å¤§è§„æ¨¡æ··æ²Œå®éªŒ

### ç¬¬å››é˜¶æ®µï¼šæŒç»­ä¼˜åŒ– (æŒç»­è¿›è¡Œ)
- [ ] åŸºäºå®éªŒç»“æœæŒç»­ä¼˜åŒ–ç³»ç»Ÿ
- [ ] æ‰©å±•æ•…éšœåœºæ™¯è¦†ç›–é¢
- [ ] æå‡è‡ªåŠ¨åŒ–æ°´å¹³
- [ ] å»ºç«‹è¡Œä¸šæœ€ä½³å®è·µ
```

### 7.2 æˆåŠŸæ¡ˆä¾‹åˆ†äº«

#### 7.2.1 ç”µå•†å¹³å°æ··æ²Œå®éªŒæ¡ˆä¾‹
```yaml
# ecommerce_chaos_case_study.yaml
case_study:
  company: "æŸå¤§å‹ç”µå•†å¹³å°"
  objective: "éªŒè¯è´­ç‰©è½¦æœåŠ¡åœ¨å„ç§æ•…éšœä¸‹çš„å¯é æ€§"
  
  experiment_scenarios:
    - name: "black-friday-traffic-surge"
      description: "æ¨¡æ‹Ÿé»‘è‰²æ˜ŸæœŸäº”æµé‡æ¿€å¢åœºæ™¯"
      setup:
        baseline_users: 10000
        peak_users: 100000
        ramp_up_time: "30m"
      chaos_actions:
        - type: "pod-delete"
          target: "cart-service"
          frequency: "every_5m"
        - type: "network-delay"
          target: "database"
          latency: "500ms"
      results:
        system_availability: "99.97%"
        response_time_p95: "180ms"
        recovery_time: "15s"
        
    - name: "payment-gateway-outage"
      description: "æ¨¡æ‹Ÿæ”¯ä»˜ç½‘å…³æ•…éšœ"
      setup:
        concurrent_users: 50000
        transaction_rate: "1000tps"
      chaos_actions:
        - type: "network-partition"
          duration: "2m"
          target: "payment-service"
      results:
        graceful_degradation: true
        fallback_mechanism: "successful"
        data_consistency: "maintained"
        
  key_learnings:
    - implemented_circuit_breaker: true
    - added_retry_mechanism: true
    - improved_load_balancing: true
    - enhanced_monitoring: true
    
  business_impact:
    confidence_increase: "40%"
    incident_reduction: "60%"
    customer_satisfaction: "improved"
```

### 7.3 è¿ç»´æ£€æŸ¥æ¸…å•

#### 7.3.1 æ··æ²Œå®éªŒå‰æ£€æŸ¥
```markdown
## æ··æ²Œå®éªŒå‰ç½®æ£€æŸ¥æ¸…å•

### ğŸ” å®éªŒå‡†å¤‡æ£€æŸ¥
- [ ] å®éªŒç›®æ ‡å’Œå‡è®¾å·²æ˜ç¡®å®šä¹‰
- [ ] å·²è·å¾—å¿…è¦çš„å®¡æ‰¹å’Œæˆæƒ
- [ ] ç›®æ ‡ç³»ç»Ÿçš„å¥åº·çŠ¶æ€å·²ç¡®è®¤
- [ ] ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿå·²å°±ç»ª
- [ ] å›æ»šå’Œæ¢å¤æ–¹æ¡ˆå·²åˆ¶å®š
- [ ] é€šè®¯æ¸ é“å’Œäººå‘˜å·²åˆ°ä½

### ğŸ›¡ï¸ å®‰å…¨æ§åˆ¶æ£€æŸ¥
- [ ] å®éªŒèŒƒå›´å’Œçˆ†ç‚¸åŠå¾„å·²é™å®š
- [ ] èµ„æºé…é¢å’Œé™åˆ¶å·²é…ç½®
- [ ] æ•°æ®å¤‡ä»½å·²å®Œæˆ
- [ ] å®¢æˆ·é€šçŸ¥å·²å‘é€ï¼ˆå¦‚éœ€è¦ï¼‰
- [ ] åº”æ€¥è”ç³»äººå·²ç¡®è®¤
- [ ] å®éªŒæ—¶é—´çª—å£å·²ç¡®è®¤

### ğŸ“Š ç›‘æ§å‡†å¤‡æ£€æŸ¥
- [ ] å…³é”®ä¸šåŠ¡æŒ‡æ ‡å·²è¯†åˆ«
- [ ] åŸºçº¿æ•°æ®å·²æ”¶é›†
- [ ] å‘Šè­¦é˜ˆå€¼å·²è®¾ç½®
- [ ] æ—¥å¿—æ”¶é›†å·²é…ç½®
- [ ] å¯è§†åŒ–ä»ªè¡¨æ¿å·²å‡†å¤‡
- [ ] æ•°æ®åˆ†æå·¥å…·å·²å°±ç»ª
```

---

**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ | **ä¸“å®¶è¯„å®¡**: å·²é€šè¿‡ | **æœ€åæ›´æ–°**: 2026-02 | **é€‚ç”¨åœºæ™¯**: ä¼ä¸šçº§æ··æ²Œå·¥ç¨‹å®è·µå’Œç³»ç»Ÿå¯é æ€§æå‡