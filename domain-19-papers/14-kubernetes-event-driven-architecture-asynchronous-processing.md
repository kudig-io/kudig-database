# Kubernetes äº‹ä»¶é©±åŠ¨æ¶æ„ä¸å¼‚æ­¥å¤„ç† (Event-Driven Architecture and Asynchronous Processing)

> **ä½œè€…**: äº‘åŸç”Ÿæ¶æ„ä¸“å®¶ | **ç‰ˆæœ¬**: v1.3 | **æ›´æ–°æ—¶é—´**: 2026-02-07
> **é€‚ç”¨åœºæ™¯**: å¾®æœåŠ¡äº‹ä»¶é©±åŠ¨æ¶æ„ | **å¤æ‚åº¦**: â­â­â­â­â­

## ğŸ¯ æ‘˜è¦

æœ¬æ–‡æ¡£æ·±å…¥æ¢è®¨äº†Kubernetesç¯å¢ƒä¸‹äº‹ä»¶é©±åŠ¨æ¶æ„çš„è®¾è®¡æ¨¡å¼ã€å®ç°æŠ€æœ¯å’Œæœ€ä½³å®è·µï¼ŒåŸºäºå¤§è§„æ¨¡å¾®æœåŠ¡æ¶æ„çš„å®é™…æ¡ˆä¾‹ï¼Œæä¾›ä»äº‹ä»¶å»ºæ¨¡åˆ°å¼‚æ­¥å¤„ç†çš„å®Œæ•´æŠ€æœ¯æŒ‡å—ï¼Œå¸®åŠ©ä¼ä¸šæ„å»ºé«˜å¼¹æ€§ã€ä½è€¦åˆçš„ç°ä»£åŒ–åº”ç”¨æ¶æ„ã€‚

## 1. äº‹ä»¶é©±åŠ¨æ¶æ„åŸºç¡€

### 1.1 æ ¸å¿ƒæ¦‚å¿µä¸æ¨¡å¼

```yaml
äº‹ä»¶é©±åŠ¨æ¶æ„æ ¸å¿ƒç»„ä»¶:
  äº‹ä»¶æº (Event Source):
    - äº§ç”Ÿä¸šåŠ¡äº‹ä»¶çš„ç»„ä»¶
    - è´Ÿè´£äº‹ä»¶çš„åˆ›å»ºå’Œå‘å¸ƒ
    - ä¿è¯äº‹ä»¶çš„å¯é æ€§å’Œä¸€è‡´æ€§
  
  äº‹ä»¶æ€»çº¿ (Event Bus):
    - äº‹ä»¶ä¼ è¾“çš„ä¸­é—´ä»¶
    - æä¾›äº‹ä»¶è·¯ç”±å’Œåˆ†å‘
    - æ”¯æŒå¤šç§ä¼ è¾“åè®®
  
  äº‹ä»¶å¤„ç†å™¨ (Event Handler):
    - æ¶ˆè´¹å’Œå¤„ç†äº‹ä»¶çš„ç»„ä»¶
    - å®ç°ä¸šåŠ¡é€»è¾‘å¤„ç†
    - æ”¯æŒå¼‚æ­¥å’ŒåŒæ­¥å¤„ç†
  
  äº‹ä»¶å­˜å‚¨ (Event Store):
    - æŒä¹…åŒ–äº‹ä»¶æ•°æ®
    - æ”¯æŒäº‹ä»¶å›æº¯å’Œé‡æ”¾
    - æä¾›äº‹ä»¶æŸ¥è¯¢èƒ½åŠ›
```

### 1.2 æ¶æ„æ¨¡å¼åˆ†ç±»

```mermaid
graph TD
    A[äº‹ä»¶é©±åŠ¨æ¶æ„æ¨¡å¼] --> B[å‘å¸ƒ-è®¢é˜…æ¨¡å¼]
    A --> C[äº‹ä»¶æº¯æºæ¨¡å¼]
    A --> D[å‘½ä»¤æŸ¥è¯¢è´£ä»»åˆ†ç¦»]
    A --> E[äº‹ä»¶æµå¤„ç†]
    
    B --> F[æ¶ˆæ¯é˜Ÿåˆ—å®ç°]
    B --> G[ä¸»é¢˜è®¢é˜…æ¨¡å¼]
    
    C --> H[äº‹ä»¶æ—¥å¿—å­˜å‚¨]
    C --> I[çŠ¶æ€é‡å»ºæœºåˆ¶]
    
    D --> J[å‘½ä»¤æ¨¡å‹]
    D --> K[æŸ¥è¯¢æ¨¡å‹]
    
    E --> L[å®æ—¶æµå¤„ç†]
    E --> M[æ‰¹å¤„ç†æµå¤„ç†]
```

## 2. Kubernetesäº‹ä»¶ç³»ç»Ÿ

### 2.1 å†…ç½®äº‹ä»¶æœºåˆ¶

```yaml
# Kubernetesäº‹ä»¶é…ç½®
apiVersion: v1
kind: Event
metadata:
  name: pod-scheduled-event
  namespace: default
involvedObject:
  kind: Pod
  name: my-app-pod
  namespace: default
reason: Scheduled
message: "Successfully assigned default/my-app-pod to node-1"
source:
  component: default-scheduler
firstTimestamp: "2024-01-15T10:00:00Z"
lastTimestamp: "2024-01-15T10:00:00Z"
count: 1
type: Normal
---
# äº‹ä»¶ç›‘å¬å™¨é…ç½®
apiVersion: v1
kind: Pod
metadata:
  name: event-listener
  namespace: monitoring
spec:
  containers:
  - name: event-listener
    image: event-listener:latest
    command:
    - /event-listener
    - --watch-events
    - --namespace=default
    - --event-types=Pod,Scheduled,Failed
    env:
    - name: EVENT_WEBHOOK_URL
      value: "https://webhook.example.com/events"
    resources:
      requests:
        memory: "64Mi"
        cpu: "100m"
      limits:
        memory: "128Mi"
        cpu: "200m"
```

### 2.2 è‡ªå®šä¹‰äº‹ä»¶å¤„ç†

```go
// Kubernetesäº‹ä»¶å¤„ç†å™¨å®ç°
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "net/http"
    "time"

    corev1 "k8s.io/api/core/v1"
    metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
    "k8s.io/apimachinery/pkg/runtime"
    "k8s.io/apimachinery/pkg/watch"
    "k8s.io/client-go/kubernetes"
    "k8s.io/client-go/rest"
    "k8s.io/client-go/tools/cache"
    "k8s.io/client-go/tools/clientcmd"
)

type EventProcessor struct {
    clientset kubernetes.Interface
    webhookURL string
}

func NewEventProcessor(kubeconfig, webhookURL string) (*EventProcessor, error) {
    var config *rest.Config
    var err error

    if kubeconfig != "" {
        config, err = clientcmd.BuildConfigFromFlags("", kubeconfig)
    } else {
        config, err = rest.InClusterConfig()
    }

    if err != nil {
        return nil, err
    }

    clientset, err := kubernetes.NewForConfig(config)
    if err != nil {
        return nil, err
    }

    return &EventProcessor{
        clientset: clientset,
        webhookURL: webhookURL,
    }, nil
}

func (ep *EventProcessor) StartEventProcessing() {
    // ç›‘å¬Podäº‹ä»¶
    ep.watchPodEvents()
    
    // ç›‘å¬Deploymentäº‹ä»¶
    ep.watchDeploymentEvents()
    
    // ç›‘å¬Serviceäº‹ä»¶
    ep.watchServiceEvents()
}

func (ep *EventProcessor) watchPodEvents() {
    listWatch := &cache.ListWatch{
        ListFunc: func(options metav1.ListOptions) (runtime.Object, error) {
            return ep.clientset.CoreV1().Events("").List(context.TODO(), options)
        },
        WatchFunc: func(options metav1.ListOptions) (watch.Interface, error) {
            return ep.clientset.CoreV1().Events("").Watch(context.TODO(), options)
        },
    }

    _, controller := cache.NewInformer(
        listWatch,
        &corev1.Event{},
        time.Second*30,
        cache.ResourceEventHandlerFuncs{
            AddFunc: func(obj interface{}) {
                ep.handleEvent(obj.(*corev1.Event))
            },
            UpdateFunc: func(oldObj, newObj interface{}) {
                ep.handleEvent(newObj.(*corev1.Event))
            },
        },
    )

    stopCh := make(chan struct{})
    go controller.Run(stopCh)
    <-stopCh
}

func (ep *EventProcessor) handleEvent(event *corev1.Event) {
    // è¿‡æ»¤äº‹ä»¶ç±»å‹
    if !ep.shouldProcessEvent(event) {
        return
    }

    // å¤„ç†äº‹ä»¶
    processedEvent := ep.processEvent(event)
    
    // å‘é€åˆ°Webhook
    ep.sendToWebhook(processedEvent)
    
    // è®°å½•å¤„ç†æ—¥å¿—
    log.Printf("Processed event: %s/%s - %s", 
        event.InvolvedObject.Namespace, 
        event.InvolvedObject.Name, 
        event.Reason)
}

func (ep *EventProcessor) shouldProcessEvent(event *corev1.Event) bool {
    // å®šä¹‰éœ€è¦å¤„ç†çš„äº‹ä»¶ç±»å‹
    importantReasons := map[string]bool{
        "Scheduled": true,
        "Failed": true,
        "Killing": true,
        "BackOff": true,
        "Unhealthy": true,
        "Created": true,
        "Started": true,
    }

    return importantReasons[event.Reason]
}

func (ep *EventProcessor) processEvent(event *corev1.Event) map[string]interface{} {
    return map[string]interface{}{
        "timestamp": event.FirstTimestamp.Time,
        "namespace": event.InvolvedObject.Namespace,
        "object": map[string]interface{}{
            "kind": event.InvolvedObject.Kind,
            "name": event.InvolvedObject.Name,
            "uid":  string(event.InvolvedObject.UID),
        },
        "reason":   event.Reason,
        "message":  event.Message,
        "source": map[string]interface{}{
            "component": event.Source.Component,
            "host":      event.Source.Host,
        },
        "count":    event.Count,
        "type":     event.Type,
        "metadata": event.ObjectMeta,
    }
}

func (ep *EventProcessor) sendToWebhook(eventData map[string]interface{}) {
    if ep.webhookURL == "" {
        return
    }

    jsonData, err := json.Marshal(eventData)
    if err != nil {
        log.Printf("Error marshaling event data: %v", err)
        return
    }

    resp, err := http.Post(ep.webhookURL, "application/json", bytes.NewBuffer(jsonData))
    if err != nil {
        log.Printf("Error sending webhook: %v", err)
        return
    }
    defer resp.Body.Close()

    if resp.StatusCode != http.StatusOK {
        log.Printf("Webhook returned status: %d", resp.StatusCode)
    }
}

func main() {
    webhookURL := os.Getenv("EVENT_WEBHOOK_URL")
    if webhookURL == "" {
        log.Fatal("EVENT_WEBHOOK_URL environment variable is required")
    }

    processor, err := NewEventProcessor("", webhookURL)
    if err != nil {
        log.Fatal("Failed to create event processor:", err)
    }

    log.Println("Starting Kubernetes event processor...")
    processor.StartEventProcessing()
}
```

## 3. æ¶ˆæ¯é˜Ÿåˆ—é›†æˆ

### 3.1 Kafkaé›†æˆæ–¹æ¡ˆ

```yaml
# Kafka Operatoréƒ¨ç½²
apiVersion: v1
kind: Namespace
metadata:
  name: kafka-system
---
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: event-bus-cluster
  namespace: kafka-system
spec:
  kafka:
    version: 3.4.0
    replicas: 3
    listeners:
    - name: plain
      port: 9092
      type: internal
      tls: false
    - name: tls
      port: 9093
      type: internal
      tls: true
    - name: external
      port: 9094
      type: loadbalancer
      tls: true
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      default.replication.factor: 3
      min.insync.replicas: 2
      inter.broker.protocol.version: "3.4"
    storage:
      type: jbod
      volumes:
      - id: 0
        type: persistent-claim
        size: 100Gi
        deleteClaim: false
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 100Gi
      deleteClaim: false
  entityOperator:
    topicOperator: {}
    userOperator: {}
---
# Kafkaä¸»é¢˜é…ç½®
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: pod-events
  namespace: kafka-system
  labels:
    strimzi.io/cluster: event-bus-cluster
spec:
  partitions: 6
  replicas: 3
  config:
    retention.ms: 604800000  # 7å¤©
    segment.bytes: 1073741824  # 1GB
---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: deployment-events
  namespace: kafka-system
  labels:
    strimzi.io/cluster: event-bus-cluster
spec:
  partitions: 3
  replicas: 3
  config:
    retention.ms: 2592000000  # 30å¤©
    segment.bytes: 1073741824
```

### 3.2 äº‹ä»¶ç”Ÿäº§è€…å®ç°

```go
// Kubernetesäº‹ä»¶ç”Ÿäº§è€…
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "time"

    "github.com/segmentio/kafka-go"
    corev1 "k8s.io/api/core/v1"
    metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
    "k8s.io/apimachinery/pkg/runtime"
    "k8s.io/apimachinery/pkg/watch"
    "k8s.io/client-go/kubernetes"
    "k8s.io/client-go/rest"
    "k8s.io/client-go/tools/cache"
)

type KafkaEventProducer struct {
    clientset kubernetes.Interface
    kafkaWriter *kafka.Writer
    topic string
}

func NewKafkaEventProducer(kafkaBrokers []string, topic string) (*KafkaEventProducer, error) {
    // åˆ›å»ºKuberneteså®¢æˆ·ç«¯
    config, err := rest.InClusterConfig()
    if err != nil {
        return nil, err
    }

    clientset, err := kubernetes.NewForConfig(config)
    if err != nil {
        return nil, err
    }

    // åˆ›å»ºKafkaå†™å…¥å™¨
    writer := &kafka.Writer{
        Addr:     kafka.TCP(kafkaBrokers...),
        Topic:    topic,
        Balancer: &kafka.LeastBytes{},
        BatchTimeout: 10 * time.Millisecond,
        BatchSize: 100,
    }

    return &KafkaEventProducer{
        clientset: clientset,
        kafkaWriter: writer,
        topic: topic,
    }, nil
}

func (kep *KafkaEventProducer) StartProducing() {
    // ç›‘å¬ä¸åŒç±»å‹çš„äº‹ä»¶
    kep.watchPodEvents()
    kep.watchDeploymentEvents()
    kep.watchServiceEvents()
}

func (kep *KafkaEventProducer) watchPodEvents() {
    listWatch := &cache.ListWatch{
        ListFunc: func(options metav1.ListOptions) (runtime.Object, error) {
            return kep.clientset.CoreV1().Events("").List(context.TODO(), options)
        },
        WatchFunc: func(options metav1.ListOptions) (watch.Interface, error) {
            return kep.clientset.CoreV1().Events("").Watch(context.TODO(), options)
        },
    }

    _, controller := cache.NewInformer(
        listWatch,
        &corev1.Event{},
        time.Second*30,
        cache.ResourceEventHandlerFuncs{
            AddFunc: func(obj interface{}) {
                kep.produceEvent("pod", obj.(*corev1.Event))
            },
            UpdateFunc: func(oldObj, newObj interface{}) {
                kep.produceEvent("pod", newObj.(*corev1.Event))
            },
        },
    )

    stopCh := make(chan struct{})
    go controller.Run(stopCh)
    <-stopCh
}

func (kep *KafkaEventProducer) produceEvent(eventType string, event *corev1.Event) {
    // æ„å»ºäº‹ä»¶æ¶ˆæ¯
    eventMessage := map[string]interface{}{
        "eventType": eventType,
        "timestamp": time.Now().Unix(),
        "kubernetes": map[string]interface{}{
            "namespace": event.InvolvedObject.Namespace,
            "object": map[string]interface{}{
                "kind": event.InvolvedObject.Kind,
                "name": event.InvolvedObject.Name,
                "uid":  string(event.InvolvedObject.UID),
            },
            "reason":  event.Reason,
            "message": event.Message,
            "source": map[string]interface{}{
                "component": event.Source.Component,
                "host":      event.Source.Host,
            },
            "count": event.Count,
            "type":  event.Type,
        },
    }

    // åºåˆ—åŒ–æ¶ˆæ¯
    messageBytes, err := json.Marshal(eventMessage)
    if err != nil {
        log.Printf("Error marshaling event: %v", err)
        return
    }

    // å‘é€åˆ°Kafka
    err = kep.kafkaWriter.WriteMessages(context.Background(),
        kafka.Message{
            Key:   []byte(fmt.Sprintf("%s-%s", event.InvolvedObject.Kind, event.InvolvedObject.Name)),
            Value: messageBytes,
        },
    )

    if err != nil {
        log.Printf("Error writing to Kafka: %v", err)
        return
    }

    log.Printf("Event produced to Kafka: %s/%s - %s", 
        event.InvolvedObject.Namespace, 
        event.InvolvedObject.Name, 
        event.Reason)
}

func (kep *KafkaEventProducer) Close() {
    if kep.kafkaWriter != nil {
        kep.kafkaWriter.Close()
    }
}

func main() {
    kafkaBrokers := []string{"kafka-cluster-kafka-bootstrap.kafka-system:9092"}
    topic := "kubernetes-events"

    producer, err := NewKafkaEventProducer(kafkaBrokers, topic)
    if err != nil {
        log.Fatal("Failed to create Kafka producer:", err)
    }
    defer producer.Close()

    log.Println("Starting Kafka event producer...")
    producer.StartProducing()
}
```

## 4. äº‹ä»¶å¤„ç†ä¸æ¶ˆè´¹

### 4.1 äº‹ä»¶æ¶ˆè´¹è€…å®ç°

```go
// Kubernetesäº‹ä»¶æ¶ˆè´¹è€…
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "time"

    "github.com/segmentio/kafka-go"
    "k8s.io/client-go/kubernetes"
    "k8s.io/client-go/rest"
)

type EventConsumer struct {
    clientset kubernetes.Interface
    kafkaReader *kafka.Reader
    topic string
}

type KubernetesEvent struct {
    EventType   string `json:"eventType"`
    Timestamp   int64  `json:"timestamp"`
    Kubernetes  struct {
        Namespace string `json:"namespace"`
        Object    struct {
            Kind string `json:"kind"`
            Name string `json:"name"`
            UID  string `json:"uid"`
        } `json:"object"`
        Reason  string `json:"reason"`
        Message string `json:"message"`
        Source  struct {
            Component string `json:"component"`
            Host      string `json:"host"`
        } `json:"source"`
        Count int    `json:"count"`
        Type  string `json:"type"`
    } `json:"kubernetes"`
}

func NewEventConsumer(kafkaBrokers []string, topic, groupID string) (*EventConsumer, error) {
    // åˆ›å»ºKuberneteså®¢æˆ·ç«¯
    config, err := rest.InClusterConfig()
    if err != nil {
        return nil, err
    }

    clientset, err := kubernetes.NewForConfig(config)
    if err != nil {
        return nil, err
    }

    // åˆ›å»ºKafkaè¯»å–å™¨
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers:   kafkaBrokers,
        Topic:     topic,
        GroupID:   groupID,
        MinBytes:  10e3,  // 10KB
        MaxBytes:  10e6,  // 10MB
        MaxWait:   time.Second,
    })

    return &EventConsumer{
        clientset:   clientset,
        kafkaReader: reader,
        topic:       topic,
    }, nil
}

func (ec *EventConsumer) StartConsuming() {
    ctx := context.Background()
    
    for {
        msg, err := ec.kafkaReader.ReadMessage(ctx)
        if err != nil {
            log.Printf("Error reading message: %v", err)
            continue
        }

        // å¤„ç†äº‹ä»¶æ¶ˆæ¯
        if err := ec.processEventMessage(msg.Value); err != nil {
            log.Printf("Error processing event: %v", err)
            continue
        }

        log.Printf("Processed event from partition %d at offset %d", msg.Partition, msg.Offset)
    }
}

func (ec *EventConsumer) processEventMessage(message []byte) error {
    var event KubernetesEvent
    if err := json.Unmarshal(message, &event); err != nil {
        return fmt.Errorf("failed to unmarshal event: %w", err)
    }

    // æ ¹æ®äº‹ä»¶ç±»å‹æ‰§è¡Œä¸åŒçš„å¤„ç†é€»è¾‘
    switch event.Kubernetes.Reason {
    case "Scheduled":
        return ec.handlePodScheduled(event)
    case "Failed":
        return ec.handlePodFailed(event)
    case "Created":
        return ec.handleResourceCreated(event)
    case "Deleted":
        return ec.handleResourceDeleted(event)
    default:
        return ec.handleGenericEvent(event)
    }
}

func (ec *EventConsumer) handlePodScheduled(event KubernetesEvent) error {
    log.Printf("Pod scheduled: %s/%s", event.Kubernetes.Namespace, event.Kubernetes.Object.Name)
    
    // å¯ä»¥åœ¨è¿™é‡Œå®ç°è‡ªå®šä¹‰é€»è¾‘ï¼Œå¦‚ï¼š
    // - å‘é€é€šçŸ¥
    // - æ›´æ–°ç›‘æ§æŒ‡æ ‡
    // - è§¦å‘å…¶ä»–è‡ªåŠ¨åŒ–æµç¨‹
    
    return nil
}

func (ec *EventConsumer) handlePodFailed(event KubernetesEvent) error {
    log.Printf("Pod failed: %s/%s - %s", 
        event.Kubernetes.Namespace, 
        event.Kubernetes.Object.Name, 
        event.Kubernetes.Message)
    
    // å®ç°æ•…éšœå¤„ç†é€»è¾‘
    // - å‘é€å‘Šè­¦é€šçŸ¥
    // - è‡ªåŠ¨é‡å¯Pod
    // - è®°å½•æ•…éšœæ—¥å¿—
    
    return nil
}

func (ec *EventConsumer) handleResourceCreated(event KubernetesEvent) error {
    log.Printf("Resource created: %s/%s/%s", 
        event.Kubernetes.Object.Kind,
        event.Kubernetes.Namespace, 
        event.Kubernetes.Object.Name)
    
    // å®ç°èµ„æºåˆ›å»ºåçš„å¤„ç†é€»è¾‘
    return nil
}

func (ec *EventConsumer) handleResourceDeleted(event KubernetesEvent) error {
    log.Printf("Resource deleted: %s/%s/%s", 
        event.Kubernetes.Object.Kind,
        event.Kubernetes.Namespace, 
        event.Kubernetes.Object.Name)
    
    // å®ç°èµ„æºåˆ é™¤åçš„æ¸…ç†é€»è¾‘
    return nil
}

func (ec *EventConsumer) handleGenericEvent(event KubernetesEvent) error {
    log.Printf("Generic event: %s - %s/%s/%s", 
        event.Kubernetes.Reason,
        event.Kubernetes.Object.Kind,
        event.Kubernetes.Namespace, 
        event.Kubernetes.Object.Name)
    
    return nil
}

func (ec *EventConsumer) Close() {
    if ec.kafkaReader != nil {
        ec.kafkaReader.Close()
    }
}

func main() {
    kafkaBrokers := []string{"kafka-cluster-kafka-bootstrap.kafka-system:9092"}
    topic := "kubernetes-events"
    groupID := "kubernetes-event-processor"

    consumer, err := NewEventConsumer(kafkaBrokers, topic, groupID)
    if err != nil {
        log.Fatal("Failed to create event consumer:", err)
    }
    defer consumer.Close()

    log.Println("Starting event consumer...")
    consumer.StartConsuming()
}
```

### 4.2 äº‹ä»¶é©±åŠ¨çš„è‡ªåŠ¨åŒ–æµç¨‹

```yaml
# äº‹ä»¶é©±åŠ¨çš„è‡ªåŠ¨åŒ–å·¥ä½œæµ
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  name: event-driven-deployment-workflow
  namespace: automation
spec:
  entrypoint: event-handler
  templates:
  - name: event-handler
    steps:
    - - name: process-event
        template: process-kubernetes-event
    - - name: trigger-actions
        template: trigger-automated-actions
        when: "{{steps.process-event.outputs.result}} == true"
  
  - name: process-kubernetes-event
    inputs:
      parameters:
      - name: event-data
    script:
      image: python:3.9
      command: [python]
      source: |
        import json
        import sys
        
        event_data = json.loads('{{inputs.parameters.event-data}}')
        
        # åˆ†æäº‹ä»¶ç±»å‹å’Œå†…å®¹
        event_type = event_data.get('kubernetes', {}).get('reason')
        namespace = event_data.get('kubernetes', {}).get('namespace')
        object_name = event_data.get('kubernetes', {}).get('object', {}).get('name')
        
        print(f"Processing {event_type} event for {namespace}/{object_name}")
        
        # æ ¹æ®äº‹ä»¶ç±»å‹å†³å®šæ˜¯å¦è§¦å‘è‡ªåŠ¨åŒ–
        automation_triggers = {
            'Failed': True,
            'BackOff': True,
            'Unhealthy': True,
            'Scheduled': False
        }
        
        should_trigger = automation_triggers.get(event_type, False)
        print(f"Should trigger automation: {should_trigger}")
        
        # è¾“å‡ºç»“æœä¾›åç»­æ­¥éª¤ä½¿ç”¨
        result = {
            'should_trigger': should_trigger,
            'event_info': {
                'type': event_type,
                'namespace': namespace,
                'object': object_name
            }
        }
        
        print(json.dumps(result))
  
  - name: trigger-automated-actions
    inputs:
      parameters:
      - name: event-info
    steps:
    - - name: send-alert
        template: send-slack-alert
        arguments:
          parameters:
          - name: message
            value: "Critical event detected: {{inputs.parameters.event-info}}"
    - - name: auto-recovery
        template: auto-recovery-workflow
        arguments:
          parameters:
          - name: namespace
            value: "{{inputs.parameters.event-info.namespace}}"
          - name: object-name
            value: "{{inputs.parameters.event-info.object}}"
---
# Slacké€šçŸ¥æ¨¡æ¿
apiVersion: batch/v1
kind: Job
metadata:
  name: slack-notifier
  namespace: automation
spec:
  template:
    spec:
      containers:
      - name: notifier
        image: curlimages/curl:latest
        command:
        - sh
        - -c
        - |
          curl -X POST -H 'Content-type: application/json' \
          --data '{
            "text": "ğŸš¨ Kubernetes Event Alert\nNamespace: $NAMESPACE\nObject: $OBJECT_NAME\nEvent: $EVENT_REASON\nMessage: $EVENT_MESSAGE",
            "channel": "#kubernetes-alerts",
            "username": "Kubernetes Bot"
          }' $SLACK_WEBHOOK_URL
        env:
        - name: SLACK_WEBHOOK_URL
          valueFrom:
            secretKeyRef:
              name: slack-webhook
              key: webhook-url
        - name: NAMESPACE
          value: "{{workflow.parameters.namespace}}"
        - name: OBJECT_NAME
          value: "{{workflow.parameters.object-name}}"
        - name: EVENT_REASON
          value: "{{workflow.parameters.event-reason}}"
        - name: EVENT_MESSAGE
          value: "{{workflow.parameters.event-message}}"
      restartPolicy: Never
```

## 5. äº‹ä»¶æº¯æºä¸CQRS

### 5.1 äº‹ä»¶å­˜å‚¨è®¾è®¡

```yaml
# äº‹ä»¶å­˜å‚¨é…ç½®
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: event-store
  namespace: event-driven
spec:
  serviceName: event-store
  replicas: 3
  selector:
    matchLabels:
      app: event-store
  template:
    metadata:
      labels:
        app: event-store
    spec:
      containers:
      - name: event-store
        image: eventstore/eventstore:21.10.2-buster-slim
        ports:
        - containerPort: 1113
          name: tcp
        - containerPort: 2113
          name: http
        env:
        - name: EVENTSTORE_CLUSTER_SIZE
          value: "3"
        - name: EVENTSTORE_RUN_PROJECTIONS
          value: "All"
        - name: EVENTSTORE_START_STANDARD_PROJECTIONS
          value: "true"
        - name: EVENTSTORE_EXT_TCP_PORT
          value: "1113"
        - name: EVENTSTORE_HTTP_PORT
          value: "2113"
        - name: EVENTSTORE_EXT_HTTP_PORT
          value: "2113"
        - name: EVENTSTORE_INT_TCP_PORT
          value: "1112"
        - name: EVENTSTORE_INT_HTTP_PORT
          value: "2112"
        volumeMounts:
        - name: eventstore-data
          mountPath: /var/lib/eventstore
  volumeClaimTemplates:
  - metadata:
      name: eventstore-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 100Gi
---
# äº‹ä»¶æ¨¡å¼å®šä¹‰
apiVersion: v1
kind: ConfigMap
metadata:
  name: event-schemas
  namespace: event-driven
data:
  pod-event-schema.json: |
    {
      "type": "object",
      "properties": {
        "eventId": {"type": "string"},
        "eventType": {"type": "string"},
        "timestamp": {"type": "string", "format": "date-time"},
        "version": {"type": "string"},
        "data": {
          "type": "object",
          "properties": {
            "namespace": {"type": "string"},
            "podName": {"type": "string"},
            "reason": {"type": "string"},
            "message": {"type": "string"},
            "source": {
              "type": "object",
              "properties": {
                "component": {"type": "string"},
                "host": {"type": "string"}
              }
            }
          },
          "required": ["namespace", "podName", "reason"]
        }
      },
      "required": ["eventId", "eventType", "timestamp", "data"]
    }
```

### 5.2 CQRSæŸ¥è¯¢æ¨¡å‹

```go
// CQRSæŸ¥è¯¢å¤„ç†å™¨
package main

import (
    "database/sql"
    "encoding/json"
    "fmt"
    "log"
    "net/http"
    "time"

    _ "github.com/lib/pq"
    "github.com/gorilla/mux"
)

type QueryHandler struct {
    db *sql.DB
}

type PodEventView struct {
    ID        string    `json:"id"`
    Namespace string    `json:"namespace"`
    PodName   string    `json:"podName"`
    Reason    string    `json:"reason"`
    Message   string    `json:"message"`
    Timestamp time.Time `json:"timestamp"`
    Status    string    `json:"status"`
}

func NewQueryHandler(connectionString string) (*QueryHandler, error) {
    db, err := sql.Open("postgres", connectionString)
    if err != nil {
        return nil, err
    }

    if err := db.Ping(); err != nil {
        return nil, err
    }

    return &QueryHandler{db: db}, nil
}

func (qh *QueryHandler) InitializeSchema() error {
    schema := `
    CREATE TABLE IF NOT EXISTS pod_events_view (
        id UUID PRIMARY KEY,
        namespace VARCHAR(255) NOT NULL,
        pod_name VARCHAR(255) NOT NULL,
        reason VARCHAR(100) NOT NULL,
        message TEXT,
        event_timestamp TIMESTAMP NOT NULL,
        status VARCHAR(50) NOT NULL,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );

    CREATE INDEX IF NOT EXISTS idx_pod_events_namespace ON pod_events_view(namespace);
    CREATE INDEX IF NOT EXISTS idx_pod_events_timestamp ON pod_events_view(event_timestamp);
    CREATE INDEX IF NOT EXISTS idx_pod_events_status ON pod_events_view(status);
    `

    _, err := qh.db.Exec(schema)
    return err
}

func (qh *QueryHandler) HandleEvent(eventData map[string]interface{}) error {
    query := `
    INSERT INTO pod_events_view (id, namespace, pod_name, reason, message, event_timestamp, status)
    VALUES ($1, $2, $3, $4, $5, $6, $7)
    ON CONFLICT (id) DO UPDATE SET
        reason = EXCLUDED.reason,
        message = EXCLUDED.message,
        status = EXCLUDED.status
    `

    id := eventData["eventId"].(string)
    data := eventData["data"].(map[string]interface{})
    
    _, err := qh.db.Exec(query,
        id,
        data["namespace"],
        data["podName"],
        data["reason"],
        data["message"],
        eventData["timestamp"],
        determineStatus(data["reason"].(string)),
    )

    return err
}

func determineStatus(reason string) string {
    criticalReasons := map[string]bool{
        "Failed":    true,
        "BackOff":   true,
        "Unhealthy": true,
        "OOMKilled": true,
    }

    if criticalReasons[reason] {
        return "CRITICAL"
    }
    return "NORMAL"
}

// HTTPæŸ¥è¯¢æ¥å£
func (qh *QueryHandler) RegisterRoutes(router *mux.Router) {
    router.HandleFunc("/api/v1/pod-events", qh.getPodEvents).Methods("GET")
    router.HandleFunc("/api/v1/pod-events/{namespace}", qh.getPodEventsByNamespace).Methods("GET")
    router.HandleFunc("/api/v1/pod-events/status/{status}", qh.getPodEventsByStatus).Methods("GET")
}

func (qh *QueryHandler) getPodEvents(w http.ResponseWriter, r *http.Request) {
    rows, err := qh.db.Query("SELECT id, namespace, pod_name, reason, message, event_timestamp, status FROM pod_events_view ORDER BY event_timestamp DESC LIMIT 100")
    if err != nil {
        http.Error(w, err.Error(), http.StatusInternalServerError)
        return
    }
    defer rows.Close()

    var events []PodEventView
    for rows.Next() {
        var event PodEventView
        if err := rows.Scan(&event.ID, &event.Namespace, &event.PodName, &event.Reason, &event.Message, &event.Timestamp, &event.Status); err != nil {
            http.Error(w, err.Error(), http.StatusInternalServerError)
            return
        }
        events = append(events, event)
    }

    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(events)
}

func (qh *QueryHandler) getPodEventsByNamespace(w http.ResponseWriter, r *http.Request) {
    vars := mux.Vars(r)
    namespace := vars["namespace"]

    rows, err := qh.db.Query("SELECT id, namespace, pod_name, reason, message, event_timestamp, status FROM pod_events_view WHERE namespace = $1 ORDER BY event_timestamp DESC", namespace)
    if err != nil {
        http.Error(w, err.Error(), http.StatusInternalServerError)
        return
    }
    defer rows.Close()

    var events []PodEventView
    for rows.Next() {
        var event PodEventView
        if err := rows.Scan(&event.ID, &event.Namespace, &event.PodName, &event.Reason, &event.Message, &event.Timestamp, &event.Status); err != nil {
            http.Error(w, err.Error(), http.StatusInternalServerError)
            return
        }
        events = append(events, event)
    }

    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(events)
}

func (qh *QueryHandler) getPodEventsByStatus(w http.ResponseWriter, r *http.Request) {
    vars := mux.Vars(r)
    status := vars["status"]

    rows, err := qh.db.Query("SELECT id, namespace, pod_name, reason, message, event_timestamp, status FROM pod_events_view WHERE status = $1 ORDER BY event_timestamp DESC", status)
    if err != nil {
        http.Error(w, err.Error(), http.StatusInternalServerError)
        return
    }
    defer rows.Close()

    var events []PodEventView
    for rows.Next() {
        var event PodEventView
        if err := rows.Scan(&event.ID, &event.Namespace, &event.PodName, &event.Reason, &event.Message, &event.Timestamp, &event.Status); err != nil {
            http.Error(w, err.Error(), http.StatusInternalServerError)
            return
        }
        events = append(events, event)
    }

    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(events)
}

func main() {
    connectionString := "host=eventstore-db port=5432 user=eventuser dbname=eventstore sslmode=disable"
    
    handler, err := NewQueryHandler(connectionString)
    if err != nil {
        log.Fatal("Failed to create query handler:", err)
    }

    if err := handler.InitializeSchema(); err != nil {
        log.Fatal("Failed to initialize schema:", err)
    }

    router := mux.NewRouter()
    handler.RegisterRoutes(router)

    log.Println("Starting CQRS query service on :8080")
    log.Fatal(http.ListenAndServe(":8080", router))
}
```

## 6. ç›‘æ§ä¸å¯è§‚æµ‹æ€§

### 6.1 äº‹ä»¶ç›‘æ§æŒ‡æ ‡

```yaml
# äº‹ä»¶ç›‘æ§é…ç½®
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: event-driven-monitoring
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: event-driven-system
  endpoints:
  - port: metrics
    path: /metrics
    interval: 30s
    metricRelabelings:
    - sourceLabels: [__name__]
      regex: 'event_(.*)'
      targetLabel: __name__
---
# Prometheuså‘Šè­¦è§„åˆ™
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: event-driven-alerts
  namespace: monitoring
spec:
  groups:
  - name: event.rules
    rules:
    # äº‹ä»¶å¤„ç†å»¶è¿Ÿå‘Šè­¦
    - alert: EventProcessingDelayHigh
      expr: |
        histogram_quantile(0.99, rate(event_processing_duration_seconds_bucket[5m])) > 2
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "äº‹ä»¶å¤„ç†å»¶è¿Ÿè¿‡é«˜ (p99 > 2ç§’)"
        description: "99%çš„äº‹ä»¶å¤„ç†å»¶è¿Ÿè¶…è¿‡2ç§’"
    
    # ç§¯å‹äº‹ä»¶å‘Šè­¦
    - alert: EventBacklogHigh
      expr: |
        rate(event_backlog_size[5m]) > 1000
      for: 3m
      labels:
        severity: critical
      annotations:
        summary: "äº‹ä»¶ç§¯å‹æ•°é‡è¿‡å¤š (> 1000)"
        description: "æœªå¤„ç†äº‹ä»¶ç§¯å‹è¶…è¿‡é˜ˆå€¼"
    
    # äº‹ä»¶å¤„ç†å¤±è´¥å‘Šè­¦
    - alert: EventProcessingFailure
      expr: |
        increase(event_processing_failures_total[5m]) > 10
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "äº‹ä»¶å¤„ç†å¤±è´¥è¿‡å¤š (> 10)"
        description: "è¿‡å»5åˆ†é’Ÿå†…äº‹ä»¶å¤„ç†å¤±è´¥è¶…è¿‡10æ¬¡"
    
    # Kafkaæ¶ˆè´¹è€…å»¶è¿Ÿ
    - alert: KafkaConsumerLagHigh
      expr: |
        kafka_consumergroup_lag > 10000
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "Kafkaæ¶ˆè´¹è€…æ»åè¿‡å¤§ (> 10000)"
        description: "Kafkaæ¶ˆè´¹è€…æ»åæ¶ˆæ¯æ•°è¶…è¿‡10000æ¡"
```

### 6.2 åˆ†å¸ƒå¼è¿½è¸ªé…ç½®

```yaml
# OpenTelemetryè¿½è¸ªé…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: opentelemetry-collector-config
  namespace: monitoring
data:
  collector.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
          http:
    
    processors:
      batch:
        timeout: 10s
        send_batch_size: 1000
      attributes:
        actions:
        - key: event.namespace
          action: upsert
          from_attribute: namespace
        - key: event.kind
          action: upsert
          from_attribute: object_kind
        - key: event.name
          action: upsert
          from_attribute: object_name
    
    exporters:
      jaeger:
        endpoint: jaeger-collector.observability.svc.cluster.local:14250
        tls:
          insecure: true
      prometheus:
        endpoint: 0.0.0.0:9090
        const_labels:
          service: kubernetes-event-system
        send_timestamps: true
        metric_expiration: 180m
    
    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch, attributes]
          exporters: [jaeger]
        metrics:
          receivers: [otlp]
          processors: [batch, attributes]
          exporters: [prometheus]
```

## 7. æœ€ä½³å®è·µä¸å®æ–½æŒ‡å—

### 7.1 äº‹ä»¶é©±åŠ¨è®¾è®¡åŸåˆ™

```markdown
## ğŸ¯ äº‹ä»¶é©±åŠ¨è®¾è®¡åŸåˆ™

### 1. äº‹ä»¶ç²’åº¦
- è®¾è®¡æœ‰æ„ä¹‰çš„äº‹ä»¶
- é¿å…äº‹ä»¶è¿‡äºç»†åŒ–æˆ–ç²—ç³™
- è€ƒè™‘ä¸šåŠ¡åœºæ™¯çš„éœ€æ±‚

### 2. å¼‚æ­¥å¤„ç†
- åˆ©ç”¨äº‹ä»¶é˜Ÿåˆ—çš„ç¼“å†²èƒ½åŠ›
- å®ç°é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- æ³¨æ„é¡ºåºä¸€è‡´æ€§ä¿è¯

### 3. æœ€ç»ˆä¸€è‡´æ€§
- æ¥å—æœ€ç»ˆä¸€è‡´æ€§æ¨¡å‹
- è®¾è®¡è¡¥å¿æœºåˆ¶
- å®ç°å¹‚ç­‰æ€§å¤„ç†

### 4. å¯è§‚æµ‹æ€§
- å»ºç«‹å®Œæ•´çš„ç›‘æ§æŒ‡æ ‡
- å®ç°åˆ†å¸ƒå¼è¿½è¸ª
- å»ºç«‹å‘Šè­¦æœºåˆ¶
```

### 7.2 å®æ–½æ£€æŸ¥æ¸…å•

```yaml
äº‹ä»¶é©±åŠ¨æ¶æ„å®æ–½æ¸…å•:
  æ¶æ„è®¾è®¡:
    â˜ äº‹ä»¶å»ºæ¨¡å®Œæˆ
    â˜ æ¶ˆæ¯é˜Ÿåˆ—é€‰å‹
    â˜ äº‹ä»¶å­˜å‚¨ç­–ç•¥ç¡®å®š
    â˜ CQRSæ¨¡å¼è®¾è®¡
  
  æŠ€æœ¯å®ç°:
    â˜ äº‹ä»¶ç”Ÿäº§è€…å¼€å‘
    â˜ äº‹ä»¶æ¶ˆè´¹è€…å¼€å‘
    â˜ äº‹ä»¶å¤„ç†é€»è¾‘å®ç°
    â˜ é”™è¯¯å¤„ç†æœºåˆ¶
  
  è¿ç»´ç›‘æ§:
    â˜ ç›‘æ§æŒ‡æ ‡é…ç½®
    â˜ å‘Šè­¦è§„åˆ™è®¾ç½®
    â˜ åˆ†å¸ƒå¼è¿½è¸ªé›†æˆ
    â˜ æ—¥å¿—æ”¶é›†é…ç½®
  
  å®‰å…¨åˆè§„:
    â˜ äº‹ä»¶åŠ å¯†ä¼ è¾“
    â˜ è®¿é—®æ§åˆ¶é…ç½®
    â˜ å®¡è®¡æ—¥å¿—è®°å½•
    â˜ æ•°æ®ä¿ç•™ç­–ç•¥
```

## 8. æœªæ¥å‘å±•è¶‹åŠ¿

### 8.1 äº‘åŸç”Ÿäº‹ä»¶ç³»ç»Ÿ

```yaml
äº‘åŸç”Ÿäº‹ä»¶å‘å±•è¶‹åŠ¿:
  1. Serverlessäº‹ä»¶å¤„ç†
     - äº‹ä»¶é©±åŠ¨çš„å‡½æ•°è®¡ç®—
     - è‡ªåŠ¨æ‰©ç¼©å®¹èƒ½åŠ›
     - æŒ‰éœ€ä»˜è´¹æ¨¡å¼
  
  2. è¾¹ç¼˜äº‹ä»¶å¤„ç†
     - è¾¹ç¼˜èŠ‚ç‚¹äº‹ä»¶æ”¶é›†
     - æœ¬åœ°äº‹ä»¶å¤„ç†
     - æ–­ç½‘è‡ªæ²»èƒ½åŠ›
  
  3. AIé©±åŠ¨çš„äº‹ä»¶åˆ†æ
     - æ™ºèƒ½äº‹ä»¶åˆ†ç±»
     - å¼‚å¸¸æ£€æµ‹é¢„è­¦
     - è‡ªåŠ¨åŒ–å“åº”å†³ç­–
```

---
*æœ¬æ–‡æ¡£åŸºäºä¼ä¸šçº§äº‹ä»¶é©±åŠ¨æ¶æ„å®è·µç»éªŒç¼–å†™ï¼ŒæŒç»­æ›´æ–°æœ€æ–°æŠ€æœ¯å’Œæœ€ä½³å®è·µã€‚*