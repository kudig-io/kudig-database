# Datadog ä¼ä¸šçº§ç›‘æ§å¹³å°æ·±åº¦å®è·µ

## æ¦‚è¿° (Overview)

Datadogæ˜¯ä¸šç•Œé¢†å…ˆçš„ä¼ä¸šçº§ç›‘æ§å¹³å°ï¼Œæä¾›åŸºç¡€è®¾æ–½ã€åº”ç”¨ç¨‹åºå’Œä¸šåŠ¡æŒ‡æ ‡çš„ç»Ÿä¸€ç›‘æ§è§£å†³æ–¹æ¡ˆã€‚æœ¬æ–‡æ¡£ä»ä¼ä¸šçº§è¿ç»´ä¸“å®¶è§’åº¦ï¼Œæ·±å…¥æ¢è®¨Datadogçš„æ¶æ„è®¾è®¡ã€ç›‘æ§ç­–ç•¥ã€å‘Šè­¦ç®¡ç†å’Œæœ€ä½³å®è·µã€‚

Datadog is the industry-leading enterprise monitoring platform that provides unified monitoring solutions for infrastructure, applications, and business metrics. This document explores Datadog's architecture design, monitoring strategies, alert management, and best practices from an enterprise operations expert perspective.

## æ¶æ„è®¾è®¡ (Architecture Design)

### Datadog ä¼ä¸šçº§ç›‘æ§æ¶æ„ (Enterprise Datadog Monitoring Architecture)

```yaml
# Datadog Agent éƒ¨ç½²é…ç½®
datadog_agent:
  version: "7.44.0"
  deployment:
    method: "DaemonSet"
    namespace: "datadog"
    replicas: "æ¯ä¸ªèŠ‚ç‚¹ä¸€ä¸ªå®ä¾‹"
    
  configuration:
    api_key: "${DATADOG_API_KEY}"
    site: "datadoghq.com"
    log_level: "INFO"
    
    # æ ¸å¿ƒåŠŸèƒ½å¯ç”¨
    apm:
      enabled: true
      env: "production"
      service: "my-service"
      version: "1.0.0"
      
    logs:
      enabled: true
      container_collect_all: true
      
    process_agent:
      enabled: true
      process_collection: true
      
    network_performance_monitoring:
      enabled: true
      
    # å®‰å…¨é…ç½®
    dogstatsd:
      use_dogstatsd: true
      dogstatsd_port: 8125
      telemetry_enabled: true
```

### ç›‘æ§æ¶æ„å›¾ (Monitoring Architecture Diagram)

```mermaid
graph TB
    subgraph "åŸºç¡€è®¾æ–½å±‚"
        HOSTS[ç‰©ç†ä¸»æœº/è™šæ‹Ÿæœº]
        CONTAINERS[Dockerå®¹å™¨]
        K8S[Kubernetesé›†ç¾¤]
        CLOUD[AWS/Azure/GCP]
    end
    
    subgraph "Datadog Agentå±‚"
        AGENT1[Datadog Agent 1]
        AGENT2[Datadog Agent 2]
        AGENT3[Datadog Agent 3]
    end
    
    subgraph "æ•°æ®æ”¶é›†å±‚"
        METRICS[æŒ‡æ ‡æ”¶é›†]
        LOGS[æ—¥å¿—æ”¶é›†]
        APM[åº”ç”¨æ€§èƒ½ç›‘æ§]
        RUM[ç”¨æˆ·ä½“éªŒç›‘æ§]
        SYNTHETICS[åˆæˆç›‘æ§]
    end
    
    subgraph "Datadogå¹³å°"
        INGESTION[æ•°æ®æ‘„å–]
        PROCESSING[æ•°æ®å¤„ç†]
        STORAGE[æ•°æ®å­˜å‚¨]
        ANALYTICS[æ•°æ®åˆ†æ]
    end
    
    subgraph "å¯è§†åŒ–å±‚"
        DASHBOARDS[ç›‘æ§ä»ªè¡¨æ¿]
        ALERTS[å‘Šè­¦ç³»ç»Ÿ]
        NOTEBOOKS[åˆ†æç¬”è®°æœ¬]
        MONITORS[ç›‘æ§å™¨]
    end
    
    HOSTS --> AGENT1
    CONTAINERS --> AGENT2
    K8S --> AGENT3
    CLOUD --> AGENT1
    
    AGENT1 --> METRICS
    AGENT2 --> LOGS
    AGENT3 --> APM
    
    METRICS --> INGESTION
    LOGS --> INGESTION
    APM --> INGESTION
    RUM --> INGESTION
    SYNTHETICS --> INGESTION
    
    INGESTION --> PROCESSING
    PROCESSING --> STORAGE
    STORAGE --> ANALYTICS
    
    ANALYTICS --> DASHBOARDS
    ANALYTICS --> ALERTS
    ANALYTICS --> NOTEBOOKS
    ANALYTICS --> MONITORS
```

## æ ¸å¿ƒåŠŸèƒ½é…ç½® (Core Functionality Configuration)

### åŸºç¡€è®¾æ–½ç›‘æ§é…ç½® (Infrastructure Monitoring Configuration)

```yaml
# åŸºç¡€è®¾æ–½ç›‘æ§å®Œæ•´é…ç½®
infrastructure_monitoring:
  # ä¸»æœºç›‘æ§
  host_metrics:
    cpu:
      enabled: true
      metrics:
        - system.cpu.idle
        - system.cpu.user
        - system.cpu.system
        - system.cpu.iowait
        
    memory:
      enabled: true
      metrics:
        - system.mem.total
        - system.mem.used
        - system.mem.free
        - system.mem.usable
        
    disk:
      enabled: true
      metrics:
        - system.disk.in_use
        - system.disk.read_bytes
        - system.disk.write_bytes
        - system.io.util
        
    network:
      enabled: true
      metrics:
        - system.net.bytes_rcvd
        - system.net.bytes_sent
        - system.net.packets_in.count
        - system.net.packets_out.count

  # å®¹å™¨ç›‘æ§
  container_monitoring:
    docker:
      enabled: true
      metrics:
        - docker.mem.cache
        - docker.mem.rss
        - docker.cpu.usage
        - docker.net.bytes_rcvd
        
    kubernetes:
      enabled: true
      metrics:
        - kubernetes.cpu.limits
        - kubernetes.memory.requests
        - kubernetes.pods.running
        - kubernetes.nodes.ready

  # äº‘å¹³å°ç›‘æ§
  cloud_integration:
    aws:
      enabled: true
      services:
        - ec2
        - rds
        - s3
        - elb
        - lambda
        
    azure:
      enabled: true
      services:
        - virtual_machines
        - sql_database
        - storage_accounts
        - app_service
        
    gcp:
      enabled: true
      services:
        - compute_engine
        - cloud_sql
        - cloud_storage
        - cloud_run
```

### åº”ç”¨æ€§èƒ½ç›‘æ§é…ç½® (APM Configuration)

```yaml
# APM åº”ç”¨æ€§èƒ½ç›‘æ§é…ç½®
apm_configuration:
  # é€šç”¨é…ç½®
  general:
    enabled: true
    env: "production"
    service: "web-application"
    version: "1.2.3"
    
  # é‡‡æ ·é…ç½®
  sampling:
    sample_rate: 1.0  # 100%é‡‡æ ·
    priority_sampling: true
    ignore_resources:
      - "^OPTIONS "
      - "^GET /health"
      - "^GET /metrics"
      
  # è¿½è¸ªé…ç½®
  tracing:
    distributed_tracing: true
    trace_propagation_style: "datadog,b3"
    span_sampling_rules:
      - service: "database"
        name: "query"
        sample_rate: 0.1
      - service: "cache"
        name: "redis.command"
        sample_rate: 0.05
        
  # æœåŠ¡æ˜ å°„
  service_mapping:
    - from: "sqlalchemy"
      to: "database"
    - from: "redis"
      to: "cache"
    - from: "requests"
      to: "external-api"
      
  # æ ‡ç­¾é…ç½®
  tags:
    - env:production
    - team:backend
    - datacenter:us-east-1
    - kubernetes_pod:${KUBERNETES_POD_NAME}
```

## ç›‘æ§ç­–ç•¥ (Monitoring Strategies)

### å…³é”®ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§ (Key Business Metrics Monitoring)

```python
# Datadog ç›‘æ§ç­–ç•¥ Python SDK ç¤ºä¾‹
from datadog import initialize, api
import time

class DatadogMonitoringStrategy:
    def __init__(self):
        self.options = {
            'api_key': 'your_api_key',
            'app_key': 'your_app_key'
        }
        initialize(**self.options)
        
    def create_business_metrics_monitor(self):
        """åˆ›å»ºä¸šåŠ¡å…³é”®æŒ‡æ ‡ç›‘æ§"""
        
        # è®¢å•å¤„ç†ç›‘æ§
        order_processing_monitor = {
            'name': '[Business] Order Processing Latency',
            'type': 'metric alert',
            'query': 'avg(last_5m):avg:business.order.processing_time{*} > 5000',
            'message': '@slack-commerce-team @pagerduty Order processing latency exceeds 5 seconds',
            'tags': ['business', 'orders', 'latency'],
            'priority': 2
        }
        
        # ç”¨æˆ·æ³¨å†Œç›‘æ§
        user_registration_monitor = {
            'name': '[Business] User Registration Rate',
            'type': 'metric alert',
            'query': 'avg(last_10m):avg:business.user.registrations{*}.as_count() < 10',
            'message': '@slack-growth-team User registration rate dropped below 10 per 10 minutes',
            'tags': ['business', 'users', 'growth'],
            'priority': 3
        }
        
        # æ”¶å…¥ç›‘æ§
        revenue_monitor = {
            'name': '[Business] Revenue Drop Detection',
            'type': 'forecast',
            'query': 'forecast(avg:business.revenue{*}, \'linear\', 30, interval='1h', history='1d', model='default') < 0.8 * avg:business.revenue{*}',
            'message': '@finance-team @ceo Potential revenue drop detected - investigate immediately',
            'tags': ['business', 'revenue', 'finance'],
            'priority': 1
        }
        
        return [
            order_processing_monitor,
            user_registration_monitor,
            revenue_monitor
        ]
    
    def create_infrastructure_monitors(self):
        """åˆ›å»ºåŸºç¡€è®¾æ–½ç›‘æ§å™¨"""
        
        monitors = [
            # CPUä½¿ç”¨ç‡ç›‘æ§
            {
                'name': '[Infra] High CPU Usage',
                'type': 'metric alert',
                'query': 'avg(last_5m):avg:system.cpu.user{*} by {host} > 80',
                'message': '@devops-team High CPU usage detected on {{host.name}}',
                'tags': ['infrastructure', 'cpu', 'performance'],
                'priority': 3
            },
            
            # å†…å­˜ä½¿ç”¨ç‡ç›‘æ§
            {
                'name': '[Infra] High Memory Usage',
                'type': 'metric alert',
                'query': 'avg(last_5m):avg:system.mem.pct_usable{*} by {host} < 0.2',
                'message': '@devops-team Low memory available on {{host.name}}',
                'tags': ['infrastructure', 'memory', 'performance'],
                'priority': 3
            },
            
            # ç£ç›˜ç©ºé—´ç›‘æ§
            {
                'name': '[Infra] Low Disk Space',
                'type': 'metric alert',
                'query': 'avg(last_5m):avg:system.disk.in_use{*} by {host,device} > 0.9',
                'message': '@devops-team Critical disk space on {{host.name}}:{{device}}',
                'tags': ['infrastructure', 'disk', 'storage'],
                'priority': 2
            }
        ]
        
        return monitors

# ä½¿ç”¨ç¤ºä¾‹
strategy = DatadogMonitoringStrategy()

# åˆ›å»ºä¸šåŠ¡ç›‘æ§å™¨
business_monitors = strategy.create_business_metrics_monitor()
for monitor in business_monitors:
    result = api.Monitor.create(**monitor)
    print(f"Created monitor: {result['name']} with ID: {result['id']}")

# åˆ›å»ºåŸºç¡€è®¾æ–½ç›‘æ§å™¨
infra_monitors = strategy.create_infrastructure_monitors()
for monitor in infra_monitors:
    result = api.Monitor.create(**monitor)
    print(f"Created monitor: {result['name']} with ID: {result['id']}")
```

### æ—¥å¿—ç›‘æ§é…ç½® (Log Monitoring Configuration)

```yaml
# æ—¥å¿—ç›‘æ§å’Œåˆ†æé…ç½®
logs_configuration:
  # æ—¥å¿—æ”¶é›†é…ç½®
  log_collection:
    sources:
      - type: "docker"
        service: "application"
        source: "java"
        log_processing_rules:
          - type: "multi_line"
            name: "new_log_start_with_date"
            pattern: "\\d{4}\\-\\d{2}\\-\\d{2}"
            
      - type: "file"
        path: "/var/log/application/*.log"
        service: "backend"
        source: "python"
        log_processing_rules:
          - type: "include_at_match"
            name: "include_error_logs"
            pattern: "ERROR|CRITICAL"
            
  # æ—¥å¿—å¤„ç†ç®¡é“
  processing_pipelines:
    - name: "application_log_pipeline"
      is_enabled: true
      filter:
        query: "source:java OR source:python"
      processors:
        - name: "grok_parser"
          type: "grok-parser"
          source: "message"
          grok:
            pattern: "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{DATA:logger} - %{GREEDYDATA:message}"
            
        - name: "status_classifier"
          type: "status-code-remapper"
          sources:
            - "http.status_code"
          target: "http.status_category"
          
        - name: "geoip_processor"
          type: "geo-ip-parser"
          sources:
            - "network.client.ip"
            
  # æ—¥å¿—å‘Šè­¦é…ç½®
  log_alerts:
    - name: "[Logs] Application Error Rate"
      query: 'status:error AND service:application'.index('main').rollup('count').last('5m') > 100
      message: "@dev-team High error rate detected in application logs"
      tags: ["logs", "errors", "application"]
      
    - name: "[Logs] Security Event"
      query: 'security.attack.type:* AND @severity:high'.index('security').rollup('count').last('10m') > 5
      message: "@security-team High severity security events detected"
      tags: ["logs", "security", "alerts"]
```

## å‘Šè­¦ç®¡ç† (Alert Management)

### æ™ºèƒ½å‘Šè­¦é…ç½® (Intelligent Alerting Configuration)

```json
{
  "alerting_strategies": {
    "composite_alerts": {
      "order_processing_issues": {
        "name": "Order Processing Issues Composite Alert",
        "type": "composite",
        "message": "@ops-team Critical order processing issues detected",
        "tags": ["composite", "business", "orders"],
        "priority": 1,
        "query": "1 && 2 && (3 || 4)",
        "monitors": [
          {
            "id": 1,
            "name": "High Order Processing Latency"
          },
          {
            "id": 2,
            "name": "Order Failure Rate Spike"
          },
          {
            "id": 3,
            "name": "Payment Processing Timeout"
          },
          {
            "id": 4,
            "name": "Inventory Sync Failure"
          }
        ]
      }
    },
    
    "anomaly_detection": {
      "traffic_anomaly": {
        "name": "Traffic Anomaly Detection",
        "type": "query alert",
        "query": "avg(last_4h):anomalies(avg:nginx.net.request_per_s{*}, 'basic', 2, direction='both', alert_window='last_15m', interval=60, count_default_zero='true', seasonality='weekly') >= 1",
        "message": "@web-team Unusual traffic pattern detected",
        "tags": ["anomaly", "traffic", "web"],
        "priority": 2
      }
    },
    
    "forecast_alerts": {
      "capacity_planning": {
        "name": "Resource Capacity Forecast",
        "type": "query alert",
        "query": "forecast(avg:system.cpu.user{*} by {host}, 'linear', 24, interval='1h', history='7d', model='default') > 85",
        "message": "@devops-team CPU capacity will exceed 85% in 24 hours",
        "tags": ["forecast", "capacity", "cpu"],
        "priority": 3
      }
    }
  }
}
```

### å‘Šè­¦æŠ‘åˆ¶å’Œå»é‡ (Alert Suppression and Deduplication)

```yaml
# å‘Šè­¦æŠ‘åˆ¶ç­–ç•¥
alert_suppression:
  # æ—¶é—´çª—å£æŠ‘åˆ¶
  time_windows:
    - name: "maintenance_window"
      start: "02:00"
      end: "04:00"
      timezone: "America/New_York"
      suppressed_monitors:
        - "High CPU Usage"
        - "Low Memory"
        
  # ä¾èµ–å…³ç³»æŠ‘åˆ¶
  dependency_suppression:
    - name: "database_dependent_services"
      parent_monitor: "Database Connection Pool"
      child_monitors:
        - "User Authentication Service"
        - "Order Processing Service"
        - "Payment Service"
      suppression_logic: "suppress children when parent is critical"
      
  # å‘Šè­¦å»é‡è§„åˆ™
  deduplication_rules:
    - name: "similar_host_alerts"
      group_by: ["host", "service"]
      time_window: "10m"
      merge_strategy: "keep_highest_priority"
      
    - name: "related_metric_alerts"
      group_by: ["team", "environment"]
      correlation_window: "5m"
      aggregation_method: "combine_similar_messages"
```

## ä»ªè¡¨æ¿å’Œå¯è§†åŒ– (Dashboards and Visualization)

### ä¼ä¸šçº§ä»ªè¡¨æ¿é…ç½® (Enterprise Dashboard Configuration)

```json
{
  "dashboard_templates": {
    "executive_overview": {
      "title": "Executive Business Overview",
      "layout_type": "ordered",
      "widgets": [
        {
          "id": 1,
          "definition": {
            "type": "timeseries",
            "title": "Business KPIs - Last 24 Hours",
            "show_legend": true,
            "requests": [
              {
                "q": "avg:business.orders.count{*}.as_count()",
                "display_type": "area",
                "style": {
                  "palette": "warm"
                }
              },
              {
                "q": "avg:business.revenue{*}",
                "display_type": "bars",
                "style": {
                  "palette": "cool"
                }
              }
            ]
          }
        },
        {
          "id": 2,
          "definition": {
            "type": "toplist",
            "title": "Top Performing Services",
            "requests": [
              {
                "q": "top(avg:trace.servlet.request.hits{*} by {service}, 10, 'mean', 'desc')"
              }
            ]
          }
        },
        {
          "id": 3,
          "definition": {
            "type": "heatmap",
            "title": "User Experience Heatmap",
            "requests": [
              {
                "q": "avg:rum.browser.long_task.duration{*} by {browser.name}"
              }
            ]
          }
        }
      ]
    },
    
    "infrastructure_health": {
      "title": "Infrastructure Health Dashboard",
      "template_variables": [
        {
          "name": "env",
          "default": "production"
        },
        {
          "name": "region",
          "default": "us-east-1"
        }
      ],
      "widgets": [
        {
          "id": 1,
          "definition": {
            "type": "hostmap",
            "title": "Host Health Status",
            "requests": [
              {
                "fill": {
                  "q": "avg:system.cpu.user{$env,$region} by {host}"
                },
                "size": {
                  "q": "avg:system.mem.pct_usable{$env,$region} by {host}"
                }
              }
            ],
            "node_type": "host",
            "no_group_hosts": false,
            "no_metric_hosts": false,
            "style": {
              "palette": "green_to_orange",
              "palette_flip": false
            }
          }
        }
      ]
    }
  }
}
```

## è¿ç»´ç®¡ç† (Operational Management)

### è‡ªåŠ¨åŒ–è¿ç»´è„šæœ¬ (Automated Operations Scripts)

```bash
#!/bin/bash
# Datadog è¿ç»´ç®¡ç†è‡ªåŠ¨åŒ–è„šæœ¬

# ç¯å¢ƒå˜é‡é…ç½®
export DATADOG_API_KEY="your_api_key"
export DATADOG_APP_KEY="your_app_key"
export DATADOG_SITE="datadoghq.com"

# ç›‘æ§å™¨å¥åº·æ£€æŸ¥
check_monitor_health() {
    echo "=== Checking Datadog Monitor Health ==="
    
    # è·å–æ‰€æœ‰ç›‘æ§å™¨çŠ¶æ€
    monitors=$(curl -s -X GET \
        "https://api.${DATADOG_SITE}/api/v1/monitor" \
        -H "DD-API-KEY: ${DATADOG_API_KEY}" \
        -H "DD-APPLICATION-KEY: ${DATADOG_APP_KEY}")
    
    # åˆ†æç›‘æ§å™¨çŠ¶æ€
    echo "$monitors" | jq -r '.[] | select(.overall_state != "OK") | 
        "âš ï¸  Monitor: \(.name) - State: \(.overall_state) - ID: \(.id)"'
    
    # ç»Ÿè®¡å„ç±»çŠ¶æ€
    total=$(echo "$monitors" | jq 'length')
    ok_count=$(echo "$monitors" | jq '[.[] | select(.overall_state == "OK")] | length')
    warning_count=$(echo "$monitors" | jq '[.[] | select(.overall_state == "Warning")] | length')
    alert_count=$(echo "$monitors" | jq '[.[] | select(.overall_state == "Alert")] | length')
    
    echo "ğŸ“Š Total Monitors: $total"
    echo "âœ… OK: $ok_count"
    echo "âš ï¸  Warning: $warning_count"
    echo "ğŸš¨ Alert: $alert_count"
}

# è‡ªåŠ¨æ‰©å®¹å»ºè®®
generate_scaling_recommendations() {
    echo "=== Generating Scaling Recommendations ==="
    
    # CPUä½¿ç”¨ç‡åˆ†æ
    high_cpu_hosts=$(curl -s -X GET \
        "https://api.${DATADOG_SITE}/api/v1/query" \
        -H "DD-API-KEY: ${DATADOG_API_KEY}" \
        -H "DD-APPLICATION-KEY: ${DATADOG_APP_KEY}" \
        --data-urlencode "from=$(($(date +%s) - 3600))" \
        --data-urlencode "to=$(date +%s)" \
        --data-urlencode "query=avg:system.cpu.user{*} by {host} > 75")
    
    echo "ğŸ–¥ï¸  Hosts with high CPU (>75%):"
    echo "$high_cpu_hosts" | jq -r '.series[] | "  - \(.scope) - Average: \(.pointlist[-1][1])%"'
    
    # å†…å­˜å‹åŠ›åˆ†æ
    low_memory_hosts=$(curl -s -X GET \
        "https://api.${DATADOG_SITE}/api/v1/query" \
        -H "DD-API-KEY: ${DATADOG_API_KEY}" \
        -H "DD-APPLICATION-KEY: ${DATADOG_APP_KEY}" \
        --data-urlencode "from=$(($(date +%s) - 3600))" \
        --data-urlencode "to=$(date +%s)" \
        --data-urlencode "query=avg:system.mem.pct_usable{*} by {host} < 0.2")
    
    echo "ğŸ’¾ Hosts with low memory (<20% available):"
    echo "$low_memory_hosts" | jq -r '.series[] | "  - \(.scope) - Available: \(.pointlist[-1][1]*100)%"`
}

# æ—¥å¿—å¼‚å¸¸æ£€æµ‹
detect_log_anomalies() {
    echo "=== Detecting Log Anomalies ==="
    
    # é”™è¯¯æ—¥å¿—çªå¢æ£€æµ‹
    error_spike=$(curl -s -X GET \
        "https://api.${DATADOG_SITE}/api/v1/query" \
        -H "DD-API-KEY: ${DATADOG_API_KEY}" \
        -H "DD-APPLICATION-KEY: ${DATADOG_APP_KEY}" \
        --data-urlencode "from=$(($(date +%s) - 3600))" \
        --data-urlencode "to=$(date +%s)" \
        --data-urlencode "query=count:logs.status:error{*}.as_count() > 100")
    
    if [ "$(echo "$error_spike" | jq '.series | length')" -gt 0 ]; then
        echo "ğŸš¨ Error log spike detected:"
        echo "$error_spike" | jq -r '.series[] | "  Service: \(.scope) - Count: \(.pointlist[-1][1])"'
    else
        echo "âœ… No significant error log spikes detected"
    fi
}

# æ€§èƒ½åŸºå‡†å»ºç«‹
establish_performance_baselines() {
    echo "=== Establishing Performance Baselines ==="
    
    services=("web-server" "api-service" "database" "cache")
    
    for service in "${services[@]}"; do
        echo "ğŸ“Š Establishing baseline for $service"
        
        # è·å–è¿‡å»ä¸€å‘¨çš„æ€§èƒ½æ•°æ®
        baseline_data=$(curl -s -X GET \
            "https://api.${DATADOG_SITE}/api/v1/query" \
            -H "DD-API-KEY: ${DATADOG_API_KEY}" \
            -H "DD-APPLICATION-KEY: ${DATADOG_APP_KEY}" \
            --data-urlencode "from=$(($(date +%s) - 604800))" \
            --data-urlencode "to=$(date +%s)" \
            --data-urlencode "query=avg:trace.servlet.request.duration{service:$service}")
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        avg_response_time=$(echo "$baseline_data" | jq -r '.series[0].pointlist | map(.[1]) | add / length')
        p95_response_time=$(echo "$baseline_data" | jq -r '.series[0].pointlist | map(.[1]) | sort | .[.[] | length * 0.95 | floor]')
        
        echo "  Average Response Time: ${avg_response_time}ms"
        echo "  95th Percentile: ${p95_response_time}ms"
        
        # ä¿å­˜åŸºçº¿æ•°æ®
        echo "{\"service\":\"$service\",\"avg\":$avg_response_time,\"p95\":$p95_response_time,\"timestamp\":\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"}" >> /tmp/performance_baselines.json
    done
}

# ä¸»æ‰§è¡Œå‡½æ•°
main() {
    echo "ğŸš€ Starting Datadog Operations Management"
    echo "Timestamp: $(date)"
    echo "========================================"
    
    check_monitor_health
    echo
    generate_scaling_recommendations
    echo
    detect_log_anomalies
    echo
    establish_performance_baselines
    
    echo "========================================"
    echo "âœ… Datadog Operations Management Completed"
}

# æ‰§è¡Œä¸»å‡½æ•°
main
```

## æœ€ä½³å®è·µ (Best Practices)

### ç›‘æ§è®¾è®¡åŸåˆ™ (Monitoring Design Principles)

1. **ä¸šåŠ¡å¯¼å‘ç›‘æ§**
   ```yaml
   # ä¸šåŠ¡ä»·å€¼é©±åŠ¨çš„ç›‘æ§æŒ‡æ ‡
   business_metrics:
     - name: "è®¢å•è½¬åŒ–ç‡"
       metric: "business.order.conversion_rate"
       threshold: "< 2.5%"
       action: "ç«‹å³é€šçŸ¥äº§å“å›¢é˜Ÿ"
       
     - name: "ç”¨æˆ·æ´»è·ƒåº¦"
       metric: "business.user.active_daily"
       threshold: "< 10000"
       action: "é€šçŸ¥å¢é•¿å›¢é˜Ÿè°ƒæŸ¥"
   ```

2. **åˆ†å±‚å‘Šè­¦ç­–ç•¥**
   ```yaml
   # å¤šå±‚æ¬¡å‘Šè­¦ä½“ç³»
   alert_hierarchy:
     level_1: # ä¸šåŠ¡å½±å“å‘Šè­¦
       severity: "critical"
       notification: "@business-stakeholders @pagerduty"
       response_time: "15åˆ†é’Ÿå†…å“åº”"
       
     level_2: # ç³»ç»Ÿæ€§èƒ½å‘Šè­¦
       severity: "warning" 
       notification: "@devops-team @slack-notifications"
       response_time: "1å°æ—¶å†…å“åº”"
       
     level_3: # åŸºç¡€è®¾æ–½å‘Šè­¦
       severity: "info"
       notification: "@infrastructure-team"
       response_time: "ä¸‹ä¸€ä¸ªå·¥ä½œæ—¥å¤„ç†"
   ```

3. **æˆæœ¬ä¼˜åŒ–ç­–ç•¥**
   ```yaml
   # ç›‘æ§æˆæœ¬æ§åˆ¶
   cost_optimization:
     data_retention:
       high_value_metrics: "13 months"
       medium_value_metrics: "6 months" 
       low_value_metrics: "3 months"
       
     sampling_strategies:
       production: "100% sampling"
       staging: "50% sampling"
       development: "10% sampling"
       
     log_ingestion:
       exclude_patterns:
         - "DEBUG logs"
         - "verbose output"
         - "temporary files"
   ```

### å®‰å…¨å’Œåˆè§„ (Security and Compliance)

```yaml
# å®‰å…¨ç›‘æ§é…ç½®
security_monitoring:
  # è®¿é—®æ§åˆ¶ç›‘æ§
  access_control:
    failed_login_attempts:
      threshold: "> 10 in 5 minutes"
      action: "è´¦æˆ·é”å®š + å®‰å…¨å›¢é˜Ÿé€šçŸ¥"
      
    privilege_escalation:
      detection: "sudoå‘½ä»¤ä½¿ç”¨ç›‘æ§"
      alert_level: "high"
      
  # æ•°æ®å®‰å…¨ç›‘æ§
  data_protection:
    sensitive_data_access:
      monitored_patterns:
        - "credit_card"
        - "social_security"
        - "password"
      action: "å®æ—¶å‘Šè­¦ + å®¡è®¡æ—¥å¿—"
      
    data_exfiltration:
      network_traffic_analysis: true
      anomaly_detection: true
      threshold: "å¼‚å¸¸æ•°æ®ä¼ è¾“é‡ > 100MB"
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2024å¹´2æœˆ7æ—¥  
**é€‚ç”¨ç‰ˆæœ¬**: Datadog Agent 7.44+