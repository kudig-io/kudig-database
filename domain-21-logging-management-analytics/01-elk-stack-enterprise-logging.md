# ELK Stackä¼ä¸šçº§æ—¥å¿—ç®¡ç†ç³»ç»Ÿæ·±åº¦å®è·µ

> **ä½œè€…**: æ—¥å¿—ç³»ç»Ÿæ¶æ„ä¸“å®¶ | **ç‰ˆæœ¬**: v1.0 | **æ›´æ–°æ—¶é—´**: 2026-02-07
> **é€‚ç”¨åœºæ™¯**: ä¼ä¸šçº§æ—¥å¿—å¹³å°æ¶æ„ | **å¤æ‚åº¦**: â­â­â­â­â­

## ğŸ¯ æ‘˜è¦

æœ¬æ–‡æ¡£æ·±å…¥æ¢è®¨äº†ELK Stackä¼ä¸šçº§æ—¥å¿—ç®¡ç†ç³»ç»Ÿçš„æ¶æ„è®¾è®¡ã€éƒ¨ç½²å®è·µå’Œè¿ç»´ç®¡ç†ï¼ŒåŸºäºå¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒçš„å®è·µç»éªŒï¼Œæä¾›ä»æ—¥å¿—æ”¶é›†åˆ°åˆ†æå¯è§†åŒ–çš„å®Œæ•´æŠ€æœ¯æŒ‡å—ï¼Œå¸®åŠ©ä¼ä¸šæ„å»ºé«˜æ•ˆã€å¯é çš„æ—¥å¿—ç®¡ç†ä½“ç³»ã€‚

## 1. ELKæ¶æ„æ·±åº¦è§£æ

### 1.1 æ ¸å¿ƒç»„ä»¶æ¶æ„

```mermaid
graph TB
    subgraph "æ—¥å¿—æ”¶é›†å±‚"
        A[Filebeat] --> B[Logstash]
        C[Metricbeat] --> B
        D[Packetbeat] --> B
        E[Winlogbeat] --> B
        F[Journald] --> B
    end
    
    subgraph "æ—¥å¿—å¤„ç†å±‚"
        B --> G[Elasticsearch Ingest Node]
        G --> H[Logstash Processing Pipeline]
        H --> I[Elasticsearch Master Node]
    end
    
    subgraph "å­˜å‚¨æ£€ç´¢å±‚"
        I --> J[Elasticsearch Data Node]
        J --> K[Elasticsearch Coordinating Node]
    end
    
    subgraph "åˆ†æå±•ç¤ºå±‚"
        L[Kibana] --> K
        M[Grafana] --> K
        N[APM Server] --> K
    end
    
    subgraph "ç›‘æ§ç®¡ç†å±‚"
        O[Elasticsearch Monitoring]
        P[X-Pack Security]
        Q[Elasticsearch Alerting]
    end
```

### 1.2 ç»„ä»¶åŠŸèƒ½è¯¦è§£

```yaml
ELK Stackç»„ä»¶è¯´æ˜:
  Elasticsearch:
    åŠŸèƒ½: åˆ†å¸ƒå¼æœç´¢å¼•æ“å’Œåˆ†æå¼•æ“
    ç‰¹æ€§: 
      - å…¨æ–‡æœç´¢å’Œç»“æ„åŒ–æœç´¢
      - å®æ—¶åˆ†æèƒ½åŠ›
      - æ°´å¹³æ‰©å±•æ€§
      - é«˜å¯ç”¨æ€§
    ç‰ˆæœ¬: 8.11.0+
  
  Logstash:
    åŠŸèƒ½: æ•°æ®å¤„ç†ç®¡é“
    ç‰¹æ€§:
      - è¾“å…¥æ’ä»¶ä¸°å¯Œ
      - è¿‡æ»¤å¤„ç†å¼ºå¤§
      - è¾“å‡ºæ’ä»¶å¤šæ ·
      - å¯ç¼–ç¨‹æ€§é«˜
    ç‰ˆæœ¬: 8.11.0+
  
  Kibana:
    åŠŸèƒ½: æ•°æ®å¯è§†åŒ–å’Œç®¡ç†ç•Œé¢
    ç‰¹æ€§:
      - ä¸°å¯Œçš„å›¾è¡¨ç±»å‹
      - ä»ªè¡¨æ¿å®šåˆ¶
      - å¼€å‘è€…å·¥å…·
      - æœºå™¨å­¦ä¹ é›†æˆ
    ç‰ˆæœ¬: 8.11.0+
  
  Beats:
    åŠŸèƒ½: è½»é‡çº§æ•°æ®æ”¶é›†å™¨
    ç‰¹æ€§:
      - èµ„æºå ç”¨å°‘
      - éƒ¨ç½²ç®€å•
      - å®æ—¶æ€§å¼º
      - æ’ä»¶åŒ–æ¶æ„
    ç‰ˆæœ¬: 8.11.0+
```

## 2. ä¼ä¸šçº§éƒ¨ç½²æ¶æ„

### 2.1 é«˜å¯ç”¨é›†ç¾¤éƒ¨ç½²

```yaml
# Elasticsearché›†ç¾¤éƒ¨ç½²
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch-master
  namespace: logging
spec:
  serviceName: elasticsearch-master
  replicas: 3
  selector:
    matchLabels:
      app: elasticsearch
      role: master
  template:
    metadata:
      labels:
        app: elasticsearch
        role: master
    spec:
      initContainers:
      - name: sysctl
        image: busybox:1.27.2
        command:
        - sysctl
        - -w
        - vm.max_map_count=262144
        securityContext:
          privileged: true
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
        env:
        - name: cluster.name
          value: "elk-cluster"
        - name: node.name
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: discovery.seed_hosts
          value: "elasticsearch-master-0.elasticsearch-master,elasticsearch-master-1.elasticsearch-master,elasticsearch-master-2.elasticsearch-master"
        - name: cluster.initial_master_nodes
          value: "elasticsearch-master-0,elasticsearch-master-1,elasticsearch-master-2"
        - name: ES_JAVA_OPTS
          value: "-Xms2g -Xmx2g"
        - name: xpack.security.enabled
          value: "true"
        - name: xpack.security.transport.ssl.enabled
          value: "true"
        ports:
        - containerPort: 9200
          name: http
        - containerPort: 9300
          name: transport
        volumeMounts:
        - name: elasticsearch-data
          mountPath: /usr/share/elasticsearch/data
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
  volumeClaimTemplates:
  - metadata:
      name: elasticsearch-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "fast-ssd"
      resources:
        requests:
          storage: 100Gi
---
# Elasticsearchæ•°æ®èŠ‚ç‚¹éƒ¨ç½²
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch-data
  namespace: logging
spec:
  serviceName: elasticsearch-data
  replicas: 3
  selector:
    matchLabels:
      app: elasticsearch
      role: data
  template:
    metadata:
      labels:
        app: elasticsearch
        role: data
    spec:
      initContainers:
      - name: sysctl
        image: busybox:1.27.2
        command:
        - sysctl
        - -w
        - vm.max_map_count=262144
        securityContext:
          privileged: true
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
        env:
        - name: cluster.name
          value: "elk-cluster"
        - name: node.name
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: node.roles
          value: "data,content,transform"
        - name: discovery.seed_hosts
          value: "elasticsearch-master-0.elasticsearch-master,elasticsearch-master-1.elasticsearch-master,elasticsearch-master-2.elasticsearch-master"
        - name: ES_JAVA_OPTS
          value: "-Xms4g -Xmx4g"
        - name: xpack.security.enabled
          value: "true"
        ports:
        - containerPort: 9200
          name: http
        - containerPort: 9300
          name: transport
        volumeMounts:
        - name: elasticsearch-data
          mountPath: /usr/share/elasticsearch/data
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
          limits:
            memory: "8Gi"
            cpu: "4"
  volumeClaimTemplates:
  - metadata:
      name: elasticsearch-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "fast-ssd"
      resources:
        requests:
          storage: 500Gi
```

### 2.2 Filebeatæ—¥å¿—æ”¶é›†é…ç½®

```yaml
# Filebeaté…ç½®æ–‡ä»¶
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/*.log
    - /var/log/application/*.log
    - /var/log/nginx/*.log
  fields:
    service: application
    environment: production
  fields_under_root: true
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'
  multiline.negate: true
  multiline.match: after
  ignore_older: 72h
  close_inactive: 2h
  scan_frequency: 10s

- type: container
  enabled: true
  paths:
    - /var/lib/docker/containers/*/*.log
  stream: all
  processors:
    - add_docker_metadata: ~
    - add_kubernetes_metadata:
        host: ${NODE_NAME}
        matchers:
        - logs_path:
            logs_path: "/var/lib/docker/containers/"

processors:
- add_host_metadata: ~
- add_cloud_metadata: ~
- add_fields:
    target: ''
    fields:
      index_prefix: "application-logs"
      log_type: "application"

output.elasticsearch:
  hosts: ["elasticsearch-data-0.elasticsearch-data:9200"]
  username: "${ELASTIC_USERNAME}"
  password: "${ELASTIC_PASSWORD}"
  index: "%{[index_prefix]}-%{+yyyy.MM.dd}"
  bulk_max_size: 2048
  worker: 2

setup.template.enabled: false
setup.ilm.enabled: false

logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
```

## 3. æ—¥å¿—å¤„ç†ç®¡é“è®¾è®¡

### 3.1 Logstashé…ç½®ç®¡é“

```ruby
# Logstashä¸»é…ç½®æ–‡ä»¶
input {
  beats {
    port => 5044
    ssl => true
    ssl_certificate => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
  }
  
  kafka {
    bootstrap_servers => "kafka-0:9092,kafka-1:9092,kafka-2:9092"
    topics => ["application-logs", "system-logs", "security-logs"]
    group_id => "logstash-consumer"
    codec => "json"
  }
}

filter {
  # é€šç”¨å­—æ®µå¤„ç†
  mutate {
    add_field => {
      "[@metadata][received_at]" => "%{@timestamp}"
      "[@metadata][pipeline]" => "main"
    }
    rename => {
      "message" => "raw_message"
    }
  }
  
  # æ—¶é—´æˆ³æ ‡å‡†åŒ–
  date {
    match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss", "UNIX_MS" ]
    target => "@timestamp"
    remove_field => [ "timestamp" ]
  }
  
  # JSONæ¶ˆæ¯è§£æ
  json {
    source => "raw_message"
    skip_on_invalid_json => true
    target => "parsed_json"
  }
  
  # åº”ç”¨æ—¥å¿—å¤„ç†
  if [fields][service] == "application" {
    grok {
      match => {
        "raw_message" => [
          "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{JAVACLASS:class} - %{GREEDYDATA:message}",
          "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}"
        ]
      }
      tag_on_failure => ["_grokparsefailure_application"]
    }
    
    # åº”ç”¨ç‰¹å®šå­—æ®µæå–
    if [parsed_json] {
      mutate {
        add_field => {
          "user_id" => "%{[parsed_json][userId]}"
          "request_id" => "%{[parsed_json][requestId]}"
          "response_time" => "%{[parsed_json][responseTime]}"
        }
      }
    }
  }
  
  # Nginxè®¿é—®æ—¥å¿—å¤„ç†
  if [fields][service] == "nginx" {
    grok {
      match => {
        "raw_message" => '%{IPORHOST:clientip} %{USER:ident} %{USER:auth} \[%{HTTPDATE:timestamp}\] "%{WORD:verb} %{DATA:request} HTTP/%{NUMBER:httpversion}" %{NUMBER:response:int} (?:%{NUMBER:bytes:int}|-) (?:"(?:%{URI:referrer}|-)"|%{QS:referrer}) %{QS:agent}'
      }
      tag_on_failure => ["_grokparsefailure_nginx"]
    }
    
    # ç”¨æˆ·ä»£ç†è§£æ
    useragent {
      source => "agent"
      target => "user_agent"
    }
    
    # åœ°ç†ä½ç½®è§£æ
    geoip {
      source => "clientip"
      target => "geoip"
    }
  }
  
  # ç³»ç»Ÿæ—¥å¿—å¤„ç†
  if [fields][service] == "system" {
    syslog_pri { }
    
    grok {
      match => {
        "raw_message" => "<%{POSINT:priority}>%{SYSLOGTIMESTAMP:timestamp} %{SYSLOGHOST:logsource} %{PROG:program}(?:\[%{POSINT:pid}\])?: %{GREEDYDATA:message}"
      }
      tag_on_failure => ["_grokparsefailure_syslog"]
    }
  }
  
  # å­—æ®µç±»å‹è½¬æ¢
  mutate {
    convert => {
      "response_time" => "float"
      "bytes" => "integer"
      "response" => "integer"
    }
  }
  
  # æ·»åŠ ç´¢å¼•è·¯ç”±ä¿¡æ¯
  mutate {
    add_field => {
      "[@metadata][index]" => "%{[fields][service]}-%{+YYYY.MM.dd}"
      "[@metadata][routing]" => "%{[fields][environment]}"
    }
  }
}

output {
  # ä¸»è¦è¾“å‡ºåˆ°Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch-data-0.elasticsearch-data:9200"]
    index => "%{[@metadata][index]}"
    routing => "%{[@metadata][routing]}"
    user => "${ELASTIC_USERNAME}"
    password => "${ELASTIC_PASSWORD}"
    ssl => true
    ssl_certificate_verification => false
    ilm_enabled => true
    ilm_rollover_alias => "%{[fields][service]}-logs"
    ilm_pattern => "{now/d}-000001"
    ilm_policy => "log-lifecycle-policy"
    template_name => "%{[fields][service]}-template"
    template => "/etc/logstash/templates/%{[fields][service]}-template.json"
    template_overwrite => true
  }
  
  # å¤‡ä»½è¾“å‡ºåˆ°Kafka
  kafka {
    bootstrap_servers => "kafka-0:9092,kafka-1:9092,kafka-2:9092"
    topic_id => "%{[fields][service]}-backup"
    codec => json
  }
  
  # ç›‘æ§è¾“å‡º
  if "_grokparsefailure" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch-data-0.elasticsearch-data:9200"]
      index => "failed-parses-%{+YYYY.MM.dd}"
      user => "${ELASTIC_USERNAME}"
      password => "${ELASTIC_PASSWORD}"
    }
  }
}
```

## 4. ç´¢å¼•ç”Ÿå‘½å‘¨æœŸç®¡ç†

### 4.1 ILMç­–ç•¥é…ç½®

```json
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_age": "7d",
            "max_size": "50gb",
            "max_docs": 10000000
          },
          "set_priority": {
            "priority": 100
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "allocate": {
            "number_of_replicas": 1
          },
          "readonly": {},
          "set_priority": {
            "priority": 50
          }
        }
      },
      "cold": {
        "min_age": "30d",
        "actions": {
          "allocate": {
            "require": {
              "box_type": "cold"
            }
          },
          "freeze": {},
          "set_priority": {
            "priority": 0
          }
        }
      },
      "delete": {
        "min_age": "90d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
```

### 4.2 ç´¢å¼•æ¨¡æ¿é…ç½®

```json
{
  "index_patterns": ["application-logs-*"],
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1,
      "refresh_interval": "30s",
      "blocks": {
        "read_only_allow_delete": "false"
      },
      "codec": "best_compression",
      "translog": {
        "durability": "async",
        "sync_interval": "5s"
      }
    },
    "mappings": {
      "properties": {
        "@timestamp": {
          "type": "date"
        },
        "level": {
          "type": "keyword"
        },
        "message": {
          "type": "text",
          "analyzer": "standard"
        },
        "raw_message": {
          "type": "text",
          "index": false
        },
        "service": {
          "type": "keyword"
        },
        "environment": {
          "type": "keyword"
        },
        "host": {
          "properties": {
            "name": { "type": "keyword" },
            "ip": { "type": "ip" }
          }
        },
        "container": {
          "properties": {
            "id": { "type": "keyword" },
            "name": { "type": "keyword" },
            "image": { "type": "keyword" }
          }
        },
        "kubernetes": {
          "properties": {
            "pod": {
              "properties": {
                "name": { "type": "keyword" },
                "uid": { "type": "keyword" }
              }
            },
            "namespace": { "type": "keyword" },
            "node": { "type": "keyword" }
          }
        },
        "geoip": {
          "properties": {
            "location": { "type": "geo_point" },
            "country_name": { "type": "keyword" },
            "city_name": { "type": "keyword" }
          }
        }
      }
    }
  },
  "composed_of": ["logs-mappings", "logs-settings"],
  "priority": 500,
  "version": 3,
  "_meta": {
    "description": "Application logs template"
  }
}
```

## 5. Kibanaå¯è§†åŒ–é…ç½®

### 5.1 ä»ªè¡¨æ¿é…ç½®

```json
{
  "dashboard": {
    "title": "Application Logs Overview",
    "description": "ç»¼åˆåº”ç”¨æ—¥å¿—ç›‘æ§é¢æ¿",
    "panelsJSON": "[{\"id\":\"application-logs-metrics\",\"type\":\"visualization\",\"panelIndex\":1,\"gridData\":{\"x\":0,\"y\":0,\"w\":24,\"h\":12}}, {\"id\":\"error-rate-trend\",\"type\":\"visualization\",\"panelIndex\":2,\"gridData\":{\"x\":0,\"y\":12,\"w\":12,\"h\":12}}, {\"id\":\"top-error-sources\",\"type\":\"visualization\",\"panelIndex\":3,\"gridData\":{\"x\":12,\"y\":12,\"w\":12,\"h\":12}}]",
    "optionsJSON": "{\"darkTheme\":false,\"hidePanelTitles\":false,\"useMargins\":true}",
    "version": 1,
    "timeRestore": true,
    "timeTo": "now",
    "timeFrom": "now-24h",
    "refreshInterval": {
      "display": "30 seconds",
      "pause": false,
      "value": 30000
    }
  }
}
```

### 5.2 å¯è§†åŒ–æŸ¥è¯¢é…ç½®

```json
{
  "visualization": {
    "title": "Error Rate Trend",
    "visState": "{\"title\":\"Error Rate Trend\",\"type\":\"line\",\"params\":{\"addTooltip\":true,\"addLegend\":true,\"legendPosition\":\"right\",\"scale\":\"linear\",\"mode\":\"normal\",\"times\":[],\"addTimeMarker\":false,\"defaultYExtents\":false,\"setYExtents\":false,\"yAxis\":{}},\"aggs\":[{\"id\":\"1\",\"enabled\":true,\"type\":\"cardinality\",\"schema\":\"metric\",\"params\":{\"field\":\"request_id\"}},{\"id\":\"2\",\"enabled\":true,\"type\":\"date_histogram\",\"schema\":\"segment\",\"params\":{\"field\":\"@timestamp\",\"interval\":\"auto\",\"customInterval\":\"2h\",\"min_doc_count\":1,\"extended_bounds\":{}}},{\"id\":\"3\",\"enabled\":true,\"type\":\"terms\",\"schema\":\"group\",\"params\":{\"field\":\"level\",\"size\":5,\"order\":\"desc\",\"orderBy\":\"1\"}}],\"listeners\":{}}",
    "uiStateJSON": "{}",
    "description": "",
    "version": 1,
    "kibanaSavedObjectMeta": {
      "searchSourceJSON": "{\"index\":\"application-logs-*\",\"filter\":[],\"query\":{\"query\":\"level:ERROR OR level:CRITICAL\",\"language\":\"kuery\"}}"
    }
  }
}
```

## 6. å®‰å…¨ä¸æƒé™ç®¡ç†

### 6.1 Elasticsearchå®‰å…¨é…ç½®

```yaml
# Elasticsearchå®‰å…¨é…ç½®
xpack.security.enabled: true
xpack.security.transport.ssl.enabled: true
xpack.security.transport.ssl.verification_mode: certificate
xpack.security.transport.ssl.key: certs/elastic-certificates.key
xpack.security.transport.ssl.certificate: certs/elastic-certificates.crt
xpack.security.transport.ssl.certificate_authorities: certs/elastic-stack-ca.crt
xpack.security.http.ssl.enabled: true
xpack.security.http.ssl.truststore.path: certs/elastic-certificates.p12
xpack.security.http.ssl.keystore.path: certs/elastic-certificates.p12

# ç”¨æˆ·è§’è‰²é…ç½®
xpack.security.authc.realms:
  native.native1:
    order: 0
  ldap.ldap1:
    order: 1
    url: "ldaps://ldap.example.com:636"
    bind_dn: "cn=admin,dc=example,dc=com"
    user_search:
      base_dn: "dc=example,dc=com"
      filter: "(cn={0})"
    group_search:
      base_dn: "dc=example,dc=com"
    files:
      role_mapping: "/usr/share/elasticsearch/config/roles_mapping.yml"
```

### 6.2 è§’è‰²æƒé™é…ç½®

```yaml
# Elasticsearchè§’è‰²å®šä¹‰
roles:
  log_admin:
    cluster: 
      - all
    indices:
      - names: '*'
        privileges: 
          - all
    
  log_viewer:
    cluster:
      - monitor
    indices:
      - names: 'application-logs-*'
        privileges:
          - read
          - view_index_metadata
      - names: 'system-logs-*'
        privileges:
          - read
          - view_index_metadata
    
  developer:
    cluster:
      - monitor
    indices:
      - names: 'application-logs-*'
        privileges:
          - read
          - view_index_metadata
        field_security:
          grant: ['message', 'level', 'timestamp', 'service']
    
  auditor:
    cluster:
      - monitor
    indices:
      - names: '*'
        privileges:
          - read
          - view_index_metadata
        query: '{"term": {"environment": "production"}}'
```

## 7. æ€§èƒ½ä¼˜åŒ–ä¸è°ƒä¼˜

### 7.1 Elasticsearchæ€§èƒ½è°ƒä¼˜

```yaml
# Elasticsearchæ€§èƒ½ä¼˜åŒ–é…ç½®
performance_tuning:
  jvm:
    heap_size: "31g"  # æ€»å†…å­˜çš„50%ï¼Œä¸è¶…è¿‡32GB
    gc_settings:
      - "-XX:+UseG1GC"
      - "-XX:MaxGCPauseMillis=200"
      - "-XX:G1HeapRegionSize=32m"
  
  indexing:
    refresh_interval: "30s"
    translog:
      durability: "async"
      sync_interval: "5s"
    merge:
      policy:
        max_merge_at_once: 10
        segments_per_tier: 10
  
  search:
    request_cache: true
    query_cache: true
    field_data_cache: true
    indices:
      queries:
        cache:
          size: "20%"
  
  networking:
    tcp:
      no_delay: true
      keep_alive: true
    http:
      compression: true
      max_content_length: "200mb"
  
  thread_pools:
    search:
      size: 20
      queue_size: 1000
    write:
      size: 10
      queue_size: 1000
    get:
      size: 10
      queue_size: 1000
```

### 7.2 Logstashæ€§èƒ½ä¼˜åŒ–

```ruby
# Logstashæ€§èƒ½ä¼˜åŒ–é…ç½®
pipeline:
  batch_size: 125
  batch_delay: 50
  workers: 4
  
input {
  beats {
    port => 5044
    codec => "json"
    # å¯ç”¨å‹ç¼©
    client_inactivity_timeout => 3600
  }
}

filter {
  # å¹¶è¡Œå¤„ç†
  if [type] == "application" {
    # åº”ç”¨ç‰¹å®šå¤„ç†
  } else if [type] == "nginx" {
    # Nginxç‰¹å®šå¤„ç†
  }
  
  # é¿å…ä¸å¿…è¦çš„å­—æ®µå¤„ç†
  mutate {
    remove_field => ["@version", "tags", "_id"]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch-host:9200"]
    # æ‰¹é‡æäº¤ä¼˜åŒ–
    flush_size => 5000
    idle_flush_time => 5
    # è¿æ¥æ± ä¼˜åŒ–
    pool_max => 20
    pool_max_per_route => 10
  }
}
```

## 8. ç›‘æ§ä¸å‘Šè­¦

### 8.1 ç³»ç»Ÿç›‘æ§é…ç½®

```yaml
# Elasticsearchç›‘æ§é…ç½®
monitoring:
  collection:
    enabled: true
    exporters:
      local:
        type: local
      http:
        type: http
        host: ["monitoring-elasticsearch:9200"]
        auth:
          username: monitoring_user
          password: monitoring_password

# Logstashç›‘æ§é…ç½®
monitoring.enabled: true
monitoring.elasticsearch.hosts: ["elasticsearch:9200"]
monitoring.elasticsearch.username: "logstash_monitoring"
monitoring.elasticsearch.password: "password"
```

### 8.2 å‘Šè­¦è§„åˆ™é…ç½®

```yaml
# Elastic Stackå‘Šè­¦è§„åˆ™
alerts:
  - name: "High Error Rate"
    type: "metric"
    condition: "avg(error_rate) > 0.05"
    timeframe: "5m"
    actions:
      - type: "email"
        recipients: ["ops-team@example.com"]
      - type: "slack"
        channel: "#alerts"
  
  - name: "Elasticsearch Cluster Health"
    type: "cluster_health"
    condition: "cluster_status != 'green'"
    timeframe: "1m"
    actions:
      - type: "pagerduty"
        service_key: "your-pagerduty-key"
  
  - name: "Log Ingestion Lag"
    type: "ingestion_lag"
    condition: "lag_seconds > 300"
    timeframe: "10m"
    actions:
      - type: "webhook"
        url: "https://internal-api.example.com/alerts"
```

## 9. æ•…éšœæ’æŸ¥ä¸ç»´æŠ¤

### 9.1 å¸¸è§é—®é¢˜è¯Šæ–­

```bash
# ELK Stackæ•…éšœæ’æŸ¥å‘½ä»¤

# 1. æ£€æŸ¥Elasticsearché›†ç¾¤çŠ¶æ€
curl -u elastic:password -X GET "localhost:9200/_cluster/health?pretty"

# 2. æŸ¥çœ‹èŠ‚ç‚¹ç»Ÿè®¡ä¿¡æ¯
curl -u elastic:password -X GET "localhost:9200/_nodes/stats?pretty"

# 3. æ£€æŸ¥ç´¢å¼•çŠ¶æ€
curl -u elastic:password -X GET "localhost:9200/_cat/indices?v"

# 4. æŸ¥çœ‹æœªåˆ†é…åˆ†ç‰‡
curl -u elastic:password -X GET "localhost:9200/_cat/shards?v&h=index,shard,prirep,state,unassigned.reason"

# 5. æ£€æŸ¥Logstashå¤„ç†çŠ¶æ€
curl -X GET "localhost:9600/_node/stats/pipeline?pretty"

# 6. FilebeatçŠ¶æ€æ£€æŸ¥
filebeat test config
filebeat test output

# 7. æ€§èƒ½åˆ†æ
curl -u elastic:password -X GET "localhost:9200/_cluster/allocation/explain?pretty"
```

### 9.2 ç»´æŠ¤è„šæœ¬

```python
#!/usr/bin/env python3
# elk_maintenance.py

import requests
import json
import logging
from datetime import datetime, timedelta

class ELKMaintenance:
    def __init__(self, es_host, username, password):
        self.es_host = es_host
        self.auth = (username, password)
        self.session = requests.Session()
        self.session.auth = self.auth
        self.logger = logging.getLogger(__name__)
    
    def check_cluster_health(self):
        """æ£€æŸ¥é›†ç¾¤å¥åº·çŠ¶æ€"""
        try:
            response = self.session.get(f"{self.es_host}/_cluster/health")
            health = response.json()
            
            self.logger.info(f"Cluster Status: {health['status']}")
            self.logger.info(f"Active Shards: {health['active_shards']}/{health['active_shards'] + health['unassigned_shards']}")
            
            if health['status'] != 'green':
                self.logger.warning(f"Cluster health is {health['status']}")
                return False
            return True
        except Exception as e:
            self.logger.error(f"Failed to check cluster health: {e}")
            return False
    
    def clean_old_indices(self, days_to_keep=30):
        """æ¸…ç†æ—§ç´¢å¼•"""
        try:
            # è·å–æ‰€æœ‰ç´¢å¼•
            response = self.session.get(f"{self.es_host}/_cat/indices?format=json")
            indices = response.json()
            
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)
            
            for index in indices:
                index_name = index['index']
                # è§£ææ—¥æœŸ
                if '-' in index_name:
                    try:
                        date_part = index_name.split('-')[-1]
                        index_date = datetime.strptime(date_part, '%Y.%m.%d')
                        
                        if index_date < cutoff_date:
                            self.logger.info(f"Deleting old index: {index_name}")
                            delete_response = self.session.delete(f"{self.es_host}/{index_name}")
                            if delete_response.status_code == 200:
                                self.logger.info(f"Successfully deleted {index_name}")
                    except ValueError:
                        continue
                        
        except Exception as e:
            self.logger.error(f"Failed to clean old indices: {e}")
    
    def optimize_indices(self):
        """ä¼˜åŒ–ç´¢å¼•æ€§èƒ½"""
        try:
            # å¼ºåˆ¶åˆå¹¶å°æ®µ
            response = self.session.post(f"{self.es_host}/_forcemerge?max_num_segments=1")
            if response.status_code == 200:
                self.logger.info("Index optimization completed")
        except Exception as e:
            self.logger.error(f"Failed to optimize indices: {e}")

if __name__ == "__main__":
    maintenance = ELKMaintenance(
        "http://localhost:9200",
        "elastic",
        "password"
    )
    
    maintenance.check_cluster_health()
    maintenance.clean_old_indices(30)
    maintenance.optimize_indices()
```

## 10. æœ€ä½³å®è·µä¸æœªæ¥å‘å±•

### 10.1 æ—¥å¿—ç®¡ç†æœ€ä½³å®è·µ

```markdown
## ğŸ“ æ—¥å¿—ç®¡ç†æœ€ä½³å®è·µ

### 1. æ—¥å¿—æ ¼å¼æ ‡å‡†åŒ–
- ä½¿ç”¨JSONæ ¼å¼è®°å½•ç»“æ„åŒ–æ—¥å¿—
- ç»Ÿä¸€æ—¶é—´æˆ³æ ¼å¼(ISO8601)
- åŒ…å«å¿…è¦çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
- é¿å…æ•æ„Ÿä¿¡æ¯æ³„éœ²

### 2. ç´¢å¼•ç­–ç•¥ä¼˜åŒ–
- æŒ‰æœåŠ¡å’Œæ—¶é—´åˆ†å‰²ç´¢å¼•
- åˆç†è®¾ç½®åˆ†ç‰‡å’Œå‰¯æœ¬æ•°
- å®æ–½ç”Ÿå‘½å‘¨æœŸç®¡ç†
- å®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®

### 3. æ€§èƒ½ä¼˜åŒ–è¦ç‚¹
- é€‚å½“è°ƒæ•´JVMå †å¤§å°
- ä¼˜åŒ–æ‰¹é‡å¤„ç†å‚æ•°
- å¯ç”¨é€‚å½“çš„ç¼“å­˜æœºåˆ¶
- ç›‘æ§å’Œè°ƒä¼˜èµ„æºä½¿ç”¨

### 4. å®‰å…¨åˆè§„è¦æ±‚
- å¯ç”¨ä¼ è¾“å±‚åŠ å¯†
- å®æ–½ç»†ç²’åº¦è®¿é—®æ§åˆ¶
- å®šæœŸå®¡è®¡æ—¥å¿—è®¿é—®
- ç¬¦åˆæ•°æ®ä¿æŠ¤æ³•è§„
```

### 10.2 æŠ€æœ¯å‘å±•è¶‹åŠ¿

```yaml
æ—¥å¿—æŠ€æœ¯å‘å±•è¶‹åŠ¿:
  1. äº‘åŸç”Ÿæ—¥å¿—:
     - Serverlessæ—¥å¿—æ”¶é›†
     - å¤šäº‘ç»Ÿä¸€æ—¥å¿—å¹³å°
     - è¾¹ç¼˜è®¡ç®—æ—¥å¿—å¤„ç†
     - æ— æœåŠ¡å™¨æ¶æ„é›†æˆ
  
  2. æ™ºèƒ½åŒ–åˆ†æ:
     - AIé©±åŠ¨çš„å¼‚å¸¸æ£€æµ‹
     - è‡ªç„¶è¯­è¨€å¤„ç†æ—¥å¿—
     - è‡ªåŠ¨æ ¹å› åˆ†æ
     - é¢„æµ‹æ€§ç»´æŠ¤
  
  3. å®æ—¶å¤„ç†å¢å¼º:
     - æµå¼å¤„ç†èƒ½åŠ›æå‡
     - å¤æ‚äº‹ä»¶å¤„ç†
     - å®æ—¶å‘Šè­¦å“åº”
     - äº¤äº’å¼æŸ¥è¯¢ä¼˜åŒ–
```

---
*æœ¬æ–‡æ¡£åŸºäºä¼ä¸šçº§æ—¥å¿—ç®¡ç†ç³»ç»Ÿå®è·µç»éªŒç¼–å†™ï¼ŒæŒç»­æ›´æ–°æœ€æ–°æŠ€æœ¯å’Œæœ€ä½³å®è·µã€‚*