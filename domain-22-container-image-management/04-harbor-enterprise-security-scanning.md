# Harborä¼ä¸šçº§é•œåƒå®‰å…¨æ‰«ææ·±åº¦å®è·µ

> **ä½œè€…**: ä¼ä¸šçº§å®¹å™¨å®‰å…¨ä¸“å®¶ | **ç‰ˆæœ¬**: v1.0 | **æ›´æ–°æ—¶é—´**: 2026-02-07
> **é€‚ç”¨åœºæ™¯**: ä¼ä¸šçº§å®¹å™¨é•œåƒå®‰å…¨æ‰«æä¸æ²»ç† | **å¤æ‚åº¦**: â­â­â­â­â­

## ğŸ¯ æ‘˜è¦

æœ¬æ–‡æ¡£æ·±å…¥æ¢è®¨Harborä¼ä¸šçº§é•œåƒå®‰å…¨æ‰«æç³»ç»Ÿçš„æ¶æ„è®¾è®¡ã€æ¼æ´æ£€æµ‹å®è·µå’Œå®‰å…¨æ²»ç†ç­–ç•¥ï¼ŒåŸºäºé‡‘èã€åŒ»ç–—ã€æ”¿åºœç­‰é«˜åº¦ç›‘ç®¡è¡Œä¸šçš„å®è·µç»éªŒï¼Œæä¾›ä»é•œåƒæ„å»ºåˆ°éƒ¨ç½²çš„å…¨ç”Ÿå‘½å‘¨æœŸå®‰å…¨ç®¡æ§æŠ€æœ¯æŒ‡å—ã€‚

## 1. ä¼ä¸šçº§å®‰å…¨æ‰«ææ¶æ„

### 1.1 å®‰å…¨æ‰«æä½“ç³»è®¾è®¡

```mermaid
graph TB
    subgraph "é•œåƒç”Ÿå‘½å‘¨æœŸ"
        A[é•œåƒæ„å»º] --> B[å®‰å…¨æ‰«æ]
        B --> C[æ¼æ´è¯„ä¼°]
        C --> D[å‡†å…¥æ§åˆ¶]
        D --> E[é•œåƒéƒ¨ç½²]
        E --> F[è¿è¡Œæ—¶ç›‘æ§]
    end
    
    subgraph "æ‰«æå¼•æ“å±‚"
        G[Clairæ‰«æå™¨] --> H[æ¼æ´æ•°æ®åº“]
        I[Trivyæ‰«æå™¨] --> J[å®‰å…¨è§„åˆ™åº“]
        K[Anchoreå¼•æ“] --> L[ç­–ç•¥å¼•æ“]
        M[è‡ªå®šä¹‰æ‰«æå™¨] --> N[ä¼ä¸šè§„åˆ™]
    end
    
    subgraph "è¯„ä¼°åˆ†æå±‚"
        O[é£é™©è¯„ä¼°] --> P[æ¼æ´åˆ†çº§]
        Q[ä¾èµ–åˆ†æ] --> R[ä¾›åº”é“¾æ£€æµ‹]
        S[é…ç½®æ£€æŸ¥] --> T[æœ€ä½³å®è·µéªŒè¯]
        U[è®¸å¯è¯æ‰«æ] --> V[åˆè§„æ€§æ£€æŸ¥]
    end
    
    subgraph "æ²»ç†æ§åˆ¶å±‚"
        W[å‡†å…¥ç­–ç•¥] --> X[é˜»æ–­æœºåˆ¶]
        Y[å‘Šè­¦é€šçŸ¥] --> Z[ä¿®å¤å»ºè®®]
        AA[å®¡è®¡è·Ÿè¸ª] --> AB[åˆè§„æŠ¥å‘Š]
        AC[é•œåƒç­¾å] --> AD[ä¿¡ä»»é“¾éªŒè¯]
    end
    
    subgraph "é›†æˆååŒå±‚"
        AE[CI/CDé›†æˆ] --> AF[æµæ°´çº¿æ‰«æ]
        AG[IDEæ’ä»¶] --> AH[å¼€å‘æ—¶æ£€æµ‹]
        AI[æ³¨å†Œè¡¨é›†æˆ] --> AJ[è‡ªåŠ¨æ‰«æ]
        AK[ç›‘æ§ç³»ç»Ÿ] --> AL[å®‰å…¨æ€åŠ¿]
    end
```

### 1.2 å¤šå±‚é˜²å¾¡ä½“ç³»

#### 1.2.1 å®‰å…¨æ‰«æå±‚çº§

```yaml
# security-scanning-layers.yaml
security_layers:
  build_time_scanning:
    scope: "é•œåƒæ„å»ºé˜¶æ®µ"
    tools:
      - hadolint: "Dockerfileé™æ€åˆ†æ"
      - docker-scan: "æ„å»ºæ—¶å®‰å…¨æ£€æŸ¥"
      - snyk: "ä¾èµ–æ¼æ´æ‰«æ"
    checks:
      - åŸºç¡€é•œåƒå®‰å…¨æ€§
      - Dockerfileæœ€ä½³å®è·µ
      - ä¾èµ–åŒ…æ¼æ´æ£€æµ‹
      - æ•æ„Ÿä¿¡æ¯æ³„éœ²æ£€æŸ¥
      
  registry_scanning:
    scope: "é•œåƒä»“åº“é˜¶æ®µ"
    tools:
      - clair: "CVEæ¼æ´æ‰«æ"
      - trivy: "å¤šå±‚æ¼æ´æ£€æµ‹"
      - anchore: "æ·±åº¦å®‰å…¨åˆ†æ"
    checks:
      - æ“ä½œç³»ç»Ÿæ¼æ´
      - åº”ç”¨ç¨‹åºæ¼æ´
      - é…ç½®å®‰å…¨æ£€æŸ¥
      - è®¸å¯è¯åˆè§„æ€§
      
  deployment_scanning:
    scope: "éƒ¨ç½²å‰æ£€æŸ¥"
    tools:
      - opa: "ç­–ç•¥å³ä»£ç "
      - kube-bench: "K8så®‰å…¨åŸºå‡†"
      - falco: "è¿è¡Œæ—¶å¼‚å¸¸æ£€æµ‹"
    checks:
      - éƒ¨ç½²ç­–ç•¥éªŒè¯
      - èµ„æºé™åˆ¶æ£€æŸ¥
      - ç½‘ç»œç­–ç•¥å®¡æŸ¥
      - å®‰å…¨ä¸Šä¸‹æ–‡éªŒè¯
      
  runtime_monitoring:
    scope: "è¿è¡Œæ—¶ç›‘æ§"
    tools:
      - falco: "å¼‚å¸¸è¡Œä¸ºæ£€æµ‹"
      - sysdig: "ç³»ç»Ÿè°ƒç”¨ç›‘æ§"
      - aqua: "å®¹å™¨å®‰å…¨å¹³å°"
    checks:
      - è¿è¡Œæ—¶æ”»å‡»æ£€æµ‹
      - å¼‚å¸¸è¡Œä¸ºè¯†åˆ«
      - æ•°æ®æ³„éœ²ç›‘æ§
      - æƒé™æ»¥ç”¨æ£€æµ‹

scanning_pipeline:
  trigger_events:
    - image_push: "é•œåƒæ¨é€åˆ°ä»“åº“"
    - scheduled_scan: "å®šæ—¶æ‰«æç­–ç•¥"
    - manual_trigger: "æ‰‹åŠ¨è§¦å‘æ‰«æ"
    - ci_cd_integration: "CI/CDæµæ°´çº¿é›†æˆ"
    
  scan_stages:
    stage_1_preparation:
      tasks:
        - ä¸‹è½½é•œåƒå±‚
        - æå–æ–‡ä»¶ç³»ç»Ÿ
        - åˆå§‹åŒ–æ‰«æç¯å¢ƒ
      timeout: "300s"
      
    stage_2_static_analysis:
      tasks:
        - æ“ä½œç³»ç»ŸåŒ…æ‰«æ
        - åº”ç”¨ä¾èµ–åˆ†æ
        - é…ç½®æ–‡ä»¶æ£€æŸ¥
        - æ•æ„Ÿæ•°æ®æ£€æµ‹
      timeout: "600s"
      
    stage_3_dynamic_analysis:
      tasks:
        - æ¨¡æ‹Ÿè¿è¡Œç¯å¢ƒ
        - è¡Œä¸ºæ¨¡å¼åˆ†æ
        - ç½‘ç»œè¿æ¥æ£€æŸ¥
        - æ–‡ä»¶ç³»ç»Ÿç›‘æ§
      timeout: "900s"
      
    stage_4_policy_evaluation:
      tasks:
        - æ¼æ´ä¸¥é‡æ€§è¯„ä¼°
        - ä¸šåŠ¡å½±å“åˆ†æ
        - åˆè§„æ€§æ£€æŸ¥
        - å‡†å…¥å†³ç­–
      timeout: "120s"
      
  result_processing:
    vulnerability_classification:
      critical: "CVSS >= 9.0"
      high: "CVSS 7.0-8.9"
      medium: "CVSS 4.0-6.9"
      low: "CVSS 0.1-3.9"
      negligible: "CVSS = 0.0"
      
    remediation_advice:
      immediate_action: "ä¸¥é‡æ¼æ´éœ€ç«‹å³ä¿®å¤"
      planned_fix: "é«˜å±æ¼æ´éœ€åˆ¶å®šä¿®å¤è®¡åˆ’"
      monitoring_required: "ä¸­ä½é£é™©æ¼æ´æŒç»­ç›‘æ§"
      accepted_risk: "å¯æ¥å—é£é™©éœ€æ–‡æ¡£è®°å½•"
```

## 2. Harborå®‰å…¨æ‰«ææ·±åº¦é›†æˆ

### 2.1 ä¼ä¸šçº§Harboréƒ¨ç½²

#### 2.1.1 é«˜å¯ç”¨Harboré›†ç¾¤

```yaml
# harbor-ha-deployment.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: harbor-system

---
# PostgreSQLä¸»ä»é›†ç¾¤
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: harbor-database
  namespace: harbor-system
spec:
  serviceName: "harbor-db"
  replicas: 3
  selector:
    matchLabels:
      app: harbor-database
  template:
    metadata:
      labels:
        app: harbor-database
    spec:
      containers:
      - name: postgresql
        image: postgres:13-alpine
        env:
        - name: POSTGRES_DB
          value: "registry"
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: harbor-database-secret
              key: username
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: harbor-database-secret
              key: password
        - name: PG_REPLICATION
          value: "true"
        ports:
        - containerPort: 5432
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
        livenessProbe:
          exec:
            command: ["pg_isready", "-U", "postgres"]
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command: ["pg_isready", "-U", "postgres"]
          initialDelaySeconds: 5
          periodSeconds: 5
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi

---
# Redisé›†ç¾¤
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: harbor-redis
  namespace: harbor-system
spec:
  serviceName: "harbor-redis"
  replicas: 3
  selector:
    matchLabels:
      app: harbor-redis
  template:
    metadata:
      labels:
        app: harbor-redis
    spec:
      containers:
      - name: redis
        image: redis:6-alpine
        command: ["redis-server", "--appendonly", "yes", "--cluster-enabled", "yes"]
        ports:
        - containerPort: 6379
        volumeMounts:
        - name: redis-storage
          mountPath: /data
  volumeClaimTemplates:
  - metadata:
      name: redis-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 50Gi

---
# Harboræ ¸å¿ƒç»„ä»¶
apiVersion: apps/v1
kind: Deployment
metadata:
  name: harbor-core
  namespace: harbor-system
spec:
  replicas: 3
  selector:
    matchLabels:
      app: harbor-core
  template:
    metadata:
      labels:
        app: harbor-core
    spec:
      containers:
      - name: core
        image: goharbor/harbor-core:v2.8.0
        env:
        - name: CORE_SECRET
          valueFrom:
            secretKeyRef:
              name: harbor-core-secret
              key: secret
        - name: JOBSERVICE_SECRET
          valueFrom:
            secretKeyRef:
              name: harbor-jobservice-secret
              key: secret
        - name: DATABASE_TYPE
          value: "postgresql"
        - name: DATABASE_HOST
          value: "harbor-database.harbor-system.svc.cluster.local"
        - name: DATABASE_PORT
          value: "5432"
        - name: DATABASE_USERNAME
          valueFrom:
            secretKeyRef:
              name: harbor-database-secret
              key: username
        - name: DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: harbor-database-secret
              key: password
        - name: DATABASE_NAME
          value: "registry"
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /api/v2.0/ping
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
```

#### 2.1.2 å®‰å…¨æ‰«æå™¨é›†æˆé…ç½®

```yaml
# harbor-security-scanner.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: harbor-scanner-config
  namespace: harbor-system
data:
  scanner-config.yaml: |
    scanners:
      clair:
        enabled: true
        url: "http://clair-scanner.harbor-system.svc.cluster.local:6060"
        timeout: "300s"
        skip_tls_verify: false
        
      trivy:
        enabled: true
        url: "http://trivy-scanner.harbor-system.svc.cluster.local:8080"
        timeout: "600s"
        skip_tls_verify: false
        github_token: "${TRIVY_GITHUB_TOKEN}"
        
      anchore:
        enabled: false  # ä¼ä¸šç‰ˆåŠŸèƒ½
        url: "https://anchore-enterprise.harbor-system.svc.cluster.local"
        timeout: "900s"
        
    scan_policies:
      default_policy:
        reject_vulnerabilities:
          - severity: "critical"
            fix_available: true
          - severity: "high"
            age_days: 30
            fix_available: true
            
        allow_vulnerabilities:
          - severity: "medium"
            justification_required: true
          - severity: "low"
            auto_approve: true
            
        grace_periods:
          critical: "0h"
          high: "72h"
          medium: "168h"
          low: "720h"
          
    notification_settings:
      webhook_urls:
        - "https://security-notifications.company.internal/webhook"
        - "https://slack-webhook.company.internal/security"
        
      email_recipients:
        - "security-team@company.com"
        - "devops-team@company.com"
        
      notification_levels:
        - "critical"
        - "high"
        - "policy_violation"
```

### 2.2 æ¼æ´ç®¡ç†ä¸ä¿®å¤

#### 2.2.1 è‡ªåŠ¨åŒ–æ¼æ´ä¿®å¤æµç¨‹

```python
# vulnerability-auto-remediation.py
import requests
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import subprocess
import logging

class VulnerabilityAutoRemediator:
    def __init__(self, harbor_api_url: str, api_token: str):
        self.harbor_url = harbor_api_url
        self.headers = {
            'Authorization': f'Bearer {api_token}',
            'Content-Type': 'application/json'
        }
        self.logger = logging.getLogger(__name__)
        
    def scan_image_for_vulnerabilities(self, project_name: str, 
                                     repository_name: str, 
                                     tag: str) -> Dict:
        """æ‰«æé•œåƒæ¼æ´"""
        scan_url = f"{self.harbor_url}/api/v2.0/projects/{project_name}/repositories/{repository_name}/artifacts/{tag}/scan"
        
        try:
            # è§¦å‘æ‰«æ
            response = requests.post(scan_url, headers=self.headers)
            if response.status_code != 202:
                raise Exception(f"æ‰«æè§¦å‘å¤±è´¥: {response.status_code}")
                
            # ç­‰å¾…æ‰«æå®Œæˆ
            max_wait_time = 300  # 5åˆ†é’Ÿ
            start_time = time.time()
            
            while time.time() - start_time < max_wait_time:
                scan_status = self.get_scan_status(project_name, repository_name, tag)
                if scan_status.get('scan_status') == 'Success':
                    break
                elif scan_status.get('scan_status') == 'Error':
                    raise Exception("æ‰«æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯")
                time.sleep(10)
            else:
                raise Exception("æ‰«æè¶…æ—¶")
                
            # è·å–æ‰«æç»“æœ
            return self.get_vulnerability_report(project_name, repository_name, tag)
            
        except Exception as e:
            self.logger.error(f"é•œåƒæ‰«æå¤±è´¥: {e}")
            return {}
    
    def get_scan_status(self, project_name: str, repository_name: str, tag: str) -> Dict:
        """è·å–æ‰«æçŠ¶æ€"""
        status_url = f"{self.harbor_url}/api/v2.0/projects/{project_name}/repositories/{repository_name}/artifacts/{tag}"
        
        response = requests.get(status_url, headers=self.headers)
        if response.status_code == 200:
            artifact_info = response.json()
            return {
                'scan_status': artifact_info.get('scan_overview', {}).get('scan_status', 'Unknown'),
                'severity_summary': artifact_info.get('scan_overview', {}).get('summary', {})
            }
        return {'scan_status': 'Error'}
    
    def get_vulnerability_report(self, project_name: str, repository_name: str, tag: str) -> Dict:
        """è·å–æ¼æ´æŠ¥å‘Š"""
        report_url = f"{self.harbor_url}/api/v2.0/projects/{project_name}/repositories/{repository_name}/artifacts/{tag}/additions/vulnerabilities"
        
        response = requests.get(report_url, headers=self.headers)
        if response.status_code == 200:
            return response.json()
        return {}
    
    def prioritize_vulnerabilities(self, vulnerabilities: List[Dict]) -> List[Dict]:
        """æ¼æ´ä¼˜å…ˆçº§æ’åº"""
        severity_weights = {
            'Critical': 5,
            'High': 4,
            'Medium': 3,
            'Low': 2,
            'Negligible': 1
        }
        
        # æ·»åŠ ä¼˜å…ˆçº§åˆ†æ•°
        for vuln in vulnerabilities:
            severity = vuln.get('severity', 'Unknown')
            cvss_score = vuln.get('vendor_attributes', {}).get('CVSS', {}).get('Score', 0)
            
            # è®¡ç®—ä¼˜å…ˆçº§åˆ†æ•°
            base_score = severity_weights.get(severity, 0)
            age_factor = self._calculate_age_factor(vuln.get('published_date'))
            exploit_factor = 1.5 if vuln.get('exploit_available', False) else 1.0
            fix_factor = 1.3 if vuln.get('fix_version') else 0.7
            
            priority_score = base_score * cvss_score * age_factor * exploit_factor * fix_factor
            vuln['priority_score'] = round(priority_score, 2)
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        return sorted(vulnerabilities, key=lambda x: x['priority_score'], reverse=True)
    
    def _calculate_age_factor(self, published_date: str) -> float:
        """è®¡ç®—æ¼æ´å¹´é¾„å› å­"""
        if not published_date:
            return 1.0
            
        try:
            pub_date = datetime.fromisoformat(published_date.replace('Z', '+00:00'))
            age_days = (datetime.now() - pub_date).days
            
            if age_days <= 30:
                return 2.0  # æ–°æ¼æ´ï¼Œé«˜ä¼˜å…ˆçº§
            elif age_days <= 90:
                return 1.5  # è¾ƒæ–°æ¼æ´
            elif age_days <= 365:
                return 1.2  # ä¸€å¹´å†…æ¼æ´
            else:
                return 1.0  # è€æ¼æ´
        except:
            return 1.0
    
    def generate_remediation_plan(self, prioritized_vulns: List[Dict]) -> Dict:
        """ç”Ÿæˆä¿®å¤è®¡åˆ’"""
        plan = {
            'immediate_actions': [],      # ç«‹å³ä¿®å¤
            'short_term_fixes': [],       # çŸ­æœŸè®¡åˆ’
            'long_term_improvements': [], # é•¿æœŸæ”¹è¿›
            'accepted_risks': []          # å¯æ¥å—é£é™©
        }
        
        for vuln in prioritized_vulns:
            severity = vuln['severity']
            priority_score = vuln['priority_score']
            fix_version = vuln.get('fix_version')
            
            remediation_item = {
                'vulnerability_id': vuln['id'],
                'package_name': vuln['package'],
                'severity': severity,
                'cvss_score': vuln.get('vendor_attributes', {}).get('CVSS', {}).get('Score'),
                'description': vuln['description'][:100] + '...' if len(vuln['description']) > 100 else vuln['description'],
                'fix_available': bool(fix_version),
                'fix_version': fix_version,
                'priority_score': priority_score
            }
            
            if severity == 'Critical' or (severity == 'High' and priority_score > 20):
                plan['immediate_actions'].append(remediation_item)
            elif severity == 'High' or (severity == 'Medium' and priority_score > 15):
                plan['short_term_fixes'].append(remediation_item)
            elif severity == 'Medium' or severity == 'Low':
                plan['long_term_improvements'].append(remediation_item)
            else:
                plan['accepted_risks'].append(remediation_item)
        
        return plan
    
    def auto_patch_image(self, project_name: str, repository_name: str, 
                        current_tag: str, fix_plan: Dict) -> Optional[str]:
        """è‡ªåŠ¨ä¿®å¤é•œåƒ"""
        try:
            # æ„å»ºæ–°çš„Dockerfile
            new_dockerfile = self._generate_patched_dockerfile(
                project_name, repository_name, current_tag, fix_plan
            )
            
            # æ„å»ºæ–°é•œåƒ
            new_tag = f"{current_tag}-patched-{datetime.now().strftime('%Y%m%d%H%M%S')}"
            build_result = self._build_patched_image(
                project_name, repository_name, new_tag, new_dockerfile
            )
            
            if build_result:
                # æ‰«ææ–°é•œåƒ
                new_scan_result = self.scan_image_for_vulnerabilities(
                    project_name, repository_name, new_tag
                )
                
                # éªŒè¯ä¿®å¤æ•ˆæœ
                if self._verify_patches_effective(new_scan_result, fix_plan):
                    self.logger.info(f"é•œåƒä¿®å¤æˆåŠŸ: {new_tag}")
                    return new_tag
                else:
                    self.logger.warning(f"ä¿®å¤éªŒè¯å¤±è´¥: {new_tag}")
                    return None
            else:
                self.logger.error("é•œåƒæ„å»ºå¤±è´¥")
                return None
                
        except Exception as e:
            self.logger.error(f"è‡ªåŠ¨ä¿®å¤è¿‡ç¨‹å¤±è´¥: {e}")
            return None
    
    def _generate_patched_dockerfile(self, project_name: str, repository_name: str,
                                   current_tag: str, fix_plan: Dict) -> str:
        """ç”Ÿæˆä¿®å¤åçš„Dockerfile"""
        # è·å–åŸå§‹é•œåƒä¿¡æ¯
        image_info = self._get_image_info(project_name, repository_name, current_tag)
        
        dockerfile_lines = [
            f"FROM {image_info.get('digest', f'{project_name}/{repository_name}:{current_tag}')}",
            "",
            "# å®‰å…¨è¡¥ä¸æ›´æ–°"
        ]
        
        # æ·»åŠ åŒ…æ›´æ–°å‘½ä»¤
        critical_fixes = [item for item in fix_plan['immediate_actions'] 
                         if item['fix_available']]
        
        if critical_fixes:
            packages_to_update = [item['package_name'] for item in critical_fixes]
            dockerfile_lines.extend([
                "RUN apt-get update && apt-get upgrade -y \\",
                f"    {' '.join(packages_to_update)} \\",
                "    && apt-get clean \\",
                "    && rm -rf /var/lib/apt/lists/*"
            ])
        
        # æ·»åŠ å®‰å…¨é…ç½®
        dockerfile_lines.extend([
            "",
            "# å®‰å…¨å¼ºåŒ–é…ç½®",
            "USER nobody",
            "WORKDIR /app",
            'ENV NODE_ENV="production"'
        ])
        
        return "\n".join(dockerfile_lines)
    
    def _build_patched_image(self, project_name: str, repository_name: str, 
                           new_tag: str, dockerfile_content: str) -> bool:
        """æ„å»ºä¿®å¤åçš„é•œåƒ"""
        try:
            # å†™å…¥Dockerfile
            with open('/tmp/Dockerfile.patched', 'w') as f:
                f.write(dockerfile_content)
            
            # æ„å»ºé•œåƒ
            build_cmd = [
                'docker', 'build',
                '-f', '/tmp/Dockerfile.patched',
                '-t', f'{project_name}/{repository_name}:{new_tag}',
                '.'
            ]
            
            result = subprocess.run(build_cmd, capture_output=True, text=True, cwd='/tmp')
            
            if result.returncode == 0:
                # æ¨é€é•œåƒåˆ°Harbor
                push_cmd = ['docker', 'push', f'{project_name}/{repository_name}:{new_tag}']
                push_result = subprocess.run(push_cmd, capture_output=True, text=True)
                
                return push_result.returncode == 0
            else:
                self.logger.error(f"é•œåƒæ„å»ºå¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            self.logger.error(f"æ„å»ºè¿‡ç¨‹å¼‚å¸¸: {e}")
            return False
    
    def _verify_patches_effective(self, new_scan_result: Dict, fix_plan: Dict) -> bool:
        """éªŒè¯ä¿®å¤æ˜¯å¦æœ‰æ•ˆ"""
        if not new_scan_result:
            return False
            
        # æ£€æŸ¥å…³é”®æ¼æ´æ˜¯å¦å·²ä¿®å¤
        immediate_fixes = {item['vulnerability_id'] for item in fix_plan['immediate_actions']}
        remaining_critical = set()
        
        for scanner_result in new_scan_result.values():
            if 'vulnerabilities' in scanner_result:
                for vuln in scanner_result['vulnerabilities']:
                    if vuln['id'] in immediate_fixes and vuln['severity'] in ['Critical', 'High']:
                        remaining_critical.add(vuln['id'])
        
        # å¦‚æœæ²¡æœ‰å‰©ä½™çš„å…³é”®æ¼æ´ï¼Œè®¤ä¸ºä¿®å¤æœ‰æ•ˆ
        return len(remaining_critical) == 0

# ä½¿ç”¨ç¤ºä¾‹
remediator = VulnerabilityAutoRemediator(
    "https://harbor.company.internal",
    "harbor-api-token"
)

# æ‰«æé•œåƒ
vulns = remediator.scan_image_for_vulnerabilities("myproject", "myapp", "v1.2.3")

# ä¼˜å…ˆçº§æ’åº
prioritized = remediator.prioritize_vulnerabilities(vulns.get('application/vnd.security.vulnerability.report', []))

# ç”Ÿæˆä¿®å¤è®¡åˆ’
fix_plan = remediator.generate_remediation_plan(prioritized)

# è‡ªåŠ¨ä¿®å¤
new_tag = remediator.auto_patch_image("myproject", "myapp", "v1.2.3", fix_plan)
if new_tag:
    print(f"ä¿®å¤æˆåŠŸï¼Œæ–°æ ‡ç­¾: {new_tag}")
```

## 3. ä¼ä¸šçº§å®‰å…¨ç­–ç•¥

### 3.1 é•œåƒå‡†å…¥æ§åˆ¶ç­–ç•¥

#### 3.1.1 åŠ¨æ€å‡†å…¥ç­–ç•¥å¼•æ“

```yaml
# admission-control-policies.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: harbor-admission-policies
  namespace: harbor-system
data:
  policies.json: |
    {
      "policy_sets": {
        "production_policy": {
          "name": "ç”Ÿäº§ç¯å¢ƒå‡†å…¥ç­–ç•¥",
          "description": "ä¸¥æ ¼çš„ç”Ÿäº§ç¯å¢ƒé•œåƒå‡†å…¥æ§åˆ¶",
          "rules": [
            {
              "name": "åŸºç¡€é•œåƒæ£€æŸ¥",
              "condition": "artifact.base_image.trusted == true",
              "action": "allow",
              "severity": "block"
            },
            {
              "name": "ä¸¥é‡æ¼æ´é˜»æ–­",
              "condition": "vulnerabilities.critical.count > 0",
              "action": "deny",
              "severity": "block"
            },
            {
              "name": "é«˜å±æ¼æ´æ£€æŸ¥",
              "condition": "vulnerabilities.high.count > 3 AND vulnerabilities.high.fix_available == true",
              "action": "deny",
              "severity": "block"
            },
            {
              "name": "è®¸å¯è¯åˆè§„æ£€æŸ¥",
              "condition": "licenses.restricted.contains(['GPL', 'AGPL'])",
              "action": "deny",
              "severity": "warn"
            },
            {
              "name": "é•œåƒå¹´é¾„æ£€æŸ¥",
              "condition": "artifact.age_days > 90",
              "action": "warn",
              "severity": "warn"
            }
          ],
          "exceptions": [
            {
              "name": "ç´§æ€¥ä¿®å¤ä¾‹å¤–",
              "condition": "request.emergency_patch == true AND request.approver.role == 'security_admin'",
              "expires_in_hours": 24
            }
          ]
        },
        
        "development_policy": {
          "name": "å¼€å‘ç¯å¢ƒå‡†å…¥ç­–ç•¥",
          "description": "ç›¸å¯¹å®½æ¾çš„å¼€å‘ç¯å¢ƒé•œåƒå‡†å…¥æ§åˆ¶",
          "rules": [
            {
              "name": "åŸºç¡€å®‰å…¨æ£€æŸ¥",
              "condition": "vulnerabilities.critical.count == 0",
              "action": "allow",
              "severity": "block"
            },
            {
              "name": "é«˜å±æ¼æ´é™åˆ¶",
              "condition": "vulnerabilities.high.count > 10",
              "action": "deny",
              "severity": "block"
            },
            {
              "name": "æ¶æ„è½¯ä»¶æ£€æŸ¥",
              "condition": "malware.detected == true",
              "action": "deny",
              "severity": "block"
            }
          ]
        }
      },
      
      "global_settings": {
        "default_policy": "development_policy",
        "scan_timeout_seconds": 300,
        "retry_attempts": 3,
        "notification_channels": ["webhook", "email", "slack"],
        "audit_logging": true
      }
    }
```

### 3.2 ä¾›åº”é“¾å®‰å…¨æ²»ç†

#### 3.2.1 è½¯ä»¶ç‰©æ–™æ¸…å•(SBOM)ç®¡ç†

```python
# sbom-supply-chain-security.py
import json
import hashlib
from datetime import datetime
from typing import Dict, List, Optional
import requests
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.asymmetric import rsa, padding
from cryptography.hazmat.backends import default_backend
from cryptography.x509 import load_pem_x509_certificate
from cryptography.hazmat.primitives import serialization

class SBOMSupplyChainManager:
    def __init__(self, harbor_api_url: str, private_key_path: str):
        self.harbor_url = harbor_api_url
        self.private_key = self._load_private_key(private_key_path)
        self.sbom_store = {}  # ç®€åŒ–çš„SBOMå­˜å‚¨
        
    def _load_private_key(self, key_path: str) -> rsa.RSAPrivateKey:
        """åŠ è½½ç§é’¥ç”¨äºç­¾å"""
        with open(key_path, 'rb') as key_file:
            private_key = serialization.load_pem_private_key(
                key_file.read(),
                password=None,
                backend=default_backend()
            )
        return private_key
    
    def generate_sbom(self, image_digest: str, components: List[Dict]) -> Dict:
        """ç”Ÿæˆè½¯ä»¶ç‰©æ–™æ¸…å•"""
        sbom = {
            'sbom_format': 'CycloneDX',
            'spec_version': '1.4',
            'version': '1',
            'serial_number': f"urn:uuid:{self._generate_uuid()}",
            'timestamp': datetime.now().isoformat(),
            'metadata': {
                'timestamp': datetime.now().isoformat(),
                'tools': [
                    {
                        'vendor': 'Harbor',
                        'name': 'SBOM Generator',
                        'version': '1.0.0'
                    }
                ],
                'component': {
                    'type': 'container',
                    'name': 'container-image',
                    'version': image_digest,
                    'hashes': [
                        {
                            'alg': 'SHA-256',
                            'content': image_digest.replace('sha256:', '')
                        }
                    ]
                }
            },
            'components': self._normalize_components(components),
            'dependencies': self._analyze_dependencies(components)
        }
        
        return sbom
    
    def _normalize_components(self, components: List[Dict]) -> List[Dict]:
        """æ ‡å‡†åŒ–ç»„ä»¶ä¿¡æ¯"""
        normalized = []
        for component in components:
            normalized_component = {
                'type': component.get('type', 'library'),
                'name': component.get('name', 'unknown'),
                'version': component.get('version', 'unknown'),
                'purl': component.get('purl', ''),
                'licenses': component.get('licenses', []),
                'hashes': self._generate_component_hashes(component),
                'supplier': component.get('supplier', {}),
                'external_references': component.get('external_references', [])
            }
            normalized.append(normalized_component)
        return normalized
    
    def _generate_component_hashes(self, component: Dict) -> List[Dict]:
        """ç”Ÿæˆç»„ä»¶å“ˆå¸Œå€¼"""
        content = json.dumps(component, sort_keys=True)
        sha256_hash = hashlib.sha256(content.encode()).hexdigest()
        
        return [
            {
                'alg': 'SHA-256',
                'content': sha256_hash
            }
        ]
    
    def _analyze_dependencies(self, components: List[Dict]) -> List[Dict]:
        """åˆ†æç»„ä»¶ä¾èµ–å…³ç³»"""
        dependencies = []
        component_map = {comp['name']: comp for comp in components}
        
        for component in components:
            deps = component.get('dependencies', [])
            if deps:
                dependency_entry = {
                    'ref': component['name'],
                    'depends_on': [dep for dep in deps if dep in component_map]
                }
                dependencies.append(dependency_entry)
                
        return dependencies
    
    def sign_sbom(self, sbom: Dict) -> Dict:
        """å¯¹SBOMè¿›è¡Œæ•°å­—ç­¾å"""
        # åºåˆ—åŒ–SBOM
        sbom_json = json.dumps(sbom, indent=2, sort_keys=True)
        
        # ç”Ÿæˆç­¾å
        signature = self.private_key.sign(
            sbom_json.encode('utf-8'),
            padding.PSS(
                mgf=padding.MGF1(hashes.SHA256()),
                salt_length=padding.PSS.MAX_LENGTH
            ),
            hashes.SHA256()
        )
        
        # åˆ›å»ºç­¾ååŒ…è£…
        signed_sbom = {
            'sbom': sbom,
            'signature': signature.hex(),
            'signing_algorithm': 'RSASSA-PSS',
            'timestamp': datetime.now().isoformat(),
            'signer': 'Harbor Supply Chain Security'
        }
        
        return signed_sbom
    
    def verify_sbom_signature(self, signed_sbom: Dict, public_key_pem: str) -> bool:
        """éªŒè¯SBOMç­¾å"""
        try:
            # åŠ è½½å…¬é’¥
            public_key = serialization.load_pem_public_key(
                public_key_pem.encode('utf-8'),
                backend=default_backend()
            )
            
            # éªŒè¯ç­¾å
            sbom_json = json.dumps(signed_sbom['sbom'], indent=2, sort_keys=True)
            signature_bytes = bytes.fromhex(signed_sbom['signature'])
            
            public_key.verify(
                signature_bytes,
                sbom_json.encode('utf-8'),
                padding.PSS(
                    mgf=padding.MGF1(hashes.SHA256()),
                    salt_length=padding.PSS.MAX_LENGTH
                ),
                hashes.SHA256()
            )
            
            return True
        except Exception as e:
            print(f"ç­¾åéªŒè¯å¤±è´¥: {e}")
            return False
    
    def store_sbom(self, image_digest: str, signed_sbom: Dict):
        """å­˜å‚¨SBOMåˆ°æ³¨å†Œè¡¨"""
        self.sbom_store[image_digest] = signed_sbom
        
        # åŒæ—¶å­˜å‚¨åˆ°Harbor
        sbom_url = f"{self.harbor_url}/api/v2.0/sbom/{image_digest}"
        headers = {'Content-Type': 'application/json'}
        
        try:
            response = requests.post(
                sbom_url,
                headers=headers,
                data=json.dumps(signed_sbom),
                timeout=30
            )
            if response.status_code == 201:
                print(f"SBOMå·²å­˜å‚¨: {image_digest}")
            else:
                print(f"SBOMå­˜å‚¨å¤±è´¥: {response.status_code}")
        except Exception as e:
            print(f"SBOMå­˜å‚¨å¼‚å¸¸: {e}")
    
    def retrieve_sbom(self, image_digest: str) -> Optional[Dict]:
        """æ£€ç´¢SBOM"""
        # é¦–å…ˆä»æœ¬åœ°ç¼“å­˜æŸ¥æ‰¾
        if image_digest in self.sbom_store:
            return self.sbom_store[image_digest]
        
        # ä»Harboræ£€ç´¢
        sbom_url = f"{self.harbor_url}/api/v2.0/sbom/{image_digest}"
        try:
            response = requests.get(sbom_url, timeout=30)
            if response.status_code == 200:
                sbom = response.json()
                self.sbom_store[image_digest] = sbom
                return sbom
        except Exception as e:
            print(f"SBOMæ£€ç´¢å¼‚å¸¸: {e}")
        
        return None
    
    def analyze_supply_chain_risk(self, sbom: Dict) -> Dict:
        """åˆ†æä¾›åº”é“¾é£é™©"""
        risk_analysis = {
            'total_components': len(sbom['components']),
            'vulnerable_components': [],
            'license_risks': [],
            'dependency_depth': 0,
            'risk_score': 0.0
        }
        
        # åˆ†ææ¼æ´ç»„ä»¶
        for component in sbom['components']:
            if 'vulnerabilities' in component:
                risk_analysis['vulnerable_components'].append({
                    'name': component['name'],
                    'version': component['version'],
                    'vulnerability_count': len(component['vulnerabilities'])
                })
        
        # åˆ†æè®¸å¯è¯é£é™©
        restricted_licenses = ['GPL', 'AGPL', 'LGPL']
        for component in sbom['components']:
            licenses = component.get('licenses', [])
            for license_info in licenses:
                license_name = license_info.get('license', {}).get('id', '')
                if license_name in restricted_licenses:
                    risk_analysis['license_risks'].append({
                        'component': component['name'],
                        'license': license_name,
                        'risk_level': 'high'
                    })
        
        # è®¡ç®—é£é™©è¯„åˆ†
        vulnerability_risk = len(risk_analysis['vulnerable_components']) / max(risk_analysis['total_components'], 1)
        license_risk = len(risk_analysis['license_risks']) / max(risk_analysis['total_components'], 1)
        risk_analysis['risk_score'] = round((vulnerability_risk * 0.7 + license_risk * 0.3) * 100, 2)
        
        return risk_analysis
    
    def generate_supply_chain_report(self, image_digest: str) -> Dict:
        """ç”Ÿæˆä¾›åº”é“¾å®‰å…¨æŠ¥å‘Š"""
        sbom = self.retrieve_sbom(image_digest)
        if not sbom:
            return {'error': 'SBOM not found'}
        
        risk_analysis = self.analyze_supply_chain_risk(sbom['sbom'])
        
        report = {
            'image_digest': image_digest,
            'generated_at': datetime.now().isoformat(),
            'sbom_metadata': sbom['sbom']['metadata'],
            'supply_chain_analysis': risk_analysis,
            'recommendations': self._generate_recommendations(risk_analysis)
        }
        
        return report
    
    def _generate_recommendations(self, risk_analysis: Dict) -> List[str]:
        """ç”Ÿæˆé£é™©ç¼“è§£å»ºè®®"""
        recommendations = []
        
        if risk_analysis['risk_score'] > 70:
            recommendations.append("ä¾›åº”é“¾é£é™©è¾ƒé«˜ï¼Œå»ºè®®è¿›è¡Œå…¨é¢å®‰å…¨å®¡æŸ¥")
        
        if risk_analysis['vulnerable_components']:
            recommendations.append(f"å‘ç°{len(risk_analysis['vulnerable_components'])}ä¸ªå­˜åœ¨æ¼æ´çš„ç»„ä»¶ï¼Œå»ºè®®ä¼˜å…ˆä¿®å¤")
        
        if risk_analysis['license_risks']:
            recommendations.append(f"å‘ç°{len(risk_analysis['license_risks'])}ä¸ªè®¸å¯è¯é£é™©ï¼Œå»ºè®®æ³•å¾‹åˆè§„å®¡æŸ¥")
            
        if risk_analysis['total_components'] > 100:
            recommendations.append("ç»„ä»¶æ•°é‡è¾ƒå¤šï¼Œå»ºè®®ä¼˜åŒ–ä¾èµ–å…³ç³»")
        
        return recommendations

# ä½¿ç”¨ç¤ºä¾‹
sbom_manager = SBOMSupplyChainManager(
    "https://harbor.company.internal",
    "/secure/keys/sbom-private.key"
)

# ç”ŸæˆSBOM
components = [
    {
        'name': 'express',
        'version': '4.18.2',
        'type': 'framework',
        'licenses': [{'license': {'id': 'MIT'}}],
        'dependencies': ['accepts', 'array-flatten']
    },
    {
        'name': 'lodash',
        'version': '4.17.21',
        'type': 'library',
        'licenses': [{'license': {'id': 'MIT'}}],
        'dependencies': []
    }
]

sbom = sbom_manager.generate_sbom("sha256:abcd1234...", components)
signed_sbom = sbom_manager.sign_sbom(sbom)
sbom_manager.store_sbom("sha256:abcd1234...", signed_sbom)

# ç”Ÿæˆä¾›åº”é“¾æŠ¥å‘Š
report = sbom_manager.generate_supply_chain_report("sha256:abcd1234...")
print(json.dumps(report, indent=2, ensure_ascii=False))
```

é€šè¿‡ä»¥ä¸Šä¼ä¸šçº§é•œåƒå®‰å…¨æ‰«ææ·±åº¦å®è·µï¼Œä¼ä¸šå¯ä»¥å»ºç«‹å®Œæ•´çš„å®¹å™¨é•œåƒå®‰å…¨æ²»ç†ä½“ç³»ï¼Œå®ç°ä»é•œåƒæ„å»ºã€æ‰«æã€å‡†å…¥åˆ°è¿è¡Œæ—¶ç›‘æ§çš„å…¨ç”Ÿå‘½å‘¨æœŸå®‰å…¨ç®¡ç†ã€‚